{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf59f813",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "828e5157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Pytorch pre-release version 2.1.0.dev20230307+cu118 - assuming intent to test it\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display_html, clear_output\n",
    "from itertools import chain,cycle\n",
    "from copy import deepcopy\n",
    "import urllib.request\n",
    "import transformers\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "import random \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from datasets import *\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizerFast, EncoderDecoderModel, Seq2SeqTrainingArguments, Seq2SeqTrainer, AdamW, DataCollatorForSeq2Seq\n",
    "#from allennlp_models.rc.tools import squad\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "# Display dataframes\n",
    "def display(*args,titles=cycle([''])):\n",
    "    html_str=''\n",
    "    for df,title in zip(args, chain(titles,cycle(['</br>'])) ):\n",
    "        html_str+='<th style=\"text-align:left\"><td style=\"vertical-align:top\">'\n",
    "        html_str+=f'<h4 style=\"text-align: left;\">{title}</h2>'\n",
    "        html_str+=df.to_html().replace('table','table style=\"display:inline\"')\n",
    "        html_str+='</td></th>'\n",
    "    display_html(html_str,raw=True)\n",
    "    \n",
    "# Setting seeds for reproducibility\n",
    "def set_reproducibility(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    transformers.set_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea36d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # use the GPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # use the CPU\n",
    "\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7acb7c8",
   "metadata": {},
   "source": [
    "### Dataset Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28aa7557",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownloadProgressBar(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "        \n",
    "def download_url(url, output_path):\n",
    "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
    "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
    "        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n",
    "\n",
    "def download_data(data_path, url_path, suffix):    \n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "        \n",
    "    data_path = os.path.join(data_path, f'{suffix}.json')\n",
    "\n",
    "    if not os.path.exists(data_path):\n",
    "        print(f\"Downloading CoQA {suffix} data split... (it may take a while)\")\n",
    "        download_url(url=url_path, output_path=data_path)\n",
    "        urllib.request.urlretrieve(url_path, filename=data_path)\n",
    "        print(\"Download completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e51171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "train_url = \"https://nlp.stanford.edu/data/coqa/coqa-train-v1.0.json\"\n",
    "download_data(data_path='coqa', url_path=train_url, suffix='train')\n",
    "\n",
    "# Test data\n",
    "test_url = \"https://nlp.stanford.edu/data/coqa/coqa-dev-v1.0.json\"\n",
    "download_data(data_path='coqa', url_path=test_url, suffix='test') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcc715a",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b41b63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Dataframes and removing unanswerable questions\n",
    "train_data = json.load((open('coqa/train.json')))\n",
    "test_data = json.load((open('coqa/test.json')))\n",
    "\n",
    "qas = pd.json_normalize(train_data['data'], ['questions'], ['source', 'id', 'story'])\n",
    "ans = pd.json_normalize(train_data['data'], ['answers'],['id'])\n",
    "train_val_df = pd.merge(qas,ans, left_on=['id','turn_id'], right_on=['id','turn_id'])\n",
    "train_val_df = train_val_df.loc[train_val_df['input_text_y']!='unknown']\n",
    "\n",
    "qas = pd.json_normalize(test_data['data'], ['questions'], ['source', 'id', 'story'])\n",
    "ans = pd.json_normalize(test_data['data'], ['answers'],['id'])\n",
    "test_df = pd.merge(qas,ans, left_on=['id','turn_id'], right_on=['id','turn_id'])\n",
    "test_df = test_df.loc[test_df['input_text_y']!='unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f89f8452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing bad turns\n",
    "train_val_df = train_val_df.loc[(train_val_df['bad_turn_x'] != 'True') & (train_val_df['bad_turn_y'] != 'True')]\n",
    "\n",
    "# Removing equal text/answer entries\n",
    "train_val_df = train_val_df[train_val_df.story != train_val_df.input_text_y]\n",
    "test_df = test_df[test_df.story != test_df.input_text_y]\n",
    "\n",
    "# Removing enties with empty answers\n",
    "train_val_df = train_val_df[train_val_df['input_text_y'].str.len()>0]\n",
    "test_df = test_df[test_df['input_text_y'].str.len()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e69124dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocess\n",
    "def preprocess(ds,columns):\n",
    "    ds = ds.replace(r'\\n',' ', regex=True)\n",
    "    ds = ds.replace(r'[^\\w\\s]+', '', regex=True)\n",
    "    for feature in columns:\n",
    "        ds[feature] = ds[feature].str.lower().str.strip()\n",
    "        \n",
    "    return ds\n",
    "\n",
    "columns = ['story', 'input_text_x', 'span_text', 'input_text_y']\n",
    "\n",
    "train_val_df = preprocess(train_val_df,columns)\n",
    "test_df = preprocess(test_df,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31fe6985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['input_text_x', 'turn_id', 'bad_turn_x', 'source', 'id', 'story',\n",
      "       'span_start', 'span_end', 'span_text', 'input_text_y', 'bad_turn_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Train/Validation Split\n",
    "set_reproducibility(42)\n",
    "\n",
    "train_inds, val_inds = next(GroupShuffleSplit(test_size=.20, n_splits=2, random_state = 42).split(train_val_df, groups=train_val_df['id']))\n",
    "\n",
    "train_df = train_val_df.iloc[train_inds]\n",
    "val_df = train_val_df.iloc[val_inds].reset_index()\n",
    "\n",
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18ba5d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set [(85823, 11)]\n",
      "\tFeatures: ['input_text_x', 'turn_id', 'bad_turn_x', 'source', 'id', 'story', 'span_start', 'span_end', 'span_text', 'input_text_y', 'bad_turn_y']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<th style=\"text-align:left\"><td style=\"vertical-align:top\"><h4 style=\"text-align: left;\"></h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>input_text_x</th>\n",
       "      <th>input_text_y</th>\n",
       "      <th>span_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3zotghdk5ibi9cex97fepx7jetpso7</td>\n",
       "      <td>how many items are in this secret collection</td>\n",
       "      <td>150000</td>\n",
       "      <td>vatican secret archives were separated from the library at the beginning of the 17th century they contain another 150000 items</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3zotghdk5ibi9cex97fepx7jetpso7</td>\n",
       "      <td>can anyone use this library</td>\n",
       "      <td>anyone who can document their qualifications and research needs</td>\n",
       "      <td>the vatican library is open to anyone who can document their qualifications and research needs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3zotghdk5ibi9cex97fepx7jetpso7</td>\n",
       "      <td>what must be requested in person or by mail</td>\n",
       "      <td>photocopies</td>\n",
       "      <td>photocopies for private study of pages from books published between 1801 and 1990 can be requested in person or by mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3zotghdk5ibi9cex97fepx7jetpso7</td>\n",
       "      <td>of what books</td>\n",
       "      <td>only books published between 1801 and 1990</td>\n",
       "      <td>hotocopies for private study of pages from books published between 1801 and 1990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td></th>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set [(21452, 12)]\n",
      "\tFeatures: ['index', 'input_text_x', 'turn_id', 'bad_turn_x', 'source', 'id', 'story', 'span_start', 'span_end', 'span_text', 'input_text_y', 'bad_turn_y']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<th style=\"text-align:left\"><td style=\"vertical-align:top\"><h4 style=\"text-align: left;\"></h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>input_text_x</th>\n",
       "      <th>input_text_y</th>\n",
       "      <th>span_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3bdcf01ogxu7zdn9vlrbf2rqzwplyf</td>\n",
       "      <td>where was milly led to</td>\n",
       "      <td>cottonwoods</td>\n",
       "      <td>led milly erne to cottonwoods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3bdcf01ogxu7zdn9vlrbf2rqzwplyf</td>\n",
       "      <td>who took her there</td>\n",
       "      <td>a man</td>\n",
       "      <td>the man who had led milly erne to cottonwoods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3bdcf01ogxu7zdn9vlrbf2rqzwplyf</td>\n",
       "      <td>whose name would jane not speak</td>\n",
       "      <td>this mormons name</td>\n",
       "      <td>this mormons name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3bdcf01ogxu7zdn9vlrbf2rqzwplyf</td>\n",
       "      <td>did she allow herself to even think it</td>\n",
       "      <td>no</td>\n",
       "      <td>she did not even think it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3bdcf01ogxu7zdn9vlrbf2rqzwplyf</td>\n",
       "      <td>what was jane hoping lassiter would become to her</td>\n",
       "      <td>a helper of a friend of a champion</td>\n",
       "      <td>the need of a helper of a friend of a champio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td></th>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set [(7917, 9)]\n",
      "\tFeatures: ['input_text_x', 'turn_id', 'source', 'id', 'story', 'span_start', 'span_end', 'span_text', 'input_text_y']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<th style=\"text-align:left\"><td style=\"vertical-align:top\"><h4 style=\"text-align: left;\"></h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>input_text_x</th>\n",
       "      <th>input_text_y</th>\n",
       "      <th>span_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3dr23u6we5exclen4th8uq9rb42tel</td>\n",
       "      <td>did they want cotton to change the color of her fur</td>\n",
       "      <td>no</td>\n",
       "      <td>we would never want you to be any other way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3azhrg4cu4ktme1zh7c2ro3pn2430d</td>\n",
       "      <td>what was the name of the fish</td>\n",
       "      <td>asta</td>\n",
       "      <td>asta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3azhrg4cu4ktme1zh7c2ro3pn2430d</td>\n",
       "      <td>what looked like a birds belly</td>\n",
       "      <td>a bottle</td>\n",
       "      <td>a bottle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3azhrg4cu4ktme1zh7c2ro3pn2430d</td>\n",
       "      <td>who said that</td>\n",
       "      <td>asta</td>\n",
       "      <td>it looks like a birds belly said asta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3azhrg4cu4ktme1zh7c2ro3pn2430d</td>\n",
       "      <td>was sharkie a friend</td>\n",
       "      <td>yes</td>\n",
       "      <td>astas friend sharkie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td></th>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking the Dataframes\n",
    "print(f'Training set [{train_df.shape}]')\n",
    "print(f'\\tFeatures: {list(train_df.columns)}')\n",
    "display(train_df.loc[11:15,['id', 'input_text_x', 'input_text_y', 'span_text']])\n",
    "\n",
    "print(f'Validation set [{val_df.shape}]')\n",
    "print(f'\\tFeatures: {list(val_df.columns)}')\n",
    "display(val_df.loc[11:15,['id', 'input_text_x', 'input_text_y', 'span_text']])\n",
    "\n",
    "print(f'Test set [{test_df.shape}]')\n",
    "print(f'\\tFeatures: {list(test_df.columns)}')\n",
    "display(test_df.loc[11:15,['id', 'input_text_x', 'input_text_y', 'span_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1d874e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No overlap\n"
     ]
    }
   ],
   "source": [
    "# Overlap Check\n",
    "set_train = set(train_df['id'])\n",
    "set_val = set(val_df['id'])\n",
    "\n",
    "overlap = False\n",
    "for i in set_train:\n",
    "    if i in set_val:\n",
    "        overlap = True\n",
    "        break\n",
    "\n",
    "print('Overlap' if overlap else 'No overlap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0639e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes to Datasets\n",
    "train_df_to_ds = train_df[columns]\n",
    "val_df_to_ds = val_df[columns]\n",
    "test_df_to_ds = test_df[columns]\n",
    "\n",
    "train_df_to_ds = train_df_to_ds.rename(columns={'input_text_x': 'question', 'story': 'context',\\\n",
    "                                               'input_text_y': 'answer', 'span_text': 'text'})\n",
    "val_df_to_ds = val_df_to_ds.rename(columns={'input_text_x': 'question', 'story': 'context',\\\n",
    "                                               'input_text_y': 'answer', 'span_text': 'text'})\n",
    "test_df_to_ds = test_df_to_ds.rename(columns={'input_text_x': 'question', 'story': 'context',\\\n",
    "                                               'input_text_y': 'answer', 'span_text': 'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23df73f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['context', 'question', 'text', 'answer'],\n",
      "        num_rows: 4290\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['context', 'question', 'text', 'answer'],\n",
      "        num_rows: 1068\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['context', 'question', 'text', 'answer'],\n",
      "        num_rows: 396\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Datasets Batch split\n",
    "batch_size = 6\n",
    "ratio = 5\n",
    "\n",
    "train_samples = (round(train_df_to_ds.shape[0] * ratio / 100) // batch_size) * batch_size\n",
    "\n",
    "val_samples = (round(val_df_to_ds.shape[0] * ratio / 100) // batch_size) * batch_size\n",
    "test_samples = (round(test_df_to_ds.shape[0] * ratio / 100) // batch_size) * batch_size\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_df_to_ds.iloc[:train_samples])\n",
    "val_dataset = Dataset.from_dict(val_df_to_ds.iloc[:val_samples])\n",
    "test_dataset = Dataset.from_dict(test_df_to_ds.iloc[:test_samples])\n",
    "\n",
    "dataset_COQA = DatasetDict({'train':train_dataset,'validation':val_dataset,'test':test_dataset})\n",
    "print(dataset_COQA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f42e93a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_input = 512\n",
    "max_length_answer = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3afc6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(batch, tokenizer, max_length_input, max_length_answer):\n",
    "    # Tokenize the Question and Context columns\n",
    "    encoded_batch_inputs = tokenizer(\n",
    "        batch['question'],\n",
    "        batch['context'],\n",
    "        max_length=max_length_input,\n",
    "        truncation='only_second',\n",
    "        padding='max_length',\n",
    "        return_tensors='pt'        \n",
    "    )\n",
    "\n",
    "    # Tokenize the Answer column\n",
    "    encoded_batch_labels = tokenizer(\n",
    "        batch['answer'],\n",
    "        max_length=max_length_answer,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    encoded_batch_inputs['labels'] = encoded_batch_labels.input_ids\n",
    "#   encoded_batch_inputs['decoder_input_ids'] = deepcopy(encoded_batch_inputs['labels'])\n",
    "#   encoded_batch_inputs['labels'] = [[-100 if token == tokenizer.pad_token_id else token\\\n",
    "#                                    for token in labels]\\\n",
    "#                                    for labels in encoded_batch_inputs['labels']]\n",
    "    \n",
    "    encoded_batch_inputs['labels_mask'] = encoded_batch_labels.attention_mask\n",
    "\n",
    "\n",
    "    return encoded_batch_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7555d2d6",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68ee3498",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special tokens:\n",
      "bos_token: <s>\n",
      "eos_token: </s>\n",
      "unk_token: <unk>\n",
      "sep_token: </s>\n",
      "pad_token: <pad>\n",
      "cls_token: <s>\n",
      "mask_token: <mask>\n",
      "bos_token: 0\n",
      "eos_token: 2\n",
      "unk_token: 3\n",
      "sep_token: 2\n",
      "pad_token: 1\n",
      "cls_token: 0\n",
      "mask_token: 50264\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint_M1 = 'distilroberta-base'\n",
    "# Tokenizer\n",
    "tokenizer_M1 = AutoTokenizer.from_pretrained(model_checkpoint_M1)\n",
    "assert isinstance(tokenizer_M1, PreTrainedTokenizerFast)\n",
    "tokenizer_M1.bos_token = tokenizer_M1.cls_token\n",
    "tokenizer_M1.eos_token = tokenizer_M1.sep_token\n",
    "\n",
    "# Get the special tokens and their corresponding IDs\n",
    "special_tokens = tokenizer_M1.special_tokens_map\n",
    "special_ids = tokenizer_M1.convert_tokens_to_ids(list(special_tokens.values()))\n",
    "print(\"Special tokens:\")\n",
    "for token_type, token_list in special_tokens.items():\n",
    "    print(f\"{token_type}: {token_list}\")\n",
    "# Print the special tokens and their corresponding IDs\n",
    "for token, id in zip(special_tokens.keys(), special_ids):\n",
    "    print(f\"{token}: {id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07baedb4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5724319b80c0472384085c905d4d992a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/715 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36044c5a15ba4bcc8966216198821ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d045fd0d122e41888de2803fb88f91af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels', 'labels_mask'],\n",
      "        num_rows: 4290\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels', 'labels_mask'],\n",
      "        num_rows: 1068\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels', 'labels_mask'],\n",
      "        num_rows: 396\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing the Dataset\n",
    "tokenized_datasets_M1 = DatasetDict()\n",
    "\n",
    "# Use the `prepare_features` functions\n",
    "tokenized_datasets_M1 = dataset_COQA.map(\n",
    "    lambda batch: prepare_features(batch, tokenizer_M1, max_length_input, max_length_answer),\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    remove_columns=dataset_COQA['train'].column_names\n",
    ")\n",
    "\n",
    "print(tokenized_datasets_M1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fea23c",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76094d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForCausalLM were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['roberta.encoder.layer.5.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.output.dense.bias', 'roberta.encoder.layer.1.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.output.dense.weight', 'roberta.encoder.layer.1.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.output.dense.bias', 'roberta.encoder.layer.3.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.output.dense.bias', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.self.key.bias', 'roberta.encoder.layer.0.crossattention.self.key.weight', 'roberta.encoder.layer.2.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.self.key.weight', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.output.dense.bias', 'roberta.encoder.layer.3.crossattention.self.key.weight', 'roberta.encoder.layer.4.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.output.dense.bias', 'roberta.encoder.layer.4.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.1.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.self.value.weight', 'roberta.encoder.layer.0.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.self.key.bias', 'roberta.encoder.layer.1.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.output.dense.weight', 'roberta.encoder.layer.1.crossattention.output.dense.weight', 'roberta.encoder.layer.2.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.self.query.weight', 'roberta.encoder.layer.3.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.self.value.weight', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.3.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.4.crossattention.self.key.weight', 'roberta.encoder.layer.4.crossattention.self.value.weight', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.output.dense.weight', 'roberta.encoder.layer.1.crossattention.self.key.weight', 'roberta.encoder.layer.2.crossattention.self.value.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters #: 178472025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EncoderDecoderModel(\n",
       "  (encoder): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): RobertaForCausalLM(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-5): 6 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (lm_head): RobertaLMHead(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Model\n",
    "model_M1 = EncoderDecoderModel.from_encoder_decoder_pretrained(model_checkpoint_M1, model_checkpoint_M1, tie_encoder_decoder=False)\n",
    "\n",
    "# Model special tokens\n",
    "model_M1.config.decoder_start_token_id = tokenizer_M1.cls_token_id\n",
    "model_M1.config_eos_token_id = tokenizer_M1.sep_token_id\n",
    "model_M1.config.pad_token_id = tokenizer_M1.pad_token_id\n",
    "model_M1.config.vocab_size = model_M1.config.encoder.vocab_size\n",
    "\n",
    "# Model hyperparams\n",
    "model_M1.config.max_length = max_length_answer\n",
    "model_M1.config.min_length = 1\n",
    "model_M1.config.no_repeat_ngram_size = 1\n",
    "model_M1.config.early_stopping = True\n",
    "model_M1.config.repetition_penalty= 3.\n",
    "model_M1.config.num_beams = 8\n",
    "\n",
    "print(f\"Parameters #: {model_M1.num_parameters()}\")\n",
    "\n",
    "model_M1.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cb2ca5",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b9b8dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\the_s\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "training_args_M1 = Seq2SeqTrainingArguments(\n",
    "    output_dir='./M1_Checkpoints',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    predict_with_generate=True,\n",
    "    overwrite_output_dir=True,\n",
    "    #save_total_limit=2,\n",
    "    fp16=True, \n",
    "    num_train_epochs = 3,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10\n",
    "    #resume_from_checkpoint = True\n",
    ")\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer_M1 = AdamW(model_M1.parameters(),lr= 3e-5)\n",
    "scheduler_M1 = transformers.get_cosine_schedule_with_warmup(optimizer=optimizer_M1,num_warmup_steps=50,num_training_steps=batch_size*3)\n",
    "optimizers_M1 = optimizer_M1, scheduler_M1\n",
    "\n",
    "trainer_M1 = Seq2SeqTrainer(\n",
    "    model=model_M1,\n",
    "    tokenizer=tokenizer_M1,\n",
    "    args=training_args_M1,\n",
    "    #compute_metrics=compute_metrics,\n",
    "    train_dataset=tokenized_datasets_M1['train'],\n",
    "    eval_dataset=tokenized_datasets_M1['validation'],\n",
    "    optimizers=optimizers_M1,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer_M1,model=model_M1)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "356f4b1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `EncoderDecoderModel.forward` and have been ignored: labels_mask. If labels_mask are not expected by `EncoderDecoderModel.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 4290\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 6\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 6\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2145\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\the_s\\anaconda3\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:533: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2145' max='2145' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2145/2145 06:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.897400</td>\n",
       "      <td>0.619040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.617100</td>\n",
       "      <td>0.591110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.529200</td>\n",
       "      <td>0.585791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./M1_Checkpoints\\checkpoint-500\n",
      "Configuration saved in ./M1_Checkpoints\\checkpoint-500\\config.json\n",
      "Model weights saved in ./M1_Checkpoints\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in ./M1_Checkpoints\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in ./M1_Checkpoints\\checkpoint-500\\special_tokens_map.json\n",
      "C:\\Users\\the_s\\anaconda3\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:533: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "The following columns in the evaluation set don't have a corresponding argument in `EncoderDecoderModel.forward` and have been ignored: labels_mask. If labels_mask are not expected by `EncoderDecoderModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1068\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to ./M1_Checkpoints\\checkpoint-1000\n",
      "Configuration saved in ./M1_Checkpoints\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./M1_Checkpoints\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in ./M1_Checkpoints\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in ./M1_Checkpoints\\checkpoint-1000\\special_tokens_map.json\n",
      "C:\\Users\\the_s\\anaconda3\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:533: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "The following columns in the evaluation set don't have a corresponding argument in `EncoderDecoderModel.forward` and have been ignored: labels_mask. If labels_mask are not expected by `EncoderDecoderModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1068\n",
      "  Batch size = 6\n",
      "Saving model checkpoint to ./M1_Checkpoints\\checkpoint-1500\n",
      "Configuration saved in ./M1_Checkpoints\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./M1_Checkpoints\\checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in ./M1_Checkpoints\\checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in ./M1_Checkpoints\\checkpoint-1500\\special_tokens_map.json\n",
      "C:\\Users\\the_s\\anaconda3\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:533: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "Saving model checkpoint to ./M1_Checkpoints\\checkpoint-2000\n",
      "Configuration saved in ./M1_Checkpoints\\checkpoint-2000\\config.json\n",
      "Model weights saved in ./M1_Checkpoints\\checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in ./M1_Checkpoints\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in ./M1_Checkpoints\\checkpoint-2000\\special_tokens_map.json\n",
      "C:\\Users\\the_s\\anaconda3\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:533: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "The following columns in the evaluation set don't have a corresponding argument in `EncoderDecoderModel.forward` and have been ignored: labels_mask. If labels_mask are not expected by `EncoderDecoderModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1068\n",
      "  Batch size = 6\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2145, training_loss=0.857137624922888, metrics={'train_runtime': 374.3601, 'train_samples_per_second': 34.379, 'train_steps_per_second': 5.73, 'total_flos': 3972402192844800.0, 'train_loss': 0.857137624922888, 'epoch': 3.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "trainer_M1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7002c535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels', 'labels_mask'],\n",
       "    num_rows: 396\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets_M1['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c4cf641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▎                                                                                 | 1/66 [00:00<00:39,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he he was to a the him', 'he it was to a the his him', 'he he was to a the him', 'he it was to a the his him', 'he it was to a the his him']\n",
      "True ans: ['white', 'in a barn', 'no', 'with her mommy and 5 sisters', 'orange and white', 'no']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▌                                                                                | 2/66 [00:00<00:26,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he he was to a the him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him']\n",
      "True ans: ['she painted herself', 'the farmer', 'they started laughing', 'a bucket of water', 'licked her face', 'no']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███▊                                                                               | 3/66 [00:01<00:21,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him']\n",
      "True ans: ['asta', 'a bottle', 'asta', 'yes', 'yes', 'a note']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|█████                                                                              | 4/66 [00:01<00:19,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he he was to a the him']\n",
      "True ans: ['no', 'astas papa', 'yes', 'an elderly chinese lady and a little boy', 'yes', 'a paper carrier bag']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▎                                                                            | 5/66 [00:01<00:18,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he it was to a the his him', 'he he was to a the him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him']\n",
      "True ans: ['yes', 'nicole', 'shanghai', 'mother', 'food', 'yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████▌                                                                           | 6/66 [00:01<00:17,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him']\n",
      "True ans: ['i am having heart surgery soon so her mother has decided i need more nutrients', 'an ipad', 'hot soup and a container with rice vegetables and either chicken meat or shrimp sometimes with a kind of pancake', 'i am now working on some more chinese words', 'yes', 'thank you']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████████▊                                                                          | 7/66 [00:02<00:16,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he was a the one to his her', 'he was a the one to his her', 'he was a the one to his her', 'he was a the one to his her', 'he was a the one to his her', 'he was a the one to his her']\n",
      "True ans: ['yes', 'dennis farina', 'actor', 'no', 'yes', 'no']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|██████████                                                                         | 8/66 [00:02<00:16,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he was a the one to his her', 'he was a the one to his her', 'he was a the one to his her', 'he was a the one to his her', 'he was a the one to his her', 'he was a the one to his her']\n",
      "True ans: ['farina was cast in a film', 'michael mann', 'thief', 'cops or gangsters', 'he joined a tv show cast', 'law  order']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▎                                                                       | 9/66 [00:02<00:16,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he was a the one to his her', 'he was a the one to his her', 'he was a the one to his her', 'he was a the one to his her', 'he was a the one to his her', 'he was a the one to his her']\n",
      "True ans: ['detective joe fontana', 'no', 'an expensive car', 'no', 'flashy', 'no']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▍                                                                     | 10/66 [00:03<00:15,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he was a the one to his her', 'he was a the one to his her', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him']\n",
      "True ans: ['no', 'a cop', 'school', 'no', 'go to quentins house', 'no']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████▋                                                                    | 11/66 [00:03<00:15,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him']\n",
      "True ans: ['no', 'story time', 'right before bedtime', 'no one answered', 'no', 'no']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▉                                                                   | 12/66 [00:03<00:14,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him']\n",
      "True ans: ['that she was upset', 'yes', 'everything would be okay', 'her teacher', 'no', 'quintons mother']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▏                                                                 | 13/66 [00:03<00:14,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he it was to a the his him', 'he was a the east of west', 'he was a the east of west', 'he was a the east of west', 'he was a the east of west']\n",
      "True ans: ['to the dentist', 'yes', 'five', 'new york city', 'new york', 'yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|█████████████████▍                                                                | 14/66 [00:04<00:13,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he was a the east of west', 'he was a the east of west', 'he was a the east of west', 'he was a the east of west', 'he was a the east of west', 'he was a the east of west']\n",
      "True ans: ['in the southwest of the city', 'arthur kill and the kill van kull', '476015', 'no', 'nonhispanic white', 'the forgotten borough']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▋                                                               | 15/66 [00:04<00:13,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he was a the east of west', 'he was a the east of west', 'he was a the east of west', 'he he was to the a his him', 'he he was to the a his him', 'he he was to the a his him']\n",
      "True ans: ['because the inhabitants feel neglected by the city government', 'north shore', 'st george tompkinsville clifton and stapleton', 'five in the morning', 'weather forecast', 'yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▉                                                              | 16/66 [00:04<00:13,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he he was to his a the him', 'he he was to the a his him', 'he he was to the a his him', 'he he was to his a the him', 'he he was to his a the him', 'he he was to the a his him']\n",
      "True ans: ['firefighter', 'yes', 'flashlight', 'rj', 'joel', 'glass wood plaster and maybe the washing machine']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████                                                             | 17/66 [00:04<00:13,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he he was to the a his him', 'he he was to his a the him', 'he he was to his a the him', 'he was a the east of her to his their', 'he was a the west of her to his their', 'he was a the west of her to his their']\n",
      "True ans: ['no', 'eppes', 'the flashlight', 'gary giordano', 'gaithersburg', 'montgomery county']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██████████████████████▎                                                           | 18/66 [00:05<00:13,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he was a the east of her to his their', 'he was a the west of her to his their', 'he was a the her to his one', 'he was a the her to his one', 'he was a the east of her to his their', 'he was a the east of her to his their']\n",
      "True ans: ['maryland', 'aruban jail', 'suspect in the recent disappearance of an american woman', 'fbi', '15', 'aruban solicitor general taco stein']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|███████████████████████▌                                                          | 19/66 [00:05<00:13,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he was a the east of her to his their', 'he was a the her to his one', 'he was a the west of her to his their', 'he was a the west of her to his their', 'he was a the her to his one', 'he was a the west of her to his their']\n",
      "True ans: ['monday', 'at least eight more days', 'robyn gardne', 'ast seen near baby beach', 'snorkeling', 'giordano']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▊                                                         | 20/66 [00:05<00:13,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he was a the her to his one', 'he was a the her to his one', 'he was a the her to his one', 'he was a the her to his one', 'he was a the her to his one', 'he it was to the a one']\n",
      "True ans: ['no gardner was nowhere to be found', 'locals say is not a popular snorkeling spot', '50', 'august 5', '2 giordano told authorities that he had been snorkeling with gardner', 'great britain']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|██████████████████████████                                                        | 21/66 [00:06<00:12,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to his a the her', 'he it was to the a one', 'he it was to the a one', 'he it was to the a one', 'he it was to the a one', 'he it was to a his the her']\n",
      "True ans: ['india', 'may be 30 feet tall', 'prune it', 'may prevent heart disease', 'by accident', 'shen nong']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███████████████████████████▎                                                      | 22/66 [00:06<00:12,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a his the her', 'he it was to his a the her', 'he it was to a the one of his her', 'he it was to a the one of his her', 'he it was to a the his her of one', 'he it was to a the his her of one']\n",
      "True ans: ['about 2737 bc', 'yes', 'der spiegel', 'germany', 'posing over the bodies of dead afghans', 'bloody']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████▌                                                     | 23/66 [00:06<00:12,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his her of one', 'he it was to a the one of his her', 'he it was to a the his her of one', 'he it was to a the his her of one', 'he it was to a the one of his her', 'he it was to a the one of his her']\n",
      "True ans: ['propped up back to back', 'military vehicle', 'taking or retaining individual souvenirs or trophies', 'jeremy morlock', 'pfc andrew holmes', 'holmes is charged with the premeditated deaths of three civilians']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▊                                                    | 24/66 [00:07<00:12,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he was a the one to her in his', 'he it was is to a the one of her', 'he it was is to a the one of her', 'he was a the one to her in his', 'he it was is to a the one of her', 'he it was is to a the one of her']\n",
      "True ans: ['floyd mayweather and manny pacquiao', '1 is the money man', 'tbe', 'the best ever', 'the money team', 'a boxing promoter']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███████████████████████████████                                                   | 25/66 [00:07<00:12,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was is to a the one of her', 'he it was is to a the one of her', 'he it was is to a the one of her', 'he it was is to a the one of her', 'paper of the a information to their food', 'paper of the a research and computer']\n",
      "True ans: ['over 45 boxers', '300 million pending viewership numbers', '38', 'just that it has bible references and shows him enjoying gose singing with his wife', 'oclc', 'online computer library center']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|████████████████████████████████▎                                                 | 26/66 [00:07<00:11,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['paper of the a information to their food', 'paper of the a information to their food', 'paper of the a twenty century', 'paper of the a information to their food', 'paper of the a research and computer', 'paper of the a research and computer']\n",
      "True ans: ['1967', 'yes', 'ohio', 'ohio state university', 'frederick g kilgour', 'he is not']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|█████████████████████████████████▌                                                | 27/66 [00:07<00:11,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['paper of the a research and computer', 'paper of the a information to their food', 'paper of the a information to their food', 'paper of the a twenty century', 'paper of the a information to their 2020', 'paper of the a twenty century']\n",
      "True ans: ['medical school librarian', 'worldcat', 'july 5 1967', 'ohio state university', 'alden library', 'ohio university']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|██████████████████████████████████▊                                               | 28/66 [00:08<00:10,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['paper of the a information to their food', 'paper of the a research and computer', 'paper of the a research and computer', 'he heard to a the his her', 'he heard to a the her', 'he heard to a the her']\n",
      "True ans: ['online cataloging', 'august 26 1971', 'no', 'no', 'they bought flowers', 'its 15']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████████████████████████████████████                                              | 29/66 [00:08<00:10,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he heard to a the his her', 'he heard to a the her', 'he heard to a the her', 'he heard to a the her', 'he heard to a the her', 'he heard to a the her']\n",
      "True ans: ['no', 'it doesnt look good', 'summer', '15', 'no', 'a pen']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|█████████████████████████████████████▎                                            | 30/66 [00:08<00:09,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he heard to a the his her', 'he heard to a the her', 'he heard to a the her', 'he he was to a the his him', 'he he was to his a the him', 'he he was to a the his him']\n",
      "True ans: ['she already has two blouses', 'mothers birthday', 'at least 500', 'by a big lake by the woods', 'mice', 'toy boats']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|██████████████████████████████████████▌                                           | 31/66 [00:08<00:09,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he he was to a the his him', 'he he was to his a the him', 'he he was to a the his him', 'he he was to a the his him', 'he he was to a the his him', 'he he was to his a the him']\n",
      "True ans: ['yes', 'mary and steve', 'his house', 'climbed on', 'swimming and splashing', 'threw a ball into the water']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|███████████████████████████████████████▊                                          | 32/66 [00:09<00:09,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he he was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his her', 'he it was to a the his him', 'he it was to a the his him']\n",
      "True ans: ['got very wet', 'the hospital had been bombed', 'no', 'germany', 'eastern germany at the time of his hospital stay', 'western germany']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 33/66 [00:09<00:09,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him']\n",
      "True ans: ['no', 'yes', 'no', 'no just guessed', 'hans settled down in a village fifty miles away', 'yes for twenty years']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|██████████████████████████████████████████▏                                       | 34/66 [00:09<00:08,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him']\n",
      "True ans: ['a workman', 'yes', 'hans bussman', 'yes franz does', 'no', 'he assumed hans was dead']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|███████████████████████████████████████████▍                                      | 35/66 [00:10<00:08,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he he was to a his the her', 'he it was to a the his him', 'he it was to a the his him', 'he he was to a his the her', 'he he was to a his the her', 'he he was to a his the her']\n",
      "True ans: ['mrs bussman', 'franz laughed at the idea', 'no', 'the _ariel_', 'lagoon', 'no']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|████████████████████████████████████████████▋                                     | 36/66 [00:10<00:09,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he he was to a his the her', 'he he was to a his the her', 'he he was to a his the her', 'he he was to a his the her', 'he he was to a his the her', 'he he was to a his the her']\n",
      "True ans: ['winters', 'no', 'no', 'malaita', 'harley kennan', 'villa']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████████████████████████████████████████████▉                                    | 37/66 [00:10<00:08,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he he was to a the his her', 'he he was to a the his her', 'he he was to a his the her', 'he he was to a his the her', 'he he was to a his the her', 'he he was to a his the her']\n",
      "True ans: ['the arangi', 'until they get back to tulagi', 'harley kennan', 'no', 'mrs riggs', 'topsy']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|███████████████████████████████████████████████▏                                  | 38/66 [00:10<00:08,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he he was to a his the her', 'he he was to a his the her', 'he he was to a his the her', 'he he was to a his the her', 'he it was to a the his him', 'he it was to a the his him']\n",
      "True ans: ['mademoiselle de maupin', 'no', 'yes', 'every walled inlet of the outer reef and every mangrove swamp of the mainland that looked promising of cannibal life', 'brownie and spotty', 'every day']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|████████████████████████████████████████████████▍                                 | 39/66 [00:11<00:08,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him']\n",
      "True ans: ['loved each other', 'worn a path through the grass of the field', 'ted', 'brownie', 'yes', 'yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|█████████████████████████████████████████████████▋                                | 40/66 [00:11<00:08,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him']\n",
      "True ans: ['a spot half a mile from the house', 'brought him food', 'protect him from other dangers', 'keep his spirits up', 'yes', 'spotty followed ted about barking insistently']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████████████████████████████████████████████████▉                               | 41/66 [00:12<00:08,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him']\n",
      "True ans: ['yes', 'yes', 'no', 'yes they went looking for him with no success', 'no', 'they were busy with their own lives']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|████████████████████████████████████████████████████▏                             | 42/66 [00:12<00:07,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him']\n",
      "True ans: ['follow me its urgent', 'a girl and a dog', 'set on on a trip', 'the woods', 'scared', 'he wasnt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|█████████████████████████████████████████████████████▍                            | 43/66 [00:12<00:07,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him']\n",
      "True ans: ['he was interested', 'what was in the bushes', 'a bear', 'rested in the bushes', 'not really', 'surprised']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████████████████████████████▋                           | 44/66 [00:12<00:07,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him']\n",
      "True ans: ['not surprised', 'looked at the girl', 'he smiled', 'no', 'no one', 'no']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|███████████████████████████████████████████████████████▉                          | 45/66 [00:13<00:06,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to his a the her', 'he it was to a the him', 'he it was to his a the her']\n",
      "True ans: ['dark and cold', 'yes', 'no', '10yearold boy fatally shot his father', 'in the front seat of a suv', 'no']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████████████▏                        | 46/66 [00:13<00:06,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to his a the her', 'he it was to his a the her', 'he it was to a the him', 'he it was to a the him', 'he it was to his a the her', 'he it was to his a the her']\n",
      "True ans: ['outside the home of lohstrohs exwife', 'friday', '3pm', 'belonged to the boys mother', 'he exited the back of the vehicle and continued to fire at the car', 'no']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|██████████████████████████████████████████████████████████▍                       | 47/66 [00:13<00:06,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the him', 'he it was to his a the her', 'he it was to his a the her', 'he it was to a the him', 'he it was to the her of a his', 'he it was to the her of a his']\n",
      "True ans: ['at the university of texas medical branch', 'inside the house', 'yes', 'the 7yearold', 'fra girolamo', 'no']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████████████████████████████████████████████████████████▋                      | 48/66 [00:14<00:05,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to the her of a his', 'he it was to the her of a his', 'he it was to the her of a his', 'he it was to the her of a his', 'he it was to the her of a his', 'he it was to the her of a his']\n",
      "True ans: ['no', 'romola', 'in the duomo', 'june', 'for some weeks', 'a sign from baldassarre']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|████████████████████████████████████████████████████████████▉                     | 49/66 [00:14<00:05,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to the her of a his', 'he it was to the her of a his', 'he it was to the her of a his', 'he it was to the her of a his', 'he it was to a the his him', 'he it was to a the his him']\n",
      "True ans: ['sympathy with savonarola', 'plague', 'the frate', 'no', 'yes', 'to utah']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|██████████████████████████████████████████████████████████████                    | 50/66 [00:14<00:05,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him']\n",
      "True ans: ['in seattle', 'no', 'in a small apartment', 'no', 'her friends', 'yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████████████████████████████████████████████████████████████▎                  | 51/66 [00:15<00:04,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him']\n",
      "True ans: ['two', 'the large truck', 'jennys mom', 'yes', 'yummy fast food', 'she loved it']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|████████████████████████████████████████████████████████████████▌                 | 52/66 [00:15<00:04,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the one of her', 'he it was to a the one of her']\n",
      "True ans: ['a knock at the door', 'a little girl', 'to play with jenny', 'she liked it', 'she  fell on a beginners slope', 'skiing']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████████████▊                | 53/66 [00:15<00:03,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he was a the one to his her', 'he it was to a the one of her', 'he it was to a the one of her', 'he it was to a the one of her', 'he it was to a the one of her', 'he it was to a the one of her']\n",
      "True ans: ['canada', 'yes', 'she did not', 'about an hour', 'she did not show signs', 'a local hospital']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|███████████████████████████████████████████████████████████████████               | 54/66 [00:16<00:03,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he was a the one to his her', 'he it was to a the one of her', 'he it was to a the one of her', 'he it was to a the one of her', 'he it was to a the one of her', 'he it was to a the one of her']\n",
      "True ans: ['hopital du sacrecoeur', 'new york city', 'she was 45', 'a film star', 'yes', 'liam neeson']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████████████████████████████████████████████████████████████████▎             | 55/66 [00:16<00:03,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the one of her', 'he it was to a the one of her', 'he it was to a the one of her', 'he it was to a the one of her', 'he it was to a the one of her', 'he it was to a the one of her']\n",
      "True ans: ['yes', 'sons', 'yes', 'tony', 'yes', 'acting']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|█████████████████████████████████████████████████████████████████████▌            | 56/66 [00:16<00:02,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him']\n",
      "True ans: ['bark', 'three months', 'no', 'sammie', 'golden puppy', 'no']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|██████████████████████████████████████████████████████████████████████▊           | 57/66 [00:16<00:02,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him']\n",
      "True ans: ['tired', 'no', 'peter', 'find a person', 'no', 'sleep']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████████████████████████████████████████████████████████████████████          | 58/66 [00:17<00:02,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him']\n",
      "True ans: ['an alien dog', 'false', 'three', 'ti dicky and cj7', 'no', 'a movie']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|█████████████████████████████████████████████████████████████████████████▎        | 59/66 [00:17<00:02,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him']\n",
      "True ans: ['no', 'china', 'ti and his son', 'no', 'a doll', 'false']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|██████████████████████████████████████████████████████████████████████████▌       | 60/66 [00:17<00:01,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him', 'he it was to a the his him']\n",
      "True ans: ['around his neck', 'no', 'it can talk and do magic', 'no', 'he found it in the trash', 'january']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|███████████████████████████████████████████████████████████████████████████▊      | 61/66 [00:18<00:01,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to a the his him', 'he it was to his a the her', 'he it was to his a the her', 'he it was to his a the her', 'he it was to his a the her', 'he it was to his a the her']\n",
      "True ans: ['2008', 'artsandcrafts', 'recipes', 'heather neroy', 'southern california', 'shes a stayathome mom']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████████████████████████████████████████████████████████████████████████     | 62/66 [00:18<00:01,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to his a the her', 'he it was to his a the her', 'he it was to his a the her', 'he it was to his a the her', 'he it was to his a the her', 'he it was to his a the her']\n",
      "True ans: ['by copying the link', 'emailing it to herself', 'no', 'pinterest', 'no', 'yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|██████████████████████████████████████████████████████████████████████████████▎   | 63/66 [00:18<00:00,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to his a the her', 'he it was to his a the her', 'he it was to his a the her', 'he it was to his a the her', 'he it was to his a the her', 'he it was to his a the her']\n",
      "True ans: ['the filing system', 'a halloween board', 'a shared color board', 'redecorating her daughters bedroom', 'follow others boards', 'repin another persons images']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|███████████████████████████████████████████████████████████████████████████████▌  | 64/66 [00:19<00:00,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he it was to his a the her', 'he it was to his a the her', 'he it was to his a the her', 'he he was to his a the him', 'he he was to his a the him', 'he he was to his a the him']\n",
      "True ans: ['yes', 'as neat', 'yes', 'sir earl', 'archies traces', 'makes him impatient to go forward']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|████████████████████████████████████████████████████████████████████████████████▊ | 65/66 [00:19<00:00,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he he was to his a the him', 'he he was to his a the him', 'he he was to his a the him', 'he he was to his a the him', 'he he was to his a the him', 'he he was to his a the him']\n",
      "True ans: ['yes', 'orders', '3 days', 'search for bruce', 'with the hound with the earl and a large party of menatarms', 'a traitor']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 66/66 [00:19<00:00,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated ans: ['he he was to his a the him', 'he he was to his a the him', 'he he was to his a the him', 'he he was to his a the him', 'he he was to his a the him', 'he he was to his a the him']\n",
      "True ans: ['where bruce slept', 'reluctant', 'hector', 'yes', 'no', 'by foot']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the data collator\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer_M1, model=model_M1)\n",
    "\n",
    "# Create a DataLoader for your dataset using the data collator\n",
    "test_loader = torch.utils.data.DataLoader(tokenized_datasets_M1['test'], \n",
    "                                          batch_size=batch_size, \n",
    "                                          collate_fn=data_collator)\n",
    "for batch in tqdm(test_loader):\n",
    "    example = batch['input_ids'].to(device)\n",
    "    att_mask = batch['attention_mask'].to(device)\n",
    "    generated_ids = model_M1.generate(input_ids=example, \n",
    "                                      attention_mask=att_mask,\n",
    "                                      max_length=max_length_answer)\n",
    "    generated_answers = tokenizer_M1.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "    print(f'Generated ans: {generated_answers}')\n",
    "    true = batch[\"labels\"]\n",
    "    ground_truth = tokenizer_M1.batch_decode(true, skip_special_tokens=True)\n",
    "    print(f'True ans: {ground_truth}')\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d7c313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
