{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf59f813",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "828e5157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Pytorch pre-release version 2.1.0.dev20230307+cu118 - assuming intent to test it\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display_html, clear_output\n",
    "from itertools import chain,cycle\n",
    "from copy import deepcopy\n",
    "import urllib.request\n",
    "import transformers\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "import random \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from datasets import *\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizerFast, EncoderDecoderModel, Seq2SeqTrainingArguments, Seq2SeqTrainer, AdamW, DataCollatorForSeq2Seq\n",
    "#from allennlp_models.rc.tools import squad\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "# Display dataframes\n",
    "def display(*args,titles=cycle([''])):\n",
    "    html_str=''\n",
    "    for df,title in zip(args, chain(titles,cycle(['</br>'])) ):\n",
    "        html_str+='<th style=\"text-align:left\"><td style=\"vertical-align:top\">'\n",
    "        html_str+=f'<h4 style=\"text-align: left;\">{title}</h2>'\n",
    "        html_str+=df.to_html().replace('table','table style=\"display:inline\"')\n",
    "        html_str+='</td></th>'\n",
    "    display_html(html_str,raw=True)\n",
    "    \n",
    "# Setting seeds for reproducibility\n",
    "def set_reproducibility(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    transformers.set_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea36d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # use the GPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # use the CPU\n",
    "\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b86cefa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions taken from [the official evaluation script]\n",
    "(https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob/)\n",
    "for SQuAD version 2.0.\n",
    "\"\"\"\n",
    "import collections\n",
    "import re\n",
    "import string\n",
    "from typing import Callable, Sequence, TypeVar, Tuple\n",
    "\n",
    "\n",
    "def make_qid_to_has_ans(dataset):\n",
    "    qid_to_has_ans = {}\n",
    "    for article in dataset:\n",
    "        for p in article[\"paragraphs\"]:\n",
    "            for qa in p[\"qas\"]:\n",
    "                qid_to_has_ans[qa[\"id\"]] = bool(qa[\"answers\"])\n",
    "    return qid_to_has_ans\n",
    "\n",
    "\n",
    "def normalize_answer(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        return re.sub(regex, \" \", text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return \" \".join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return \"\".join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "\n",
    "def get_tokens(s):\n",
    "    if not s:\n",
    "        return []\n",
    "    return normalize_answer(s).split()\n",
    "\n",
    "\n",
    "def compute_exact(a_pred: str, a_gold: str) -> int:\n",
    "    return int(normalize_answer(a_pred) == normalize_answer(a_gold))\n",
    "\n",
    "\n",
    "def compute_f1(a_pred: str, a_gold: str) -> float:\n",
    "    pred_toks = get_tokens(a_pred)\n",
    "    gold_toks = get_tokens(a_gold)\n",
    "    common = collections.Counter(pred_toks) & collections.Counter(gold_toks)  # type: ignore[var-annotated]\n",
    "    num_same = sum(common.values())\n",
    "    if len(pred_toks) == 0 or len(gold_toks) == 0:\n",
    "        # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n",
    "        return float(pred_toks == gold_toks)\n",
    "    if num_same == 0:\n",
    "        return 0.0\n",
    "    precision = 1.0 * num_same / len(pred_toks)\n",
    "    recall = 1.0 * num_same / len(gold_toks)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "\n",
    "_P = TypeVar(\"_P\")\n",
    "_G = TypeVar(\"_G\")\n",
    "_T = TypeVar(\"_T\", int, float, Tuple[int, ...], Tuple[float, ...])\n",
    "\n",
    "\n",
    "def metric_max_over_ground_truths(\n",
    "    metric_fn: Callable[[_P, _G], _T], prediction: _P, ground_truths: Sequence[_G]\n",
    ") -> _T:\n",
    "    scores_for_ground_truths = []\n",
    "    for ground_truth in ground_truths:\n",
    "        score = metric_fn(prediction, ground_truth)\n",
    "        scores_for_ground_truths.append(score)\n",
    "    return max(scores_for_ground_truths)\n",
    "\n",
    "\n",
    "def get_metric_score(prediction: str, gold_answers: Sequence[str]) -> Tuple[int, float]:\n",
    "    exact_scores = metric_max_over_ground_truths(compute_exact, prediction, gold_answers)\n",
    "    f1_scores = metric_max_over_ground_truths(compute_f1, prediction, gold_answers)\n",
    "    return exact_scores, f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469168e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tokens(tokenizer):\n",
    "    # Get the special tokens and their corresponding IDs\n",
    "    special_tokens = tokenizer.special_tokens_map\n",
    "    special_ids = tokenizer.convert_tokens_to_ids(list(special_tokens.values()))\n",
    "    print(\"Special tokens:\")\n",
    "    for token_type, token_list in special_tokens.items():\n",
    "        print(f\"{token_type}: {token_list}\")\n",
    "    # Print the special tokens and their corresponding IDs\n",
    "    for token, id in zip(special_tokens.keys(), special_ids):\n",
    "        print(f\"{token}: {id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7acb7c8",
   "metadata": {},
   "source": [
    "### Dataset Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28aa7557",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownloadProgressBar(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "        \n",
    "def download_url(url, output_path):\n",
    "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
    "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
    "        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n",
    "\n",
    "def download_data(data_path, url_path, suffix):    \n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "        \n",
    "    data_path = os.path.join(data_path, f'{suffix}.json')\n",
    "\n",
    "    if not os.path.exists(data_path):\n",
    "        print(f\"Downloading CoQA {suffix} data split... (it may take a while)\")\n",
    "        download_url(url=url_path, output_path=data_path)\n",
    "        urllib.request.urlretrieve(url_path, filename=data_path)\n",
    "        print(\"Download completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20e51171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "train_url = \"https://nlp.stanford.edu/data/coqa/coqa-train-v1.0.json\"\n",
    "download_data(data_path='coqa', url_path=train_url, suffix='train')\n",
    "\n",
    "# Test data\n",
    "test_url = \"https://nlp.stanford.edu/data/coqa/coqa-dev-v1.0.json\"\n",
    "download_data(data_path='coqa', url_path=test_url, suffix='test') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcc715a",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b41b63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Dataframes and removing unanswerable questions\n",
    "train_data = json.load((open('coqa/train.json')))\n",
    "test_data = json.load((open('coqa/test.json')))\n",
    "\n",
    "qas = pd.json_normalize(train_data['data'], ['questions'], ['source', 'id', 'story'])\n",
    "ans = pd.json_normalize(train_data['data'], ['answers'],['id'])\n",
    "train_val_df = pd.merge(qas,ans, left_on=['id','turn_id'], right_on=['id','turn_id'])\n",
    "train_val_df = train_val_df.loc[train_val_df['input_text_y']!='unknown']\n",
    "\n",
    "qas = pd.json_normalize(test_data['data'], ['questions'], ['source', 'id', 'story'])\n",
    "ans = pd.json_normalize(test_data['data'], ['answers'],['id'])\n",
    "test_df = pd.merge(qas,ans, left_on=['id','turn_id'], right_on=['id','turn_id'])\n",
    "test_df = test_df.loc[test_df['input_text_y']!='unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f89f8452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing bad turns\n",
    "train_val_df = train_val_df.loc[(train_val_df['bad_turn_x'] != 'True') & (train_val_df['bad_turn_y'] != 'True')]\n",
    "\n",
    "# Removing equal text/answer entries\n",
    "train_val_df = train_val_df[train_val_df.story != train_val_df.input_text_y]\n",
    "test_df = test_df[test_df.story != test_df.input_text_y]\n",
    "\n",
    "# Removing enties with empty answers\n",
    "train_val_df = train_val_df[train_val_df['input_text_y'].str.len()>0]\n",
    "test_df = test_df[test_df['input_text_y'].str.len()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e69124dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocess\n",
    "def preprocess(ds,columns):\n",
    "    ds = ds.replace(r'\\n',' ', regex=True)\n",
    "#     ds = ds.replace(r'[^\\w\\s]+', ' ', regex=True)\n",
    "#     for feature in columns:\n",
    "#         ds[feature] = ds[feature].str.lower().str.strip()\n",
    "        \n",
    "    return ds\n",
    "\n",
    "columns = ['story', 'input_text_x', 'span_text', 'input_text_y']\n",
    "\n",
    "train_val_df = preprocess(train_val_df,columns)\n",
    "test_df = preprocess(test_df,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31fe6985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['input_text_x', 'turn_id', 'bad_turn_x', 'source', 'id', 'story',\n",
      "       'span_start', 'span_end', 'span_text', 'input_text_y', 'bad_turn_y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Train/Validation Split\n",
    "set_reproducibility(42)\n",
    "\n",
    "train_inds, val_inds = next(GroupShuffleSplit(test_size=.20, n_splits=2, random_state = 42).split(train_val_df, groups=train_val_df['id']))\n",
    "\n",
    "train_df = train_val_df.iloc[train_inds]\n",
    "val_df = train_val_df.iloc[val_inds].reset_index()\n",
    "\n",
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18ba5d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set [(85823, 11)]\n",
      "\tFeatures: ['input_text_x', 'turn_id', 'bad_turn_x', 'source', 'id', 'story', 'span_start', 'span_end', 'span_text', 'input_text_y', 'bad_turn_y']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<th style=\"text-align:left\"><td style=\"vertical-align:top\"><h4 style=\"text-align: left;\"></h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>input_text_x</th>\n",
       "      <th>input_text_y</th>\n",
       "      <th>span_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3zotghdk5ibi9cex97fepx7jetpso7</td>\n",
       "      <td>how many items are in this secret collection?</td>\n",
       "      <td>150,000</td>\n",
       "      <td>Vatican Secret Archives were separated from the library at the beginning of the 17th century; they contain another 150,000 items.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3zotghdk5ibi9cex97fepx7jetpso7</td>\n",
       "      <td>Can anyone use this library?</td>\n",
       "      <td>anyone who can document their qualifications and research needs.</td>\n",
       "      <td>The Vatican Library is open to anyone who can document their qualifications and research needs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3zotghdk5ibi9cex97fepx7jetpso7</td>\n",
       "      <td>what must be requested in person or by mail?</td>\n",
       "      <td>Photocopies</td>\n",
       "      <td>Photocopies for private study of pages from books published between 1801 and 1990 can be requested in person or by mail.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3zotghdk5ibi9cex97fepx7jetpso7</td>\n",
       "      <td>of what books?</td>\n",
       "      <td>only books published between 1801 and 1990</td>\n",
       "      <td>hotocopies for private study of pages from books published between 1801 and 1990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td></th>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set [(21452, 12)]\n",
      "\tFeatures: ['index', 'input_text_x', 'turn_id', 'bad_turn_x', 'source', 'id', 'story', 'span_start', 'span_end', 'span_text', 'input_text_y', 'bad_turn_y']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<th style=\"text-align:left\"><td style=\"vertical-align:top\"><h4 style=\"text-align: left;\"></h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>input_text_x</th>\n",
       "      <th>input_text_y</th>\n",
       "      <th>span_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3bdcf01ogxu7zdn9vlrbf2rqzwplyf</td>\n",
       "      <td>Where was Milly led to?</td>\n",
       "      <td>Cottonwoods</td>\n",
       "      <td>led Milly Erne to Cottonwoods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3bdcf01ogxu7zdn9vlrbf2rqzwplyf</td>\n",
       "      <td>Who took her there?</td>\n",
       "      <td>A man</td>\n",
       "      <td>the man who had led Milly Erne to Cottonwoods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3bdcf01ogxu7zdn9vlrbf2rqzwplyf</td>\n",
       "      <td>Whose name would Jane not speak?</td>\n",
       "      <td>this Mormon's name</td>\n",
       "      <td>this Mormon's name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3bdcf01ogxu7zdn9vlrbf2rqzwplyf</td>\n",
       "      <td>Did she allow herself to even think it?</td>\n",
       "      <td>No</td>\n",
       "      <td>she did not even think it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3bdcf01ogxu7zdn9vlrbf2rqzwplyf</td>\n",
       "      <td>What was Jane hoping Lassiter would become to her?</td>\n",
       "      <td>a helper, of a friend, of a champion</td>\n",
       "      <td>the need of a helper, of a friend, of a champio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td></th>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set [(7917, 9)]\n",
      "\tFeatures: ['input_text_x', 'turn_id', 'source', 'id', 'story', 'span_start', 'span_end', 'span_text', 'input_text_y']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<th style=\"text-align:left\"><td style=\"vertical-align:top\"><h4 style=\"text-align: left;\"></h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>input_text_x</th>\n",
       "      <th>input_text_y</th>\n",
       "      <th>span_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3dr23u6we5exclen4th8uq9rb42tel</td>\n",
       "      <td>Did they want Cotton to change the color of her fur?</td>\n",
       "      <td>no</td>\n",
       "      <td>We would never want you to be any other way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3azhrg4cu4ktme1zh7c2ro3pn2430d</td>\n",
       "      <td>what was the name of the fish</td>\n",
       "      <td>Asta.</td>\n",
       "      <td>Asta.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3azhrg4cu4ktme1zh7c2ro3pn2430d</td>\n",
       "      <td>What looked like a birds belly</td>\n",
       "      <td>a bottle</td>\n",
       "      <td>a bottle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3azhrg4cu4ktme1zh7c2ro3pn2430d</td>\n",
       "      <td>who said that</td>\n",
       "      <td>Asta.</td>\n",
       "      <td>\"It looks like a bird's belly,\" said Asta.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3azhrg4cu4ktme1zh7c2ro3pn2430d</td>\n",
       "      <td>Was Sharkie a friend?</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Asta's friend Sharkie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td></th>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking the Dataframes\n",
    "print(f'Training set [{train_df.shape}]')\n",
    "print(f'\\tFeatures: {list(train_df.columns)}')\n",
    "display(train_df.loc[11:15,['id', 'input_text_x', 'input_text_y', 'span_text']])\n",
    "\n",
    "print(f'Validation set [{val_df.shape}]')\n",
    "print(f'\\tFeatures: {list(val_df.columns)}')\n",
    "display(val_df.loc[11:15,['id', 'input_text_x', 'input_text_y', 'span_text']])\n",
    "\n",
    "print(f'Test set [{test_df.shape}]')\n",
    "print(f'\\tFeatures: {list(test_df.columns)}')\n",
    "display(test_df.loc[11:15,['id', 'input_text_x', 'input_text_y', 'span_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1d874e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No overlap\n"
     ]
    }
   ],
   "source": [
    "# Overlap Check\n",
    "set_train = set(train_df['id'])\n",
    "set_val = set(val_df['id'])\n",
    "\n",
    "overlap = False\n",
    "for i in set_train:\n",
    "    if i in set_val:\n",
    "        overlap = True\n",
    "        break\n",
    "\n",
    "print('Overlap' if overlap else 'No overlap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0639e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes to Datasets\n",
    "train_df_to_ds = train_df[columns]\n",
    "val_df_to_ds = val_df[columns]\n",
    "test_df_to_ds = test_df[columns]\n",
    "\n",
    "train_df_to_ds = train_df_to_ds.rename(columns={'input_text_x': 'question', 'story': 'context',\\\n",
    "                                               'input_text_y': 'answer', 'span_text': 'text'})\n",
    "val_df_to_ds = val_df_to_ds.rename(columns={'input_text_x': 'question', 'story': 'context',\\\n",
    "                                               'input_text_y': 'answer', 'span_text': 'text'})\n",
    "test_df_to_ds = test_df_to_ds.rename(columns={'input_text_x': 'question', 'story': 'context',\\\n",
    "                                               'input_text_y': 'answer', 'span_text': 'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23df73f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['context', 'question', 'text', 'answer'],\n",
      "        num_rows: 1712\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['context', 'question', 'text', 'answer'],\n",
      "        num_rows: 424\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['context', 'question', 'text', 'answer'],\n",
      "        num_rows: 152\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Datasets Batch split\n",
    "batch_size = 8\n",
    "ratio = 2\n",
    "\n",
    "train_samples = (round(train_df_to_ds.shape[0] * ratio / 100) // batch_size) * batch_size\n",
    "\n",
    "val_samples = (round(val_df_to_ds.shape[0] * ratio / 100) // batch_size) * batch_size\n",
    "test_samples = (round(test_df_to_ds.shape[0] * ratio / 100) // batch_size) * batch_size\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_df_to_ds.iloc[:train_samples])\n",
    "val_dataset = Dataset.from_dict(val_df_to_ds.iloc[:val_samples])\n",
    "test_dataset = Dataset.from_dict(test_df_to_ds.iloc[:test_samples])\n",
    "\n",
    "dataset_COQA = DatasetDict({'train':train_dataset,'validation':val_dataset,'test':test_dataset})\n",
    "print(dataset_COQA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f42e93a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_input = 512\n",
    "max_length_answer = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3afc6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(batch, tokenizer, max_length_input, max_length_answer):\n",
    "    # Tokenize the Question and Context columns\n",
    "    encoded_batch_inputs = tokenizer(\n",
    "        batch['question'],\n",
    "        batch['context'],\n",
    "        max_length=max_length_input,\n",
    "        truncation='only_second',\n",
    "        padding='max_length',\n",
    "        return_tensors='pt'        \n",
    "    )\n",
    "\n",
    "    # Tokenize the Answer column\n",
    "    encoded_batch_labels = tokenizer(\n",
    "        batch['answer'],\n",
    "        max_length=max_length_answer,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    encoded_batch_inputs['labels'] = encoded_batch_labels.input_ids\n",
    "#   encoded_batch_inputs['decoder_input_ids'] = deepcopy(encoded_batch_inputs['labels'])\n",
    "#   encoded_batch_inputs['labels'] = [[-100 if token == tokenizer.pad_token_id else token\\\n",
    "#                                    for token in labels]\\\n",
    "#                                    for labels in encoded_batch_inputs['labels']]\n",
    "    \n",
    "    encoded_batch_inputs['labels_mask'] = encoded_batch_labels.attention_mask\n",
    "\n",
    "\n",
    "    return encoded_batch_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7555d2d6",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68ee3498",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special tokens:\n",
      "bos_token: <s>\n",
      "eos_token: </s>\n",
      "unk_token: <unk>\n",
      "sep_token: </s>\n",
      "pad_token: <pad>\n",
      "cls_token: <s>\n",
      "mask_token: <mask>\n",
      "bos_token: 0\n",
      "eos_token: 2\n",
      "unk_token: 3\n",
      "sep_token: 2\n",
      "pad_token: 1\n",
      "cls_token: 0\n",
      "mask_token: 50264\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint_M1 = 'distilroberta-base'\n",
    "# Tokenizer\n",
    "tokenizer_M1 = AutoTokenizer.from_pretrained(model_checkpoint_M1)\n",
    "assert isinstance(tokenizer_M1, PreTrainedTokenizerFast)\n",
    "tokenizer_M1.bos_token = tokenizer_M1.cls_token\n",
    "tokenizer_M1.eos_token = tokenizer_M1.sep_token\n",
    "check_tokens(tokenizer_M1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07baedb4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af091d2be6984d38b2e923c5921ba463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/214 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3773c0e11368485ebaa598cc2c8f3262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14fb5e4724e48e29fe0eee8d65eaec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels', 'labels_mask'],\n",
      "        num_rows: 1712\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels', 'labels_mask'],\n",
      "        num_rows: 424\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels', 'labels_mask'],\n",
      "        num_rows: 152\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing the Dataset\n",
    "tokenized_datasets_M1 = DatasetDict()\n",
    "\n",
    "# Use the `prepare_features` functions\n",
    "tokenized_datasets_M1 = dataset_COQA.map(\n",
    "    lambda batch: prepare_features(batch, tokenizer_M1, max_length_input, max_length_answer),\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    remove_columns=dataset_COQA['train'].column_names\n",
    ")\n",
    "\n",
    "print(tokenized_datasets_M1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fea23c",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76094d2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForCausalLM were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['roberta.encoder.layer.2.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.self.value.weight', 'roberta.encoder.layer.5.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.self.key.bias', 'roberta.encoder.layer.1.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.self.value.bias', 'roberta.encoder.layer.1.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.self.query.bias', 'roberta.encoder.layer.4.crossattention.output.dense.weight', 'roberta.encoder.layer.2.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.self.query.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.4.crossattention.self.key.bias', 'roberta.encoder.layer.1.crossattention.self.value.weight', 'roberta.encoder.layer.0.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.self.value.weight', 'roberta.encoder.layer.1.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.self.query.weight', 'roberta.encoder.layer.3.crossattention.self.key.weight', 'roberta.encoder.layer.0.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.5.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.self.value.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.2.crossattention.self.query.weight', 'roberta.encoder.layer.3.crossattention.self.value.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.5.crossattention.self.key.weight', 'roberta.encoder.layer.4.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.self.key.weight', 'roberta.encoder.layer.2.crossattention.self.key.bias', 'roberta.encoder.layer.1.crossattention.self.query.bias', 'roberta.encoder.layer.4.crossattention.output.dense.bias', 'roberta.encoder.layer.4.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.output.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters #: 178472025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EncoderDecoderModel(\n",
       "  (encoder): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): RobertaForCausalLM(\n",
       "    (roberta): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-5): 6 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (lm_head): RobertaLMHead(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Model\n",
    "model_M1 = EncoderDecoderModel.from_encoder_decoder_pretrained(model_checkpoint_M1, model_checkpoint_M1, tie_encoder_decoder=False)\n",
    "\n",
    "# Model special tokens\n",
    "model_M1.config.decoder_start_token_id = tokenizer_M1.cls_token_id\n",
    "model_M1.config_eos_token_id = tokenizer_M1.sep_token_id\n",
    "model_M1.config.pad_token_id = tokenizer_M1.pad_token_id\n",
    "model_M1.config.vocab_size = model_M1.config.encoder.vocab_size\n",
    "\n",
    "# Model hyperparams\n",
    "model_M1.config.max_length = max_length_answer\n",
    "model_M1.config.min_length = 1\n",
    "model_M1.config.no_repeat_ngram_size = 1\n",
    "model_M1.config.early_stopping = True\n",
    "model_M1.config.repetition_penalty= 3.\n",
    "model_M1.config.num_beams = 8\n",
    "\n",
    "print(f\"Parameters #: {model_M1.num_parameters()}\")\n",
    "\n",
    "model_M1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6242911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions\n",
    "    \n",
    "    labels_text = tokenizer_M1.batch_decode(labels, skip_special_tokens=True)\n",
    "    preds_text = tokenizer_M1.batch_decode(preds, skip_special_tokens=True)\n",
    "    \n",
    "    squad_scores=[]\n",
    "    for i in range(len(preds_text)):\n",
    "        squad_scores.append(compute_f1(str(preds_text[i]), str(labels_text[i])))\n",
    "    mean_squad_f1 = sum(squad_scores)/len(squad_scores)\n",
    "\n",
    "    return {\"squad_f1_score\": mean_squad_f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cb2ca5",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b9b8dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\the_s\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "training_args_M1 = Seq2SeqTrainingArguments(\n",
    "    output_dir='./M1_Checkpoints',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    predict_with_generate=True,\n",
    "    overwrite_output_dir=True,\n",
    "    #save_total_limit=2,\n",
    "    fp16=True, \n",
    "    num_train_epochs = epochs,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10\n",
    "    #resume_from_checkpoint = True\n",
    ")\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer_M1 = AdamW(model_M1.parameters(),lr= 5e-5)\n",
    "train_steps  = epochs*len(tokenized_datasets_M1['train'])/batch_size\n",
    "scheduler_M1 = transformers.get_cosine_schedule_with_warmup(optimizer=optimizer_M1,num_warmup_steps=50,num_training_steps=train_steps)\n",
    "optimizers_M1 = optimizer_M1, scheduler_M1\n",
    "\n",
    "trainer_M1 = Seq2SeqTrainer(\n",
    "    model=model_M1,\n",
    "    tokenizer=tokenizer_M1,\n",
    "    args=training_args_M1,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=tokenized_datasets_M1['train'],\n",
    "    eval_dataset=tokenized_datasets_M1['validation'],\n",
    "    optimizers=optimizers_M1,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer_M1,model=model_M1)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "356f4b1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `EncoderDecoderModel.forward` and have been ignored: labels_mask. If labels_mask are not expected by `EncoderDecoderModel.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 1712\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 642\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\the_s\\anaconda3\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:533: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='642' max='642' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [642/642 02:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Squad F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.883500</td>\n",
       "      <td>0.730930</td>\n",
       "      <td>0.018661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.693200</td>\n",
       "      <td>0.687643</td>\n",
       "      <td>0.103449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.755100</td>\n",
       "      <td>0.683339</td>\n",
       "      <td>0.049163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `EncoderDecoderModel.forward` and have been ignored: labels_mask. If labels_mask are not expected by `EncoderDecoderModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 424\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `EncoderDecoderModel.forward` and have been ignored: labels_mask. If labels_mask are not expected by `EncoderDecoderModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 424\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./M1_Checkpoints\\checkpoint-500\n",
      "Configuration saved in ./M1_Checkpoints\\checkpoint-500\\config.json\n",
      "Model weights saved in ./M1_Checkpoints\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in ./M1_Checkpoints\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in ./M1_Checkpoints\\checkpoint-500\\special_tokens_map.json\n",
      "C:\\Users\\the_s\\anaconda3\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_encoder_decoder.py:533: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "The following columns in the evaluation set don't have a corresponding argument in `EncoderDecoderModel.forward` and have been ignored: labels_mask. If labels_mask are not expected by `EncoderDecoderModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 424\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=642, training_loss=1.2746291621080441, metrics={'train_runtime': 175.956, 'train_samples_per_second': 29.189, 'train_steps_per_second': 3.649, 'total_flos': 1585257005629440.0, 'train_loss': 1.2746291621080441, 'epoch': 3.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "trainer_M1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4d1bf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|████▎                                                                              | 1/19 [00:00<00:06,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What color was Cotton?Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. Cotton lived high up in a nice warm place above the barn where all of the farmer's horses slept. But Cotton wasn't alone in her little home above the barn, oh no. She shared her hay bed with her mommy and 5 other sisters. All of her sisters were cute and fluffy, like Cotton. But she was the only white one in the bunch. The rest of her sisters were all orange with beautiful white tiger stripes like Cotton's mommy. Being different made Cotton quite sad. She often wished she looked like the rest of her family. So one day, when Cotton found a can of the old farmer's orange paint, she used it to paint herself like them. When her mommy and sisters found her they started laughing.   \"What are you doing, Cotton?!\"   \"I only wanted to be more like you\".   Cotton's mommy rubbed her face on Cotton's and said \"Oh Cotton, but your fur is so pretty and special, like you. We would never want you to be any other way\". And with that, Cotton's mommy picked her up and dropped her into a big bucket of water. When Cotton came out she was herself again. Her sisters licked her face until Cotton's fur was all all dry.   \"Don't ever do that again, Cotton!\" they all cried. \"Next time you might mess up that pretty white fur of yours and we wouldn't want that!\"   Then Cotton thought, \"I change my mind. I like being special\".\n",
      "['What color was Cotton?', 'Where did she live?', 'Did she live alone?', 'Who did she live with?', 'What color were her sisters?', 'Was Cotton happy that she looked different than the rest of her family?', 'What did she do to try to make herself the same color as her sisters?', 'Whose paint was it?']\n",
      "Generated ans: ['He him the he to a was his', 'He him the he to a was his', 'He him the he to a was his', 'He him the he to a was his', 'He him the he to a was his', 'He him the he to a was his', 'He him the he to a was his', 'He him the he to a was his']\n",
      "True ans: ['white', 'in a barn', 'no', 'with her mommy and 5 sisters', 'orange and white', 'no', 'she painted herself', 'the farmer']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████████▋                                                                          | 2/19 [00:00<00:06,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What did Cotton's mother and siblings do when they saw her painted orange?Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. Cotton lived high up in a nice warm place above the barn where all of the farmer's horses slept. But Cotton wasn't alone in her little home above the barn, oh no. She shared her hay bed with her mommy and 5 other sisters. All of her sisters were cute and fluffy, like Cotton. But she was the only white one in the bunch. The rest of her sisters were all orange with beautiful white tiger stripes like Cotton's mommy. Being different made Cotton quite sad. She often wished she looked like the rest of her family. So one day, when Cotton found a can of the old farmer's orange paint, she used it to paint herself like them. When her mommy and sisters found her they started laughing.   \"What are you doing, Cotton?!\"   \"I only wanted to be more like you\".   Cotton's mommy rubbed her face on Cotton's and said \"Oh Cotton, but your fur is so pretty and special, like you. We would never want you to be any other way\". And with that, Cotton's mommy picked her up and dropped her into a big bucket of water. When Cotton came out she was herself again. Her sisters licked her face until Cotton's fur was all all dry.   \"Don't ever do that again, Cotton!\" they all cried. \"Next time you might mess up that pretty white fur of yours and we wouldn't want that!\"   Then Cotton thought, \"I change my mind. I like being special\".\n",
      "[\"What did Cotton's mother and siblings do when they saw her painted orange?\", \"Where did Cotton's mother put her to clean the paint off?\", 'What did the other cats do when Cotton emerged from the bucket of water?', 'Did they want Cotton to change the color of her fur?', 'what was the name of the fish', 'What looked like a birds belly', 'who said that', 'Was Sharkie a friend?']\n",
      "Generated ans: ['He him the he to a was his', 'He him the he to a have his was', 'He him the he to a was his', 'He him the he to a was his', 'He he the a to', 'He he the a to', 'He he the a to', 'He he the a to']\n",
      "True ans: ['they started laughing', 'a bucket of water', 'licked her face', 'no', 'Asta.', 'a bottle', 'Asta.', 'Yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████████████                                                                      | 3/19 [00:01<00:05,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did they get the bottle?Once there was a beautiful fish named Asta. Asta lived in the ocean. There were lots of other fish in the ocean where Asta lived. They played all day long.   One day, a bottle floated by over the heads of Asta and his friends. They looked up and saw the bottle. \"What is it?\" said Asta's friend Sharkie. \"It looks like a bird's belly,\" said Asta. But when they swam closer, it was not a bird's belly. It was hard and clear, and there was something inside it.   The bottle floated above them. They wanted to open it. They wanted to see what was inside. So they caught the bottle and carried it down to the bottom of the ocean. They cracked it open on a rock. When they got it open, they found what was inside. It was a note. The note was written in orange crayon on white paper. Asta could not read the note. Sharkie could not read the note. They took the note to Asta's papa. \"What does it say?\" they asked.   Asta's papa read the note. He told Asta and Sharkie, \"This note is from a little girl. She wants to be your friend. If you want to be her friend, we can write a note to her. But you have to find another bottle so we can send it to her.\" And that is what they did.\n",
      "['did they get the bottle?', 'What was in it', 'Did a little boy write the note', 'Who could read the note', 'did they write back', 'Who is at the door?', 'Is she carrying something?', 'What?']\n",
      "Generated ans: ['He he the a to', 'He he the a to', 'He he the a to', 'He he the a to', 'He he the a to', 'He he the to a was', 'He he the to a was', 'He he the to a was']\n",
      "True ans: ['Yes', 'a note', 'No', \"Asta's papa\", 'yes', 'An elderly Chinese lady and a little boy', 'Yes', 'a paper carrier bag']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|█████████████████▍                                                                 | 4/19 [00:01<00:04,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do I know her?My doorbell rings. On the step, I find the elderly Chinese lady, small and slight, holding the hand of a little boy. In her other hand, she holds a paper carrier bag.   I know this lady. It is not her first visit. She is the boy's grandmother, and her daughter bought the house next door last October.   Her daughter, Nicole, speaks fluent English. But she is now in Shanghai, and her parents are here with the little boy. Nicole has obviously told her mother that I am having heart surgery soon, so her mother has decided I need more nutrients.   I know what is inside the bag--a thermos with hot soup and a stainless-steel container with rice, vegetables and either chicken, meat or shrimp, sometimes with a kind of pancake. This has become an almost-daily practice.   Communication between us is somewhat affected by the fact that she doesn't speak English and all I can say in Chinese is hello. Once, she brought an iPad as well as the food. She pointed to the screen, which displayed a message from her daughter telling me that her mother wanted to know if the food was all right and whether it was too salty. I am not used to iPads, so she indicated I should go with her to her house. Then, she handed the iPad to her husband and almost immediately I found myself looking at Nicole in Shanghai and discussing her mother's cooking and salt intake. Instantly, tears welled in my eyes.   \"Your mother just can't be bringing me meals like this all the time,\" I insisted. \"I can hardly do dishes in return.\"   \"Oh, no, Lucy.\" Nicole said. \"Mum doesn't like western food. Don't worry about it; she has to cook for the three of them anyway, and she wants to do it.\"   The doorbell keeps ringing and there is the familiar brown paper carrier bag, handed smilingly to me.   I am now working on some more Chinese words--it's the least I can do after such display of kindness.   \"Thank you\" is, of course, the first one. Somehow, it seems inadequate.\n",
      "['Do I know her?', 'Who is her daughter?', 'Where does Nicole live?', 'How is she related to the boy?', 'What is in the bag?', 'Has she done this before?', 'Why?', 'What has helped us communicate?']\n",
      "Generated ans: ['He he the to a was', 'He he the to a was', 'He he the to a was', 'He he the to a was', 'He he the to a was', 'He he the to a was', 'He he the to a was', 'He he the to a was']\n",
      "True ans: ['Yes', 'Nicole', 'Shanghai', 'mother', 'food', 'Yes', 'I am having heart surgery soon, so her mother has decided I need more nutrients', 'an iPad']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████▊                                                             | 5/19 [00:01<00:04,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What kind of dishes does she bring?My doorbell rings. On the step, I find the elderly Chinese lady, small and slight, holding the hand of a little boy. In her other hand, she holds a paper carrier bag.   I know this lady. It is not her first visit. She is the boy's grandmother, and her daughter bought the house next door last October.   Her daughter, Nicole, speaks fluent English. But she is now in Shanghai, and her parents are here with the little boy. Nicole has obviously told her mother that I am having heart surgery soon, so her mother has decided I need more nutrients.   I know what is inside the bag--a thermos with hot soup and a stainless-steel container with rice, vegetables and either chicken, meat or shrimp, sometimes with a kind of pancake. This has become an almost-daily practice.   Communication between us is somewhat affected by the fact that she doesn't speak English and all I can say in Chinese is hello. Once, she brought an iPad as well as the food. She pointed to the screen, which displayed a message from her daughter telling me that her mother wanted to know if the food was all right and whether it was too salty. I am not used to iPads, so she indicated I should go with her to her house. Then, she handed the iPad to her husband and almost immediately I found myself looking at Nicole in Shanghai and discussing her mother's cooking and salt intake. Instantly, tears welled in my eyes.   \"Your mother just can't be bringing me meals like this all the time,\" I insisted. \"I can hardly do dishes in return.\"   \"Oh, no, Lucy.\" Nicole said. \"Mum doesn't like western food. Don't worry about it; she has to cook for the three of them anyway, and she wants to do it.\"   The doorbell keeps ringing and there is the familiar brown paper carrier bag, handed smilingly to me.   I am now working on some more Chinese words--it's the least I can do after such display of kindness.   \"Thank you\" is, of course, the first one. Somehow, it seems inadequate.\n",
      "['What kind of dishes does she bring?', 'What do I do to help communicate with her?', 'Do she continue bringing the bag?', 'What is the first phrase I learn?', 'Is someone in showbiz?', 'Whom?', 'What did he do?', 'Is he still alive?']\n",
      "Generated ans: ['He he the a was to him', 'He he the to a was', 'He he the to a was', 'He he the a was to him', 'Yes.', 'Yes.', 'Yes.', 'Yes.']\n",
      "True ans: ['hot soup and a container with rice, vegetables and either chicken, meat or shrimp, sometimes with a kind of pancake', 'I am now working on some more Chinese words', 'Yes', '\"Thank you\"', 'Yes.', 'Dennis Farina', 'Actor', 'No']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|██████████████████████████▏                                                        | 6/19 [00:01<00:03,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Was he in movies?(CNN) -- Dennis Farina, the dapper, mustachioed cop-turned-actor best known for his tough-as-nails work in such TV series as \"Law & Order,\" \"Crime Story,\" and \"Miami Vice,\" has died. He was 69.   \"We are deeply saddened by the loss of a great actor and a wonderful man,\" said his publicist, Lori De Waal, in a statement Monday. \"Dennis Farina was always warmhearted and professional, with a great sense of humor and passion for his profession. He will be greatly missed by his family, friends and colleagues.\"   Farina, who had a long career as a police officer in Chicago, got into acting through director Michael Mann, who used him as a consultant and cast him in his 1981 movie, \"Thief.\" That role led to others in such Mann-created shows as \"Miami Vice\" (in which Farina played a mobster) and \"Crime Story\" (in which he starred as Lt. Mike Torello).   Farina also had roles, generally as either cops or gangsters, in a number of movies, including \"Midnight Run\" (1988), \"Get Shorty\" (1995), \"The Mod Squad\" (1999) and \"Snatch\" (2000).   In 2004, he joined the cast of the long-running \"Law & Order\" after Jerry Orbach's departure, playing Detective Joe Fontana, a role he reprised on the spinoff \"Trial by Jury.\" Fontana was known for flashy clothes and an expensive car, a distinct counterpoint to Orbach's rumpled Lennie Briscoe.   Farina was on \"Law & Order\" for two years, partnered with Jesse L. Martin's Ed Green. Martin's character became a senior detective after Farina left the show. \n",
      "['Was he in movies?', 'Anything recent?', \"What happened in the early 80's?\", 'Who cast him?', 'What was the title of the movie?', 'What parts did he usually get?', 'What happened in 2004?', 'Which one?']\n",
      "Generated ans: ['Yes.', 'Yes.', 'Yes.', 'Yes.', 'Yes.', 'Yes.', 'Yes.', 'Yes.']\n",
      "True ans: ['Yes', 'No', 'Farina was cast in a film', 'Michael Mann', '\"Thief\"', 'cops or gangsters', 'He joined a TV show cast.', '\"Law & Order\"']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|██████████████████████████████▌                                                    | 7/19 [00:02<00:03,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who did he portray?(CNN) -- Dennis Farina, the dapper, mustachioed cop-turned-actor best known for his tough-as-nails work in such TV series as \"Law & Order,\" \"Crime Story,\" and \"Miami Vice,\" has died. He was 69.   \"We are deeply saddened by the loss of a great actor and a wonderful man,\" said his publicist, Lori De Waal, in a statement Monday. \"Dennis Farina was always warmhearted and professional, with a great sense of humor and passion for his profession. He will be greatly missed by his family, friends and colleagues.\"   Farina, who had a long career as a police officer in Chicago, got into acting through director Michael Mann, who used him as a consultant and cast him in his 1981 movie, \"Thief.\" That role led to others in such Mann-created shows as \"Miami Vice\" (in which Farina played a mobster) and \"Crime Story\" (in which he starred as Lt. Mike Torello).   Farina also had roles, generally as either cops or gangsters, in a number of movies, including \"Midnight Run\" (1988), \"Get Shorty\" (1995), \"The Mod Squad\" (1999) and \"Snatch\" (2000).   In 2004, he joined the cast of the long-running \"Law & Order\" after Jerry Orbach's departure, playing Detective Joe Fontana, a role he reprised on the spinoff \"Trial by Jury.\" Fontana was known for flashy clothes and an expensive car, a distinct counterpoint to Orbach's rumpled Lennie Briscoe.   Farina was on \"Law & Order\" for two years, partnered with Jesse L. Martin's Ed Green. Martin's character became a senior detective after Farina left the show. \n",
      "['Who did he portray?', 'Did he have a beater for a car?', 'What did he have?', 'Were the characters clothes frumpy?', 'What were they like?', 'Was he on the show for five years?', 'Was he always an actor?', 'What had he been before?']\n",
      "Generated ans: ['Yes.', 'Yes.', 'Yes.', 'Yes.', 'Yes.', 'Yes.', 'Yes.', 'Yes.']\n",
      "True ans: ['Detective Joe Fontana', 'No', 'An expensive car', 'No', 'Flashy', 'No', 'No', 'A cop']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|██████████████████████████████████▉                                                | 8/19 [00:02<00:03,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where do Quinton and Kendra travel to and from every day?Kendra and Quinton travel to and from school every day. Kendra lives further from the bus stop than Quinton does, stops every morning at Quinton's house to join him to walk to the bus stop. Every afternoon, after school, when walking home from the bus stop they go in for cookies and milk that Quinton's mother has ready and waiting for them. Quinton can't eat cheese or cake so they had the same snack every day. They both work together on their homework and when they are done they play together. Kendra always makes sure to leave in time to get home for dinner. She doesn't want to miss story time which was right before bedtime.   One morning Kendra walked up to Quinton's house, she thought something might be wrong because normally Quinton was waiting outside for her and on this morning he was not to be found. Kendra went up to the door and knocked. She waited and waited and yet no one answered. She saw that Quinton's mother's car wasn't in their driveway which was weird. She waited for a few bit looking up and down the block and getting worried when Quinton was nowhere to be found.   Kendra didn't want to miss the bus to school and hurried off to make it in time. The bus driver saw that she was upset and that Quinton was not with her that morning. She told him what happened and he said that he was sure that everything would be okay.   Kendra got to school, ran to her teacher and told him what happened that morning. The teacher smiled and told her not to worry, Quinton's mother had called and he was going to the dentist and would be at school after lunch and that she would see him at the bus stop like normal tomorrow.\n",
      "['Where do Quinton and Kendra travel to and from every day?', 'Does Quinton live further from the bus stop?', 'What do they do every afternoon after school?', 'Does Quinton eat cheese?', 'Do they play before their homework?', 'What does Kendra not want to miss?', 'When is that?', \"What happened when Kendra knocked on Quinton's door?\"]\n",
      "Generated ans: ['He him the to he a his was', 'He him the to he a his was', 'He him the to a he his was', 'He him the he to was a have his', 'He him the he to was a have his', 'He him the to a he his was', 'He him the he to was a have his', 'He him the to a he his was']\n",
      "True ans: ['school', 'No', \"go to Quentin's house\", 'No', 'No', 'story time', 'right before bedtime', 'no one answered']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|███████████████████████████████████████▎                                           | 9/19 [00:02<00:03,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did she see the car?Kendra and Quinton travel to and from school every day. Kendra lives further from the bus stop than Quinton does, stops every morning at Quinton's house to join him to walk to the bus stop. Every afternoon, after school, when walking home from the bus stop they go in for cookies and milk that Quinton's mother has ready and waiting for them. Quinton can't eat cheese or cake so they had the same snack every day. They both work together on their homework and when they are done they play together. Kendra always makes sure to leave in time to get home for dinner. She doesn't want to miss story time which was right before bedtime.   One morning Kendra walked up to Quinton's house, she thought something might be wrong because normally Quinton was waiting outside for her and on this morning he was not to be found. Kendra went up to the door and knocked. She waited and waited and yet no one answered. She saw that Quinton's mother's car wasn't in their driveway which was weird. She waited for a few bit looking up and down the block and getting worried when Quinton was nowhere to be found.   Kendra didn't want to miss the bus to school and hurried off to make it in time. The bus driver saw that she was upset and that Quinton was not with her that morning. She told him what happened and he said that he was sure that everything would be okay.   Kendra got to school, ran to her teacher and told him what happened that morning. The teacher smiled and told her not to worry, Quinton's mother had called and he was going to the dentist and would be at school after lunch and that she would see him at the bus stop like normal tomorrow.\n",
      "['Did she see the car?', 'Did she miss the bus?', 'What did the bus driver see?', 'Did Kendra tell him why?', 'What did he say?', 'When she got to school, who did she tell?', 'Did he frown?', 'Who had called?']\n",
      "Generated ans: ['He him the he to was a have his', 'He him the he to was a have his', 'He him the to a he his was', 'He him the he to was a have his', 'He him the he to was a have his', 'He him the he to was a have his', 'He him the he to was a have his', 'He him the he to was a have his']\n",
      "True ans: ['No', 'No', 'that she was upset', 'yes', 'everything would be okay', 'her teacher', 'No', \"Quinton's mother\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|███████████████████████████████████████████▏                                      | 10/19 [00:03<00:03,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where did he go?Kendra and Quinton travel to and from school every day. Kendra lives further from the bus stop than Quinton does, stops every morning at Quinton's house to join him to walk to the bus stop. Every afternoon, after school, when walking home from the bus stop they go in for cookies and milk that Quinton's mother has ready and waiting for them. Quinton can't eat cheese or cake so they had the same snack every day. They both work together on their homework and when they are done they play together. Kendra always makes sure to leave in time to get home for dinner. She doesn't want to miss story time which was right before bedtime.   One morning Kendra walked up to Quinton's house, she thought something might be wrong because normally Quinton was waiting outside for her and on this morning he was not to be found. Kendra went up to the door and knocked. She waited and waited and yet no one answered. She saw that Quinton's mother's car wasn't in their driveway which was weird. She waited for a few bit looking up and down the block and getting worried when Quinton was nowhere to be found.   Kendra didn't want to miss the bus to school and hurried off to make it in time. The bus driver saw that she was upset and that Quinton was not with her that morning. She told him what happened and he said that he was sure that everything would be okay.   Kendra got to school, ran to her teacher and told him what happened that morning. The teacher smiled and told her not to worry, Quinton's mother had called and he was going to the dentist and would be at school after lunch and that she would see him at the bus stop like normal tomorrow.\n",
      "['Where did he go?', 'When would he be back?', 'How many burroughs are there?', 'in what city?', 'and state?', 'Is staten island one?', 'Where is it?', 'What separates it from new jersey?']\n",
      "Generated ans: ['He him the he to was a have his', 'He him the he to was a have his', '193', '193', '193', '193', '193', '193']\n",
      "True ans: ['to the dentist', 'yes', 'five', 'New York City', 'New York', 'Yes', 'In the southwest of the city', 'Arthur Kill and the Kill Van Kull']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|███████████████████████████████████████████████▍                                  | 11/19 [00:03<00:02,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is its population?Staten Island is one of the five boroughs of New York City in the U.S. state of New York. In the southwest of the city, Staten Island is the southernmost part of both the city and state of New York, with Conference House Park at the southern tip of the island and the state. The borough is separated from New Jersey by the Arthur Kill and the Kill Van Kull, and from the rest of New York by New York Bay. With a 2016 Census-estimated population of 476,015, Staten Island is the least populated of the boroughs but is the third-largest in area at. Staten Island is the only borough of New York with a non-Hispanic White majority. The borough is coextensive with Richmond County, and until 1975 was the Borough of Richmond. Its flag was later changed to reflect this. Staten Island has been sometimes called \"the forgotten borough\" by inhabitants who feel neglected by the city government.   The North Shore—especially the neighborhoods of St. George, Tompkinsville, Clifton, and Stapleton—is the most urban part of the island; it contains the designated St. George Historic District and the St. Paul's Avenue-Stapleton Heights Historic District, which feature large Victorian houses. The East Shore is home to the F.D.R. Boardwalk, the fourth-longest in the world. The South Shore, site of the 17th-century Dutch and French Huguenot settlement, developed rapidly beginning in the 1960s and 1970s and is now mostly suburban in character. The West Shore is the least populated and most industrial part of the island.\n",
      "['What is its population?', 'Is it the most populated?', 'what ethnicity is the majority?', 'What is it sometimes called?', 'why?', 'what is the most urban part?', 'which neighborhoods?', 'When did Reginald Eppes wake up?']\n",
      "Generated ans: ['193', '193', '193', '193', '193', '193', '193', 'He to the a']\n",
      "True ans: ['476,015', 'no', 'non-Hispanic White', 'the forgotten borough', 'because the inhabitants feel neglected by the city government', 'North Shore', 'St. George, Tompkinsville, Clifton, and Stapleton', 'Five in the morning']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|███████████████████████████████████████████████████▊                              | 12/19 [00:03<00:02,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What was the first thing he checked?Thunder was coming when Reginald Eppes woke up at five in the morning. He checked the weather forecast. A violent storm was coming,but it sounded like his small town wouldn't be hit too hard. But Eppes, a firefighter, had clearly known the power of these huge storms from experiences. \"Do you know where the flashlights are?\" he asked his wife. Danielle. Just then, thunder was all-around them. The moment he turned the flashlight on. The house lights went off. A second later, the kitchen windows were broken. Eppes and Danielle ran to their boys who were still sleeping in their bedroom.   \"Get up, get up, R.J.! \" Eppes shouted, waving his flashlight. The sleepy boy moved to the edge of the bed. Eppes held out his arms and ordered his son to jump. He was too late. The roof was torn down. R.J. was buried,under the pieces.   \"I've lost him,\" Eppes thought. Quickly, he hurried to Joel to shield him. Glass, wood, and plaster ( ) hit them. Then something huge, heavy-maybe the washing machine-knocked into him. He hurt his arms, but he still held the flashlight in one hand.   After a long period, the wind began to die down. Eppes found himself standing in the ruins of his home. Darkness lay all about him. Then he thought he saw a shape moving straight toward him. It was R.J., guided home by the light of his father's flashlight.   At the hospital later, R.J. described what had happened to him. \"I rushed out when the wall started moving I was scared. My mom and dad were gone. Pieces of glass hit my back, and something hit my neck really hard. \"   R.J. had been raised up into the air by the wind and dropped back to the ground. Amazingly, R.J. was not hurt badly. Of all his family, Eppes was hurt most seriously.\n",
      "['What was the first thing he checked?', 'Was there a storm headed that way?', 'What was his profession?', 'Did the house lights go out?', 'What device did they use when the power went out?', 'Who was buried under the roof?', 'Who did he need to shield?', 'What were they hit by?']\n",
      "Generated ans: ['He to the a', 'He to the a', 'He to the a', 'He to the a', 'He to the a', 'He to the a', 'He to the a', 'He to the a']\n",
      "True ans: ['Weather forecast', 'Yes', 'Firefighter', 'Yes', 'Flashlight', 'R.J.', 'Joel', 'Glass, wood, plaster, and maybe the washing machine']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|████████████████████████████████████████████████████████                          | 13/19 [00:04<00:01,  3.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Was RJ badly hurt?Thunder was coming when Reginald Eppes woke up at five in the morning. He checked the weather forecast. A violent storm was coming,but it sounded like his small town wouldn't be hit too hard. But Eppes, a firefighter, had clearly known the power of these huge storms from experiences. \"Do you know where the flashlights are?\" he asked his wife. Danielle. Just then, thunder was all-around them. The moment he turned the flashlight on. The house lights went off. A second later, the kitchen windows were broken. Eppes and Danielle ran to their boys who were still sleeping in their bedroom.   \"Get up, get up, R.J.! \" Eppes shouted, waving his flashlight. The sleepy boy moved to the edge of the bed. Eppes held out his arms and ordered his son to jump. He was too late. The roof was torn down. R.J. was buried,under the pieces.   \"I've lost him,\" Eppes thought. Quickly, he hurried to Joel to shield him. Glass, wood, and plaster ( ) hit them. Then something huge, heavy-maybe the washing machine-knocked into him. He hurt his arms, but he still held the flashlight in one hand.   After a long period, the wind began to die down. Eppes found himself standing in the ruins of his home. Darkness lay all about him. Then he thought he saw a shape moving straight toward him. It was R.J., guided home by the light of his father's flashlight.   At the hospital later, R.J. described what had happened to him. \"I rushed out when the wall started moving I was scared. My mom and dad were gone. Pieces of glass hit my back, and something hit my neck really hard. \"   R.J. had been raised up into the air by the wind and dropped back to the ground. Amazingly, R.J. was not hurt badly. Of all his family, Eppes was hurt most seriously.\n",
      "['Was RJ badly hurt?', 'Who was hurt the worst?', 'What guided RJ home?', 'Whose house was searched?', 'In what city?', 'County?', 'State?', 'Where is he now?']\n",
      "Generated ans: ['He to the a', 'He to the a', 'He to the a', 'Yes.', 'Yes.', 'Yes.', 'Yes.', 'Yes.']\n",
      "True ans: ['No', 'Eppes', 'The flashlight', 'Gary Giordano', 'Gaithersburg', 'Montgomery County', 'Maryland', 'Aruban jail']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|████████████████████████████████████████████████████████████▍                     | 14/19 [00:04<00:01,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why?(CNN) -- FBI agents on Friday night searched the Maryland home of the suspect in the recent disappearance of an American woman in Aruba, an agent said.   The search is occurring in the Gaithersburg residence of Gary Giordano, who is currently being held in an Aruban jail, FBI Special Agent Rich Wolf told CNN.   Agents, wearing vests that said FBI and carrying empty cardboard and plastic boxes, arrived about 8:40 p.m. Friday. About 15 unmarked cars could be seen on the street, as well as a Montgomery County police vehicle.   Supervisory Special Agent Philip Celestini, who was at the residence, declined to comment further on the search, citing the active investigation.   Aruban Solicitor General Taco Stein said earlier Friday that the suspect will appear in court Monday, where an investigating magistrate could order him held for at least eight more days, order him to remain on the island or release him outright due to a lack of evidence.   Giordano was arrested by Aruban police on August 5, three days after Robyn Gardner was last seen near Baby Beach on the western tip of the Caribbean island.   Giordano told authorities that he had been snorkeling with Gardner when he signaled to her to swim back, according to a statement. When he reached the beach, Gardner was nowhere to be found, Giordano allegedly said.   The area that Giordano led authorities to is a rocky, unsightly location that locals say is not a popular snorkeling spot.   Although prosecutors have continued to identify the 50-year-old American man by his initials, GVG, they also released a photo of a man who appears to be Giordano. His attorney, Michael Lopez, also has said that his client is being held as a suspect in Gardner's death. Lopez has not returned telephone calls seeking comment. \n",
      "['Why?', 'What organization is doing the search?', 'How many unmarked vehicles were there?', 'Who spoke for the Aruban government?', 'When will Giordano go to court?', 'How many days could he be held?', 'Who went missing?', 'Where?']\n",
      "Generated ans: ['Yes.', 'Yes.', 'Yes.', 'Yes.', 'Yes.', 'Yes.', 'Yes.', 'Yes.']\n",
      "True ans: ['suspect in the recent disappearance of an American woman', 'FBI', '15', 'Aruban Solicitor General Taco Stein', 'Monday', 'at least eight more days', 'Robyn Gardne', 'ast seen near Baby Beach']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|█████████████████████████████████████████████████████████████████████             | 16/19 [00:04<00:00,  4.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What was she doing?(CNN) -- FBI agents on Friday night searched the Maryland home of the suspect in the recent disappearance of an American woman in Aruba, an agent said.   The search is occurring in the Gaithersburg residence of Gary Giordano, who is currently being held in an Aruban jail, FBI Special Agent Rich Wolf told CNN.   Agents, wearing vests that said FBI and carrying empty cardboard and plastic boxes, arrived about 8:40 p.m. Friday. About 15 unmarked cars could be seen on the street, as well as a Montgomery County police vehicle.   Supervisory Special Agent Philip Celestini, who was at the residence, declined to comment further on the search, citing the active investigation.   Aruban Solicitor General Taco Stein said earlier Friday that the suspect will appear in court Monday, where an investigating magistrate could order him held for at least eight more days, order him to remain on the island or release him outright due to a lack of evidence.   Giordano was arrested by Aruban police on August 5, three days after Robyn Gardner was last seen near Baby Beach on the western tip of the Caribbean island.   Giordano told authorities that he had been snorkeling with Gardner when he signaled to her to swim back, according to a statement. When he reached the beach, Gardner was nowhere to be found, Giordano allegedly said.   The area that Giordano led authorities to is a rocky, unsightly location that locals say is not a popular snorkeling spot.   Although prosecutors have continued to identify the 50-year-old American man by his initials, GVG, they also released a photo of a man who appears to be Giordano. His attorney, Michael Lopez, also has said that his client is being held as a suspect in Gardner's death. Lopez has not returned telephone calls seeking comment. \n",
      "['What was she doing?', 'With whom?', 'Did she return safely?', 'Is the beach a good snorkeling place?', 'How old is he?', 'When was he arrested?', 'How many were snorkeling?', 'Which country consumes tea the most?']\n",
      "Generated ans: ['Yes.', 'Yes.', 'Yes.', 'Yes.', 'Yes.', 'Yes.', 'Yes.', 'Yes.']\n",
      "True ans: ['snorkeling', 'Giordano', 'No, Gardner was nowhere to be found', 'locals say is not a popular snorkeling spot.', '50', 'August 5', '2, Giordano told authorities that he had been snorkeling with Gardner', 'Great Britain']\n",
      "Which country grows it the most?Which country grows the most tea? The answer is India. It grows three times as much as China. Which country drinks the most tea? It's neither China nor Japan. It's Great Britain. In the wild, tea plants may be 30 feet tall. But a plant grown for market is pruned. Pruning keeps the plant only three or four feet tall. This is an easy height for tea picking. Only the two top leaves and bud of each new shoot are picked. So to make money, tea plantations must be huge. In general, there are two kinds of tea. Black tea and green tea. Black tea is fermented. In the process, the tea loses nearly all of its healthy qualities. Green tea is steamed right after the leaves are picked. Green tea _ its healthy qualities. For example, it may prevent heart disease. How did we get tea bag? The answer: by accident. Tea merchants used to send samples in tin boxes. This was costly. One merchant thought of a cheaper way. He sent samples in small silk bags. Customers would cut open the bag. They would brew the leaves as usual. One customer put the bag into a pot. Then he just poured hot water over it. And the tea bag was born. Shen Nong was the first to drink tea. (Shen was a Chinese emperor.) This was about 2737 B.C. Shen had bad digestion. So he drank several cups of hot water daily. One day something happened. Leaves from a wild tea tree fell into the hot water pot. The next cup was poured. The water was now colored. Shen sipped it. He liked it. He drank it all. Shen was proud of his new drink. He served it to his guests. Word spread. People thought this way. Tea is good enough for the Emperor. So it must be good enough for the people. Tea became the drink of China.\n",
      "['Which country grows it the most?', 'How tall is the tea plant?', 'What did they do to green tea after picking it?', 'What good thing do the tea do to the health?', 'How was the tea created?', 'Who took the tea first?', 'When did he take it?', 'Was he happy with it?']\n",
      "Generated ans: ['Yes.', 'Yes.', 'Yes.', 'Yes.', 'Yes.', 'Yes.', 'Yes.', 'Yes.']\n",
      "True ans: ['India.', 'may be 30 feet tall', 'prune it', 'may prevent heart disease.', 'by accident', 'Shen Nong', 'about 2737 B.C', 'yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|█████████████████████████████████████████████████████████████████████████▎        | 17/19 [00:04<00:00,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What news agency showed photos of American soldiers?Kabul, Afghanistan (CNN) -- The German news outlet Der Spiegel has published photographs of what appear to be two U.S. soldiers in Afghanistan posing over the bodies of dead Afghans -- images which threaten to further complicate the American military effort there.   Two images show the soldiers kneeling by a bloody body sprawled over a patch of sand and grass. A third shows what appears to be two bodies propped up, back to back, against a post in front of a military vehicle.   Der Spiegel identifies the soldiers as Spc. Jeremy Morlock and Pfc. Andrew Holmes, who are both facing charges relating to the wrongful deaths of Afghan civilians.   Specifically, Holmes is charged with the premeditated deaths of three civilians, possessing a dismembered human finger, wrongfully possessing photographs of human casualties, and smoking hashish.   He is also accused of conspiring with Morlock to shoot at a civilian and then toss a grenade so it would look like the soldiers were under attack.   Morlock is charged with three counts of murder. He is accused of killing one Afghan civilian in January 2010 with a grenade and rifle; killing another in May 2010 in a similar manner; and shooting a third to death in February 2010.   U.S. military rules also prohibit \"taking or retaining individual souvenirs or trophies,\" which the photographs may be construed as.   The trial for the two soldiers is being conducted at Joint Base Lewis-McChord in Washington. Morlock's court martial is slated to begin Wednesday, while the start date for Holmes' court martial has not been publicly announced. \n",
      "['What news agency showed photos of American soldiers?', 'From what country?', 'What were the soldiers doing in the photos?', 'What was the condition of the body?', 'What does another photo show?', 'Near what?', 'What could the photos be construed as?', 'What is the name of one of the soldiers?']\n",
      "Generated ans: ['Four.', 'Four.', 'Four.', 'Four.', 'Four.', 'Four.', 'Four.', 'Four.']\n",
      "True ans: ['Der Spiegel', 'Germany', 'posing over the bodies of dead Afghans', 'bloody', 'propped up, back to back', 'military vehicle.', 'taking or retaining individual souvenirs or trophies', 'Jeremy Morlock']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████████████████████████████████████████████████████████████████████████▋    | 18/19 [00:05<00:00,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The other?Kabul, Afghanistan (CNN) -- The German news outlet Der Spiegel has published photographs of what appear to be two U.S. soldiers in Afghanistan posing over the bodies of dead Afghans -- images which threaten to further complicate the American military effort there.   Two images show the soldiers kneeling by a bloody body sprawled over a patch of sand and grass. A third shows what appears to be two bodies propped up, back to back, against a post in front of a military vehicle.   Der Spiegel identifies the soldiers as Spc. Jeremy Morlock and Pfc. Andrew Holmes, who are both facing charges relating to the wrongful deaths of Afghan civilians.   Specifically, Holmes is charged with the premeditated deaths of three civilians, possessing a dismembered human finger, wrongfully possessing photographs of human casualties, and smoking hashish.   He is also accused of conspiring with Morlock to shoot at a civilian and then toss a grenade so it would look like the soldiers were under attack.   Morlock is charged with three counts of murder. He is accused of killing one Afghan civilian in January 2010 with a grenade and rifle; killing another in May 2010 in a similar manner; and shooting a third to death in February 2010.   U.S. military rules also prohibit \"taking or retaining individual souvenirs or trophies,\" which the photographs may be construed as.   The trial for the two soldiers is being conducted at Joint Base Lewis-McChord in Washington. Morlock's court martial is slated to begin Wednesday, while the start date for Holmes' court martial has not been publicly announced. \n",
      "['The other?', 'What is Holmes being charged with?', 'Who are the two boxer featured in this article?', 'What is Mayweathers nick name?', 'what is the other', 'which stand for?', 'what is the name of his clothing line?', 'Who is Sauerland?']\n",
      "Generated ans: ['Four.', 'Four.', 'Yes.', 'Yes.', 'Yes.', 'Yes.', 'Yes.', 'Yes.']\n",
      "True ans: ['Pfc. Andrew Holmes', 'Holmes is charged with the premeditated deaths of three civilians', 'Floyd Mayweather and Manny Pacquiao', '1 is the money man', 'TBE', 'The Best Ever', 'The Money Team,', 'a boxing promoter']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:05<00:00,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how many people does he promote(CNN)A chiseled boxer's Instagram feed shows him making constant references to the Bible and enjoying gospel singing with his wife.   Another features his formidable opponent counting stacks of money, hanging out in strip clubs, and flashing diamond watches and Ferraris.   Welcome to the world of boxing promotion, circa 2015.   American Floyd Mayweather and Filipino Manny Pacquiao are set to officially announce their heavily anticipated boxing match at a press conference in Los Angeles Wednesday.   With the combined purse for the May 2 bout in Las Vegas reported to touch $300 million pending viewership numbers, the incentives to self-promote could not be higher.   \"Nowadays you have to be on social media to launch the fight and to build hype,\" says boxing promoter Nisse Sauerland, CEO of Team Sauerland. \"It couldn't be done without it.\"   Thirty-eight year old Mayweather (47-0, 26 knockouts), who favors the moniker \"The Money Man\" or \"TBE\" (The Best Ever), boasts nearly five million Instagram followers, 5.65 million followers on Twitter and 9.2 million Facebook likes.   He famously confirmed the fight via Shots, a photo sharing social media application that he's invested in, and displays links to his clothing brand, The Money Team, on all his accounts.   Along with professing to the be the best fighter of all time, he could also stake a claim to be one of the greatest social media users in sports.   \"I think they're both playing their roles,\" says Sauerland, who promotes over 45 boxers. \"You've got the bad guy and the good guy, really. You've got the guy who throws the money around (Mayweather), that's his image, and Pacquiao, he's the hope of a nation.\" \n",
      "['how many people does he promote', 'what is the combined purse for this match?', 'how old is mayweather?', 'what do they say about pacquiao and his following?', 'What is the main topic?', 'What does it stand for?', 'When did it begin?', 'Was it founded the same year?']\n",
      "Generated ans: ['Yes.', 'Yes.', 'Yes.', 'Yes.', 'November.', 'November.', 'November.', 'November.']\n",
      "True ans: ['over 45 boxers.', '$300 million pending viewership numbers', '38', 'just that it has bible references and shows him enjoying gos[e; singing with his wife', 'OCLC', 'Online Computer Library Center', '1967', 'Yes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the data collator\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer_M1, model=model_M1)\n",
    "\n",
    "# Create a DataLoader for the dataset using the data collator\n",
    "test_loader = torch.utils.data.DataLoader(tokenized_datasets_M1['test'], \n",
    "                                          batch_size=batch_size, \n",
    "                                          collate_fn=data_collator)\n",
    "torch.cuda.empty_cache()\n",
    "# Generate answersù\n",
    "i=0\n",
    "for batch in tqdm(test_loader):\n",
    "    \n",
    "    example = batch['input_ids'].to(device)\n",
    "    att_mask = batch['attention_mask'].to(device)\n",
    "    generated_ids = model_M1.generate(input_ids=example, \n",
    "                                      attention_mask=att_mask,\n",
    "                                      max_length=max_length_answer\n",
    "                                     )\n",
    "    ex = tokenizer_M1.batch_decode(example, skip_special_tokens=True)\n",
    "    print(ex[0])\n",
    "    print(dataset_COQA['test']['question'][i:i+batch_size])\n",
    "    \n",
    "    generated_answers = tokenizer_M1.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "    print(f'Generated ans: {generated_answers}')\n",
    "    true = batch[\"labels\"]\n",
    "    ground_truth = tokenizer_M1.batch_decode(true, skip_special_tokens=True)\n",
    "    print(f'True ans: {ground_truth}')\n",
    "    i+=batch_size\n",
    "    \n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
