{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8f4d21942ba8418dba2c82bcf82b092a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_218d6f277d804fc9a26aa342f343d8d3",
              "IPY_MODEL_b7df52c77ee142f29b81a22055d0a15a",
              "IPY_MODEL_c5c23da1be3d46f08652f5ec89b00e5f"
            ],
            "layout": "IPY_MODEL_e3f94bfe8ee141979955f8f55f806191"
          }
        },
        "218d6f277d804fc9a26aa342f343d8d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d0bc9d6338d48ac83c3b3887d7e033b",
            "placeholder": "​",
            "style": "IPY_MODEL_738d80200b7b4c96b1afb630c16e57cc",
            "value": "100%"
          }
        },
        "b7df52c77ee142f29b81a22055d0a15a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c6cb21868b84073bb1c1f7dc04fc2fe",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1576aecc030a4c488f87d63dc81ac8d1",
            "value": 1
          }
        },
        "c5c23da1be3d46f08652f5ec89b00e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2a68175c08c4f339d823201ed4cf02d",
            "placeholder": "​",
            "style": "IPY_MODEL_b94e8cf12aa3485295e8e0e3035720e2",
            "value": " 1/1 [00:01&lt;00:00,  1.15s/ba]"
          }
        },
        "e3f94bfe8ee141979955f8f55f806191": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d0bc9d6338d48ac83c3b3887d7e033b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "738d80200b7b4c96b1afb630c16e57cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c6cb21868b84073bb1c1f7dc04fc2fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1576aecc030a4c488f87d63dc81ac8d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2a68175c08c4f339d823201ed4cf02d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b94e8cf12aa3485295e8e0e3035720e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5500402f8ee94331af7bd87173a0e65a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78726d6de6114a49a60ae2e864c61ec7",
              "IPY_MODEL_6372149817744d7db74f50b4a8087ee8",
              "IPY_MODEL_8b833b84e8874235a983cefe782d37c8"
            ],
            "layout": "IPY_MODEL_caa16bbcab9945ce9ce52ebb08230aa8"
          }
        },
        "78726d6de6114a49a60ae2e864c61ec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2d22cdea265447fb1490058e328fdcb",
            "placeholder": "​",
            "style": "IPY_MODEL_457e8676311a4f9f9d4b8997661b0af7",
            "value": "100%"
          }
        },
        "6372149817744d7db74f50b4a8087ee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf01238f52e941fe80cd14f7401aad2b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a56d48aab8c045719dbed8d6edeb2aab",
            "value": 1
          }
        },
        "8b833b84e8874235a983cefe782d37c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e206941487e1433dbfa657de74e8395e",
            "placeholder": "​",
            "style": "IPY_MODEL_c2e8f869b41944e688dd6bdb40f9fca7",
            "value": " 1/1 [00:00&lt;00:00,  1.44ba/s]"
          }
        },
        "caa16bbcab9945ce9ce52ebb08230aa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2d22cdea265447fb1490058e328fdcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "457e8676311a4f9f9d4b8997661b0af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf01238f52e941fe80cd14f7401aad2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a56d48aab8c045719dbed8d6edeb2aab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e206941487e1433dbfa657de74e8395e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2e8f869b41944e688dd6bdb40f9fca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57a28b93f8ae4067a48d234962743659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_362c03a5f8264bb085f78cf7fe51cd86",
              "IPY_MODEL_9c29c3d670954b148264080cc5bc65c8",
              "IPY_MODEL_12f3f63977d04f1587184f2baac27ab7"
            ],
            "layout": "IPY_MODEL_bcd54bb2698c46caa98f1609797ac535"
          }
        },
        "362c03a5f8264bb085f78cf7fe51cd86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63e245d87cbf4e738fd67a6f61ab005c",
            "placeholder": "​",
            "style": "IPY_MODEL_ebd081f14c324e319b5b34bbf8a34890",
            "value": "100%"
          }
        },
        "9c29c3d670954b148264080cc5bc65c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9636b588ac1d47fe96d5847fd671771a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5dd470ed6104a15b9ce303855b066af",
            "value": 1
          }
        },
        "12f3f63977d04f1587184f2baac27ab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33f35262ca7e47b9a4a087e39925daa5",
            "placeholder": "​",
            "style": "IPY_MODEL_6ff889491fed4a038efbb04f016d5ff9",
            "value": " 1/1 [00:00&lt;00:00,  2.01ba/s]"
          }
        },
        "bcd54bb2698c46caa98f1609797ac535": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63e245d87cbf4e738fd67a6f61ab005c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebd081f14c324e319b5b34bbf8a34890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9636b588ac1d47fe96d5847fd671771a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5dd470ed6104a15b9ce303855b066af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33f35262ca7e47b9a4a087e39925daa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ff889491fed4a038efbb04f016d5ff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqNyqsO-Sbqh",
        "outputId": "127abc43-a7d4-4df5-aa9d-cdf1d51c3398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.8/dist-packages (0.19.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow_addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.8.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install tensorflow_addons\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from typing import *\n",
        "\n",
        "import os\n",
        "import urllib.request\n",
        "from tqdm import tqdm\n",
        "from copy import deepcopy\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import torch\n",
        "\n",
        "from transformers import BertForQuestionAnswering, TFAutoModelForQuestionAnswering\n",
        "from transformers import AutoTokenizer, BertTokenizer\n",
        "\n",
        "squad_v2=False"
      ],
      "metadata": {
        "id": "EGBZhUriSgPX"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DownloadProgressBar(tqdm):\n",
        "  def update_to(self, b=1, bsize=1, tsize=None):\n",
        "    if tsize is not None:\n",
        "      self.total = tsize\n",
        "    self.update(b*bsize - self.n)\n",
        "\n",
        "def download_url(url, output_path):\n",
        "  with DownloadProgressBar(unit='B', unit_scale=True, miniters=1, desc=url.split('/')[-1]) as t:\n",
        "    urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n",
        "\n",
        "def download_data(data_path, url_path, suffix):\n",
        "  if not os.path.exists(data_path):\n",
        "    os.makedirs(data_path)\n",
        "\n",
        "  data_path = os.path.join(data_path,f'{suffix}.json')\n",
        "\n",
        "  if not os.path.exists(data_path):\n",
        "    print(f\"Downloading CoQA {suffix} data split... (it may take a while)\")\n",
        "    download_url(url=url_path, output_path=data_path)\n",
        "    print(\"Download Completed!\")"
      ],
      "metadata": {
        "id": "YERtKBwKSjPV"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Data\n",
        "train_url = \"https://nlp.stanford.edu/data/coqa/coqa-train-v1.0.json\"\n",
        "download_data(data_path='coqa',url_path=train_url, suffix='train')\n",
        "\n",
        "#Test Data\n",
        "test_url = \"https://nlp.stanford.edu/data/coqa/coqa-dev-v1.0.json\"\n",
        "download_data(data_path='coqa', url_path = test_url, suffix='test')"
      ],
      "metadata": {
        "id": "Y7wFzE4ySlU7"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = json.load((open('/content/coqa/train.json')))\n",
        "qas = pd.json_normalize(train_data['data'], ['questions'], ['source', 'id', 'story'])\n",
        "ans = pd.json_normalize(train_data['data'], ['answers'],['id'])\n",
        "train_df = pd.merge(qas,ans, left_on=['id','turn_id'], right_on=['id','turn_id'])"
      ],
      "metadata": {
        "id": "d50Lxw2vSlwt"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['q_first_word']=train_df['input_text_x'].str.lower().str.extract(r'(\\w+)')\n",
        "train_df['q_first_two_words']=train_df['input_text_x'].str.lower().str.extract(r'^((?:\\S+\\s+){1}\\S+).*')"
      ],
      "metadata": {
        "id": "zGgfpOsykgYm"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.loc[train_df['input_text_y']!='unknown']"
      ],
      "metadata": {
        "id": "vNL2QiDekiXA"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = json.load((open('/content/coqa/test.json')))\n",
        "qas = pd.json_normalize(test_data['data'], ['questions'], ['source', 'id', 'story'])\n",
        "ans = pd.json_normalize(test_data['data'], ['answers'],['id'])\n",
        "test_df = pd.merge(qas,ans, left_on=['id','turn_id'], right_on=['id','turn_id'])\n",
        "test_df = test_df.loc[test_df['input_text_y']!='unknown']"
      ],
      "metadata": {
        "id": "KCHdm9p_kkrw"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, val = train_test_split(train_df, test_size=0.2, random_state=42)\n",
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "id": "RkevE1ZVkoN_",
        "outputId": "c5b16790-1bda-49a5-ac17-98a948fb4915"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 input_text_x  turn_id bad_turn_x     source  \\\n",
              "54860              So how did they get to 28?       20        NaN       race   \n",
              "69607      How much was the package in value?        9        NaN        cnn   \n",
              "94456  Did she think Adams was untrustworthy?        6        NaN        cnn   \n",
              "94333                  Who was he talking to?        3        NaN  gutenberg   \n",
              "47220   What does Pleistocene mean literally?       15        NaN  wikipedia   \n",
              "\n",
              "                                   id  \\\n",
              "54860  39dd6s19jpbtyxnmal6qgea8wr2ze3   \n",
              "69607  3ii4upycoj7fsz8vructj3gjsr7qdt   \n",
              "94456  3wq3b2kge8gywyqusjv8nckbhrp1bi   \n",
              "94333  3qapzx2qn4d41w5gd7yx8eyxhj320q   \n",
              "47220  3nvc2eb65qzqj9xkpfnbjgx90ke3yk   \n",
              "\n",
              "                                                   story  span_start  \\\n",
              "54860  Where did that number come from? Eleven and Tw...        1639   \n",
              "69607  Abidjan, Ivory Coast (CNN) -- The European Uni...          80   \n",
              "94456  ATLANTA, Georgia (CNN) -- Michele Trobaugh reg...         426   \n",
              "94333  CHAPTER V--\"BLOODY AS THE HUNTER\" \\n\\nThe lads...        1208   \n",
              "47220  The Pleistocene (, often colloquially referred...        1410   \n",
              "\n",
              "       span_end                                          span_text  \\\n",
              "54860      1740  he took one day from each of the 30-day months...   \n",
              "69607        98                                  180 million euros   \n",
              "94456       462               She says she trusted him right away.   \n",
              "94333      1244               \"Ye but deride me,\" answered Matcham   \n",
              "47220      1420                                         \"Most New\"   \n",
              "\n",
              "                                            input_text_y bad_turn_y  \\\n",
              "54860  he took one day from each of the 30-day months...        NaN   \n",
              "69607                                  180 million euros        NaN   \n",
              "94456                                                 No        NaN   \n",
              "94333                                            Matcham        NaN   \n",
              "47220                                        \"Most New.\"        NaN   \n",
              "\n",
              "      q_first_word q_first_two_words  \n",
              "54860           so            so how  \n",
              "69607          how          how much  \n",
              "94456          did           did she  \n",
              "94333          who           who was  \n",
              "47220         what         what does  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17492872-653f-4ade-ac1b-1ce00083a046\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_text_x</th>\n",
              "      <th>turn_id</th>\n",
              "      <th>bad_turn_x</th>\n",
              "      <th>source</th>\n",
              "      <th>id</th>\n",
              "      <th>story</th>\n",
              "      <th>span_start</th>\n",
              "      <th>span_end</th>\n",
              "      <th>span_text</th>\n",
              "      <th>input_text_y</th>\n",
              "      <th>bad_turn_y</th>\n",
              "      <th>q_first_word</th>\n",
              "      <th>q_first_two_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>54860</th>\n",
              "      <td>So how did they get to 28?</td>\n",
              "      <td>20</td>\n",
              "      <td>NaN</td>\n",
              "      <td>race</td>\n",
              "      <td>39dd6s19jpbtyxnmal6qgea8wr2ze3</td>\n",
              "      <td>Where did that number come from? Eleven and Tw...</td>\n",
              "      <td>1639</td>\n",
              "      <td>1740</td>\n",
              "      <td>he took one day from each of the 30-day months...</td>\n",
              "      <td>he took one day from each of the 30-day months...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>so</td>\n",
              "      <td>so how</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69607</th>\n",
              "      <td>How much was the package in value?</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cnn</td>\n",
              "      <td>3ii4upycoj7fsz8vructj3gjsr7qdt</td>\n",
              "      <td>Abidjan, Ivory Coast (CNN) -- The European Uni...</td>\n",
              "      <td>80</td>\n",
              "      <td>98</td>\n",
              "      <td>180 million euros</td>\n",
              "      <td>180 million euros</td>\n",
              "      <td>NaN</td>\n",
              "      <td>how</td>\n",
              "      <td>how much</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94456</th>\n",
              "      <td>Did she think Adams was untrustworthy?</td>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cnn</td>\n",
              "      <td>3wq3b2kge8gywyqusjv8nckbhrp1bi</td>\n",
              "      <td>ATLANTA, Georgia (CNN) -- Michele Trobaugh reg...</td>\n",
              "      <td>426</td>\n",
              "      <td>462</td>\n",
              "      <td>She says she trusted him right away.</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>did</td>\n",
              "      <td>did she</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94333</th>\n",
              "      <td>Who was he talking to?</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gutenberg</td>\n",
              "      <td>3qapzx2qn4d41w5gd7yx8eyxhj320q</td>\n",
              "      <td>CHAPTER V--\"BLOODY AS THE HUNTER\" \\n\\nThe lads...</td>\n",
              "      <td>1208</td>\n",
              "      <td>1244</td>\n",
              "      <td>\"Ye but deride me,\" answered Matcham</td>\n",
              "      <td>Matcham</td>\n",
              "      <td>NaN</td>\n",
              "      <td>who</td>\n",
              "      <td>who was</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47220</th>\n",
              "      <td>What does Pleistocene mean literally?</td>\n",
              "      <td>15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>wikipedia</td>\n",
              "      <td>3nvc2eb65qzqj9xkpfnbjgx90ke3yk</td>\n",
              "      <td>The Pleistocene (, often colloquially referred...</td>\n",
              "      <td>1410</td>\n",
              "      <td>1420</td>\n",
              "      <td>\"Most New\"</td>\n",
              "      <td>\"Most New.\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>what</td>\n",
              "      <td>what does</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17492872-653f-4ade-ac1b-1ce00083a046')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-17492872-653f-4ade-ac1b-1ce00083a046 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-17492872-653f-4ade-ac1b-1ce00083a046');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = train[['id','story','input_text_x', 'input_text_y', 'span_text', 'span_start','span_end']]\n",
        "val = val[['id','story','input_text_x', 'input_text_y', 'span_text', 'span_start','span_end']]\n",
        "test_df = test_df[['id','story','input_text_x', 'input_text_y', 'span_text', 'span_start','span_end']]\n",
        "train.rename(columns={'input_text_x': 'questions', 'input_text_y': 'answers', 'span_text': 'reasons'}, inplace=True)\n",
        "val.rename(columns={'input_text_x': 'questions', 'input_text_y': 'answers', 'span_text': 'reasons'}, inplace=True)\n",
        "test_df.rename(columns={'input_text_x': 'questions', 'input_text_y': 'answers', 'span_text': 'reasons'}, inplace=True)\n",
        "display(train.head(),val.head(),test_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "565p6CqnkrIo",
        "outputId": "c3c46bc3-cad8-4f61-a34d-16cb503291b2"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:5039: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return super().rename(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                   id  \\\n",
              "54860  39dd6s19jpbtyxnmal6qgea8wr2ze3   \n",
              "69607  3ii4upycoj7fsz8vructj3gjsr7qdt   \n",
              "94456  3wq3b2kge8gywyqusjv8nckbhrp1bi   \n",
              "94333  3qapzx2qn4d41w5gd7yx8eyxhj320q   \n",
              "47220  3nvc2eb65qzqj9xkpfnbjgx90ke3yk   \n",
              "\n",
              "                                                   story  \\\n",
              "54860  Where did that number come from? Eleven and Tw...   \n",
              "69607  Abidjan, Ivory Coast (CNN) -- The European Uni...   \n",
              "94456  ATLANTA, Georgia (CNN) -- Michele Trobaugh reg...   \n",
              "94333  CHAPTER V--\"BLOODY AS THE HUNTER\" \\n\\nThe lads...   \n",
              "47220  The Pleistocene (, often colloquially referred...   \n",
              "\n",
              "                                    questions  \\\n",
              "54860              So how did they get to 28?   \n",
              "69607      How much was the package in value?   \n",
              "94456  Did she think Adams was untrustworthy?   \n",
              "94333                  Who was he talking to?   \n",
              "47220   What does Pleistocene mean literally?   \n",
              "\n",
              "                                                 answers  \\\n",
              "54860  he took one day from each of the 30-day months...   \n",
              "69607                                  180 million euros   \n",
              "94456                                                 No   \n",
              "94333                                            Matcham   \n",
              "47220                                        \"Most New.\"   \n",
              "\n",
              "                                                 reasons  span_start  span_end  \n",
              "54860  he took one day from each of the 30-day months...        1639      1740  \n",
              "69607                                  180 million euros          80        98  \n",
              "94456               She says she trusted him right away.         426       462  \n",
              "94333               \"Ye but deride me,\" answered Matcham        1208      1244  \n",
              "47220                                         \"Most New\"        1410      1420  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-096560c8-2b50-430b-ba65-7a2ff6636e56\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>story</th>\n",
              "      <th>questions</th>\n",
              "      <th>answers</th>\n",
              "      <th>reasons</th>\n",
              "      <th>span_start</th>\n",
              "      <th>span_end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>54860</th>\n",
              "      <td>39dd6s19jpbtyxnmal6qgea8wr2ze3</td>\n",
              "      <td>Where did that number come from? Eleven and Tw...</td>\n",
              "      <td>So how did they get to 28?</td>\n",
              "      <td>he took one day from each of the 30-day months...</td>\n",
              "      <td>he took one day from each of the 30-day months...</td>\n",
              "      <td>1639</td>\n",
              "      <td>1740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69607</th>\n",
              "      <td>3ii4upycoj7fsz8vructj3gjsr7qdt</td>\n",
              "      <td>Abidjan, Ivory Coast (CNN) -- The European Uni...</td>\n",
              "      <td>How much was the package in value?</td>\n",
              "      <td>180 million euros</td>\n",
              "      <td>180 million euros</td>\n",
              "      <td>80</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94456</th>\n",
              "      <td>3wq3b2kge8gywyqusjv8nckbhrp1bi</td>\n",
              "      <td>ATLANTA, Georgia (CNN) -- Michele Trobaugh reg...</td>\n",
              "      <td>Did she think Adams was untrustworthy?</td>\n",
              "      <td>No</td>\n",
              "      <td>She says she trusted him right away.</td>\n",
              "      <td>426</td>\n",
              "      <td>462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94333</th>\n",
              "      <td>3qapzx2qn4d41w5gd7yx8eyxhj320q</td>\n",
              "      <td>CHAPTER V--\"BLOODY AS THE HUNTER\" \\n\\nThe lads...</td>\n",
              "      <td>Who was he talking to?</td>\n",
              "      <td>Matcham</td>\n",
              "      <td>\"Ye but deride me,\" answered Matcham</td>\n",
              "      <td>1208</td>\n",
              "      <td>1244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47220</th>\n",
              "      <td>3nvc2eb65qzqj9xkpfnbjgx90ke3yk</td>\n",
              "      <td>The Pleistocene (, often colloquially referred...</td>\n",
              "      <td>What does Pleistocene mean literally?</td>\n",
              "      <td>\"Most New.\"</td>\n",
              "      <td>\"Most New\"</td>\n",
              "      <td>1410</td>\n",
              "      <td>1420</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-096560c8-2b50-430b-ba65-7a2ff6636e56')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-096560c8-2b50-430b-ba65-7a2ff6636e56 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-096560c8-2b50-430b-ba65-7a2ff6636e56');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                   id  \\\n",
              "90158  3uj1cz6izhpw128f4sjfgr7sxvrs53   \n",
              "90995  3ouygizwr7y0t36mf5994r6qtxgp0u   \n",
              "88481  3ryc5t2d73totxql9isoon7d2tsrpj   \n",
              "6129   3hutx6f6vunp4dxzfs08yfuffl8o2p   \n",
              "14367  3ty7zaog5fkzic962d418akrztkk0a   \n",
              "\n",
              "                                                   story  \\\n",
              "90158  Hong Kong, officially the Hong Kong Special Ad...   \n",
              "90995  Volleyball has become a worldwide sport that i...   \n",
              "88481  (CNN)The suspect behind the knife attack on th...   \n",
              "6129   A Sudanese woman sentenced to die for refusing...   \n",
              "14367  Baronets are a rank in the British aristocracy...   \n",
              "\n",
              "                                           questions  \\\n",
              "90158  Are they involved with China in these groups?   \n",
              "90995      Did it remain popular for that age group?   \n",
              "88481                   was he invited to the event?   \n",
              "6129               What about her mother's religion?   \n",
              "14367                             What was the cost?   \n",
              "\n",
              "                          answers  \\\n",
              "90158                          no   \n",
              "90995                         Yes   \n",
              "88481                          no   \n",
              "6129   she was Ethiopian Orthodox   \n",
              "14367                      £1,095   \n",
              "\n",
              "                                                 reasons  span_start  span_end  \n",
              "90158  such as the Asia-Pacific Economic Cooperation ...        1440      1559  \n",
              "90995                        popular with all age groups          48        75  \n",
              "88481                wasn't on the list of those invited        1553      1588  \n",
              "6129                   her mother was Ethiopian Orthodox        1366      1399  \n",
              "14367                                             £1,095         511       517  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-957a3eab-1950-48c7-9086-13966069bdf0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>story</th>\n",
              "      <th>questions</th>\n",
              "      <th>answers</th>\n",
              "      <th>reasons</th>\n",
              "      <th>span_start</th>\n",
              "      <th>span_end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>90158</th>\n",
              "      <td>3uj1cz6izhpw128f4sjfgr7sxvrs53</td>\n",
              "      <td>Hong Kong, officially the Hong Kong Special Ad...</td>\n",
              "      <td>Are they involved with China in these groups?</td>\n",
              "      <td>no</td>\n",
              "      <td>such as the Asia-Pacific Economic Cooperation ...</td>\n",
              "      <td>1440</td>\n",
              "      <td>1559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90995</th>\n",
              "      <td>3ouygizwr7y0t36mf5994r6qtxgp0u</td>\n",
              "      <td>Volleyball has become a worldwide sport that i...</td>\n",
              "      <td>Did it remain popular for that age group?</td>\n",
              "      <td>Yes</td>\n",
              "      <td>popular with all age groups</td>\n",
              "      <td>48</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88481</th>\n",
              "      <td>3ryc5t2d73totxql9isoon7d2tsrpj</td>\n",
              "      <td>(CNN)The suspect behind the knife attack on th...</td>\n",
              "      <td>was he invited to the event?</td>\n",
              "      <td>no</td>\n",
              "      <td>wasn't on the list of those invited</td>\n",
              "      <td>1553</td>\n",
              "      <td>1588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6129</th>\n",
              "      <td>3hutx6f6vunp4dxzfs08yfuffl8o2p</td>\n",
              "      <td>A Sudanese woman sentenced to die for refusing...</td>\n",
              "      <td>What about her mother's religion?</td>\n",
              "      <td>she was Ethiopian Orthodox</td>\n",
              "      <td>her mother was Ethiopian Orthodox</td>\n",
              "      <td>1366</td>\n",
              "      <td>1399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14367</th>\n",
              "      <td>3ty7zaog5fkzic962d418akrztkk0a</td>\n",
              "      <td>Baronets are a rank in the British aristocracy...</td>\n",
              "      <td>What was the cost?</td>\n",
              "      <td>£1,095</td>\n",
              "      <td>£1,095</td>\n",
              "      <td>511</td>\n",
              "      <td>517</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-957a3eab-1950-48c7-9086-13966069bdf0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-957a3eab-1950-48c7-9086-13966069bdf0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-957a3eab-1950-48c7-9086-13966069bdf0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                               id  \\\n",
              "0  3dr23u6we5exclen4th8uq9rb42tel   \n",
              "1  3dr23u6we5exclen4th8uq9rb42tel   \n",
              "2  3dr23u6we5exclen4th8uq9rb42tel   \n",
              "3  3dr23u6we5exclen4th8uq9rb42tel   \n",
              "4  3dr23u6we5exclen4th8uq9rb42tel   \n",
              "\n",
              "                                               story  \\\n",
              "0  Once upon a time, in a barn near a farm house,...   \n",
              "1  Once upon a time, in a barn near a farm house,...   \n",
              "2  Once upon a time, in a barn near a farm house,...   \n",
              "3  Once upon a time, in a barn near a farm house,...   \n",
              "4  Once upon a time, in a barn near a farm house,...   \n",
              "\n",
              "                      questions                       answers  \\\n",
              "0        What color was Cotton?                         white   \n",
              "1           Where did she live?                     in a barn   \n",
              "2           Did she live alone?                            no   \n",
              "3        Who did she live with?  with her mommy and 5 sisters   \n",
              "4  What color were her sisters?              orange and white   \n",
              "\n",
              "                                             reasons  span_start  span_end  \n",
              "0                 a little white kitten named Cotton          59        93  \n",
              "1  in a barn near a farm house, there lived a lit...          18        80  \n",
              "2                                Cotton wasn't alone         196       215  \n",
              "3                 with her mommy and 5 other sisters         281       315  \n",
              "4  her sisters were all orange with beautiful whi...         428       490  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-30919fbc-b116-49f9-bc92-1ffdf1110a8e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>story</th>\n",
              "      <th>questions</th>\n",
              "      <th>answers</th>\n",
              "      <th>reasons</th>\n",
              "      <th>span_start</th>\n",
              "      <th>span_end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3dr23u6we5exclen4th8uq9rb42tel</td>\n",
              "      <td>Once upon a time, in a barn near a farm house,...</td>\n",
              "      <td>What color was Cotton?</td>\n",
              "      <td>white</td>\n",
              "      <td>a little white kitten named Cotton</td>\n",
              "      <td>59</td>\n",
              "      <td>93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3dr23u6we5exclen4th8uq9rb42tel</td>\n",
              "      <td>Once upon a time, in a barn near a farm house,...</td>\n",
              "      <td>Where did she live?</td>\n",
              "      <td>in a barn</td>\n",
              "      <td>in a barn near a farm house, there lived a lit...</td>\n",
              "      <td>18</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3dr23u6we5exclen4th8uq9rb42tel</td>\n",
              "      <td>Once upon a time, in a barn near a farm house,...</td>\n",
              "      <td>Did she live alone?</td>\n",
              "      <td>no</td>\n",
              "      <td>Cotton wasn't alone</td>\n",
              "      <td>196</td>\n",
              "      <td>215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3dr23u6we5exclen4th8uq9rb42tel</td>\n",
              "      <td>Once upon a time, in a barn near a farm house,...</td>\n",
              "      <td>Who did she live with?</td>\n",
              "      <td>with her mommy and 5 sisters</td>\n",
              "      <td>with her mommy and 5 other sisters</td>\n",
              "      <td>281</td>\n",
              "      <td>315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3dr23u6we5exclen4th8uq9rb42tel</td>\n",
              "      <td>Once upon a time, in a barn near a farm house,...</td>\n",
              "      <td>What color were her sisters?</td>\n",
              "      <td>orange and white</td>\n",
              "      <td>her sisters were all orange with beautiful whi...</td>\n",
              "      <td>428</td>\n",
              "      <td>490</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30919fbc-b116-49f9-bc92-1ffdf1110a8e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-30919fbc-b116-49f9-bc92-1ffdf1110a8e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-30919fbc-b116-49f9-bc92-1ffdf1110a8e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "data_train = Dataset.from_pandas(train)\n",
        "data_val = Dataset.from_pandas(val)"
      ],
      "metadata": {
        "id": "4dXL4HYtTJ39"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import ClassLabel, Sequence\n",
        "import random\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "\n",
        "def show_random_elements(dataset, num_examples=10):\n",
        "    assert num_examples <= len(\n",
        "        dataset\n",
        "    ), \"Can't pick more elements than there are in the dataset.\"\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset) - 1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset) - 1)\n",
        "        picks.append(pick)\n",
        "\n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
        "            df[column] = df[column].transform(\n",
        "                lambda x: [typ.feature.names[i] for i in x]\n",
        "            )\n",
        "    display(HTML(df.to_html()))"
      ],
      "metadata": {
        "id": "Sk8qic0NTSYi"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_random_elements(data_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wRp97UPvTcv-",
        "outputId": "30ed35b8-4fda-4c46-f58d-3dd80e129f35"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>story</th>\n",
              "      <th>questions</th>\n",
              "      <th>answers</th>\n",
              "      <th>reasons</th>\n",
              "      <th>span_start</th>\n",
              "      <th>span_end</th>\n",
              "      <th>__index_level_0__</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3fui0jhjpxyp360w0uultm1wq81339</td>\n",
              "      <td>(CNN) -- Sidney Frank made millions marketing Jagermeister and other alcohol brands. Three years after his death, he's a big hit with students at the Ivy League college he briefly attended. \\n\\nSidney Frank, shown accepting an honorary degree in 2005, gave $100 million to Brown University. \\n\\nHe's a big hit not because of what he sold but because he's given dozens of them what he couldn't afford as a young man: an education at Rhode Island's Brown University. \\n\\nOn Sunday, 49 students from low-income families became the first four-year Sidney E. Frank Scholars to graduate from Brown, owing virtually nothing except gratitude to the late liquor magnate. \\n\\n\"The world of difference that he made for each and every one of us is unbelievable, incredible,\" one of the Frank Scholars, 22-year-old Shane Reil, said Sunday. \\n\\nFrank -- who left Brown after one year in the late 1930s because he couldn't afford to stay -- gave the school a $100 million endowment in 2004. He stipulated that the fund's income go exclusively to covering all tuition and expenses for the neediest of Brown's admitted applicants. Hear graduates say how their dreams came true » \\n\\nFor this year's graduates, tuition and expenses came to a four-year total of about $180,000 each. The median annual income of the recipients' families was $18,984. \\n\\nThe gift was the largest single one ever given to Brown and one of the largest ever given for undergraduate scholarships in the United States, according to the school. \\n\\nReil, a history major who is preparing to co-chair a student conference on U.S.-South Korean relations and aspires to work in politics or foreign service, says the scholarship was the stuff of dreams.</td>\n",
              "      <td>Who is Shane Reil?</td>\n",
              "      <td>a history major .</td>\n",
              "      <td>Reil, a history major who is preparing to co-chair a student conference on U.S.-South Korean relations and aspires to work in politics or foreign service, says the scholarship was the stuff of dreams.</td>\n",
              "      <td>1490</td>\n",
              "      <td>1690</td>\n",
              "      <td>66565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3vzlgyjeyla24xe35qwi43vfd6oxz4</td>\n",
              "      <td>LONDON, England (CNN) -- The death of a teenage girl in a Welsh village in an apparent copycat suicide has raised fears she may have been part of an Internet death cult already blamed for the deaths of six young men. \\n\\nNatasha Randall, 17, who was found hanged in her bedroom in Blaengarw, near Bridgend, south Wales, on Thursday, was the seventh person believed to have killed themselves in the local area in the past 12 months, the UK's Press Association reported. \\n\\nPolice are examining Randall's computer after the teenager posted messages on a social networking site, Bebo, prior to her death dedicated to 20-year-old Liam Clarke, who was found hanged in a Bridgend park last month. \\n\\nThe message read: \"RIP Clarky boy!! gonna miss ya! always remember the gd times! love ya x. Me too!\" \\n\\nMessages have also been posted on Randall's page since her death, PA said. \"RIP tash - can't believe you done it!\" one said. Another read: \"Heyaa Babe. Just Poppin In To Say I Let My Balloon Off With A Message On It, Hope You Got It Ok And It Made You Laugh Up There.\" \\n\\nFive more men aged between 17 and 27 have been found hanged in the area since January 2007. \\n\\nSpeaking to the Daily Mail newspaper, Liam Clarke's father, Kevin Clarke, said the seven who had killed themselves appeared to have known each other. \\n\\n\"We don't know if it is some weird cult or copycat suicides or if they have had some bizarre pact to kill themselves,\" Clarke said.</td>\n",
              "      <td>According to who?</td>\n",
              "      <td>UK's Press Association</td>\n",
              "      <td>the UK's Press Association reported</td>\n",
              "      <td>430</td>\n",
              "      <td>465</td>\n",
              "      <td>22613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3pb5a5bd0v68y1d7xl4vpx2l0qwg7q</td>\n",
              "      <td>CHAPTER XIII \\n\\nTHE WESTERN EXPRESS \\n\\nThe old miser was very much excited and began to pace the floor of his cottage. \\n\\n\"Yes, I better tell the police, that's what I better do,\" he muttered. \\n\\n\"There won't be any necessity to tell the police--if it was really my brother who did it,\" said Sam. \\n\\n\"Why not, I'd like to know?\" challenged Hiram Duff. \"He ain't no better'n other folks.\" \\n\\n\"If he took the box, I and my family will see to it that you are repaid for your loss, Mr. Duff,\" answered the youngest Rover. \\n\\n\"Humph! Do you guarantee that?\" demanded the old miser, suspiciously. \\n\\n\"Yes.\" \\n\\n\"And you can take his word for it, sir,\" added Songbird. \"The Rovers are well-known and wealthy, and they will do exactly as they promise. \\n\\n\"I've heard that name before. Didn't you have some trouble with the railroad company?\" asked Hiram Duff. \"About a busted-up flying machine?\" \\n\\n\"Yes,\" replied Sam. \\n\\n\"And got the best of that skinflint lawyer, Belright Fogg?\" \\n\\n\"We made Mr. Fogg pay for the biplane, yes.\" \\n\\n\"I know all about it,\" chuckled Hiram Duff. \"Served Fogg right. And he lost his job with the railroad company, too.\" The old man pursed up his lips. \"Well, if you'll give me your word that you will settle with me I won't go to the police. But I want every cent that is coming to me, understand that.\" \\n\\n\"You'll get it--if my brother took the box,\" answered Sam. \"But listen to me. First of all I want to find my brother. I think he ought to be under a doctor's care.\"</td>\n",
              "      <td>Whose sibling is that?</td>\n",
              "      <td>Rover.</td>\n",
              "      <td>answered the youngest Rover.</td>\n",
              "      <td>482</td>\n",
              "      <td>512</td>\n",
              "      <td>82442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>320duz38g7m1iwe9yutssn7urg5gjw</td>\n",
              "      <td>Lying in the sun on a rock, the cougar saw Jeb and his son, Tom, before they saw it. Jeb put his bag down quickly and pulled his jacket open with both hands, making himself look big to the cougar. It worked. The cougar hesitated, ready to attack Jeb, but ready to forget the whole thing, too. \\n\\nJeb let go of his jacket, grasped Tom and held him across his body, making a cross. Now the cougar's enemy looked even bigger, and it rose up, ready to move away, but unfortunately Tom got scared and struggled free of Jeb. \\n\\n\"Tom, no!\" shouted his father. \\n\\nBut Tom broke and ran and that's the last thing you do with a cougar. The second Tom broke free, Jeb threw himself on the cougar, just as it jumped from the rock. They hit each other in mid-air and both fell. The cougar was on Jeb in a flash, forgetting about Tom, which was what Jeb wanted. \\n\\nCougars are not as big as most people think and a determined man stands a chance, even with just his fists. As the cougar's claws got into his left shoulder, Jeb swung his fist at its eyes and hit hard. The animal howled and put its head back. Jeb followed up with his other fist. Then out of the corner of his eye, Jeb saw Tom. The boy was running back to help his father. \\n\\n\"Knife, Tom\" shouted Jeb. \\n\\nThe boy ran to his father's bag, while Jeb stated shouting as well as hitting, to keep the cougar's attention away from Tom. Tom got the knife and ran over to Jeb. The cougar was moving its head in and out, trying to find a way through the wall Jeb was making out of his arms. Tom swung with the knife, into the cougar's back. It howled horribly and ran off into the mountains. \\n\\nThe whole fight had taken about thirty seconds.</td>\n",
              "      <td>Does he have a child?</td>\n",
              "      <td>Yes.</td>\n",
              "      <td>Tom, no!\" shouted his father. \\n</td>\n",
              "      <td>521</td>\n",
              "      <td>552</td>\n",
              "      <td>75165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3cn4lgxd5xob15goptsutlpfefyy4e</td>\n",
              "      <td>\"Ceci, wake up. It's an earthquake!\" That's what Cecilia Wallace heard her mother shouting on the early morning of February 27th. \\n\\nCecilia is a 7th-grader. She, her parents and her brother, Sam, were in Chile's capital city, Santiago, the day a big earthquake hit Chile. And like just about everyone else, they were shaken out of their sleep. \\n\\n\"It was so frightening,\" Sam wrote. \"The shaking was so huge that I will never go on a ride again.\" Cecilia and Sam wrote about their earthquake experiences. Their reports were later posted on the website. \\n\\nCecilia, Sam and their parents were staying in an apartment on the 15th floor of a building. They were lucky. Their building stayed standing, because it was built to withstand earthquakes. \\n\\nNot everyone was as lucky as the Wallace family. More than 800 people died. Many older buildings fell down during the earthquake. \\n\\nThe damage in Santiago wasn't as bad as in other parts of Chile. So the supermarkets were open for business on the morning of the quake. But it wasn't business as usual. \"The supermarkets have been crazy with people rushing to buy their food for the next while,\" Sam wrote. \\n\\nNot everyone was able to get money to buy food that morning. So Cecilia and Sam made food bags to _ to people who were begging outside the supermarket. \"We gave some to a kid of my age. I made sure he got cookies and bread.\" Sam and Cecilia's mother wrote that the kids also collected money for the Red Cross. \\n\\nIt's certainly an experience Cecilia, Sam and their parents will never forget. Thankfully, they lived to tell their stories.</td>\n",
              "      <td>Where did the family live in Chile?</td>\n",
              "      <td>in Chile's capital city, Santiago</td>\n",
              "      <td>in Chile's capital city, Santiago</td>\n",
              "      <td>201</td>\n",
              "      <td>234</td>\n",
              "      <td>52491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3lpw2n6lkt2cgf0jtxefvspgiwju50</td>\n",
              "      <td>.British people are famous for drinking tea. But brother and sister, Sarah and Bobby Green, became young millionaires when they opened a chain of American-style coffee shops in the UK. Having the idea: It started when Sarah took a weekend trip to New York to visit her brother Bobby. One evening, in a Thai restaurant, Sarah told Bobby how much she wished she could buy American-style coffee in London. Bobby suggested they started their own coffee shop. Sarah fell in love with the idea. Doing the Research: Back in London, she spent a whole day on the London subway, getting off the train at different stations to taste the coffee. \"It was terrible, and I knew there was a gap in the market.\" In 1995, they opened their first Coffee Republic shop in central London. Making it work: The first year was very difficult. British people were not used to the names of American coffees, like latte and macchiato. But being successful was their dream and they were not going to give up. Today, there are over 100 Coffee Republic shops all over the country and the company has PS30 million a year. Advice for others: Sarah has now written a best-selling book about their experience, calledAnyone Can Do It ! She hopes it will help other young people to start their own businesses. She says, \"If you think you have the energy, then get out and follow your dream.\"</td>\n",
              "      <td>What do you need to do to follow your dream?</td>\n",
              "      <td>Get out and follow it</td>\n",
              "      <td>\"If you think you have the energy, then get out and follow your dream.\"</td>\n",
              "      <td>1284</td>\n",
              "      <td>1355</td>\n",
              "      <td>83517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3xm0hyn6nkzzktlgnc8opg8un5dpeh</td>\n",
              "      <td>CHAPTER XXV \\n\\nMARCHING ORDERS \\n\\nA silence followed. To Mike, lying in bed, holding his breath, it seemed a long silence. As a matter of fact it lasted for perhaps ten seconds. Then Mr. Wain spoke. \\n\\n\"You have been out, James?\" \\n\\nIt is curious how in the more dramatic moments of life the inane remark is the first that comes to us. \\n\\n\"Yes, sir,\" said Wyatt. \\n\\n\"I am astonished. Exceedingly astonished.\" \\n\\n\"I got a bit of a start myself,\" said Wyatt. \\n\\n\"I shall talk to you in my study. Follow me there.\" \\n\\n\"Yes, sir.\" \\n\\nHe left the room, and Wyatt suddenly began to chuckle. \\n\\n\"I say, Wyatt!\" said Mike, completely thrown off his balance by the events of the night. \\n\\nWyatt continued to giggle helplessly. He flung himself down on his bed, rolling with laughter. Mike began to get alarmed. \\n\\n\"It's all right,\" said Wyatt at last, speaking with difficulty. \"But, I say, how long had he been sitting there?\" \\n\\n\"It seemed hours. About an hour, I suppose, really.\" \\n\\n\"It's the funniest thing I've ever struck. Me sweating to get in quietly, and all the time him camping out on my bed!\" \\n\\n\"But look here, what'll happen?\" \\n\\nWyatt sat up. \\n\\n\"That reminds me. Suppose I'd better go down.\" \\n\\n\"What'll he do, do you think?\" \\n\\n\"Ah, now, what!\" \\n\\n\"But, I say, it's awful. What'll happen?\" \\n\\n\"That's for him to decide. Speaking at a venture, I should say----\" \\n\\n\"You don't think----?\" \\n\\n\"The boot. The swift and sudden boot. I shall be sorry to part with you, but I'm afraid it's a case of 'Au revoir, my little Hyacinth.' We shall meet at Philippi. This is my Moscow. To-morrow I shall go out into the night with one long, choking sob. Years hence a white-haired bank-clerk will tap at your door when you're a prosperous professional cricketer with your photograph in _Wisden_. That'll be me. Well, I suppose I'd better go down. We'd better all get to bed _some_ time to-night. Don't go to sleep.\"</td>\n",
              "      <td>Who said something after it?</td>\n",
              "      <td>Mr. Wain</td>\n",
              "      <td>As a matter of fact it lasted for perhaps ten seconds. Then Mr. Wain spoke.</td>\n",
              "      <td>121</td>\n",
              "      <td>197</td>\n",
              "      <td>18671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3ywrv122cszv3xjlrvli7cz7km4u8m</td>\n",
              "      <td>CHAPTER XVII \\n\\nTHREE DAYS \\n\\nLincoln awaited Graham in an apartment beneath the flying stages. He seemed curious to learn all that had happened, pleased to hear of the extraordinary delight and interest which Graham took in flying. Graham was in a mood of enthusiasm. \"I must learn to fly,\" he cried. \"I must master that. I pity all poor souls who have died without this opportunity. The sweet swift air! It is the most wonderful experience in the world.\" \\n\\n\"You will find our new times full of wonderful experiences,\" said Lincoln. \"I do not know what you will care to do now. We have music that may seem novel.\" \\n\\n\"For the present,\" said Graham, \"flying holds me. Let me learn more of that. Your aeronaut was saying there is some trades union objection to one's learning.\" \\n\\n\"There is, I believe,\" said Lincoln. \"But for you--! If you would like to occupy yourself with that, we can make you a sworn aeronaut to-morrow.\" \\n\\nGraham expressed his wishes vividly and talked of his sensations for a while. \"And as for affairs,\" he asked abruptly. \"How are things going on?\" \\n\\nLincoln waved affairs aside. \"Ostrog will tell you that to-morrow,\" he said. \"Everything is settling down. The Revolution accomplishes itself all over the world. Friction is inevitable here and there, of course; but your rule is assured. You may rest secure with things in Ostrog's hands.\" \\n\\n\"Would it be possible for me to be made a sworn aeronaut, as you call it, forthwith--before I sleep?\" said Graham, pacing. \"Then I could be at it the very first thing to-morrow again....\"</td>\n",
              "      <td>whose rule is assured?</td>\n",
              "      <td>Graham</td>\n",
              "      <td>Graham</td>\n",
              "      <td>924</td>\n",
              "      <td>930</td>\n",
              "      <td>105780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3ftyuglfsulqzdpx72oqlslsvfw5da</td>\n",
              "      <td>Hellen Keller was born in 1880 in the USA. When she was about 19 months old, she got very ill. After many weeks, the doctor told her parents, \"Your daughter is better, but now she can't see and she can't hear.\" Her mother and her father were very sad. After a few years , things got worse. There was no way for Helen to speak to other people. She heard nothing. She didn't understand anything. Then one day a teacher came. Her name was Anne Sullivan. She lived with Helen and her family. The teacher helped Helen learn words. Helen was a very bright child and soon she learned to spell her first word. When she was older, she went to college . Helen was a very old woman when she died. The world remembers her today as a brave and wonderful person. She was blind and deaf, but she found a way to see and hear. It helped many people in the world.</td>\n",
              "      <td>When?</td>\n",
              "      <td>1880</td>\n",
              "      <td>in 1880</td>\n",
              "      <td>23</td>\n",
              "      <td>30</td>\n",
              "      <td>80107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3auqqel7u5tdyn3i1hi8ajv8ft30vs</td>\n",
              "      <td>CHAPTER V. \\n\\nIN LOWER EGYPT. \\n\\n\"I am going on a journey,\" Ameres said to his son a few days after the return from the farm. \"I shall take you with me, Chebron, for I am going to view the progress of a fresh canal that is being made on our estate in Goshen. The officer who is superintending it has doubts whether, when the sluices are opened, it will altogether fulfill its purpose, and I fear that some mistake must have been made in the levels. I have already taught you the theory of the work; it is well that you should gain some practical experience in it; for there is no more useful or honorable profession than that of carrying out works by which the floods of the Nile are conveyed to the thirsty soil.\" \\n\\n\"Thank you, father. I should like it greatly,\" Chebron replied in a tone of delight, for he had never before been far south of Thebes. \"And may Amuba go with us?\" \\n\\n\"Yes; I was thinking of taking him,\" the high priest said. \"Jethro can also go, for I take a retinue with me. Did I consult my own pleasure I would far rather travel without this state and ceremony; but as a functionary of state I must conform to the customs. And, indeed, even in Goshen it is as well always to travel in some sort of state. The people there are of a different race to ourselves. Although they have dwelt a long time in the land and conform to its customs, still they are notoriously a stubborn and obstinate people, and there is more trouble in getting the public works executed there than in any other part of the country.\"</td>\n",
              "      <td>And what would he attain on this trip hopefully?</td>\n",
              "      <td>practical experience</td>\n",
              "      <td>; it is well that you should gain some practical experience in it;</td>\n",
              "      <td>495</td>\n",
              "      <td>562</td>\n",
              "      <td>2665</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"distilroberta-base\"\n",
        "batch_size = 16\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "m9V3KOFPTeKr"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pad_on_right = tokenizer.padding_side == \"right\""
      ],
      "metadata": {
        "id": "zsRewks2ThZA"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_train_features(examples):\n",
        "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
        "    # in one example possible giving several features when a context is long, each of those features having a\n",
        "    # context that overlaps a bit the context of the previous feature.\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"questions\" if pad_on_right else \"story\"],\n",
        "        examples[\"story\" if pad_on_right else \"questions\"],\n",
        "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
        "        max_length=400,\n",
        "        stride=200,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
        "    # its corresponding example. This key gives us just that.\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
        "    # help us compute the start_positions and end_positions.\n",
        "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
        "\n",
        "    # Let's label those examples!\n",
        "    tokenized_examples[\"start_positions\"] = []\n",
        "    tokenized_examples[\"end_positions\"] = []\n",
        "\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "        # We will label impossible answers with the index of the CLS token.\n",
        "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
        "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
        "\n",
        "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "\n",
        "        # One example can give several spans, this is the index of the example containing this span of text.\n",
        "        sample_index = sample_mapping[i]\n",
        "        answers = {\"answers\": examples[\"reasons\"][sample_index], \"span_start\":examples[\"span_start\"][sample_index], \"span_end\":examples[\"span_end\"][sample_index]}\n",
        "        # If no answers are given, set the cls_index as answer.\n",
        "        if answers[\"span_start\"] == 0:\n",
        "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "        else:\n",
        "            # Start/end character index of the answer in the text.\n",
        "            start_char = answers[\"span_start\"]\n",
        "            end_char = answers[\"span_end\"]\n",
        "\n",
        "            # Start token index of the current span in the text.\n",
        "            token_start_index = 0\n",
        "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
        "                token_start_index += 1\n",
        "\n",
        "            # End token index of the current span in the text.\n",
        "            token_end_index = len(input_ids) - 1\n",
        "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
        "                token_end_index -= 1\n",
        "\n",
        "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
        "            if not (\n",
        "                offsets[token_start_index][0] <= start_char\n",
        "                and offsets[token_end_index][1] >= end_char\n",
        "            ):\n",
        "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "            else:\n",
        "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
        "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
        "                while (\n",
        "                    token_start_index < len(offsets)\n",
        "                    and offsets[token_start_index][0] <= start_char\n",
        "                ):\n",
        "                    token_start_index += 1\n",
        "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
        "                while offsets[token_end_index][1] >= end_char:\n",
        "                    token_end_index -= 1\n",
        "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
        "\n",
        "    return tokenized_examples"
      ],
      "metadata": {
        "id": "ghXjHnfSUDw5"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train_smaller = Dataset.from_dict(data_train[:500])\n",
        "data_val_smaller = Dataset.from_dict(data_val[:500])"
      ],
      "metadata": {
        "id": "2Yvxs5jD9n4-"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = data_train_smaller.map(\n",
        "    prepare_train_features, batched=True, remove_columns=data_train.column_names\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8f4d21942ba8418dba2c82bcf82b092a",
            "218d6f277d804fc9a26aa342f343d8d3",
            "b7df52c77ee142f29b81a22055d0a15a",
            "c5c23da1be3d46f08652f5ec89b00e5f",
            "e3f94bfe8ee141979955f8f55f806191",
            "8d0bc9d6338d48ac83c3b3887d7e033b",
            "738d80200b7b4c96b1afb630c16e57cc",
            "9c6cb21868b84073bb1c1f7dc04fc2fe",
            "1576aecc030a4c488f87d63dc81ac8d1",
            "d2a68175c08c4f339d823201ed4cf02d",
            "b94e8cf12aa3485295e8e0e3035720e2"
          ]
        },
        "id": "5dYHwRnkUH92",
        "outputId": "9451f2b1-2ccb-4f5b-c10f-da66ee5ef81b"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f4d21942ba8418dba2c82bcf82b092a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets_v = data_val_smaller.map(\n",
        "    prepare_train_features, batched=True, remove_columns=data_val.column_names\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5500402f8ee94331af7bd87173a0e65a",
            "78726d6de6114a49a60ae2e864c61ec7",
            "6372149817744d7db74f50b4a8087ee8",
            "8b833b84e8874235a983cefe782d37c8",
            "caa16bbcab9945ce9ce52ebb08230aa8",
            "e2d22cdea265447fb1490058e328fdcb",
            "457e8676311a4f9f9d4b8997661b0af7",
            "cf01238f52e941fe80cd14f7401aad2b",
            "a56d48aab8c045719dbed8d6edeb2aab",
            "e206941487e1433dbfa657de74e8395e",
            "c2e8f869b41944e688dd6bdb40f9fca7"
          ]
        },
        "id": "SX26D74mmZ5Y",
        "outputId": "d6e63c26-bb26-4f48-ce98-37be7bf44803"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5500402f8ee94331af7bd87173a0e65a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = TFAutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIWhvpacUSA4",
        "outputId": "bcd68c1b-14cc-4ae5-dc43-5b6de8b186c2"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForQuestionAnswering.\n",
            "\n",
            "Some layers of TFRobertaForQuestionAnswering were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['qa_outputs']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 2e-5\n",
        "num_train_epochs = 2\n",
        "weight_decay = 0.01"
      ],
      "metadata": {
        "id": "tlpeCxRjbCME"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = model.prepare_tf_dataset(\n",
        "    tokenized_datasets,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "validation_set = model.prepare_tf_dataset(\n",
        "    tokenized_datasets_v,\n",
        "    shuffle=False,\n",
        "    batch_size=batch_size,\n",
        ")"
      ],
      "metadata": {
        "id": "vC23r7lObKHZ"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import create_optimizer\n",
        "\n",
        "total_train_steps = len(train_set) * num_train_epochs\n",
        "\n",
        "optimizer, schedule = create_optimizer(\n",
        "    init_lr=learning_rate, num_warmup_steps=0, num_train_steps=total_train_steps\n",
        ")"
      ],
      "metadata": {
        "id": "9DBSJnw4bNZS"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model.compile(optimizer=optimizer, jit_compile=True, metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoGyHOnTbSPt",
        "outputId": "58cc6866-a31e-47b3-e88d-b5a09d718367"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_set,\n",
        "    validation_data=validation_set,\n",
        "    epochs=num_train_epochs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlyrASYpbUTP",
        "outputId": "cfe9cd6f-1acf-465b-b78c-4318a9c505ed"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "41/41 [==============================] - 2089s 50s/step - loss: 5.6956 - end_logits_accuracy: 0.0213 - start_logits_accuracy: 0.0366 - val_loss: 5.1562 - val_end_logits_accuracy: 0.1714 - val_start_logits_accuracy: 0.1398\n",
            "Epoch 2/2\n",
            "41/41 [==============================] - 2004s 49s/step - loss: 4.8942 - end_logits_accuracy: 0.1113 - start_logits_accuracy: 0.1433 - val_loss: 4.7812 - val_end_logits_accuracy: 0.1955 - val_start_logits_accuracy: 0.1955\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fed6dcf29d0>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(validation_set))\n",
        "output = model.predict_on_batch(batch)\n",
        "output.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-phgZNTbY-v",
        "outputId": "cd887a7e-aaca-445a-f381-ff4ef801fae8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['start_logits', 'end_logits'])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.start_logits.shape, output.end_logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCjMmorPoBvF",
        "outputId": "05a6a4cb-ebf8-4638-eb45-0083b040b44c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((16, 400), (16, 400))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.argmax(output.start_logits, -1), np.argmax(output.end_logits, -1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLenskB2Bde-",
        "outputId": "e955afe4-7ef0-45e6-9a6b-9a886a2b68ad"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([264,   0,   0, 291, 296, 167,   0, 339, 314,   0,   0, 262, 164,\n",
              "          0, 296,  56]),\n",
              " array([131, 203, 103, 116, 152, 128, 172,  35, 135, 144, 167, 120, 150,\n",
              "        187, 259, 238]))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_best_size = 20"
      ],
      "metadata": {
        "id": "KtxPayEpBlgS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "start_logits = output.start_logits[0]\n",
        "end_logits = output.end_logits[0]\n",
        "# Gather the indices the best start/end logits:\n",
        "start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "valid_answers = []\n",
        "for start_index in start_indexes:\n",
        "    for end_index in end_indexes:\n",
        "        if (\n",
        "            start_index <= end_index\n",
        "        ):  # We need to refine that test to check the answer is inside the context\n",
        "            valid_answers.append(\n",
        "                {\n",
        "                    \"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                    \"text\": \"\",  # We need to find a way to get back the original substring corresponding to the answer in the context\n",
        "                }\n",
        "            )"
      ],
      "metadata": {
        "id": "pZs3QTQPBrU4"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_validation_features(examples):\n",
        "    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n",
        "    # in one example possible giving several features when a context is long, each of those features having a\n",
        "    # context that overlaps a bit the context of the previous feature.\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"questions\" if pad_on_right else \"story\"],\n",
        "        examples[\"story\" if pad_on_right else \"questions\"],\n",
        "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
        "        max_length=400,\n",
        "        stride=200,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
        "    # its corresponding example. This key gives us just that.\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "\n",
        "    # We keep the example_id that gave us this feature and we will store the offset mappings.\n",
        "    tokenized_examples[\"example_id\"] = []\n",
        "\n",
        "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
        "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "        context_index = 1 if pad_on_right else 0\n",
        "\n",
        "        # One example can give several spans, this is the index of the example containing this span of text.\n",
        "        sample_index = sample_mapping[i]\n",
        "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
        "\n",
        "        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n",
        "        # position is part of the context or not.\n",
        "        tokenized_examples[\"offset_mapping\"][i] = [\n",
        "            (o if sequence_ids[k] == context_index else None)\n",
        "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
        "        ]\n",
        "\n",
        "    return tokenized_examples"
      ],
      "metadata": {
        "id": "9OInKUWKBuxV"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_features = data_val_smaller.map(\n",
        "    prepare_validation_features,\n",
        "    batched=True,\n",
        "    remove_columns=data_val_smaller.column_names,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "57a28b93f8ae4067a48d234962743659",
            "362c03a5f8264bb085f78cf7fe51cd86",
            "9c29c3d670954b148264080cc5bc65c8",
            "12f3f63977d04f1587184f2baac27ab7",
            "bcd54bb2698c46caa98f1609797ac535",
            "63e245d87cbf4e738fd67a6f61ab005c",
            "ebd081f14c324e319b5b34bbf8a34890",
            "9636b588ac1d47fe96d5847fd671771a",
            "b5dd470ed6104a15b9ce303855b066af",
            "33f35262ca7e47b9a4a087e39925daa5",
            "6ff889491fed4a038efbb04f016d5ff9"
          ]
        },
        "id": "TJnzJGIZB2BC",
        "outputId": "8f685793-58bd-4720-ff59-18aa96030aa8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57a28b93f8ae4067a48d234962743659"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_dataset = model.prepare_tf_dataset(\n",
        "     validation_features,\n",
        "     shuffle=False,\n",
        "     batch_size=batch_size,\n",
        ")"
      ],
      "metadata": {
        "id": "xyLjkS1qe0Ju"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_predictions = model.predict(validation_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oN0GiTpmTUF",
        "outputId": "fbdce9f5-6dd4-44ad-a418-3eaa51c6bfc2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 156s 18s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyIlr_bzmX1u",
        "outputId": "57474152-3213-4a84-eefe-22c2223877b6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TFQuestionAnsweringModelOutput(loss=None, start_logits=array([[ 0.4271657 ,  0.30052865,  0.14134446, ..., -0.01493698,\n",
              "        -0.01493686, -0.01493686],\n",
              "       [ 0.36933422,  0.17928202, -0.07047553, ...,  0.13830562,\n",
              "         0.00629536,  0.18118   ],\n",
              "       [ 0.38566452,  0.16822846, -0.02404393, ..., -0.11820608,\n",
              "        -0.11820603, -0.11820603],\n",
              "       ...,\n",
              "       [ 0.41097334,  0.23812789,  0.13180749, ..., -0.04167751,\n",
              "        -0.04167754, -0.04167754],\n",
              "       [ 0.36087972,  0.04035559, -0.03299645, ...,  0.10421532,\n",
              "        -0.04431308,  0.12851638],\n",
              "       [ 0.37638766,  0.02158862, -0.06588422, ..., -0.10202938,\n",
              "        -0.10202915, -0.10202915]], dtype=float32), end_logits=array([[-0.5190739 , -0.66327655, -0.67198646, ..., -0.54919183,\n",
              "        -0.54919195, -0.54919195],\n",
              "       [-0.5273227 , -0.6123692 , -0.5719215 , ..., -0.71364063,\n",
              "        -0.52982175, -0.6679364 ],\n",
              "       [-0.5315317 , -0.6139098 , -0.56993294, ..., -0.46260598,\n",
              "        -0.46260613, -0.46260613],\n",
              "       ...,\n",
              "       [-0.5326136 , -0.7080045 , -0.6552358 , ..., -0.62487316,\n",
              "        -0.62487316, -0.62487316],\n",
              "       [-0.54081106, -0.5691158 , -0.6202431 , ..., -0.63529766,\n",
              "        -0.48329255, -0.7231224 ],\n",
              "       [-0.55583256, -0.5833809 , -0.63765585, ..., -0.7288699 ,\n",
              "        -0.72887   , -0.72887   ]], dtype=float32), hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_answer_length = 40"
      ],
      "metadata": {
        "id": "_AOBNCIimZFj"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_logits = output.start_logits[0]\n",
        "end_logits = output.end_logits[0]\n",
        "offset_mapping = validation_features[0][\"offset_mapping\"]\n",
        "\n",
        "#first feature comes from first example. For more general case we need to match example_id to example index\n",
        "context = data_val_smaller[0][\"story\"]\n",
        "\n",
        "\n",
        "#Gather indices best start/end logits:\n",
        "start_indexes = np.argsort(start_logits)[-1: -n_best_size - 1: -1].tolist()\n",
        "end_indexes = np.argsort(end_logits)[-1: -n_best_size - 1: -1].tolist()\n",
        "valid_answers = []\n",
        "\n",
        "for start_index in start_indexes:\n",
        "  for end_index  in end_indexes:\n",
        "    # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
        "    # to part of the input_ids that are not in the context.\n",
        "    if (start_index >= len(offset_mapping) or end_index >= len(offset_mapping) or offset_mapping[start_index] is None or offset_mapping[end_index] is None):\n",
        "      continue\n",
        "\n",
        "    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
        "    if(end_index < start_index or end_index - start_index + 1 > max_answer_length):\n",
        "      continue\n",
        "    if(start_index <= end_index):\n",
        "      start_char = offset_mapping[start_index][0]\n",
        "      end_char = offset_mapping[end_index][1]\n",
        "      valid_answers.append({\"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                           \"text\": context[start_char:end_char]})\n",
        "      \n",
        "valid_answers = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[:n_best_size]\n",
        "valid_answers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqRrwhNqmb-e",
        "outputId": "57015946-b9be-431e-ce85-b83fb625402c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.22252774,\n",
              "  'text': '. \\n\\nHong Kong used to be a British colony with the perpetual cession of Hong Kong Island from the Qing Empire after the First Opium War (1839'},\n",
              " {'score': 0.17686221,\n",
              "  'text': '. Except in military defence and foreign affairs, Hong Kong maintains its independent executive, legislative and judiciary'},\n",
              " {'score': 0.15881693,\n",
              "  'text': '. \\n\\nHong Kong used to be a British colony with the perpetual cession of Hong Kong'},\n",
              " {'score': 0.15745232,\n",
              "  'text': '. \\n\\nHong Kong used to be a British colony with the perpetual cession of Hong Kong Island from the Qing Empire after the First Opium War (18'},\n",
              " {'score': 0.14902288,\n",
              "  'text': '. \\n\\nHong Kong used to be a British colony with the perpetual cession of Hong'},\n",
              " {'score': 0.14461243,\n",
              "  'text': '. \\n\\nUnder the principle of \"one country, two systems\", Hong Kong maintains a separate political and economic system from China'},\n",
              " {'score': 0.14208171,\n",
              "  'text': '. \\n\\nHong Kong used to be a British colony with the perpetual cession of Hong Kong Island from the Qing Empire after the First Opium'},\n",
              " {'score': 0.13355273,\n",
              "  'text': '. \\n\\nHong Kong used to be a British colony with the perpetual cession of Hong Kong Island from the Qing Empire after the First Opium War (1839–18'},\n",
              " {'score': 0.13165873,\n",
              "  'text': '. \\n\\nHong Kong used to be a British colony with the perpetual cession of Hong Kong Island from the Qing'},\n",
              " {'score': 0.10433218,\n",
              "  'text': '. \\n\\nUnder the principle of \"one country, two systems\", Hong Kong maintains a separate political and economic system from'},\n",
              " {'score': 0.10388526,\n",
              "  'text': '. The Sino-British Joint Declaration signed between the United Kingdom and China in 1984 paved way for the transfer of sovereignty of Hong'},\n",
              " {'score': 0.09912118,\n",
              "  'text': '. The Sino-British Joint Declaration signed between the United Kingdom and China'},\n",
              " {'score': 0.09838918,\n",
              "  'text': '. Hong Kong was later occupied by Japan during the Second World War until British control resumed in 1945. The Sino-British Joint Declaration signed between the United Kingdom and China'},\n",
              " {'score': 0.05665934,\n",
              "  'text': 'Hong Kong maintains its independent executive, legislative and judiciary'},\n",
              " {'score': 0.039894164,\n",
              "  'text': 'Hong Kong maintains a separate political and economic system from China. Except in military defence and foreign affairs, Hong Kong maintains its independent executive, legislative and judiciary'},\n",
              " {'score': 0.0086247325,\n",
              "  'text': 'Hong Kong maintains a separate political and economic system from China'},\n",
              " {'score': -0.03165552,\n",
              "  'text': 'Hong Kong maintains a separate political and economic system from'}]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_val_smaller[0][\"answers\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "00l2FcWsoQzR",
        "outputId": "af8712e2-951e-4c92-b771-e95466aa8963"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'no'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_val_smaller[0]['questions']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AKC24czooZwi",
        "outputId": "24034a05-fe06-4e99-a92e-71ba54185e9f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Are they involved with China in these groups?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "examples = data_val_smaller\n",
        "features = validation_features\n",
        "\n",
        "example_id_to_index = {k: i for i,k in enumerate(examples[\"id\"])}\n",
        "features_per_example = collections.defaultdict(list)\n",
        "for i, feature in enumerate(features):\n",
        "  features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)"
      ],
      "metadata": {
        "id": "4DP7H81LolFS"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess_qa_predictions(examples, features, all_start_logits, all_end_logits, n_best_size=20, max_answer_length=30):\n",
        "  \n",
        "  example_id_to_index = {k: i for i,k in enumerate(examples[\"id\"])}\n",
        "  features_per_example = collections.defaultdict(list)\n",
        "  for i, feature in enumerate(features):\n",
        "    features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
        "  \n",
        "  predictions = collections.OrderedDict()\n",
        "\n",
        "  print(f\"Post-processing{len(examples)} example preditions split into {len(features)} features.\")\n",
        "\n",
        "\n",
        "  for example_index, example in enumerate(tqdm(examples)):\n",
        "    #indices of the features associated to current example\n",
        "    feature_indices = features_per_example[example_index]\n",
        "    min_null_score = None #used if squad_v2 is true\n",
        "    valid_answers = []\n",
        "\n",
        "    #loop through all features associated to current example\n",
        "    for feature_index in feature_indices:\n",
        "      #grab predictions of model for this feature.\n",
        "      start_logits = all_start_logits[feature_index]\n",
        "      end_logits = all_end_logits[feature_index]\n",
        "\n",
        "      #map positions in out logits to span of texts inoriginal story\n",
        "      cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
        "      feature_null_score = start_logits[cls_index]+end_logits[cls_index]\n",
        "      if min_null_score is None or min_null_score < feature_null_score:\n",
        "        min_null_score = feature_null_score\n",
        "      \n",
        "      #Go through all possibilities for 'n_best_size' greater start and end logits\n",
        "      start_indexes = np.argsort(start_logits)[-1: -n_best_size - 1: -1].tolist()\n",
        "      end_indexes = np.argsort(end_logits)[-1: -n_best_size - 1: -1].tolist()\n",
        "      for start_index in start_indexes:\n",
        "        for end_index  in end_indexes:\n",
        "          # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
        "          # to part of the input_ids that are not in the context.\n",
        "          if (start_index >= len(offset_mapping) or end_index >= len(offset_mapping) or offset_mapping[start_index] is None or offset_mapping[end_index] is None):\n",
        "            continue\n",
        "\n",
        "          # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
        "          if(end_index < start_index or end_index - start_index + 1 > max_answer_length):\n",
        "            continue\n",
        "          if(start_index <= end_index):\n",
        "            start_char = offset_mapping[start_index][0]\n",
        "            end_char = offset_mapping[end_index][1]\n",
        "            valid_answers.append({\"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                                \"text\": context[start_char:end_char]})\n",
        "    if len(valid_answers)>0:\n",
        "      best_answer = sorted(valid_answers,key=lambda x: x[\"score\"], reverse=True)[0]\n",
        "    else:\n",
        "      best_answer = {\"text\": \"\", \"score\": 0}\n",
        "    \n",
        "    if not squad_v2:\n",
        "      predictions[example[\"id\"]]=best_answer[\"text\"]\n",
        "    else:\n",
        "      answer = (best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else \"\")\n",
        "      predictions[example[\"id\"]] = answer\n",
        "\n",
        "  return predictions"
      ],
      "metadata": {
        "id": "dhnTugCwpjrb"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_predictions = postprocess_qa_predictions(data_val_smaller, validation_features, raw_predictions[\"start_logits\"], raw_predictions[\"end_logits\"],)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN3xdRjRvAik",
        "outputId": "2cb1ff7b-7902-4bbd-d5ee-295bdfa4ceb3"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Post-processing500 example preditions split into 127 features.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:00<00:00, 1545.00it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "metric = load_metric(\"squad\")"
      ],
      "metadata": {
        "id": "OXLebdNWW5cG"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if squad_v2:\n",
        "    formatted_predictions = [\n",
        "        {\"id\": k, \"prediction_text\": v, \"no_answer_probability\": 0.0}\n",
        "        for k, v in final_predictions.items()\n",
        "    ]\n",
        "else:\n",
        "    formatted_predictions = [\n",
        "        {\"id\": k, \"prediction_text\": v} for k, v in final_predictions.items()\n",
        "    ]\n",
        "references = [\n",
        "    {\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in data_val_smaller\n",
        "]\n",
        "metric.compute(predictions=formatted_predictions, references=references)\n",
        "print(formatted_predictions)\n",
        "print(references)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "QrvjOiU4vZgp",
        "outputId": "ad060fb3-0729-4c0d-b3e3-704effb9a55b"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-203d97eb69b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"answers\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"answers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_val_smaller\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m ]\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatted_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/datasets/metric.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/datasets/metric.py\u001b[0m in \u001b[0;36madd_batch\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"predictions\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"references\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mintput_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mintput_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mintput_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/datasets/features/features.py\u001b[0m in \u001b[0;36mencode_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m   1816\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1817\u001b[0m             \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast_to_python_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1818\u001b[0;31m             \u001b[0mencoded_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mencode_nested_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1819\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mencoded_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/datasets/features/features.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1816\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1817\u001b[0m             \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast_to_python_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1818\u001b[0;31m             \u001b[0mencoded_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mencode_nested_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1819\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mencoded_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/datasets/features/features.py\u001b[0m in \u001b[0;36mencode_nested_example\u001b[0;34m(schema, obj, level)\u001b[0m\n\u001b[1;32m   1200\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Got None but expected a dictionary instead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m         return (\n\u001b[0;32m-> 1202\u001b[0;31m             {\n\u001b[0m\u001b[1;32m   1203\u001b[0m                 \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mencode_nested_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msub_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_obj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/datasets/features/features.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1201\u001b[0m         return (\n\u001b[1;32m   1202\u001b[0m             {\n\u001b[0;32m-> 1203\u001b[0;31m                 \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mencode_nested_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msub_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_obj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m             }\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/datasets/features/features.py\u001b[0m in \u001b[0;36mencode_nested_example\u001b[0;34m(schema, obj, level)\u001b[0m\n\u001b[1;32m   1234\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m                 \u001b[0;31m# obj is a single dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msub_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_objs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0mlist_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mencode_nested_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msub_objs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlist_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36mzip_dict\u001b[0;34m(*dicts)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munique_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# set merge all keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;31m# Will raise KeyError if the dict don't have the same keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munique_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# set merge all keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;31m# Will raise KeyError if the dict don't have the same keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "question_answerer = pipeline(\"question-answering\", \"distilroberta-base\", framework=\"tf\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9vt6Sk5Wuo-",
        "outputId": "8b35b6b3-0b30-47b7-f897-8426d91ffc98"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFRobertaForQuestionAnswering.\n",
            "\n",
            "Some layers of TFRobertaForQuestionAnswering were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['qa_outputs']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_answerer(context=data_val_smaller[\"story\"], question=data_val_smaller[\"questions\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUOoX0KXaxDn",
        "outputId": "53ac7cdf-c535-4da1-c051-f62ae5b0a7e3"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 1.879495903267525e-05,\n",
              "  'start': 232,\n",
              "  'end': 245,\n",
              "  'answer': 'nationalities'},\n",
              " {'score': 4.3813564843731e-05,\n",
              "  'start': 1305,\n",
              "  'end': 1317,\n",
              "  'answer': 'players must'},\n",
              " {'score': 8.743636135477573e-05,\n",
              "  'start': 1560,\n",
              "  'end': 1623,\n",
              "  'answer': 'on the list of those invited for the event, according to police'},\n",
              " {'score': 1.4067890333535615e-05,\n",
              "  'start': 0,\n",
              "  'end': 10,\n",
              "  'answer': 'A Sudanese'},\n",
              " {'score': 1.25002870845492e-05,\n",
              "  'start': 198,\n",
              "  'end': 249,\n",
              "  'answer': 'created the hereditary Order of Baronets in England'},\n",
              " {'score': 2.5469362299190834e-05, 'start': 188, 'end': 189, 'answer': '\\n'},\n",
              " {'score': 1.404230988555355e-05, 'start': 247, 'end': 251, 'answer': 'Sen.'},\n",
              " {'score': 4.708084452431649e-05,\n",
              "  'start': 1375,\n",
              "  'end': 1391,\n",
              "  'answer': 'when the Burmese'},\n",
              " {'score': 1.5132605767576024e-05, 'start': 167, 'end': 168, 'answer': '\\n'},\n",
              " {'score': 5.7525248848833144e-05,\n",
              "  'start': 1089,\n",
              "  'end': 1159,\n",
              "  'answer': 'not just a filmmaker who followed the man who is now arguably the most'},\n",
              " {'score': 1.7586929971002974e-05,\n",
              "  'start': 31,\n",
              "  'end': 89,\n",
              "  'answer': 'between Sen. Mitch McConnell and his Democratic challenger'},\n",
              " {'score': 5.129471901454963e-05,\n",
              "  'start': 924,\n",
              "  'end': 942,\n",
              "  'answer': 'myself, yet I seem'},\n",
              " {'score': 4.993143738829531e-05,\n",
              "  'start': 1176,\n",
              "  'end': 1252,\n",
              "  'answer': 'system), and philosophy, especially the philosophy of language, epistemology'},\n",
              " {'score': 6.237706111278385e-05,\n",
              "  'start': 1381,\n",
              "  'end': 1419,\n",
              "  'answer': 'it is now suggested that federalism is'},\n",
              " {'score': 5.444655835162848e-05,\n",
              "  'start': 1112,\n",
              "  'end': 1143,\n",
              "  'answer': 'it too, though she could hardly'},\n",
              " {'score': 4.227286626701243e-05,\n",
              "  'start': 119,\n",
              "  'end': 178,\n",
              "  'answer': 'looked through the seed magazines. She ordered the tastiest'},\n",
              " {'score': 1.4853395441605244e-05,\n",
              "  'start': 64,\n",
              "  'end': 91,\n",
              "  'answer': 'Mr. Jones, tightly enfolded'},\n",
              " {'score': 1.4767005268367939e-05,\n",
              "  'start': 38,\n",
              "  'end': 98,\n",
              "  'answer': 'Hàn cháo) was the second imperial dynasty of China, preceded'},\n",
              " {'score': 1.4413748431252316e-05, 'start': 164, 'end': 165, 'answer': '\\n'},\n",
              " {'score': 4.497501868172549e-05,\n",
              "  'start': 168,\n",
              "  'end': 176,\n",
              "  'answer': 'His aunt'},\n",
              " {'score': 1.4516619557980448e-05,\n",
              "  'start': 21,\n",
              "  'end': 40,\n",
              "  'answer': 'Actor Wesley Snipes'},\n",
              " {'score': 1.4890676538925618e-05,\n",
              "  'start': 233,\n",
              "  'end': 272,\n",
              "  'answer': 'glanced around the room; nothing seemed'},\n",
              " {'score': 2.9928436561021954e-05, 'start': 1098, 'end': 1099, 'answer': '\\n'},\n",
              " {'score': 3.6690180422738194e-05,\n",
              "  'start': 1301,\n",
              "  'end': 1318,\n",
              "  'answer': \"my Mom's house. \\n\"},\n",
              " {'score': 1.4143894077278674e-05, 'start': 230, 'end': 234, 'answer': 'wife'},\n",
              " {'score': 1.3280898201628588e-05,\n",
              "  'start': 47,\n",
              "  'end': 107,\n",
              "  'answer': 'Paterno and the president of the school have lost their jobs'},\n",
              " {'score': 1.9507313481881283e-05,\n",
              "  'start': 773,\n",
              "  'end': 803,\n",
              "  'answer': 'winner was Katherine Larson. \\n'},\n",
              " {'score': 1.4071213627175894e-05, 'start': 41, 'end': 42, 'answer': '\\n'},\n",
              " {'score': 6.892067904118448e-05,\n",
              "  'start': 1147,\n",
              "  'end': 1181,\n",
              "  'answer': 'Dr. Daniel Mietchen to South Korea'},\n",
              " {'score': 3.522384213283658e-05,\n",
              "  'start': 40,\n",
              "  'end': 74,\n",
              "  'answer': 'ride. He went on this ride because'},\n",
              " {'score': 2.3008522475720383e-05,\n",
              "  'start': 0,\n",
              "  'end': 76,\n",
              "  'answer': 'You might think that Olympic athletes are the healthiest people in the world'},\n",
              " {'score': 1.2671643162320834e-05,\n",
              "  'start': 1537,\n",
              "  'end': 1579,\n",
              "  'answer': 'going to change that,\" he told reporters. '},\n",
              " {'score': 1.5510084267589264e-05,\n",
              "  'start': 226,\n",
              "  'end': 237,\n",
              "  'answer': 'fourth-most'},\n",
              " {'score': 1.823169986892026e-05,\n",
              "  'start': 559,\n",
              "  'end': 617,\n",
              "  'answer': 'best friend, Michelle, walking up to her. Michelle greeted'},\n",
              " {'score': 7.224243017844856e-05,\n",
              "  'start': 1375,\n",
              "  'end': 1444,\n",
              "  'answer': 'a Chinese American writer was to act as a bridge between two cultures'},\n",
              " {'score': 2.1737745555583388e-05,\n",
              "  'start': 215,\n",
              "  'end': 229,\n",
              "  'answer': 'grew up. Angel'},\n",
              " {'score': 1.608156890142709e-05,\n",
              "  'start': 167,\n",
              "  'end': 245,\n",
              "  'answer': 'creation of free content textbooks and annotated texts that anyone can edit. \\n'},\n",
              " {'score': 2.2229291062103584e-05,\n",
              "  'start': 35,\n",
              "  'end': 95,\n",
              "  'answer': 'developed by Microsoft. It was first released on October 25,'},\n",
              " {'score': 5.365669494494796e-05,\n",
              "  'start': 1236,\n",
              "  'end': 1240,\n",
              "  'answer': '?’ \\n'},\n",
              " {'score': 2.6636811526259407e-05,\n",
              "  'start': 210,\n",
              "  'end': 242,\n",
              "  'answer': 'first stage the information must'},\n",
              " {'score': 4.5850214519305155e-05,\n",
              "  'start': 263,\n",
              "  'end': 329,\n",
              "  'answer': 'based on economics of energy supply, maintenance, and capital cost'},\n",
              " {'score': 1.6080986824817955e-05, 'start': 32, 'end': 33, 'answer': '\\n'},\n",
              " {'score': 3.8178801332833245e-05,\n",
              "  'start': 54,\n",
              "  'end': 91,\n",
              "  'answer': 'his own house in the ground. His eyes'},\n",
              " {'score': 8.201161108445376e-05,\n",
              "  'start': 1237,\n",
              "  'end': 1259,\n",
              "  'answer': 'One of her safe racers'},\n",
              " {'score': 4.583409827318974e-05,\n",
              "  'start': 1209,\n",
              "  'end': 1290,\n",
              "  'answer': 'his musical contemporaries, including Robert Schumann. In 1835 he obtained French'},\n",
              " {'score': 5.539130506804213e-05,\n",
              "  'start': 1236,\n",
              "  'end': 1256,\n",
              "  'answer': 'one who, like Lilias'},\n",
              " {'score': 1.3774073522654362e-05,\n",
              "  'start': 48,\n",
              "  'end': 71,\n",
              "  'answer': 'the iconic Led Zeppelin'},\n",
              " {'score': 8.409223664784804e-05,\n",
              "  'start': 1235,\n",
              "  'end': 1264,\n",
              "  'answer': '-year-old with cerebral palsy'},\n",
              " {'score': 3.0137814974295907e-05,\n",
              "  'start': 234,\n",
              "  'end': 265,\n",
              "  'answer': 'over to the tree to take a look'},\n",
              " {'score': 1.3962444427306764e-05,\n",
              "  'start': 32,\n",
              "  'end': 65,\n",
              "  'answer': 'Early in October Captain Marrable'},\n",
              " {'score': 8.388784772250801e-05,\n",
              "  'start': 1449,\n",
              "  'end': 1523,\n",
              "  'answer': 'he has lived a relatively quiet life as a respected author and lecturer. \\n'},\n",
              " {'score': 7.185112917795777e-05,\n",
              "  'start': 1395,\n",
              "  'end': 1424,\n",
              "  'answer': 'Everyone had at least one.\" \\n'},\n",
              " {'score': 1.2156459888501558e-05,\n",
              "  'start': 118,\n",
              "  'end': 177,\n",
              "  'answer': 'was getting acquainted with Selim, the eleven-hundred-pound'},\n",
              " {'score': 2.898300954257138e-05,\n",
              "  'start': 1213,\n",
              "  'end': 1255,\n",
              "  'answer': 'everyone had a smartphone and used them to'},\n",
              " {'score': 1.9355218682903796e-05,\n",
              "  'start': 78,\n",
              "  'end': 124,\n",
              "  'answer': 'twenty-five\". He was right. Most men at twenty'},\n",
              " {'score': 1.543698090245016e-05,\n",
              "  'start': 18,\n",
              "  'end': 41,\n",
              "  'answer': \"One of the world's most\"},\n",
              " {'score': 1.3949986168881878e-05, 'start': 281, 'end': 282, 'answer': '\\n'},\n",
              " {'score': 2.176009184040595e-05,\n",
              "  'start': 204,\n",
              "  'end': 240,\n",
              "  'answer': 'War (1861 to 1865); the second sense'},\n",
              " {'score': 1.97742829186609e-05, 'start': 260, 'end': 264, 'answer': 'wife'},\n",
              " {'score': 3.224061583750881e-05,\n",
              "  'start': 613,\n",
              "  'end': 664,\n",
              "  'answer': '$244 billion in 2012, down 12% from 2011 mainly due'},\n",
              " {'score': 1.7956705050892197e-05,\n",
              "  'start': 39,\n",
              "  'end': 106,\n",
              "  'answer': 'USC or SC) is a private research university located in Los Angeles,'},\n",
              " {'score': 7.056508911773562e-05,\n",
              "  'start': 1127,\n",
              "  'end': 1186,\n",
              "  'answer': 'it would be mean to leave his daughter with a farewell kiss'},\n",
              " {'score': 1.648787838348653e-05,\n",
              "  'start': 145,\n",
              "  'end': 173,\n",
              "  'answer': 'he passed them he recognised'},\n",
              " {'score': 4.5740358473267406e-05,\n",
              "  'start': 1117,\n",
              "  'end': 1169,\n",
              "  'answer': '-year-old secretary,so much he got a job on a Sydney'},\n",
              " {'score': 8.329802949447185e-05, 'start': 1186, 'end': 1187, 'answer': '\\n'},\n",
              " {'score': 6.356622907333076e-05,\n",
              "  'start': 1206,\n",
              "  'end': 1262,\n",
              "  'answer': '\"The Young and the Restless\" cast, said Cooper was her \"'},\n",
              " {'score': 8.173554670065641e-05,\n",
              "  'start': 1168,\n",
              "  'end': 1178,\n",
              "  'answer': 'his own. \\n'},\n",
              " {'score': 8.595189137849957e-05,\n",
              "  'start': 1257,\n",
              "  'end': 1268,\n",
              "  'answer': 'she said. \\n'},\n",
              " {'score': 4.176457514404319e-05,\n",
              "  'start': 344,\n",
              "  'end': 357,\n",
              "  'answer': 'need money. \\n'},\n",
              " {'score': 1.4355684470501728e-05,\n",
              "  'start': 292,\n",
              "  'end': 339,\n",
              "  'answer': '-0 draw that produced very little excitement. \\n'},\n",
              " {'score': 2.0466917703743093e-05,\n",
              "  'start': 124,\n",
              "  'end': 165,\n",
              "  'answer': 'working in his yard when he heard a woman'},\n",
              " {'score': 1.958514803845901e-05,\n",
              "  'start': 38,\n",
              "  'end': 78,\n",
              "  'answer': 'your parents every month? Maybe 200 yuan'},\n",
              " {'score': 2.6034220354631543e-05,\n",
              "  'start': 330,\n",
              "  'end': 345,\n",
              "  'answer': 'from the UK). \\n'},\n",
              " {'score': 1.703716770862229e-05,\n",
              "  'start': 279,\n",
              "  'end': 288,\n",
              "  'answer': 'exists or'},\n",
              " {'score': 1.4122677384875715e-05,\n",
              "  'start': 43,\n",
              "  'end': 72,\n",
              "  'answer': 'crime in connection with what'},\n",
              " {'score': 7.61868868721649e-05,\n",
              "  'start': 1263,\n",
              "  'end': 1298,\n",
              "  'answer': 'Houses. The former Florida governor'},\n",
              " {'score': 1.3949428648629691e-05,\n",
              "  'start': 80,\n",
              "  'end': 150,\n",
              "  'answer': 'Kingdom and the British Dominions and Emperor of India from 22 January'},\n",
              " {'score': 9.055074042407796e-05,\n",
              "  'start': 1426,\n",
              "  'end': 1445,\n",
              "  'answer': 'one of the officers'},\n",
              " {'score': 6.604188092751428e-05, 'start': 966, 'end': 967, 'answer': '\\n'},\n",
              " {'score': 2.114586823154241e-05,\n",
              "  'start': 59,\n",
              "  'end': 72,\n",
              "  'answer': 'he was a duck'},\n",
              " {'score': 8.203191100619733e-05,\n",
              "  'start': 1202,\n",
              "  'end': 1213,\n",
              "  'answer': 'I have ever'},\n",
              " {'score': 3.223012390662916e-05,\n",
              "  'start': 0,\n",
              "  'end': 46,\n",
              "  'answer': \"I'm Marie. I work in a nursing home and my job\"},\n",
              " {'score': 1.622070703888312e-05, 'start': 3, 'end': 7, 'answer': 'wife'},\n",
              " {'score': 1.720669388305396e-05, 'start': 209, 'end': 213, 'answer': '603,'},\n",
              " {'score': 8.35356186144054e-05,\n",
              "  'start': 1170,\n",
              "  'end': 1225,\n",
              "  'answer': 'one of the figures upon the bridge, his hand to his ear'},\n",
              " {'score': 5.67851857340429e-05,\n",
              "  'start': 1220,\n",
              "  'end': 1231,\n",
              "  'answer': 'his face. \\n'},\n",
              " {'score': 1.5174839973042253e-05,\n",
              "  'start': 127,\n",
              "  'end': 206,\n",
              "  'answer': 'decided to replace their dogs with the fierce forest dwelling beasts. According'},\n",
              " {'score': 6.454950926126912e-05,\n",
              "  'start': 931,\n",
              "  'end': 964,\n",
              "  'answer': 'his most clownish self. He yelped'},\n",
              " {'score': 8.543800504412502e-05,\n",
              "  'start': 1150,\n",
              "  'end': 1188,\n",
              "  'answer': 'she is dedicated ( ) to healing rather'},\n",
              " {'score': 8.723139035282657e-05, 'start': 1211, 'end': 1214, 'answer': 'Mrs'},\n",
              " {'score': 6.563188071595505e-05,\n",
              "  'start': 1442,\n",
              "  'end': 1462,\n",
              "  'answer': \"'s Nick Paton Walsh,\"},\n",
              " {'score': 1.3443533134704921e-05, 'start': 125, 'end': 126, 'answer': '\\n'},\n",
              " {'score': 2.1259320419630967e-05,\n",
              "  'start': 93,\n",
              "  'end': 166,\n",
              "  'answer': \"driver had his father's help in fleeing California and traveling to Texas\"},\n",
              " {'score': 1.6057983884820715e-05,\n",
              "  'start': 0,\n",
              "  'end': 35,\n",
              "  'answer': 'When Mark first arrived in Thailand'},\n",
              " {'score': 8.362691005459055e-05, 'start': 1145, 'end': 1146, 'answer': '\\n'},\n",
              " {'score': 8.968959446065128e-05, 'start': 1044, 'end': 1045, 'answer': '\\n'},\n",
              " {'score': 1.4411628399102483e-05,\n",
              "  'start': 134,\n",
              "  'end': 175,\n",
              "  'answer': 'her 17th floor New York City apartment. \\n'},\n",
              " {'score': 2.689229222596623e-05,\n",
              "  'start': 162,\n",
              "  'end': 172,\n",
              "  'answer': 'kilometres'},\n",
              " {'score': 1.9361503291293047e-05,\n",
              "  'start': 0,\n",
              "  'end': 43,\n",
              "  'answer': 'Constantine the Great (; ; 27 February 272\\xa0'},\n",
              " {'score': 5.797239646199159e-05,\n",
              "  'start': 1096,\n",
              "  'end': 1122,\n",
              "  'answer': 'from his seat and wriggled'},\n",
              " {'score': 1.2733404219034128e-05, 'start': 130, 'end': 131, 'answer': '\\n'},\n",
              " {'score': 8.36003091535531e-05, 'start': 1337, 'end': 1338, 'answer': '\\n'},\n",
              " {'score': 1.3618606317322701e-05, 'start': 211, 'end': 212, 'answer': '\\n'},\n",
              " {'score': 3.836066753137857e-05,\n",
              "  'start': 1332,\n",
              "  'end': 1391,\n",
              "  'answer': 'me, \"Normally I wouldn\\'t dare to go and talk to the manager'},\n",
              " {'score': 3.5975463106296957e-05,\n",
              "  'start': 249,\n",
              "  'end': 279,\n",
              "  'answer': 'Fellows of Harvard College) is'},\n",
              " {'score': 3.3175936550833285e-05,\n",
              "  'start': 936,\n",
              "  'end': 982,\n",
              "  'answer': 'he is really alive. He is so altered. He seems'},\n",
              " {'score': 4.664419611799531e-05,\n",
              "  'start': 1271,\n",
              "  'end': 1312,\n",
              "  'answer': 'instant that the sentence of the prisoner'},\n",
              " {'score': 1.634738509892486e-05,\n",
              "  'start': 55,\n",
              "  'end': 95,\n",
              "  'answer': 'his father, Osama: \"Find another way.\" \\n'},\n",
              " {'score': 1.3138193935446907e-05, 'start': 29, 'end': 30, 'answer': '\\n'},\n",
              " {'score': 4.905249807052314e-05,\n",
              "  'start': 1392,\n",
              "  'end': 1400,\n",
              "  'answer': 'his face'},\n",
              " {'score': 1.7631426089792512e-05, 'start': 288, 'end': 290, 'answer': 'km'},\n",
              " {'score': 8.41817309265025e-05,\n",
              "  'start': 1118,\n",
              "  'end': 1176,\n",
              "  'answer': 'speaking at the Republican National Convention in Chicago,'},\n",
              " {'score': 3.581677083275281e-05,\n",
              "  'start': 1174,\n",
              "  'end': 1232,\n",
              "  'answer': 'naming scheme for \"Bollywood\" was inspired by \"Tollywood\",'},\n",
              " {'score': 8.481444092467427e-05,\n",
              "  'start': 1049,\n",
              "  'end': 1114,\n",
              "  'answer': 'one of the most acclaimed scientists in Europe. \\n\\nThe philosopher'},\n",
              " {'score': 1.4611361621064134e-05,\n",
              "  'start': 14,\n",
              "  'end': 23,\n",
              "  'answer': 'a 24-year'},\n",
              " {'score': 4.360135426395573e-05,\n",
              "  'start': 1005,\n",
              "  'end': 1023,\n",
              "  'answer': 'one of at least 73'},\n",
              " {'score': 1.5252408957167063e-05,\n",
              "  'start': 286,\n",
              "  'end': 316,\n",
              "  'answer': 'one of the Four Corners states'},\n",
              " {'score': 7.713185914326459e-05, 'start': 1005, 'end': 1006, 'answer': '\\n'},\n",
              " {'score': 1.7029931768774986e-05,\n",
              "  'start': 112,\n",
              "  'end': 126,\n",
              "  'answer': 'he felt rather'},\n",
              " {'score': 7.601187826367095e-05, 'start': 1208, 'end': 1209, 'answer': '\\n'},\n",
              " {'score': 7.323784666368738e-05,\n",
              "  'start': 1187,\n",
              "  'end': 1221,\n",
              "  'answer': 'used to the tall skeleton trestles'},\n",
              " {'score': 5.1340055506443605e-05,\n",
              "  'start': 1102,\n",
              "  'end': 1157,\n",
              "  'answer': 'only thing that I have, and always had, is common sense'},\n",
              " {'score': 4.823726703762077e-05,\n",
              "  'start': 1378,\n",
              "  'end': 1426,\n",
              "  'answer': 'founded Wikipedia as an Internet encyclopedia to'},\n",
              " {'score': 1.4234158697945531e-05,\n",
              "  'start': 39,\n",
              "  'end': 112,\n",
              "  'answer': 'his late works returned home to Vienna for the first time since his death'},\n",
              " {'score': 1.2875747415819205e-05, 'start': 266, 'end': 267, 'answer': '\\n'},\n",
              " {'score': 4.725296821561642e-05,\n",
              "  'start': 1441,\n",
              "  'end': 1500,\n",
              "  'answer': 'up with a plan: She and Frank will sell their home and move'},\n",
              " {'score': 2.8629490770981647e-05, 'start': 1228, 'end': 1229, 'answer': '\\n'},\n",
              " {'score': 1.2126713954785373e-05,\n",
              "  'start': 32,\n",
              "  'end': 68,\n",
              "  'answer': '\\n\\nBut, though Nina differed somewhat'},\n",
              " {'score': 2.899616811191663e-05,\n",
              "  'start': 154,\n",
              "  'end': 194,\n",
              "  'answer': 'he heard a lot of people yell, \"Surprise'},\n",
              " {'score': 2.634095653775148e-05,\n",
              "  'start': 17,\n",
              "  'end': 33,\n",
              "  'answer': 'one of the world'},\n",
              " {'score': 1.7104950529756024e-05,\n",
              "  'start': 284,\n",
              "  'end': 303,\n",
              "  'answer': '1. Michael Morton \\n'},\n",
              " {'score': 1.4555625966750085e-05, 'start': 42, 'end': 47, 'answer': 'world'},\n",
              " {'score': 2.9413871743599884e-05,\n",
              "  'start': 369,\n",
              "  'end': 402,\n",
              "  'answer': 'his first game in charge was a 2–'},\n",
              " {'score': 1.5538969819317572e-05, 'start': 191, 'end': 192, 'answer': '\\n'},\n",
              " {'score': 8.730879926588386e-05,\n",
              "  'start': 968,\n",
              "  'end': 995,\n",
              "  'answer': 'off to play with his sister'},\n",
              " {'score': 2.18103905353928e-05,\n",
              "  'start': 17,\n",
              "  'end': 72,\n",
              "  'answer': 'students\"), alternatively spelled Taleban, which refers'},\n",
              " {'score': 1.6921603673836216e-05,\n",
              "  'start': 195,\n",
              "  'end': 290,\n",
              "  'answer': 'worked for a private security firm when President Obama visited the Centers for Disease Control'},\n",
              " {'score': 1.5669200365664437e-05,\n",
              "  'start': 29,\n",
              "  'end': 102,\n",
              "  'answer': 'A young, female suicide bomber was behind a blast in Pakistan that killed'},\n",
              " {'score': 1.3884169675293379e-05, 'start': 40, 'end': 41, 'answer': '\\n'},\n",
              " {'score': 2.799963294819463e-05,\n",
              "  'start': 1392,\n",
              "  'end': 1447,\n",
              "  'answer': 'the psychedelic album \"Their Satanic Majesties Request\"'},\n",
              " {'score': 2.0280065655242652e-05,\n",
              "  'start': 18,\n",
              "  'end': 58,\n",
              "  'answer': 'born in the USA on May,1907. Her mother,'},\n",
              " {'score': 5.2191731811035424e-05,\n",
              "  'start': 1130,\n",
              "  'end': 1139,\n",
              "  'answer': 'it seemed'},\n",
              " {'score': 4.8569221689831465e-05,\n",
              "  'start': 1778,\n",
              "  'end': 1800,\n",
              "  'answer': 'all, as Helena Hamerow'},\n",
              " {'score': 6.651846342720091e-05,\n",
              "  'start': 1095,\n",
              "  'end': 1110,\n",
              "  'answer': 'your brother. \\n'},\n",
              " {'score': 7.42477277526632e-05, 'start': 1024, 'end': 1025, 'answer': '\\n'},\n",
              " {'score': 7.60524781071581e-05, 'start': 1213, 'end': 1214, 'answer': '\\n'},\n",
              " {'score': 7.280909630935639e-05,\n",
              "  'start': 983,\n",
              "  'end': 1008,\n",
              "  'answer': 'on the other side. Norway'},\n",
              " {'score': 3.312445551273413e-05,\n",
              "  'start': 771,\n",
              "  'end': 837,\n",
              "  'answer': 'then suddenly old Ricks stopped short. He was commencing to \"smell'},\n",
              " {'score': 2.6501063985051587e-05,\n",
              "  'start': 78,\n",
              "  'end': 91,\n",
              "  'answer': 'me, a hero is'},\n",
              " {'score': 6.117548036854714e-05, 'start': 1117, 'end': 1120, 'answer': 'Mrs'},\n",
              " {'score': 5.4940923291724175e-05, 'start': 1316, 'end': 1317, 'answer': '\\n'},\n",
              " {'score': 2.82714499917347e-05,\n",
              "  'start': 984,\n",
              "  'end': 991,\n",
              "  'answer': 'nothing'},\n",
              " {'score': 9.050255903275684e-05,\n",
              "  'start': 1387,\n",
              "  'end': 1440,\n",
              "  'answer': '-day stay, we aided Hannah in remembering \"one finger'},\n",
              " {'score': 4.948122295900248e-05, 'start': 980, 'end': 981, 'answer': '\\n'},\n",
              " {'score': 8.945201989263296e-05,\n",
              "  'start': 1393,\n",
              "  'end': 1397,\n",
              "  'answer': 'Hasn'},\n",
              " {'score': 8.135473035508767e-05, 'start': 1100, 'end': 1101, 'answer': '\\n'},\n",
              " {'score': 3.252513852203265e-05,\n",
              "  'start': 97,\n",
              "  'end': 137,\n",
              "  'answer': 'a new song and is ready to put it out. \\n'},\n",
              " {'score': 7.715189713053405e-05,\n",
              "  'start': 1206,\n",
              "  'end': 1228,\n",
              "  'answer': 'one of his servants. \\n'},\n",
              " {'score': 9.160149784293026e-05,\n",
              "  'start': 1280,\n",
              "  'end': 1327,\n",
              "  'answer': \"'s Christiane Amanpour at a BattleCry event » \\n\"},\n",
              " {'score': 1.415767655998934e-05,\n",
              "  'start': 1552,\n",
              "  'end': 1584,\n",
              "  'answer': 'early 18th century, Scandinavian'},\n",
              " {'score': 4.405218714964576e-05,\n",
              "  'start': 1151,\n",
              "  'end': 1163,\n",
              "  'answer': 'he had never'},\n",
              " {'score': 4.287651972845197e-05,\n",
              "  'start': 238,\n",
              "  'end': 256,\n",
              "  'answer': \"I'm a good cook or\"},\n",
              " {'score': 2.3267717551789246e-05,\n",
              "  'start': 33,\n",
              "  'end': 42,\n",
              "  'answer': 'her mommy'},\n",
              " {'score': 2.0165294699836522e-05,\n",
              "  'start': 51,\n",
              "  'end': 108,\n",
              "  'answer': 'an extended term for information communication technology'},\n",
              " {'score': 1.4797808944422286e-05, 'start': 138, 'end': 139, 'answer': '\\n'},\n",
              " {'score': 6.0397316701710224e-05, 'start': 1016, 'end': 1017, 'answer': '\\n'},\n",
              " {'score': 2.444741221552249e-05,\n",
              "  'start': 34,\n",
              "  'end': 53,\n",
              "  'answer': 'work to set a world'},\n",
              " {'score': 3.02905282296706e-05,\n",
              "  'start': 114,\n",
              "  'end': 124,\n",
              "  'answer': 'kilometres'},\n",
              " {'score': 1.6287167454720475e-05,\n",
              "  'start': 167,\n",
              "  'end': 219,\n",
              "  'answer': '\\n\\nThe government of the de facto state of Somaliland'},\n",
              " {'score': 2.9701053790631704e-05,\n",
              "  'start': 1073,\n",
              "  'end': 1084,\n",
              "  'answer': 'equal to or'},\n",
              " {'score': 6.749021849827841e-05,\n",
              "  'start': 1136,\n",
              "  'end': 1146,\n",
              "  'answer': 'she seemed'},\n",
              " {'score': 6.176059105200693e-05,\n",
              "  'start': 1030,\n",
              "  'end': 1064,\n",
              "  'answer': 'He said his men had been in danger'},\n",
              " {'score': 7.66465236665681e-05, 'start': 1207, 'end': 1208, 'answer': '\\n'},\n",
              " {'score': 1.2541585419967305e-05, 'start': 33, 'end': 34, 'answer': '\\n'},\n",
              " {'score': 1.4722113519383129e-05,\n",
              "  'start': 121,\n",
              "  'end': 174,\n",
              "  'answer': \"It's the attack ads occupying the airwaves in Iowa. \\n\"},\n",
              " {'score': 1.471702489652671e-05, 'start': 120, 'end': 122, 'answer': '-0'},\n",
              " {'score': 1.7427006241632625e-05,\n",
              "  'start': 110,\n",
              "  'end': 152,\n",
              "  'answer': 'in South Asia. It shares land borders with'},\n",
              " {'score': 1.6778709323261864e-05,\n",
              "  'start': 57,\n",
              "  'end': 78,\n",
              "  'answer': 'political parties are'},\n",
              " {'score': 4.9976173613686115e-05,\n",
              "  'start': 1319,\n",
              "  'end': 1365,\n",
              "  'answer': \"nobody does that research, we'll pay the price\"},\n",
              " {'score': 5.0572012696648017e-05, 'start': 74, 'end': 78, 'answer': 'wife'},\n",
              " {'score': 1.291051012231037e-05,\n",
              "  'start': 13,\n",
              "  'end': 94,\n",
              "  'answer': 'an American business magazine. Published bi-weekly, it features original articles'},\n",
              " {'score': 1.3062549442111049e-05,\n",
              "  'start': 93,\n",
              "  'end': 107,\n",
              "  'answer': 'on Facebook. \\n'},\n",
              " {'score': 4.21501936216373e-05,\n",
              "  'start': 1163,\n",
              "  'end': 1194,\n",
              "  'answer': 'tailored, something in her face'},\n",
              " {'score': 1.9321729268995114e-05,\n",
              "  'start': 214,\n",
              "  'end': 237,\n",
              "  'answer': 'idea. She said, \"Bailey'},\n",
              " {'score': 8.284827345050871e-05, 'start': 1451, 'end': 1452, 'answer': '\\n'},\n",
              " {'score': 2.316943573532626e-05,\n",
              "  'start': 182,\n",
              "  'end': 226,\n",
              "  'answer': 'form of church government, which is governed'},\n",
              " {'score': 5.1550268835853785e-05,\n",
              "  'start': 1174,\n",
              "  'end': 1212,\n",
              "  'answer': 'care of my father-in-law, who had lung'},\n",
              " {'score': 7.860128971515223e-05, 'start': 1172, 'end': 1173, 'answer': '\\n'},\n",
              " {'score': 7.343748438870534e-05,\n",
              "  'start': 1188,\n",
              "  'end': 1235,\n",
              "  'answer': 'worked together as chairman and managing editor'},\n",
              " {'score': 1.4798461961618159e-05,\n",
              "  'start': 134,\n",
              "  'end': 196,\n",
              "  'answer': 'in the murder trial of Olympian double-amputee Oscar Pistorius'},\n",
              " {'score': 3.638347698142752e-05,\n",
              "  'start': 1186,\n",
              "  'end': 1240,\n",
              "  'answer': \"wouldn't trust Fenn a yard, but I believe in Freistner\"},\n",
              " {'score': 1.3579470760305412e-05, 'start': 33, 'end': 34, 'answer': '\\n'},\n",
              " {'score': 1.9811252059298567e-05,\n",
              "  'start': 200,\n",
              "  'end': 212,\n",
              "  'answer': 'need? We are'},\n",
              " {'score': 1.3607267646875698e-05,\n",
              "  'start': 71,\n",
              "  'end': 95,\n",
              "  'answer': '\\n\\nMeasure for Measure. \\n'},\n",
              " {'score': 1.3201138244767208e-05,\n",
              "  'start': 1175,\n",
              "  'end': 1236,\n",
              "  'answer': 'his companions might be and how he could find his way home. \\n'},\n",
              " {'score': 4.3896317947655916e-05,\n",
              "  'start': 1107,\n",
              "  'end': 1116,\n",
              "  'answer': 'linguists'},\n",
              " {'score': 1.2084558875358198e-05,\n",
              "  'start': 330,\n",
              "  'end': 358,\n",
              "  'answer': 'make their jack-o-lanterns ('},\n",
              " {'score': 6.402946019079536e-05,\n",
              "  'start': 1073,\n",
              "  'end': 1103,\n",
              "  'answer': \"Canada's two other territories\"},\n",
              " {'score': 7.929011189844459e-05,\n",
              "  'start': 910,\n",
              "  'end': 937,\n",
              "  'answer': 'Mr. Beresford. I have heard'},\n",
              " {'score': 2.0678880900959484e-05,\n",
              "  'start': 1106,\n",
              "  'end': 1152,\n",
              "  'answer': 'part of the Kingdom of Austrasia. Under Clovis'},\n",
              " {'score': 8.114808588288724e-05,\n",
              "  'start': 1049,\n",
              "  'end': 1065,\n",
              "  'answer': 'original seat. \\n'},\n",
              " {'score': 2.0692425096058287e-05,\n",
              "  'start': 53,\n",
              "  'end': 66,\n",
              "  'answer': 'from the lady'},\n",
              " {'score': 1.549958142277319e-05,\n",
              "  'start': 30,\n",
              "  'end': 91,\n",
              "  'answer': 'new album is \"very positive\" but admits that it started out \"'},\n",
              " {'score': 2.6517025617067702e-05,\n",
              "  'start': 197,\n",
              "  'end': 239,\n",
              "  'answer': 'he sees now that his success is the result'},\n",
              " {'score': 1.357980272587156e-05,\n",
              "  'start': 346,\n",
              "  'end': 393,\n",
              "  'answer': '\\'s novel \"Emile, or On Education\" is a treatise'},\n",
              " {'score': 1.3100057003612164e-05,\n",
              "  'start': 93,\n",
              "  'end': 114,\n",
              "  'answer': 'in Midtown Manhattan,'},\n",
              " {'score': 7.548946450697258e-05,\n",
              "  'start': 1228,\n",
              "  'end': 1267,\n",
              "  'answer': 'well as later ones that have been dated'},\n",
              " {'score': 2.314438643225003e-05,\n",
              "  'start': 0,\n",
              "  'end': 55,\n",
              "  'answer': 'An antenna (plural antennae or antennas), or aerial, is'},\n",
              " {'score': 3.797805402427912e-05, 'start': 972, 'end': 976, 'answer': '.\" \\n'},\n",
              " {'score': 9.409782069269568e-05,\n",
              "  'start': 1097,\n",
              "  'end': 1128,\n",
              "  'answer': 'Mrs.Woods began feeding her.Mrs'},\n",
              " {'score': 1.34746605908731e-05,\n",
              "  'start': 70,\n",
              "  'end': 120,\n",
              "  'answer': 'was once more within the walls of Florence. Unable'},\n",
              " {'score': 3.613172520999797e-05,\n",
              "  'start': 86,\n",
              "  'end': 131,\n",
              "  'answer': 'returning at the return desk. They said hello'},\n",
              " {'score': 1.3203603884903714e-05,\n",
              "  'start': 93,\n",
              "  'end': 114,\n",
              "  'answer': 'in Midtown Manhattan,'},\n",
              " {'score': 4.7382090997416526e-05,\n",
              "  'start': 1177,\n",
              "  'end': 1225,\n",
              "  'answer': 'part of a Jewish conspiracy. \\n\\nBy 1933, the Nazi'},\n",
              " {'score': 2.9952730983495712e-05,\n",
              "  'start': 98,\n",
              "  'end': 130,\n",
              "  'answer': 'going to go swim later. As Timmy'},\n",
              " {'score': 5.4403117246693e-05,\n",
              "  'start': 1263,\n",
              "  'end': 1320,\n",
              "  'answer': 'capital of Andhra Pradesh after the States Reorganisation'},\n",
              " {'score': 1.3796628081763629e-05,\n",
              "  'start': 62,\n",
              "  'end': 121,\n",
              "  'answer': 'in the Pacific Northwest region of the United States. Named'},\n",
              " {'score': 2.7316744308336638e-05,\n",
              "  'start': 250,\n",
              "  'end': 301,\n",
              "  'answer': \"lives. He finally reached the store at 5 o'clock. \\n\"},\n",
              " {'score': 1.6108917407109402e-05,\n",
              "  'start': 113,\n",
              "  'end': 128,\n",
              "  'answer': 'he had listened'},\n",
              " {'score': 1.33728835862712e-05, 'start': 290, 'end': 291, 'answer': '\\n'},\n",
              " {'score': 2.070556001854129e-05,\n",
              "  'start': 1106,\n",
              "  'end': 1117,\n",
              "  'answer': 'part of the'},\n",
              " {'score': 1.63343756867107e-05,\n",
              "  'start': 151,\n",
              "  'end': 227,\n",
              "  'answer': 'kinds of products and goods. Including cars, movies and DVDs, sporting goods'},\n",
              " {'score': 1.5238200830935966e-05,\n",
              "  'start': 1333,\n",
              "  'end': 1366,\n",
              "  'answer': 'moved, looked at Jane, and a tear'},\n",
              " {'score': 1.7063624909496866e-05, 'start': 49, 'end': 50, 'answer': '\\n'},\n",
              " {'score': 3.5874028981197625e-05,\n",
              "  'start': 1426,\n",
              "  'end': 1446,\n",
              "  'answer': 'almost forgotten--or'},\n",
              " {'score': 2.0548130123643205e-05, 'start': 213, 'end': 216, 'answer': 'Mrs'},\n",
              " {'score': 1.5053345123305917e-05,\n",
              "  'start': 205,\n",
              "  'end': 276,\n",
              "  'answer': 'all the participants said progress was made and talks would continue. \\n'},\n",
              " {'score': 1.2721508028334938e-05, 'start': 176, 'end': 177, 'answer': '\\n'},\n",
              " {'score': 6.846667383797467e-05, 'start': 1100, 'end': 1101, 'answer': '\\n'},\n",
              " {'score': 1.5850724594201893e-05,\n",
              "  'start': 194,\n",
              "  'end': 253,\n",
              "  'answer': 'was ten when her paintings became famous all over the world'},\n",
              " {'score': 8.196516864700243e-05,\n",
              "  'start': 1375,\n",
              "  'end': 1401,\n",
              "  'answer': 'first four Crusader states'},\n",
              " {'score': 2.236007094325032e-05,\n",
              "  'start': 163,\n",
              "  'end': 196,\n",
              "  'answer': 'she change the world? Hello Kitty'},\n",
              " {'score': 8.785008685663342e-05,\n",
              "  'start': 1053,\n",
              "  'end': 1105,\n",
              "  'answer': 'dreadful to think they\\'re all over.\" \\n\\nTwo big tears'},\n",
              " {'score': 7.140023080864921e-05,\n",
              "  'start': 1247,\n",
              "  'end': 1256,\n",
              "  'answer': 'the world'},\n",
              " {'score': 1.507554406998679e-05, 'start': 161, 'end': 162, 'answer': '\\n'},\n",
              " {'score': 1.4531648048432544e-05, 'start': 37, 'end': 38, 'answer': '\\n'},\n",
              " {'score': 3.416050458326936e-05,\n",
              "  'start': 1162,\n",
              "  'end': 1177,\n",
              "  'answer': 'sure, Littleson'},\n",
              " {'score': 1.5341604012064636e-05,\n",
              "  'start': 77,\n",
              "  'end': 122,\n",
              "  'answer': 'in the blood of animals as blood sugar. It is'},\n",
              " {'score': 1.994764170376584e-05,\n",
              "  'start': 1099,\n",
              "  'end': 1176,\n",
              "  'answer': 'close they were until recently. A few months ago Bella suffered a spinal cord'},\n",
              " {'score': 8.741437341086566e-05,\n",
              "  'start': 1333,\n",
              "  'end': 1395,\n",
              "  'answer': \"winner's affair was based on lies he told her, Dickens said. \\n\"},\n",
              " {'score': 2.8254960852791555e-05,\n",
              "  'start': 121,\n",
              "  'end': 142,\n",
              "  'answer': 'one of the wealthiest'},\n",
              " {'score': 1.4279926290328149e-05,\n",
              "  'start': 294,\n",
              "  'end': 335,\n",
              "  'answer': 'working with the U.S. to \"examine a range'},\n",
              " {'score': 5.309007246978581e-05,\n",
              "  'start': 1241,\n",
              "  'end': 1268,\n",
              "  'answer': 'his eyes, we see that he is'},\n",
              " {'score': 1.3076161849312484e-05,\n",
              "  'start': 107,\n",
              "  'end': 163,\n",
              "  'answer': 'Anne, amid all her vacation joys, was haunted by a sense'},\n",
              " {'score': 8.807715494185686e-05,\n",
              "  'start': 1384,\n",
              "  'end': 1402,\n",
              "  'answer': \"'s Rosalina Nieves\"},\n",
              " {'score': 3.162916254950687e-05,\n",
              "  'start': 1473,\n",
              "  'end': 1525,\n",
              "  'answer': 'earned only about ten dollars a year from writing. \\n'},\n",
              " {'score': 7.608355372212827e-05, 'start': 1139, 'end': 1140, 'answer': '\\n'},\n",
              " {'score': 2.3126009182306007e-05,\n",
              "  'start': 3,\n",
              "  'end': 67,\n",
              "  'answer': 'you know Australia? Australia is the largest island in the world'},\n",
              " {'score': 1.604616227268707e-05,\n",
              "  'start': 62,\n",
              "  'end': 108,\n",
              "  'answer': 'How long did it take people to find the answer'},\n",
              " {'score': 7.085174001986161e-05,\n",
              "  'start': 1436,\n",
              "  'end': 1450,\n",
              "  'answer': 'his characters'},\n",
              " {'score': 4.256595639162697e-05,\n",
              "  'start': 120,\n",
              "  'end': 130,\n",
              "  'answer': 'his finger'},\n",
              " {'score': 8.439021621597931e-05,\n",
              "  'start': 933,\n",
              "  'end': 959,\n",
              "  'answer': 'every 8 December and lasts'},\n",
              " {'score': 3.1975785532267764e-05,\n",
              "  'start': 887,\n",
              "  'end': 901,\n",
              "  'answer': '“You scoundrel'},\n",
              " {'score': 1.5709756553405896e-05,\n",
              "  'start': 97,\n",
              "  'end': 155,\n",
              "  'answer': 'one of the most important statesmen of the 20th century. \\n'},\n",
              " {'score': 1.551117020426318e-05,\n",
              "  'start': 5,\n",
              "  'end': 76,\n",
              "  'answer': 'people know that Marie Curie was the first woman to win the Nobel Prize'},\n",
              " {'score': 3.8623507862212136e-05,\n",
              "  'start': 77,\n",
              "  'end': 154,\n",
              "  'answer': 'herself seriously in a competition at the Goodwill Games held in Long Island,'},\n",
              " {'score': 6.475319241872057e-05,\n",
              "  'start': 1154,\n",
              "  'end': 1204,\n",
              "  'answer': 'way,\" said he pulling at my sleeve, \"what a deuced'},\n",
              " {'score': 1.416465784132015e-05, 'start': 39, 'end': 40, 'answer': '\\n'},\n",
              " {'score': 1.9150376829202287e-05,\n",
              "  'start': 818,\n",
              "  'end': 888,\n",
              "  'answer': 'one-third of the national population lives in the metropolitan area. \\n'},\n",
              " {'score': 8.892863115761429e-05, 'start': 1140, 'end': 1141, 'answer': '\\n'},\n",
              " {'score': 3.5654895327752456e-05,\n",
              "  'start': 1426,\n",
              "  'end': 1446,\n",
              "  'answer': 'almost forgotten--or'},\n",
              " {'score': 7.519443897763267e-05,\n",
              "  'start': 1283,\n",
              "  'end': 1328,\n",
              "  'answer': 'Wagon, with four bedrooms inside the cabin. \\n'},\n",
              " {'score': 1.742426866258029e-05,\n",
              "  'start': 285,\n",
              "  'end': 293,\n",
              "  'answer': '$200,000'},\n",
              " {'score': 3.9844951970735565e-05,\n",
              "  'start': 22,\n",
              "  'end': 70,\n",
              "  'answer': \"It's about a lovely cat called Green Eyes. He is\"},\n",
              " {'score': 4.770052692038007e-05, 'start': 1437, 'end': 1440, 'answer': 'Mrs'},\n",
              " {'score': 1.2894622159365099e-05, 'start': 320, 'end': 321, 'answer': '\\n'},\n",
              " {'score': 2.895873512898106e-05,\n",
              "  'start': 4,\n",
              "  'end': 75,\n",
              "  'answer': 'chipmunks were busy getting ready for the winter. Little Chip had never'},\n",
              " {'score': 8.158669515978545e-05,\n",
              "  'start': 1055,\n",
              "  'end': 1099,\n",
              "  'answer': 'of the ship. \\n\\nBy this time Hans had managed'},\n",
              " {'score': 7.484719390049577e-05,\n",
              "  'start': 896,\n",
              "  'end': 906,\n",
              "  'answer': 'Kyrgyzstan'},\n",
              " {'score': 1.5253656783897895e-05,\n",
              "  'start': 71,\n",
              "  'end': 137,\n",
              "  'answer': \"he's prepared to fight for a new job growth plan, defend organized\"},\n",
              " {'score': 6.297134677879512e-05,\n",
              "  'start': 1298,\n",
              "  'end': 1308,\n",
              "  'answer': 'found Lady'},\n",
              " {'score': 1.5607573004672304e-05, 'start': 84, 'end': 88, 'answer': 'wife'},\n",
              " {'score': 1.3955625945527572e-05,\n",
              "  'start': 102,\n",
              "  'end': 165,\n",
              "  'answer': 'in Colorado on Sunday, died from a self-inflicted gunshot wound'},\n",
              " {'score': 4.225521843181923e-05,\n",
              "  'start': 1237,\n",
              "  'end': 1259,\n",
              "  'answer': 'a 21-year-old computer'},\n",
              " {'score': 4.270745921530761e-05,\n",
              "  'start': 111,\n",
              "  'end': 168,\n",
              "  'answer': 'on Earth. One of the most widely used definitions defines'},\n",
              " {'score': 5.786227484350093e-05,\n",
              "  'start': 1130,\n",
              "  'end': 1194,\n",
              "  'answer': \"a home's staircase with lasting impressions of the experience. \\n\"},\n",
              " {'score': 1.830086148402188e-05,\n",
              "  'start': 39,\n",
              "  'end': 125,\n",
              "  'answer': 'company that sold computers, computer components, software, and information technology'},\n",
              " {'score': 2.9343371352297254e-05,\n",
              "  'start': 34,\n",
              "  'end': 51,\n",
              "  'answer': 'a correspondingly'},\n",
              " {'score': 1.892058389785234e-05,\n",
              "  'start': 38,\n",
              "  'end': 82,\n",
              "  'answer': 'survival and reproduction of individuals due'},\n",
              " {'score': 2.4486682377755642e-05,\n",
              "  'start': 1125,\n",
              "  'end': 1180,\n",
              "  'answer': 'You know what I mean, you small willain; I drink nothin'},\n",
              " {'score': 1.2794734175258782e-05,\n",
              "  'start': 49,\n",
              "  'end': 87,\n",
              "  'answer': 'on a plane in the United Arab Emirates'},\n",
              " {'score': 7.98647160991095e-05,\n",
              "  'start': 1236,\n",
              "  'end': 1240,\n",
              "  'answer': \".' \\n\"},\n",
              " {'score': 2.6441812224220484e-05,\n",
              "  'start': 154,\n",
              "  'end': 198,\n",
              "  'answer': 'Jack plays fetch with Max for a long time. \\n'},\n",
              " {'score': 1.2881268958153669e-05,\n",
              "  'start': 41,\n",
              "  'end': 101,\n",
              "  'answer': '1649) was monarch of the three kingdoms of England, Scotland'},\n",
              " {'score': 1.3529357602237724e-05,\n",
              "  'start': 26,\n",
              "  'end': 48,\n",
              "  'answer': 'lived in a castle made'},\n",
              " {'score': 1.7334674339508638e-05,\n",
              "  'start': 197,\n",
              "  'end': 205,\n",
              "  'answer': '$210,000'},\n",
              " {'score': 1.4139450286165811e-05,\n",
              "  'start': 33,\n",
              "  'end': 87,\n",
              "  'answer': 'look! May and Fred have both gone down!\" cried Ruth. \\n'},\n",
              " {'score': 1.2743687875627074e-05, 'start': 304, 'end': 305, 'answer': '\\n'},\n",
              " {'score': 7.518888742197305e-05, 'start': 1183, 'end': 1184, 'answer': '\\n'},\n",
              " {'score': 6.19795682723634e-05,\n",
              "  'start': 1389,\n",
              "  'end': 1413,\n",
              "  'answer': '\\n\\n\"Charming and churlish'},\n",
              " {'score': 2.438036426610779e-05,\n",
              "  'start': 113,\n",
              "  'end': 166,\n",
              "  'answer': 'going to wear a black dress, so everybody will notice'},\n",
              " {'score': 4.3707746954169124e-05,\n",
              "  'start': 155,\n",
              "  'end': 224,\n",
              "  'answer': 'wasn\\'t home and grabbed her youngest brother. \"Give me your jewels or'},\n",
              " {'score': 6.830738129792735e-05, 'start': 1169, 'end': 1170, 'answer': '\\n'},\n",
              " {'score': 3.5527678846847266e-05,\n",
              "  'start': 0,\n",
              "  'end': 15,\n",
              "  'answer': 'All the Grizzly'},\n",
              " {'score': 1.690311728452798e-05,\n",
              "  'start': 211,\n",
              "  'end': 228,\n",
              "  'answer': 'of Central Europe'},\n",
              " {'score': 2.3095824872143567e-05,\n",
              "  'start': 279,\n",
              "  'end': 294,\n",
              "  'answer': 'of Paul Cézanne'},\n",
              " {'score': 8.132445509545505e-05, 'start': 1171, 'end': 1172, 'answer': '\\n'},\n",
              " {'score': 3.464064866420813e-05,\n",
              "  'start': 1162,\n",
              "  'end': 1177,\n",
              "  'answer': 'sure, Littleson'},\n",
              " {'score': 1.4129860574030317e-05,\n",
              "  'start': 251,\n",
              "  'end': 274,\n",
              "  'answer': 'him in the standings. \\n'},\n",
              " {'score': 5.034474452259019e-05,\n",
              "  'start': 1301,\n",
              "  'end': 1311,\n",
              "  'answer': 'he appears'},\n",
              " {'score': 2.8175030820420943e-05,\n",
              "  'start': 11,\n",
              "  'end': 57,\n",
              "  'answer': 'I have a best friend. His name is James. He is'},\n",
              " {'score': 5.9353114920668304e-05,\n",
              "  'start': 1138,\n",
              "  'end': 1157,\n",
              "  'answer': 'writers of eminence'},\n",
              " {'score': 7.341757009271532e-05, 'start': 1305, 'end': 1306, 'answer': '\\n'},\n",
              " {'score': 5.576998955802992e-05,\n",
              "  'start': 41,\n",
              "  'end': 111,\n",
              "  'answer': 'drawing with chalk. They drew many things with the chalk. One of those'},\n",
              " {'score': 1.5266183254425414e-05, 'start': 218, 'end': 219, 'answer': '\\n'},\n",
              " {'score': 2.2750016796635464e-05,\n",
              "  'start': 118,\n",
              "  'end': 123,\n",
              "  'answer': 'order'},\n",
              " {'score': 1.2440607861208264e-05, 'start': 131, 'end': 132, 'answer': '\\n'},\n",
              " {'score': 2.2539594283443876e-05,\n",
              "  'start': 0,\n",
              "  'end': 10,\n",
              "  'answer': 'The theory'},\n",
              " {'score': 1.4911172911524773e-05,\n",
              "  'start': 1396,\n",
              "  'end': 1401,\n",
              "  'answer': 'World'},\n",
              " {'score': 7.916947652120143e-05,\n",
              "  'start': 1314,\n",
              "  'end': 1367,\n",
              "  'answer': 'team studied the Great Lakes sea rocket, a plant that'},\n",
              " {'score': 8.303762297146022e-05,\n",
              "  'start': 1126,\n",
              "  'end': 1132,\n",
              "  'answer': 'symbol'},\n",
              " {'score': 7.236705278046429e-05,\n",
              "  'start': 1086,\n",
              "  'end': 1114,\n",
              "  'answer': 'one-year-old child weighs. \\n'},\n",
              " {'score': 4.2572239181026816e-05,\n",
              "  'start': 18,\n",
              "  'end': 85,\n",
              "  'answer': 'lived in a small town in the state of Kentucky. Jerry owned a sheep'},\n",
              " {'score': 1.7948788809007965e-05,\n",
              "  'start': 378,\n",
              "  'end': 400,\n",
              "  'answer': 'sixth-largest Scottish'},\n",
              " {'score': 1.6196845535887405e-05,\n",
              "  'start': 214,\n",
              "  'end': 278,\n",
              "  'answer': 'his new documentary, \"Something from Nothing: The Art of Rap.\" \\n'},\n",
              " {'score': 5.161054650670849e-05,\n",
              "  'start': 1241,\n",
              "  'end': 1268,\n",
              "  'answer': 'his eyes, we see that he is'},\n",
              " {'score': 2.1077494238852523e-05,\n",
              "  'start': 40,\n",
              "  'end': 116,\n",
              "  'answer': 'their animals to work , a move scientists say can be good for productivity ,'},\n",
              " {'score': 2.0715746359201148e-05,\n",
              "  'start': 209,\n",
              "  'end': 240,\n",
              "  'answer': 'the new FX anthology miniseries'},\n",
              " {'score': 1.4866779565636534e-05,\n",
              "  'start': 374,\n",
              "  'end': 418,\n",
              "  'answer': \"on his family's failing farms in Missouri. \\n\"},\n",
              " {'score': 4.950591755914502e-05,\n",
              "  'start': 1136,\n",
              "  'end': 1145,\n",
              "  'answer': 'he seemed'},\n",
              " {'score': 2.8615711926249787e-05,\n",
              "  'start': 1568,\n",
              "  'end': 1603,\n",
              "  'answer': '-ups \"Let It Bleed\" (1969), \"Sticky'},\n",
              " {'score': 7.467465184163302e-05, 'start': 1025, 'end': 1028, 'answer': 'Mrs'},\n",
              " {'score': 4.920186256640591e-05,\n",
              "  'start': 255,\n",
              "  'end': 286,\n",
              "  'answer': 'worked as a video game designer'},\n",
              " {'score': 4.56481720902957e-05,\n",
              "  'start': 40,\n",
              "  'end': 121,\n",
              "  'answer': 'his time after school playing basketball and baseball. Sometimes Timothy pretends'},\n",
              " {'score': 4.289216667530127e-05,\n",
              "  'start': 1092,\n",
              "  'end': 1098,\n",
              "  'answer': 'one. \\n'},\n",
              " {'score': 5.3368679800769314e-05,\n",
              "  'start': 998,\n",
              "  'end': 1028,\n",
              "  'answer': 'going to be a wild evening.\" \\n'},\n",
              " {'score': 3.2588137401035056e-05,\n",
              "  'start': 3205,\n",
              "  'end': 3245,\n",
              "  'answer': 'You once said you thought we were a deal'},\n",
              " {'score': 1.3502656656783074e-05,\n",
              "  'start': 1281,\n",
              "  'end': 1305,\n",
              "  'answer': 'N to as far south as 12°'},\n",
              " {'score': 7.861424091970548e-05, 'start': 1201, 'end': 1202, 'answer': '\\n'},\n",
              " {'score': 1.3933805348642636e-05, 'start': 31, 'end': 32, 'answer': '\\n'},\n",
              " {'score': 4.4488308049039915e-05,\n",
              "  'start': 1175,\n",
              "  'end': 1227,\n",
              "  'answer': 'in the United States is wasted. Wholesale food costs'},\n",
              " {'score': 1.4834615285508335e-05,\n",
              "  'start': 145,\n",
              "  'end': 169,\n",
              "  'answer': 'people with disabilities'},\n",
              " {'score': 2.2702806745655835e-05,\n",
              "  'start': 1079,\n",
              "  'end': 1127,\n",
              "  'answer': 'I had been around children so much,\" she sighs ,'},\n",
              " {'score': 1.2041154150210787e-05,\n",
              "  'start': 85,\n",
              "  'end': 95,\n",
              "  'answer': 'in Ithaca,'},\n",
              " {'score': 2.8355661925161257e-05,\n",
              "  'start': 1261,\n",
              "  'end': 1286,\n",
              "  'answer': 'his last hope--a letter--'},\n",
              " {'score': 9.451399091631174e-05,\n",
              "  'start': 1283,\n",
              "  'end': 1339,\n",
              "  'answer': 'young child, sentencing him to a future in the fields. \\n'},\n",
              " {'score': 6.111882976256311e-05,\n",
              "  'start': 1418,\n",
              "  'end': 1464,\n",
              "  'answer': 'the new novel a modern sensibility and pace. \\n'},\n",
              " {'score': 1.6256481103482656e-05,\n",
              "  'start': 28,\n",
              "  'end': 65,\n",
              "  'answer': 'in the central region of Los Angeles,'},\n",
              " {'score': 1.3061393474345095e-05, 'start': 265, 'end': 266, 'answer': '\\n'},\n",
              " {'score': 5.70674856135156e-05,\n",
              "  'start': 3161,\n",
              "  'end': 3167,\n",
              "  'answer': 'nobody'},\n",
              " {'score': 6.0910046158824116e-05,\n",
              "  'start': 1461,\n",
              "  'end': 1499,\n",
              "  'answer': 'in the worldthe definitive Hellenistic'},\n",
              " {'score': 1.3575471712101717e-05,\n",
              "  'start': 4,\n",
              "  'end': 21,\n",
              "  'answer': ') -- Three people'},\n",
              " {'score': 3.143861249554902e-05,\n",
              "  'start': 955,\n",
              "  'end': 1007,\n",
              "  'answer': 'created by Mei Lanfang, who played an important role'},\n",
              " {'score': 3.7491856346605346e-05,\n",
              "  'start': 56,\n",
              "  'end': 93,\n",
              "  'answer': 'When Helen Keller was a baby, she got'},\n",
              " {'score': 0.00010588706936687231,\n",
              "  'start': 1146,\n",
              "  'end': 1180,\n",
              "  'answer': 'only one to keep perfectly cool. \\n'},\n",
              " {'score': 5.569204586208798e-05,\n",
              "  'start': 1208,\n",
              "  'end': 1260,\n",
              "  'answer': 'whole family gathered around the sixty-year-old lady'},\n",
              " {'score': 5.1108327170368284e-05,\n",
              "  'start': 1320,\n",
              "  'end': 1340,\n",
              "  'answer': 'one million tourists'},\n",
              " {'score': 1.5232755686156452e-05,\n",
              "  'start': 81,\n",
              "  'end': 90,\n",
              "  'answer': 'his death'},\n",
              " {'score': 1.2458203855203465e-05,\n",
              "  'start': 134,\n",
              "  'end': 144,\n",
              "  'answer': 'Phoenician'},\n",
              " {'score': 1.642590905248653e-05,\n",
              "  'start': 24,\n",
              "  'end': 34,\n",
              "  'answer': 'first lady'},\n",
              " {'score': 1.2143666026531719e-05, 'start': 0, 'end': 7, 'answer': 'Cornell'},\n",
              " {'score': 1.4193453353072982e-05,\n",
              "  'start': 32,\n",
              "  'end': 62,\n",
              "  'answer': \"can't stop playing classics. \\n\"},\n",
              " {'score': 3.472420576144941e-05,\n",
              "  'start': 1180,\n",
              "  'end': 1214,\n",
              "  'answer': '-date encyclopedias , dictionaries'},\n",
              " {'score': 7.712348451605067e-05, 'start': 1566, 'end': 1567, 'answer': '\\n'},\n",
              " {'score': 1.303880344494246e-05,\n",
              "  'start': 220,\n",
              "  'end': 266,\n",
              "  'answer': 'candidate from the ruling center-left party. \\n'},\n",
              " {'score': 3.972127888118848e-05, 'start': 1050, 'end': 1051, 'answer': '\\n'},\n",
              " {'score': 1.76817957253661e-05,\n",
              "  'start': 8,\n",
              "  'end': 35,\n",
              "  'answer': '1 \\n\\nThe Information Highway'},\n",
              " {'score': 0.00010174183262279257,\n",
              "  'start': 1240,\n",
              "  'end': 1278,\n",
              "  'answer': '$10 for 10kg. He has 340 melons in all'},\n",
              " {'score': 3.4256550861755386e-05,\n",
              "  'start': 1126,\n",
              "  'end': 1131,\n",
              "  'answer': 'he is'},\n",
              " {'score': 1.3466320524457842e-05, 'start': 281, 'end': 282, 'answer': '\\n'},\n",
              " {'score': 5.368218990042806e-05,\n",
              "  'start': 1169,\n",
              "  'end': 1210,\n",
              "  'answer': 'his natural performance in \"Blind Shaft\",'},\n",
              " {'score': 4.374296258902177e-05,\n",
              "  'start': 1153,\n",
              "  'end': 1167,\n",
              "  'answer': 'every one that'},\n",
              " {'score': 3.365191878401674e-05,\n",
              "  'start': 1126,\n",
              "  'end': 1164,\n",
              "  'answer': \"who's been a restaurant critic for the\"},\n",
              " {'score': 8.837367204250768e-05,\n",
              "  'start': 1136,\n",
              "  'end': 1162,\n",
              "  'answer': 'depends on how big Comrade'},\n",
              " {'score': 3.831705544143915e-05,\n",
              "  'start': 1280,\n",
              "  'end': 1344,\n",
              "  'answer': 'authors plan to make their findings available free on the Web. \\n'},\n",
              " {'score': 9.378217509947717e-05,\n",
              "  'start': 1028,\n",
              "  'end': 1085,\n",
              "  'answer': 'trying to build on that confidence,\" he added. \\n\\nDjokovic'},\n",
              " {'score': 1.4098322026256938e-05,\n",
              "  'start': 181,\n",
              "  'end': 215,\n",
              "  'answer': 'his first goals at the Bernabeu. \\n'},\n",
              " {'score': 1.3704072443943005e-05,\n",
              "  'start': 116,\n",
              "  'end': 190,\n",
              "  'answer': '$13 million, alleging his human rights were violated when Chile extradited'},\n",
              " {'score': 2.503772520867642e-05,\n",
              "  'start': 24,\n",
              "  'end': 123,\n",
              "  'answer': 'organisms to anticipate and prepare for precise and regular environmental changes. They thus enable'},\n",
              " {'score': 1.6804553524707444e-05,\n",
              "  'start': 223,\n",
              "  'end': 278,\n",
              "  'answer': 'fourth-largest city in France, with 466,297 inhabitants'},\n",
              " {'score': 5.145225077285431e-05, 'start': 1231, 'end': 1232, 'answer': '\\n'},\n",
              " {'score': 1.768030233506579e-05,\n",
              "  'start': 19,\n",
              "  'end': 65,\n",
              "  'answer': 'people drink coffee when meeting with friends.'},\n",
              " {'score': 7.353188266279176e-05,\n",
              "  'start': 1109,\n",
              "  'end': 1113,\n",
              "  'answer': \".' \\n\"},\n",
              " {'score': 2.8030095563735813e-05,\n",
              "  'start': 115,\n",
              "  'end': 154,\n",
              "  'answer': 'a book for girls. At first, she was not'},\n",
              " {'score': 1.3032407878199592e-05,\n",
              "  'start': 92,\n",
              "  'end': 116,\n",
              "  'answer': '-year-old Syrian refugee'},\n",
              " {'score': 1.7895976270665415e-05,\n",
              "  'start': 324,\n",
              "  'end': 363,\n",
              "  'answer': 'symbol (internally called \"Bird\\'s Eye\",'},\n",
              " {'score': 1.4634743820352014e-05,\n",
              "  'start': 40,\n",
              "  'end': 49,\n",
              "  'answer': 'Црна Гора'},\n",
              " {'score': 8.247556252172217e-05,\n",
              "  'start': 1260,\n",
              "  'end': 1299,\n",
              "  'answer': 'an employee found him on the streets. \\n'},\n",
              " {'score': 1.769320442690514e-05,\n",
              "  'start': 142,\n",
              "  'end': 173,\n",
              "  'answer': 'people think the worst thing is'},\n",
              " {'score': 2.5001452740980312e-05, 'start': 1125, 'end': 1126, 'answer': '\\n'},\n",
              " {'score': 1.7734420907800086e-05,\n",
              "  'start': 14,\n",
              "  'end': 54,\n",
              "  'answer': 'FIVE \\n\\nIN WHICH TOM PINCH AND HIS SISTER'},\n",
              " {'score': 2.580331238277722e-05,\n",
              "  'start': 317,\n",
              "  'end': 380,\n",
              "  'answer': 'th largest city in the United States, with a population of 419,'},\n",
              " {'score': 1.8034017557511106e-05,\n",
              "  'start': 16,\n",
              "  'end': 37,\n",
              "  'answer': 'a 10-year-old pianist'},\n",
              " {'score': 4.894079393125139e-05,\n",
              "  'start': 233,\n",
              "  'end': 263,\n",
              "  'answer': 'write her own songs instead. \\n'},\n",
              " {'score': 1.4508275853586383e-05,\n",
              "  'start': 222,\n",
              "  'end': 278,\n",
              "  'answer': 'turned to look down the Lone Little Path. There, ambling'},\n",
              " {'score': 1.7634925825404935e-05,\n",
              "  'start': 99,\n",
              "  'end': 128,\n",
              "  'answer': 'of this new animated show isn'},\n",
              " {'score': 4.431558772921562e-05,\n",
              "  'start': 1139,\n",
              "  'end': 1143,\n",
              "  'answer': 'wife'},\n",
              " {'score': 1.4348474906000774e-05, 'start': 24, 'end': 30, 'answer': 'Henrik'},\n",
              " {'score': 1.5849689589231275e-05,\n",
              "  'start': 85,\n",
              "  'end': 144,\n",
              "  'answer': 'his New York apartment with a syringe in his left arm, died'},\n",
              " {'score': 3.8951231545070186e-05,\n",
              "  'start': 0,\n",
              "  'end': 12,\n",
              "  'answer': 'There are 45'},\n",
              " {'score': 1.6895452063181438e-05,\n",
              "  'start': 24,\n",
              "  'end': 45,\n",
              "  'answer': 'young, Drew Barrymore'},\n",
              " {'score': 4.556643762043677e-05,\n",
              "  'start': 1207,\n",
              "  'end': 1249,\n",
              "  'answer': 'he claimed he was born on 20 February 1694'},\n",
              " {'score': 8.41696746647358e-05,\n",
              "  'start': 1436,\n",
              "  'end': 1492,\n",
              "  'answer': 'running for re-election are facing primary challenges. \\n'},\n",
              " {'score': 6.0483329434646294e-05,\n",
              "  'start': 991,\n",
              "  'end': 1038,\n",
              "  'answer': 'Hi, there, Private Tubbs!\" he called out. \"Wake'},\n",
              " {'score': 2.1765537894680165e-05, 'start': 8, 'end': 12, 'answer': 'woke'},\n",
              " {'score': 1.2365407201286871e-05, 'start': 313, 'end': 314, 'answer': '\\n'},\n",
              " {'score': 1.532468741061166e-05,\n",
              "  'start': 1286,\n",
              "  'end': 1322,\n",
              "  'answer': \"creating Robot City. It's a wondrous\"},\n",
              " {'score': 1.4277527043304872e-05,\n",
              "  'start': 15,\n",
              "  'end': 36,\n",
              "  'answer': 'an optical instrument'},\n",
              " {'score': 1.619480644876603e-05,\n",
              "  'start': 1553,\n",
              "  'end': 1598,\n",
              "  'answer': \"'s Lindy Royce contributed to this report. \\n\\n\"},\n",
              " {'score': 4.233980143908411e-05,\n",
              "  'start': 1363,\n",
              "  'end': 1406,\n",
              "  'answer': 'when we were alone, \"Does she grow prettier'},\n",
              " {'score': 2.9191629437264055e-05,\n",
              "  'start': 0,\n",
              "  'end': 13,\n",
              "  'answer': 'When Christie'},\n",
              " {'score': 2.1551375539274886e-05,\n",
              "  'start': 2426,\n",
              "  'end': 2471,\n",
              "  'answer': 'an intern with the council from September 29,'},\n",
              " {'score': 7.63765347073786e-05,\n",
              "  'start': 1239,\n",
              "  'end': 1283,\n",
              "  'answer': 'call) where she was reunited with her sister'},\n",
              " {'score': 1.5285730114555918e-05,\n",
              "  'start': 209,\n",
              "  'end': 247,\n",
              "  'answer': 'Everyone is so much cleverer than I am'},\n",
              " {'score': 4.1356139263371006e-05, 'start': 963, 'end': 964, 'answer': '\\n'},\n",
              " {'score': 1.5150376384553965e-05,\n",
              "  'start': 424,\n",
              "  'end': 496,\n",
              "  'answer': 'visitors to the islands can reliably expect warm, sunny weather. Bonaire'},\n",
              " {'score': 4.398573946673423e-05,\n",
              "  'start': 1182,\n",
              "  'end': 1227,\n",
              "  'answer': 'United States is wasted. Wholesale food costs'},\n",
              " {'score': 1.481435992900515e-05,\n",
              "  'start': 1499,\n",
              "  'end': 1541,\n",
              "  'answer': \"'s Dave Alsup contributed to this report. \"},\n",
              " {'score': 4.017255560029298e-05,\n",
              "  'start': 334,\n",
              "  'end': 345,\n",
              "  'answer': 'v. Radislav'},\n",
              " {'score': 6.488576764240861e-05,\n",
              "  'start': 1453,\n",
              "  'end': 1467,\n",
              "  'answer': 'his characters'},\n",
              " {'score': 5.839678487973288e-05,\n",
              "  'start': 872,\n",
              "  'end': 921,\n",
              "  'answer': 'one has to show a Red Indian fortitude and stifle'},\n",
              " {'score': 1.2176993550383486e-05, 'start': 174, 'end': 175, 'answer': '\\n'},\n",
              " {'score': 7.98156252130866e-05,\n",
              "  'start': 1543,\n",
              "  'end': 1592,\n",
              "  'answer': 'one-on-one duel with the keeper, but Casto denied'},\n",
              " {'score': 3.0612776754423976e-05,\n",
              "  'start': 1055,\n",
              "  'end': 1059,\n",
              "  'answer': 'hand'},\n",
              " {'score': 1.5258596249623224e-05,\n",
              "  'start': 23,\n",
              "  'end': 38,\n",
              "  'answer': \"'S PECCADILLO \\n\"},\n",
              " {'score': 1.6122368833748624e-05, 'start': 31, 'end': 32, 'answer': '\\n'},\n",
              " {'score': 1.8923214156529866e-05,\n",
              "  'start': 26,\n",
              "  'end': 43,\n",
              "  'answer': 'on other planets?'},\n",
              " {'score': 2.7426318411016837e-05,\n",
              "  'start': 12,\n",
              "  'end': 45,\n",
              "  'answer': 'it may be thought that failure is'},\n",
              " {'score': 1.4390559044841211e-05,\n",
              "  'start': 12,\n",
              "  'end': 48,\n",
              "  'answer': '\\n\\nTHE CLEVERNESS OF OLD MAN COYOTE \\n'},\n",
              " {'score': 1.4330650628835429e-05,\n",
              "  'start': 84,\n",
              "  'end': 140,\n",
              "  'answer': 'using a webcam to spy on and intimidate his gay roommate'},\n",
              " {'score': 1.3236192899057642e-05, 'start': 42, 'end': 43, 'answer': '\\n'},\n",
              " {'score': 1.3710307030123658e-05,\n",
              "  'start': 115,\n",
              "  'end': 122,\n",
              "  'answer': 'Kolkata'},\n",
              " {'score': 2.8014923373120837e-05,\n",
              "  'start': 121,\n",
              "  'end': 142,\n",
              "  'answer': 'one of the wealthiest'},\n",
              " {'score': 8.225087367463857e-05,\n",
              "  'start': 1213,\n",
              "  'end': 1225,\n",
              "  'answer': 'in fourth. \\n'},\n",
              " {'score': 3.0551858799299225e-05,\n",
              "  'start': 45,\n",
              "  'end': 99,\n",
              "  'answer': 'went all around the world, to see what he could see. \\n'},\n",
              " {'score': 1.273229190701386e-05,\n",
              "  'start': 1654,\n",
              "  'end': 1708,\n",
              "  'answer': 'candidate Josefina Vazquez Mota has already conceded. '},\n",
              " {'score': 1.4905234820616897e-05,\n",
              "  'start': 25,\n",
              "  'end': 64,\n",
              "  'answer': \"It was Anabella De León's frail 86-year\"},\n",
              " {'score': 1.517560758657055e-05,\n",
              "  'start': 447,\n",
              "  'end': 467,\n",
              "  'answer': 'his 100th F1 race. \\n'},\n",
              " {'score': 5.357782720238902e-05,\n",
              "  'start': 1008,\n",
              "  'end': 1090,\n",
              "  'answer': 'castoffs , when wealthy families would clean out their toy chests at Christmastime'},\n",
              " {'score': 4.612228804035112e-05,\n",
              "  'start': 1112,\n",
              "  'end': 1152,\n",
              "  'answer': \"' in the prehistoric era. \\n\\nThe earliest\"},\n",
              " {'score': 1.2538853297883179e-05,\n",
              "  'start': 389,\n",
              "  'end': 413,\n",
              "  'answer': 'himself as the Dethroned'},\n",
              " {'score': 7.346214988501742e-05,\n",
              "  'start': 1062,\n",
              "  'end': 1128,\n",
              "  'answer': 'No. 3 in the world rankings next week following defending champion'},\n",
              " {'score': 1.642572897253558e-05,\n",
              "  'start': 211,\n",
              "  'end': 265,\n",
              "  'answer': 'new friends Jack and Jane to help build the sandcastle'},\n",
              " {'score': 1.3231535376689862e-05,\n",
              "  'start': 14,\n",
              "  'end': 30,\n",
              "  'answer': '\\n\\nBROOKE BURGESS'},\n",
              " {'score': 2.890213545470033e-05,\n",
              "  'start': 1241,\n",
              "  'end': 1251,\n",
              "  'answer': \",' said Mr\"},\n",
              " {'score': 7.429893594235182e-05, 'start': 1359, 'end': 1360, 'answer': '\\n'},\n",
              " {'score': 2.3774196961312555e-05,\n",
              "  'start': 57,\n",
              "  'end': 116,\n",
              "  'answer': 'best friend Lucy to shop for clothes to wear at the wedding'},\n",
              " {'score': 1.3710349776374642e-05,\n",
              "  'start': 13,\n",
              "  'end': 52,\n",
              "  'answer': '-year-old immigrant from Rwanda, who is'},\n",
              " {'score': 1.293508194066817e-05,\n",
              "  'start': 57,\n",
              "  'end': 101,\n",
              "  'answer': 'world powers over its nuclear program is not'},\n",
              " {'score': 4.782316318596713e-05,\n",
              "  'start': 1598,\n",
              "  'end': 1638,\n",
              "  'answer': 'use of chemicals near populated areas. \\n'},\n",
              " {'score': 6.207116530276835e-05,\n",
              "  'start': 1230,\n",
              "  'end': 1287,\n",
              "  'answer': 'then, Tilly has been diagnosed with Reflex Anoxic Seizure'},\n",
              " {'score': 6.213352753547952e-05,\n",
              "  'start': 1047,\n",
              "  'end': 1053,\n",
              "  'answer': 'he?\" \\n'},\n",
              " {'score': 1.4394468053069431e-05,\n",
              "  'start': 229,\n",
              "  'end': 271,\n",
              "  'answer': 'Every limb was at rest, every nerve seemed'},\n",
              " {'score': 2.9966373404022306e-05,\n",
              "  'start': 1073,\n",
              "  'end': 1084,\n",
              "  'answer': 'equal to or'},\n",
              " {'score': 4.483731390791945e-05,\n",
              "  'start': 1140,\n",
              "  'end': 1146,\n",
              "  'answer': 'Couldn'},\n",
              " {'score': 6.244009273359552e-05,\n",
              "  'start': 1280,\n",
              "  'end': 1287,\n",
              "  'answer': 'you are'},\n",
              " {'score': 5.262859849608503e-05,\n",
              "  'start': 1411,\n",
              "  'end': 1433,\n",
              "  'answer': '$1million. That seemed'},\n",
              " {'score': 7.95076775830239e-05,\n",
              "  'start': 1271,\n",
              "  'end': 1320,\n",
              "  'answer': 'decide whether or not to take his son -- who died'},\n",
              " {'score': 2.24080758925993e-05,\n",
              "  'start': 131,\n",
              "  'end': 192,\n",
              "  'answer': '-Man, such teams as the Avengers, the Guardians of the Galaxy'},\n",
              " {'score': 8.460733806714416e-05,\n",
              "  'start': 1228,\n",
              "  'end': 1262,\n",
              "  'answer': 'kept a few relics of past splendor'},\n",
              " {'score': 2.023114575422369e-05, 'start': 25, 'end': 26, 'answer': '\\n'},\n",
              " {'score': 6.88436339260079e-05,\n",
              "  'start': 1145,\n",
              "  'end': 1198,\n",
              "  'answer': 'it, Jack?\" shouted Dick. \"Who are you shooting at?\" \\n'},\n",
              " {'score': 3.869459396810271e-05, 'start': 96, 'end': 101, 'answer': 'It is'},\n",
              " {'score': 7.538085628766567e-05, 'start': 1122, 'end': 1123, 'answer': '\\n'},\n",
              " {'score': 1.6054407751653343e-05,\n",
              "  'start': 301,\n",
              "  'end': 318,\n",
              "  'answer': 'his Real debut. \\n'},\n",
              " {'score': 1.4433539035962895e-05,\n",
              "  'start': 216,\n",
              "  'end': 226,\n",
              "  'answer': 'one of the'},\n",
              " {'score': 3.926167846657336e-05,\n",
              "  'start': 1146,\n",
              "  'end': 1195,\n",
              "  'answer': 'England, with only 62 people per square kilometre'},\n",
              " {'score': 5.963226067251526e-05,\n",
              "  'start': 1315,\n",
              "  'end': 1380,\n",
              "  'answer': 'Oh, how wise they had been to obey the dying words of their uncle'},\n",
              " {'score': 1.336413697572425e-05,\n",
              "  'start': 72,\n",
              "  'end': 115,\n",
              "  'answer': 'one of its dancers -- that he choreographed'},\n",
              " {'score': 4.273844388080761e-05,\n",
              "  'start': 1828,\n",
              "  'end': 1854,\n",
              "  'answer': 'one of the most ethnically'},\n",
              " {'score': 3.588175241020508e-05,\n",
              "  'start': 1071,\n",
              "  'end': 1101,\n",
              "  'answer': 'every dog will make the cut. \\n'},\n",
              " {'score': 2.0703078916994855e-05,\n",
              "  'start': 123,\n",
              "  'end': 131,\n",
              "  'answer': 'designer'},\n",
              " {'score': 1.2986820365767926e-05,\n",
              "  'start': 85,\n",
              "  'end': 133,\n",
              "  'answer': 'himself as he bowed to the Frenchman, whose name'},\n",
              " {'score': 2.092034264933318e-05,\n",
              "  'start': 72,\n",
              "  'end': 106,\n",
              "  'answer': 'England, with a population of 530,'},\n",
              " {'score': 2.2531776266987436e-05,\n",
              "  'start': 216,\n",
              "  'end': 222,\n",
              "  'answer': 'he got'},\n",
              " {'score': 6.989703979343176e-05,\n",
              "  'start': 1101,\n",
              "  'end': 1125,\n",
              "  'answer': 'Her face now wore a look'},\n",
              " {'score': 1.4861791896692012e-05,\n",
              "  'start': 286,\n",
              "  'end': 292,\n",
              "  'answer': 'Wiggle'},\n",
              " {'score': 1.5731948224129155e-05,\n",
              "  'start': 89,\n",
              "  'end': 105,\n",
              "  'answer': 'created by Guido'},\n",
              " {'score': 6.955962453503162e-05, 'start': 1024, 'end': 1025, 'answer': '\\n'},\n",
              " {'score': 1.2901718946523033e-05,\n",
              "  'start': 283,\n",
              "  'end': 347,\n",
              "  'answer': 'One of the Windward Islands, it is directly north of Saint Lucia'},\n",
              " {'score': 6.0864040278829634e-05,\n",
              "  'start': 1275,\n",
              "  'end': 1342,\n",
              "  'answer': 'only thing left to fight for now was the question of the penalty. \\n'},\n",
              " {'score': 2.4501494408468716e-05,\n",
              "  'start': 2559,\n",
              "  'end': 2584,\n",
              "  'answer': 'When he embraces Isabella'},\n",
              " {'score': 1.9636332581285387e-05,\n",
              "  'start': 225,\n",
              "  'end': 292,\n",
              "  'answer': 'an interdisciplinary subject drawing on natural and social sciences'},\n",
              " {'score': 9.415681415703148e-05, 'start': 932, 'end': 936, 'answer': 'need'},\n",
              " {'score': 1.4014313819643576e-05,\n",
              "  'start': 233,\n",
              "  'end': 256,\n",
              "  'answer': '\\n\\nA computer program is'},\n",
              " {'score': 1.397823234583484e-05,\n",
              "  'start': 0,\n",
              "  'end': 57,\n",
              "  'answer': 'Fifty-two years ago in the USA, a little black girl named'},\n",
              " {'score': 8.595785038778558e-05,\n",
              "  'start': 1059,\n",
              "  'end': 1067,\n",
              "  'answer': 'He wrote'},\n",
              " {'score': 8.002854883670807e-05,\n",
              "  'start': 1031,\n",
              "  'end': 1073,\n",
              "  'answer': 'Ow, what\\'s that?\" cried Betty with a start'},\n",
              " {'score': 6.560160545632243e-05, 'start': 987, 'end': 988, 'answer': '\\n'},\n",
              " {'score': 3.055096385651268e-05,\n",
              "  'start': 45,\n",
              "  'end': 56,\n",
              "  'answer': 'in Africa ?'},\n",
              " {'score': 1.3446920092974324e-05,\n",
              "  'start': 313,\n",
              "  'end': 357,\n",
              "  'answer': 'he has no s he knows of, he does have a deer'},\n",
              " {'score': 3.8017584301996976e-05,\n",
              "  'start': 1078,\n",
              "  'end': 1088,\n",
              "  'answer': 'one finger'},\n",
              " {'score': 1.7619746358832344e-05,\n",
              "  'start': 207,\n",
              "  'end': 219,\n",
              "  'answer': 'first-degree'},\n",
              " {'score': 7.034201553324237e-05,\n",
              "  'start': 138,\n",
              "  'end': 199,\n",
              "  'answer': 'his mommy what the white stuff was. She told him with a smile'},\n",
              " {'score': 1.6024192518671043e-05,\n",
              "  'start': 383,\n",
              "  'end': 407,\n",
              "  'answer': 'Canada, the term \"Eskimo'},\n",
              " {'score': 1.4870888662699144e-05,\n",
              "  'start': 94,\n",
              "  'end': 151,\n",
              "  'answer': 'candidate Eliot Spitzer with escorts several years ago is'},\n",
              " {'score': 1.4351310710480902e-05, 'start': 148, 'end': 149, 'answer': '\\n'},\n",
              " {'score': 1.5331903341575526e-05,\n",
              "  'start': 1336,\n",
              "  'end': 1350,\n",
              "  'answer': 'No. 1 player. '},\n",
              " {'score': 8.71227020979859e-05,\n",
              "  'start': 1268,\n",
              "  'end': 1280,\n",
              "  'answer': 'his visit. \\n'},\n",
              " {'score': 5.9049696574220434e-05,\n",
              "  'start': 1028,\n",
              "  'end': 1063,\n",
              "  'answer': 'her first grand slam title ill 1999'},\n",
              " {'score': 1.3642754311149474e-05,\n",
              "  'start': 346,\n",
              "  'end': 393,\n",
              "  'answer': '\\'s novel \"Emile, or On Education\" is a treatise'},\n",
              " {'score': 2.2870057364343666e-05,\n",
              "  'start': 1426,\n",
              "  'end': 1486,\n",
              "  'answer': 'his brand new heart to good use volunteering at the homeless'},\n",
              " {'score': 2.000368112931028e-05,\n",
              "  'start': 48,\n",
              "  'end': 99,\n",
              "  'answer': 'care of Tiger. All Tiger had to do was make an oink'},\n",
              " {'score': 6.687246059300378e-05,\n",
              "  'start': 1154,\n",
              "  'end': 1169,\n",
              "  'answer': 'a dog sledder ,'},\n",
              " {'score': 1.5129694475035649e-05,\n",
              "  'start': 286,\n",
              "  'end': 316,\n",
              "  'answer': 'one of the Four Corners states'},\n",
              " {'score': 1.3441995179164223e-05,\n",
              "  'start': 257,\n",
              "  'end': 294,\n",
              "  'answer': 'she was comfortably sure she had made'},\n",
              " {'score': 3.37209457939025e-05,\n",
              "  'start': 1376,\n",
              "  'end': 1384,\n",
              "  'answer': 'his face'},\n",
              " {'score': 1.3213052625360433e-05,\n",
              "  'start': 9,\n",
              "  'end': 68,\n",
              "  'answer': 'It was at San Francisco\\'s Olympic Club that \"Gentleman Jim\"'},\n",
              " {'score': 2.174105611629784e-05,\n",
              "  'start': 91,\n",
              "  'end': 153,\n",
              "  'answer': \"wasn't watching where she was going , so she fell into a sewer\"},\n",
              " {'score': 6.765935540897772e-05,\n",
              "  'start': 954,\n",
              "  'end': 992,\n",
              "  'answer': '\\n\\nThe Rover boys could readily surmise'}]"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3JEUrtv7bHZH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}