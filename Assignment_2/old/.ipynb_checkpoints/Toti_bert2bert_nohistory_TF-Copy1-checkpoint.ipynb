{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "zefTqvMBeXRb",
   "metadata": {
    "id": "zefTqvMBeXRb"
   },
   "source": [
    "LAST LINKs:\n",
    "* https://colab.research.google.com/drive/1WIk2bxglElfZewOHboPFNj8H44_VAyKE?usp=sharing#scrollTo=Gw3IZYrfKl4Z\n",
    "* https://medium.com/analytics-vidhya/fine-tune-a-roberta-encoder-decoder-model-trained-on-mlm-for-text-generation-23da5f3c1858\n",
    "* https://huggingface.co/course/chapter7/7?fw=tf\n",
    "\n",
    "LINKs:\n",
    "* https://github.com/huggingface/notebooks/blob/main/examples/question_answering.ipynb\n",
    "\n",
    "* https://github.com/Michael-M-Mike/Unibo-NLP-Assignments/blob/main/A2_Seq2Seq_Abstractive_Question_Answering_(QA)_on_CoQA/distilroberta_42.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d23b6c",
   "metadata": {
    "id": "d1d23b6c"
   },
   "source": [
    "# Assignment 2\n",
    "\n",
    "**Credits**: Andrea Galassi, Federico Ruggeri, Paolo Torroni\n",
    "\n",
    "**Keywords**: Transformers, Question Answering, CoQA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3f451b",
   "metadata": {
    "id": "bd3f451b"
   },
   "source": [
    "## Deadlines\n",
    "\n",
    "* **December 11**, 2022: deadline for having assignments graded by January 11, 2023\n",
    "* **January 11**, 2023: deadline for half-point speed bonus per assignment\n",
    "* **After January 11**, 2023: assignments are still accepted, but there will be no speed bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ada8c8",
   "metadata": {
    "id": "11ada8c8"
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c07553",
   "metadata": {
    "id": "47c07553"
   },
   "source": [
    "### Problem\n",
    "\n",
    "Question Answering (QA) on [CoQA](https://stanfordnlp.github.io/coqa/) dataset: a conversational QA dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4907f8d",
   "metadata": {
    "id": "b4907f8d"
   },
   "source": [
    "### Task\n",
    "\n",
    "Given a question $Q$, a text passage $P$, the task is to generate the answer $A$.<br>\n",
    "$\\rightarrow A$ can be: (i) a free-form text or (ii) unanswerable;\n",
    "\n",
    "**Note**: an question $Q$ can refer to previous dialogue turns. <br>\n",
    "$\\rightarrow$ dialogue history $H$ may be a valuable input to provide the correct answer $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3760b5",
   "metadata": {
    "id": "9b3760b5"
   },
   "source": [
    "### Models\n",
    "\n",
    "We are going to experiment with transformer-based models to define the following models:\n",
    "\n",
    "1.  $A = f_\\theta(Q, P)$\n",
    "\n",
    "2. $A = f_\\theta(Q, P, H)$\n",
    "\n",
    "where $f_\\theta$ is the transformer-based model we have to define with $\\theta$ parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cfee64",
   "metadata": {
    "id": "66cfee64"
   },
   "source": [
    "## The CoQA dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996fa650",
   "metadata": {
    "id": "996fa650"
   },
   "source": [
    "<center>\n",
    "    <img src=\"https://drive.google.com/uc?export=view&id=16vrgyfoV42Z2AQX0QY7LHTfrgektEKKh\" width=\"750\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e3e7d0",
   "metadata": {
    "id": "f6e3e7d0"
   },
   "source": [
    "For detailed information about the dataset, feel free to check the original [paper](https://arxiv.org/pdf/1808.07042.pdf).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb6c37e",
   "metadata": {
    "id": "bfb6c37e"
   },
   "source": [
    "## Rationales\n",
    "\n",
    "Each QA pair is paired with a rationale $R$: it is a text span extracted from the given text passage $P$. <br>\n",
    "$\\rightarrow$ $R$ is not a requested output, but it can be used as an additional information at training time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa786e2",
   "metadata": {
    "id": "daa786e2"
   },
   "source": [
    "## Dataset Statistics\n",
    "\n",
    "* **127k** QA pairs.\n",
    "* **8k** conversations.\n",
    "* **7** diverse domains: Children's Stories, Literature, Mid/High School Exams, News, Wikipedia, Reddit, Science.\n",
    "* Average conversation length: **15 turns** (i.e., QA pairs).\n",
    "* Almost **half** of CoQA questions refer back to **conversational history**.\n",
    "* Only **train** and **validation** sets are available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26d68b7",
   "metadata": {
    "id": "d26d68b7"
   },
   "source": [
    "## Dataset snippet\n",
    "\n",
    "The dataset is stored in JSON format. Each dialogue is represented as follows:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"source\": \"mctest\",\n",
    "    \"id\": \"3dr23u6we5exclen4th8uq9rb42tel\",\n",
    "    \"filename\": \"mc160.test.41\",\n",
    "    \"story\": \"Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. \n",
    "    Cotton lived high up in a nice warm place above the barn where all of the farmer's horses slept. [...]\" % <-- $P$\n",
    "    \"questions\": [\n",
    "        {\n",
    "            \"input_text\": \"What color was Cotton?\",   % <-- $Q_1$\n",
    "            \"turn_id\": 1\n",
    "        },\n",
    "        {\n",
    "            \"input_text\": \"Where did she live?\",\n",
    "            \"turn_id\": 2\n",
    "        },\n",
    "        [...]\n",
    "    ],\n",
    "    \"answers\": [\n",
    "        {\n",
    "            \"span_start\": 59,   % <-- $R_1$ start index\n",
    "            \"spand_end\": 93,    % <-- $R_1$ end index\n",
    "            \"span_text\": \"a little white kitten named Cotton\",   % <-- $R_1$\n",
    "            \"input_text\" \"white\",   % <-- $A_1$      \n",
    "            \"turn_id\": 1\n",
    "        },\n",
    "        [...]\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c7558c",
   "metadata": {
    "id": "72c7558c"
   },
   "source": [
    "### Simplifications\n",
    "\n",
    "Each dialogue also contains an additional field ```additional_answers```. For simplicity, we **ignore** this field and only consider one groundtruth answer $A$ and text rationale $R$.\n",
    "\n",
    "CoQA only contains 1.3% of unanswerable questions. For simplicity, we **ignore** those QA pairs.\n",
    "\n",
    "# [0] Functions and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gcvzSCKbNGHv",
   "metadata": {
    "id": "gcvzSCKbNGHv"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install datasets\n",
    "# !pip install transformers\n",
    "# !pip install tensorflow_addons\n",
    "# !pip install allennlp-models\n",
    "\n",
    "\n",
    "# NOTE:\n",
    "#     - SEED ED ERRORE\n",
    "#     - LUNGHEZZA INPUTS E OUTPUTS - https://towardsdatascience.com/to-distil-or-not-to-distil-bert-roberta-and-xlnet-c777ad92f8\n",
    "#     - GRANDEZZA DATASETS\n",
    "#     - WARNINGS NELLA CREAZIONE DEL MODELLO E NEL TRAINING\n",
    "#     - COME UTILIZZARE SPAN DI TESTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "NSKlKfKr7GZe",
   "metadata": {
    "id": "NSKlKfKr7GZe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antonio\\anaconda3\\envs\\NLP\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display_html, clear_output\n",
    "from itertools import chain,cycle\n",
    "from copy import deepcopy\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "import random \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# Display dataframes\n",
    "def display(*args,titles=cycle([''])):\n",
    "    html_str=''\n",
    "    for df,title in zip(args, chain(titles,cycle(['</br>'])) ):\n",
    "        html_str+='<th style=\"text-align:left\"><td style=\"vertical-align:top\">'\n",
    "        html_str+=f'<h4 style=\"text-align: left;\">{title}</h2>'\n",
    "        html_str+=df.to_html().replace('table','table style=\"display:inline\"')\n",
    "        html_str+='</td></th>'\n",
    "    display_html(html_str,raw=True)\n",
    "\n",
    "def set_reproducibility(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01cdad7",
   "metadata": {
    "id": "e01cdad7"
   },
   "source": [
    "## [Task 1] Remove unaswerable QA pairs\n",
    "\n",
    "Write your own script to remove unaswerable QA pairs from both train and validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6643e14",
   "metadata": {
    "id": "f6643e14"
   },
   "source": [
    "## Dataset Download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "358bac70",
   "metadata": {
    "id": "358bac70"
   },
   "outputs": [],
   "source": [
    "class DownloadProgressBar(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "        \n",
    "def download_url(url, output_path):\n",
    "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
    "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
    "        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n",
    "\n",
    "def download_data(data_path, url_path, suffix):    \n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "        \n",
    "    data_path = os.path.join(data_path, f'{suffix}.json')\n",
    "\n",
    "    if not os.path.exists(data_path):\n",
    "        print(f\"Downloading CoQA {suffix} data split... (it may take a while)\")\n",
    "        download_url(url=url_path, output_path=data_path)\n",
    "        urllib.request.urlretrieve(url_path, filename=data_path)\n",
    "        print(\"Download completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f6ab3ff",
   "metadata": {
    "id": "5f6ab3ff"
   },
   "outputs": [],
   "source": [
    "# Train data\n",
    "train_url = \"https://nlp.stanford.edu/data/coqa/coqa-train-v1.0.json\"\n",
    "download_data(data_path='coqa', url_path=train_url, suffix='train')\n",
    "\n",
    "# Test data\n",
    "test_url = \"https://nlp.stanford.edu/data/coqa/coqa-dev-v1.0.json\"\n",
    "download_data(data_path='coqa', url_path=test_url, suffix='test')  # <-- Why test? See next slides for an answer!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e42311",
   "metadata": {
    "id": "40e42311"
   },
   "source": [
    "#### Data Inspection\n",
    "\n",
    "Spend some time in checking accurately the dataset format and how to retrieve the tasks' inputs and outputs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "DmuPOnX46NT5",
   "metadata": {
    "id": "DmuPOnX46NT5"
   },
   "outputs": [],
   "source": [
    "train_data = json.load((open('coqa/train.json')))\n",
    "test_data = json.load((open('coqa/test.json')))\n",
    "\n",
    "qas = pd.json_normalize(train_data['data'], ['questions'], ['source', 'id', 'story'])\n",
    "ans = pd.json_normalize(train_data['data'], ['answers'],['id'])\n",
    "train_val_df = pd.merge(qas,ans, left_on=['id','turn_id'], right_on=['id','turn_id'])\n",
    "train_val_df = train_val_df.loc[train_val_df['input_text_y']!='unknown']\n",
    "\n",
    "qas = pd.json_normalize(test_data['data'], ['questions'], ['source', 'id', 'story'])\n",
    "ans = pd.json_normalize(test_data['data'], ['answers'],['id'])\n",
    "test_df = pd.merge(qas,ans, left_on=['id','turn_id'], right_on=['id','turn_id'])\n",
    "test_df = test_df.loc[test_df['input_text_y']!='unknown']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57334e0",
   "metadata": {
    "id": "f57334e0"
   },
   "source": [
    "## [Task 2] Train, Validation and Test splits\n",
    "\n",
    "CoQA only provides a train and validation set since the test set is hidden for evaluation purposes.\n",
    "\n",
    "We'll consider the provided validation set as a test set. <br>\n",
    "$\\rightarrow$ Write your own script to:\n",
    "* Split the train data in train and validation splits (80% train and 20% val)\n",
    "* Perform splits such that a dialogue appears in one split only! (i.e., split at dialogue level)\n",
    "* Perform splitting using the following seed for reproducibility: 42\n",
    "\n",
    "#### Reproducibility Memo\n",
    "\n",
    "Check back tutorial 2 on how to fix a specific random seed for reproducibility!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2sRaINOONUmh",
   "metadata": {
    "id": "2sRaINOONUmh"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from datasets import *\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizerFast\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "yYsAxKF6_zG2",
   "metadata": {
    "id": "yYsAxKF6_zG2"
   },
   "outputs": [],
   "source": [
    "# set_reproducibility(42)\n",
    "\n",
    "train_inds, val_inds = next(GroupShuffleSplit(test_size=.20, n_splits=2, random_state = 42).split(train_val_df, groups=train_val_df['story']))\n",
    "\n",
    "train_df = train_val_df.iloc[train_inds]\n",
    "val_df = train_val_df.iloc[val_inds].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "LAl2ZKTYujo5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 981
    },
    "id": "LAl2ZKTYujo5",
    "outputId": "f4767008-e403-4c66-cc8d-add0a840cbdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set [(85968, 11)]\n",
      "\tFeatures: ['input_text_x', 'turn_id', 'bad_turn_x', 'source', 'id', 'story', 'span_start', 'span_end', 'span_text', 'input_text_y', 'bad_turn_y']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<th style=\"text-align:left\"><td style=\"vertical-align:top\"><h4 style=\"text-align: left;\"></h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>input_text_x</th>\n",
       "      <th>input_text_y</th>\n",
       "      <th>span_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3zotghdk5ibi9cex97fepx7jetpso7</td>\n",
       "      <td>how many items are in this secret collection?</td>\n",
       "      <td>150,000</td>\n",
       "      <td>Vatican Secret Archives were separated from the library at the beginning of the 17th century; they contain another 150,000 items.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3zotghdk5ibi9cex97fepx7jetpso7</td>\n",
       "      <td>Can anyone use this library?</td>\n",
       "      <td>anyone who can document their qualifications and research needs.</td>\n",
       "      <td>The Vatican Library is open to anyone who can document their qualifications and research needs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3zotghdk5ibi9cex97fepx7jetpso7</td>\n",
       "      <td>what must be requested in person or by mail?</td>\n",
       "      <td>Photocopies</td>\n",
       "      <td>Photocopies for private study of pages from books published between 1801 and 1990 can be requested in person or by mail.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3zotghdk5ibi9cex97fepx7jetpso7</td>\n",
       "      <td>of what books?</td>\n",
       "      <td>only books published between 1801 and 1990</td>\n",
       "      <td>hotocopies for private study of pages from books published between 1801 and 1990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td></th>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set [(21308, 12)]\n",
      "\tFeatures: ['index', 'input_text_x', 'turn_id', 'bad_turn_x', 'source', 'id', 'story', 'span_start', 'span_end', 'span_text', 'input_text_y', 'bad_turn_y']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<th style=\"text-align:left\"><td style=\"vertical-align:top\"><h4 style=\"text-align: left;\"></h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>input_text_x</th>\n",
       "      <th>input_text_y</th>\n",
       "      <th>span_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>369j354ofdapu1z2ebz3jj2p5ajg6o</td>\n",
       "      <td>what time were they going to the hospital?</td>\n",
       "      <td>about 11 P. M.</td>\n",
       "      <td>about 11 P. M.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>369j354ofdapu1z2ebz3jj2p5ajg6o</td>\n",
       "      <td>what is the mother's name?</td>\n",
       "      <td>May Hobson</td>\n",
       "      <td>Her mother, May Hobson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>369j354ofdapu1z2ebz3jj2p5ajg6o</td>\n",
       "      <td>how old is she?</td>\n",
       "      <td>40</td>\n",
       "      <td>May Hobson, 40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>33m4ia01qg1t26scv925i0tg4jhrx5</td>\n",
       "      <td>What did Neolithic follow?</td>\n",
       "      <td>Holocene Epipaleolithic period</td>\n",
       "      <td>the Neolithic followed the terminal Holocene Epipaleolithic period</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>33m4ia01qg1t26scv925i0tg4jhrx5</td>\n",
       "      <td>What was the Neolithic considered?</td>\n",
       "      <td>the last part of the Stone Age</td>\n",
       "      <td>considered the last part of the Stone Age</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td></th>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set [(7917, 9)]\n",
      "\tFeatures: ['input_text_x', 'turn_id', 'source', 'id', 'story', 'span_start', 'span_end', 'span_text', 'input_text_y']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<th style=\"text-align:left\"><td style=\"vertical-align:top\"><h4 style=\"text-align: left;\"></h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>input_text_x</th>\n",
       "      <th>input_text_y</th>\n",
       "      <th>span_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3dr23u6we5exclen4th8uq9rb42tel</td>\n",
       "      <td>Did they want Cotton to change the color of her fur?</td>\n",
       "      <td>no</td>\n",
       "      <td>We would never want you to be any other way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3azhrg4cu4ktme1zh7c2ro3pn2430d</td>\n",
       "      <td>what was the name of the fish</td>\n",
       "      <td>Asta.</td>\n",
       "      <td>Asta.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3azhrg4cu4ktme1zh7c2ro3pn2430d</td>\n",
       "      <td>What looked like a birds belly</td>\n",
       "      <td>a bottle</td>\n",
       "      <td>a bottle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3azhrg4cu4ktme1zh7c2ro3pn2430d</td>\n",
       "      <td>who said that</td>\n",
       "      <td>Asta.</td>\n",
       "      <td>\"It looks like a bird's belly,\" said Asta.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3azhrg4cu4ktme1zh7c2ro3pn2430d</td>\n",
       "      <td>Was Sharkie a friend?</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Asta's friend Sharkie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"></td></th>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_df = train_df.replace(r'\\n',' ', regex=True)\n",
    "# val_df = val_df.replace(r'\\n',' ', regex=True)\n",
    "# test_df = test_df.replace(r'\\n',' ', regex=True)\n",
    "\n",
    "print(f'Training set [{train_df.shape}]')\n",
    "print(f'\\tFeatures: {list(train_df.columns)}')\n",
    "display(train_df.loc[11:15,['id', 'input_text_x', 'input_text_y', 'span_text']])\n",
    "\n",
    "print(f'Validation set [{val_df.shape}]')\n",
    "print(f'\\tFeatures: {list(val_df.columns)}')\n",
    "display(val_df.loc[11:15,['id', 'input_text_x', 'input_text_y', 'span_text']])\n",
    "\n",
    "print(f'\\nTest set [{test_df.shape}]')\n",
    "print(f'\\tFeatures: {list(test_df.columns)}')\n",
    "display(test_df.loc[11:15,['id', 'input_text_x', 'input_text_y', 'span_text']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qlSIIqCP5K4z",
   "metadata": {
    "id": "qlSIIqCP5K4z"
   },
   "source": [
    "Now we check if there is any overlapping dialogue between train and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cul9guslrKP-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cul9guslrKP-",
    "outputId": "54fd377d-b06d-46b4-ec8f-aa97d9308246"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No overlap\n"
     ]
    }
   ],
   "source": [
    "set_train = set(train_df['id'])\n",
    "set_val = set(val_df['id'])\n",
    "\n",
    "overlap = False\n",
    "for i in set_train:\n",
    "    if i in set_val:\n",
    "        overlap = True\n",
    "        break\n",
    "\n",
    "print('Overlap' if overlap else 'No overlap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "LFy-wE1wCFBr",
   "metadata": {
    "id": "LFy-wE1wCFBr"
   },
   "outputs": [],
   "source": [
    "features = ['story', 'input_text_x', 'span_text', 'input_text_y']\n",
    "# features = ['id', 'story', 'input_text_x', 'span_text', 'input_text_y']\n",
    "\n",
    "train_df_to_ds = train_df[features]\n",
    "val_df_to_ds = val_df[features]\n",
    "test_df_to_ds = test_df[features]\n",
    "\n",
    "train_df_to_ds = train_df_to_ds.rename(columns={'input_text_x': 'question', 'story': 'context',\\\n",
    "                                               'input_text_y': 'answer', 'span_text': 'text'})\n",
    "val_df_to_ds = val_df_to_ds.rename(columns={'input_text_x': 'question', 'story': 'context',\\\n",
    "                                               'input_text_y': 'answer', 'span_text': 'text'})\n",
    "test_df_to_ds = test_df_to_ds.rename(columns={'input_text_x': 'question', 'story': 'context',\\\n",
    "                                               'input_text_y': 'answer', 'span_text': 'text'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14e4ff1",
   "metadata": {},
   "source": [
    "Now, since the dataset is huge and we are more focused on the reasoning behind our choices, we are going to extract a portion of it.\n",
    "The next step is gonna be the truncation of the inputs lengths. The pre-trained models that are gonna be tested can process lengths up to 512, that is why our truncation will be at least equal to this value; moreover, we are going to sort the datasets according to the sum of the lengths of the 'context' and 'question' fields together, expecting to truncate the least possible number of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2e3c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine 'context' and 'question' fields for each dataframe\n",
    "train_df_to_ds['context_question'] = train_df_to_ds['context'] + train_df_to_ds['question']\n",
    "val_df_to_ds['context_question'] = val_df_to_ds['context'] + val_df_to_ds['question']\n",
    "test_df_to_ds['context_question'] = test_df_to_ds['context'] + test_df_to_ds['question']\n",
    "\n",
    "# Define a function to compute the length of 'context_question'\n",
    "def get_context_question_length(df):\n",
    "    return (df['context_question'].apply(len))\n",
    "\n",
    "# Compute the lengths of 'context_question' for each dataframe\n",
    "train_lengths = get_context_question_length(train_df_to_ds)\n",
    "val_lengths = get_context_question_length(val_df_to_ds)\n",
    "test_lengths = get_context_question_length(test_df_to_ds)\n",
    "\n",
    "# Sort each dataframe by length of 'context + question'\n",
    "train_df_to_ds = train_df_to_ds.iloc[train_lengths.argsort()]\n",
    "val_df_to_ds = val_df_to_ds.iloc[val_lengths.argsort()]\n",
    "test_df_to_ds = test_df_to_ds.iloc[test_lengths.argsort()]\n",
    "\n",
    "# Drop the 'context_question' column from each dataframe\n",
    "train_df_to_ds = train_df_to_ds.drop('context_question', axis=1)\n",
    "val_df_to_ds = val_df_to_ds.drop('context_question', axis=1)\n",
    "test_df_to_ds = test_df_to_ds.drop('context_question', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "26fbfeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "ratio = 1\n",
    "\n",
    "train_samples = (round(train_df_to_ds.shape[0] * ratio / 100) // batch_size) * batch_size\n",
    "val_samples = (round(val_df_to_ds.shape[0] * ratio / 100) // batch_size) * batch_size\n",
    "test_samples = (round(test_df_to_ds.shape[0] * ratio / 100) // batch_size) * batch_size\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_df_to_ds.iloc[:train_samples])\n",
    "val_dataset = Dataset.from_dict(val_df_to_ds.iloc[:val_samples])\n",
    "test_dataset = Dataset.from_dict(test_df_to_ds.iloc[:test_samples])\n",
    "\n",
    "dataset_COQA = DatasetDict({'train':train_dataset,'validation':val_dataset,'test':test_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "LAQDNCRI0It0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LAQDNCRI0It0",
    "outputId": "a431b116-b8aa-4b0b-b1b3-828dd6fe312c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'context', 'question', 'text', 'answer'],\n",
       "        num_rows: 848\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'context', 'question', 'text', 'answer'],\n",
       "        num_rows: 208\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'context', 'question', 'text', 'answer'],\n",
       "        num_rows: 64\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_COQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "__IFYntoJIUa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "id": "__IFYntoJIUa",
    "outputId": "8033431d-ced3-4c92-9e95-aec09ed18f4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length:512\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa"
         },
         "name": "",
         "notched": false,
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "box",
         "x": [
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0"
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          368,
          374,
          377,
          380,
          382,
          383,
          384,
          387,
          388,
          390,
          395,
          430,
          431,
          435,
          436,
          437,
          438,
          440,
          442,
          443,
          444,
          445,
          446,
          448,
          449,
          488,
          493,
          495,
          496,
          497,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          529,
          530,
          531,
          532,
          535,
          550,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          584,
          589,
          590,
          594,
          595,
          597,
          598,
          600,
          601,
          603,
          605,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          626,
          627,
          628,
          630,
          633,
          635,
          642,
          647,
          649,
          651,
          652,
          656,
          657,
          660,
          661,
          662,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          686,
          687,
          688,
          689,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          720,
          721,
          722,
          723,
          724,
          725,
          727,
          728,
          730,
          731,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000,
          1001,
          1002,
          1003,
          1004,
          1005,
          1006,
          1007,
          1008,
          1009,
          1010,
          1011,
          1012,
          1013,
          1014,
          1015,
          1016,
          1017,
          1018,
          1019,
          1020,
          1021,
          1022,
          1023,
          1024,
          1025,
          1026,
          1027,
          1028,
          1029,
          1030,
          1031,
          1032,
          1033,
          1034,
          1035,
          1036,
          1037,
          1038,
          1039,
          1040,
          1041,
          1042,
          1043,
          1044,
          1045,
          1046,
          1047,
          1048,
          1049,
          1050,
          1051,
          1052,
          1053,
          1054,
          1055,
          1056,
          1057,
          1058,
          1059,
          1060,
          1061,
          1062,
          1063,
          1064,
          1065,
          1066,
          1067,
          1068,
          1069,
          1070,
          1071,
          1072,
          1073,
          1074,
          1075,
          1076,
          1077,
          1078,
          1079,
          1080,
          1081,
          1082,
          1083,
          1084,
          1085,
          1086,
          1087,
          1088,
          1089,
          1090,
          1091,
          1092,
          1093,
          1094,
          1095,
          1096,
          1097,
          1098,
          1099,
          1100,
          1101,
          1102,
          1103,
          1104,
          1105,
          1106,
          1107,
          1108,
          1109,
          1110,
          1111,
          1112,
          1113,
          1114,
          1115,
          1116,
          1117,
          1118,
          1119,
          1120,
          1121,
          1122,
          1123,
          1124,
          1125,
          1126,
          1127,
          1128,
          1129,
          1130,
          1131,
          1132,
          1133,
          1134,
          1135,
          1136,
          1137,
          1138,
          1139,
          1140,
          1141,
          1142,
          1143,
          1144,
          1145,
          1146,
          1147,
          1148,
          1149,
          1150,
          1151,
          1152,
          1153,
          1154,
          1155,
          1156,
          1157,
          1158,
          1159,
          1160,
          1161,
          1162,
          1163,
          1164,
          1165,
          1166,
          1167,
          1168,
          1169,
          1170,
          1171,
          1172,
          1173,
          1174,
          1175,
          1176,
          1177,
          1178,
          1179,
          1180,
          1181,
          1182,
          1183,
          1184,
          1185,
          1186,
          1187,
          1188,
          1189,
          1190,
          1191,
          1192,
          1193,
          1194,
          1195,
          1196,
          1197,
          1198,
          1199,
          1200,
          1201,
          1202,
          1203,
          1204,
          1205,
          1206,
          1207,
          1208,
          1209,
          1210,
          1211,
          1212,
          1213,
          1214,
          1215,
          1216,
          1217,
          1218,
          1219,
          1220,
          1221,
          1222,
          1223,
          1224,
          1225,
          1226,
          1227,
          1228,
          1229,
          1230,
          1231,
          1232,
          1233,
          1234,
          1235,
          1236,
          1237,
          1238,
          1239,
          1240,
          1241,
          1242,
          1243,
          1244,
          1245,
          1246,
          1247,
          1248,
          1249,
          1250,
          1251,
          1252,
          1253,
          1254,
          1255,
          1256,
          1257,
          1258,
          1259,
          1260,
          1261,
          1262,
          1263,
          1264,
          1265,
          1266,
          1267,
          1268,
          1269,
          1270,
          1271,
          1272,
          1273,
          1274,
          1275,
          1276,
          1277,
          1278,
          1279,
          1280,
          1281,
          1282,
          1283,
          1284,
          1285,
          1286,
          1287,
          1288,
          1289,
          1290,
          1291,
          1292,
          1293,
          1294,
          1295,
          1296,
          1297,
          1298,
          1299,
          1300,
          1301,
          1302,
          1303,
          1304,
          1305,
          1306,
          1307,
          1308,
          1309,
          1310,
          1311,
          1312,
          1313,
          1314,
          1315,
          1316,
          1317,
          1318,
          1319,
          1320,
          1321,
          1322,
          1323,
          1324,
          1325,
          1326,
          1327,
          1328,
          1329,
          1330,
          1331,
          1332,
          1333,
          1334,
          1335,
          1336,
          1337,
          1338,
          1339,
          1340,
          1341,
          1342,
          1343,
          1344,
          1345,
          1346,
          1347,
          1348,
          1349,
          1350,
          1351,
          1352,
          1353,
          1354,
          1355,
          1356,
          1357,
          1358,
          1359,
          1360,
          1361,
          1362,
          1363,
          1364,
          1365,
          1366,
          1367,
          1368,
          1369,
          1370,
          1371,
          1372,
          1373,
          1374,
          1375,
          1376,
          1377,
          1378,
          1379,
          1380,
          1381,
          1382,
          1383,
          1384,
          1385,
          1386,
          1387,
          1388,
          1389,
          1390,
          1391,
          1392,
          1393,
          1394,
          1395,
          1396,
          1397,
          1398,
          1399,
          1400,
          1401,
          1402,
          1403,
          1404,
          1405,
          1406,
          1407,
          1408,
          1409,
          1410,
          1411,
          1412,
          1413,
          1414,
          1415,
          1416,
          1417,
          1418,
          1419,
          1420,
          1421,
          1422,
          1423,
          1424,
          1425,
          1426,
          1427,
          1428,
          1429,
          1430,
          1431,
          1432,
          1433,
          1434,
          1435,
          1436,
          1437,
          1438,
          1439,
          1440,
          1441,
          1442,
          1443,
          1444,
          1445,
          1446,
          1447,
          1448,
          1449,
          1450,
          1451,
          1452,
          1453,
          1454,
          1455,
          1456,
          1457,
          1458,
          1459,
          1460,
          1461,
          1462,
          1463,
          1464,
          1465,
          1466,
          1467,
          1468,
          1469,
          1470,
          1471,
          1472,
          1473,
          1474,
          1475,
          1476,
          1477,
          1478,
          1479,
          1480,
          1481,
          1482,
          1483,
          1484,
          1485,
          1486,
          1487,
          1488,
          1489,
          1490,
          1491,
          1492,
          1493,
          1494,
          1495,
          1496,
          1497,
          1498,
          1499,
          1500,
          1501,
          1502,
          1503,
          1504,
          1505,
          1506,
          1507,
          1508,
          1509,
          1510,
          1511,
          1512,
          1513,
          1514,
          1515,
          1516,
          1517,
          1518,
          1519,
          1520,
          1521,
          1522,
          1523,
          1524,
          1525,
          1526,
          1527,
          1528,
          1529,
          1530,
          1531,
          1532,
          1533,
          1534,
          1535,
          1536,
          1537,
          1538,
          1539,
          1540,
          1541,
          1542,
          1543,
          1544,
          1545,
          1546,
          1547,
          1548,
          1549,
          1550,
          1551,
          1552,
          1553,
          1554,
          1555,
          1556,
          1557,
          1558,
          1559,
          1560,
          1561,
          1562,
          1563,
          1564,
          1565,
          1566,
          1567,
          1568,
          1569,
          1570,
          1571,
          1572,
          1573,
          1574,
          1575,
          1576,
          1577,
          1578,
          1579,
          1580,
          1581,
          1582,
          1583,
          1584,
          1585,
          1586,
          1587,
          1588,
          1589,
          1590,
          1591,
          1592,
          1593,
          1594,
          1595,
          1596,
          1597,
          1598,
          1599,
          1600,
          1601,
          1602,
          1603,
          1604,
          1605,
          1606,
          1607,
          1608,
          1609,
          1610,
          1611,
          1612,
          1613,
          1614,
          1615,
          1616,
          1617,
          1618,
          1619,
          1620,
          1621,
          1622,
          1623,
          1624,
          1625,
          1626,
          1627,
          1628,
          1629,
          1630,
          1631,
          1632,
          1633,
          1634,
          1635,
          1636,
          1637,
          1638,
          1639,
          1640,
          1641,
          1642,
          1643,
          1644,
          1645,
          1646,
          1647,
          1648,
          1649,
          1650,
          1651,
          1652,
          1653,
          1654,
          1655,
          1656,
          1657,
          1658,
          1659,
          1660,
          1661,
          1662,
          1663,
          1664,
          1665,
          1666,
          1667,
          1668,
          1669,
          1670,
          1671,
          1672,
          1673,
          1674,
          1675,
          1676,
          1677,
          1678,
          1679,
          1680,
          1681,
          1682,
          1683,
          1684,
          1685,
          1686,
          1687,
          1688,
          1689,
          1690,
          1691,
          1692,
          1693,
          1694,
          1695,
          1696,
          1697,
          1698,
          1699,
          1700,
          1701,
          1702,
          1703,
          1704,
          1705,
          1706,
          1707,
          1708,
          1709,
          1710,
          1711,
          1712,
          1713,
          1714,
          1715,
          1716,
          1717,
          1718,
          1719,
          1720,
          1721,
          1722,
          1723,
          1724,
          1725,
          1726,
          1727,
          1728,
          1729,
          1730,
          1731,
          1732,
          1733,
          1734,
          1735,
          1736,
          1737,
          1738,
          1739,
          1740,
          1741,
          1742,
          1743,
          1744,
          1745,
          1746,
          1747,
          1748,
          1749,
          1750,
          1751,
          1752,
          1753,
          1754,
          1755,
          1756,
          1757,
          1758,
          1759,
          1760,
          1761,
          1762,
          1763,
          1764,
          1765,
          1766,
          1767,
          1768,
          1769,
          1770,
          1771,
          1772,
          1773,
          1774,
          1775,
          1776,
          1777,
          1778,
          1779,
          1780,
          1781,
          1782,
          1783,
          1784,
          1785,
          1786,
          1787,
          1788,
          1789,
          1790,
          1791,
          1792,
          1793,
          1794,
          1795,
          1796,
          1797,
          1798,
          1799,
          1800,
          1801,
          1802,
          1803,
          1804,
          1805,
          1806,
          1807,
          1808,
          1809,
          1810,
          1811,
          1812,
          1813,
          1814,
          1815,
          1816,
          1817,
          1818,
          1819,
          1820,
          1821,
          1822,
          1823,
          1824,
          1825,
          1826,
          1827,
          1828,
          1829,
          1830,
          1831,
          1832,
          1833,
          1834,
          1835,
          1836,
          1837,
          1838,
          1839,
          1840,
          1841,
          1842,
          1843,
          1844,
          1845,
          1846,
          1847,
          1848,
          1849,
          1850,
          1851,
          1852,
          1853,
          1854,
          1855,
          1856,
          1857,
          1858,
          1859,
          1860,
          1861,
          1862,
          1863,
          1864,
          1865,
          1866,
          1867,
          1868,
          1869,
          1870,
          1871,
          1872,
          1873,
          1874,
          1875,
          1876,
          1877,
          1878,
          1879,
          1880,
          1881,
          1882,
          1883,
          1884,
          1885,
          1886,
          1887,
          1888,
          1889,
          1890,
          1891,
          1892,
          1893,
          1894,
          1895,
          1896,
          1897,
          1898,
          1899,
          1900,
          1901,
          1902,
          1903,
          1904,
          1905,
          1906,
          1907,
          1908,
          1909,
          1910,
          1911,
          1912,
          1913,
          1914,
          1915,
          1916,
          1917,
          1918,
          1919,
          1920,
          1921,
          1922,
          1923,
          1924,
          1925,
          1926,
          1927,
          1928,
          1929,
          1930,
          1931,
          1932,
          1933,
          1934,
          1935,
          1936,
          1937,
          1938,
          1939,
          1940,
          1941,
          1942,
          1943,
          1944,
          1945,
          1946,
          1947,
          1948,
          1949,
          1950,
          1951,
          1952,
          1953,
          1954,
          1955,
          1956,
          1957,
          1958,
          1959,
          1960,
          1961,
          1962,
          1963,
          1964,
          1965,
          1966,
          1967,
          1968,
          1969,
          1970,
          1971,
          1972,
          1973,
          1974,
          1975,
          1976,
          1977,
          1978,
          1979,
          1980,
          1981,
          1982,
          1983,
          1984,
          1985,
          1986,
          1987,
          1988,
          1989,
          1990,
          1991,
          1992,
          1993,
          1994,
          1995,
          1996,
          1997,
          1998,
          1999,
          2000,
          2001,
          2002,
          2003,
          2004,
          2005,
          2006,
          2007,
          2008,
          2009,
          2010,
          2011,
          2012,
          2013,
          2014,
          2015,
          2016,
          2017,
          2018,
          2019,
          2020,
          2021,
          2022,
          2023,
          2024,
          2025,
          2026,
          2027,
          2028,
          2029,
          2030,
          2031,
          2032,
          2033,
          2034,
          2035,
          2036,
          2037,
          2038,
          2039,
          2040,
          2041,
          2042,
          2043,
          2044,
          2045,
          2046,
          2047,
          2048,
          2049,
          2050,
          2051,
          2052,
          2053,
          2054,
          2055,
          2056,
          2057,
          2058,
          2059,
          2060,
          2061,
          2062,
          2063,
          2064,
          2065,
          2066,
          2067,
          2068,
          2069,
          2070,
          2071,
          2072,
          2073,
          2074,
          2075,
          2076,
          2077,
          2078,
          2079,
          2080,
          2081,
          2082,
          2083,
          2084,
          2085,
          2086,
          2087,
          2088,
          2089,
          2090,
          2091,
          2092,
          2093,
          2094,
          2095,
          2096,
          2097,
          2098,
          2099,
          2100,
          2101,
          2102,
          2103,
          2104,
          2105,
          2106,
          2107,
          2108,
          2109,
          2110,
          2111,
          2112,
          2113,
          2114,
          2115,
          2116,
          2117,
          2118,
          2119,
          2120,
          2121,
          2122,
          2123,
          2124,
          2125,
          2126,
          2127,
          2128,
          2129,
          2130,
          2131,
          2132,
          2133,
          2134,
          2135,
          2136,
          2137,
          2138,
          2139,
          2140,
          2141,
          2142,
          2143,
          2144,
          2145,
          2146,
          2147,
          2148,
          2149,
          2150,
          2151,
          2152,
          2153,
          2154,
          2155,
          2156,
          2157,
          2158,
          2159,
          2160,
          2161,
          2162,
          2163,
          2164,
          2165,
          2166,
          2167,
          2168,
          2169,
          2170,
          2171,
          2172,
          2173,
          2174,
          2175,
          2176,
          2177,
          2178,
          2179,
          2180,
          2181,
          2182,
          2183,
          2184,
          2185,
          2186,
          2187,
          2188,
          2189,
          2190,
          2191,
          2192,
          2193,
          2194,
          2195,
          2196,
          2197,
          2198,
          2199,
          2200,
          2201,
          2202,
          2203,
          2204,
          2205,
          2206,
          2207,
          2208,
          2209,
          2210,
          2211,
          2212,
          2213,
          2214,
          2215,
          2216,
          2217,
          2218,
          2219,
          2220,
          2221,
          2222,
          2223,
          2224,
          2225,
          2226,
          2227,
          2228,
          2229,
          2230,
          2231,
          2232,
          2233,
          2234,
          2235,
          2236,
          2237,
          2238,
          2239,
          2240,
          2241,
          2242,
          2243,
          2244,
          2245,
          2246,
          2247,
          2248,
          2249,
          2250,
          2251,
          2252,
          2253,
          2254,
          2255,
          2256,
          2257,
          2258,
          2259,
          2260,
          2261,
          2262,
          2263,
          2264,
          2265,
          2266,
          2267,
          2268,
          2269,
          2270,
          2271,
          2272,
          2273,
          2274,
          2275,
          2276,
          2277,
          2278,
          2279,
          2280,
          2281,
          2282,
          2283,
          2284,
          2285,
          2286,
          2287,
          2288,
          2289,
          2290,
          2291,
          2292,
          2293,
          2294,
          2295,
          2296,
          2297,
          2298,
          2299,
          2300,
          2301,
          2302,
          2303,
          2304,
          2305,
          2306,
          2307,
          2308,
          2309,
          2310,
          2311,
          2312,
          2313,
          2314,
          2315,
          2316,
          2317,
          2318,
          2319,
          2320,
          2321,
          2322,
          2323,
          2324,
          2325,
          2326,
          2327,
          2328,
          2329,
          2330,
          2331,
          2332,
          2333,
          2334,
          2335,
          2336,
          2337,
          2338,
          2339,
          2340,
          2341,
          2342,
          2343,
          2344,
          2345,
          2346,
          2347,
          2348,
          2349,
          2350,
          2351,
          2352,
          2353,
          2354,
          2355,
          2356,
          2357,
          2358,
          2359,
          2360,
          2361,
          2362,
          2363,
          2364,
          2365,
          2366,
          2367,
          2368,
          2369,
          2370,
          2371,
          2372,
          2373,
          2374,
          2375,
          2376,
          2377,
          2378,
          2379,
          2380,
          2381,
          2382,
          2383,
          2384,
          2385,
          2386,
          2387,
          2388,
          2389,
          2390,
          2391,
          2392,
          2393,
          2394,
          2395,
          2397,
          2398,
          2399,
          2400,
          2401,
          2402,
          2403,
          2404,
          2405,
          2406,
          2407,
          2408,
          2409,
          2410,
          2411,
          2412,
          2413,
          2414,
          2415,
          2416,
          2417,
          2419,
          2420,
          2421,
          2422,
          2423,
          2425,
          2426,
          2428,
          2429,
          2430,
          2431,
          2432,
          2433,
          2434,
          2435,
          2436,
          2437,
          2438,
          2439,
          2440,
          2441,
          2442,
          2443,
          2444,
          2445,
          2446,
          2447,
          2448,
          2449,
          2450,
          2451,
          2452,
          2453,
          2454,
          2455,
          2456,
          2457,
          2458,
          2459,
          2460,
          2461,
          2462,
          2463,
          2464,
          2465,
          2466,
          2468,
          2469,
          2470,
          2471,
          2472,
          2473,
          2474,
          2475,
          2476,
          2477,
          2478,
          2479,
          2480,
          2481,
          2482,
          2483,
          2484,
          2485,
          2486,
          2488,
          2489,
          2490,
          2491,
          2492,
          2494,
          2495,
          2496,
          2497,
          2498,
          2499,
          2502,
          2503,
          2504,
          2505,
          2506,
          2507,
          2508,
          2509,
          2510,
          2511,
          2512,
          2513,
          2514,
          2516,
          2518,
          2520,
          2521,
          2522,
          2523,
          2524,
          2525,
          2526,
          2527,
          2528,
          2529,
          2532,
          2533,
          2534,
          2535,
          2536,
          2537,
          2538,
          2539,
          2540,
          2541,
          2542,
          2544,
          2545,
          2546,
          2547,
          2548,
          2549,
          2550,
          2551,
          2552,
          2553,
          2554,
          2557,
          2559,
          2560,
          2561,
          2562,
          2563,
          2564,
          2565,
          2566,
          2567,
          2568,
          2569,
          2570,
          2571,
          2573,
          2575,
          2576,
          2577,
          2578,
          2579,
          2580,
          2581,
          2582,
          2583,
          2584,
          2585,
          2586,
          2587,
          2588,
          2589,
          2590,
          2591,
          2592,
          2593,
          2594,
          2595,
          2596,
          2597,
          2599,
          2601,
          2602,
          2604,
          2605,
          2608,
          2609,
          2611,
          2612,
          2613,
          2614,
          2616,
          2617,
          2618,
          2624,
          2625,
          2629,
          2631,
          2632,
          2633,
          2634,
          2635,
          2638,
          2639,
          2641,
          2642,
          2643,
          2645,
          2646,
          2647,
          2648,
          2649,
          2650,
          2651,
          2653,
          2654,
          2655,
          2656,
          2657,
          2658,
          2659,
          2660,
          2661,
          2662,
          2664,
          2665,
          2666,
          2667,
          2669,
          2670,
          2671,
          2672,
          2673,
          2674,
          2675,
          2678,
          2679,
          2682,
          2683,
          2684,
          2686,
          2689,
          2690,
          2691,
          2692,
          2693,
          2694,
          2695,
          2696,
          2697,
          2699,
          2700,
          2701,
          2702,
          2703,
          2705,
          2706,
          2707,
          2708,
          2709,
          2710,
          2711,
          2712,
          2713,
          2714,
          2715,
          2716,
          2717,
          2718,
          2719,
          2720,
          2721,
          2722,
          2723,
          2724,
          2725,
          2726,
          2727,
          2728,
          2729,
          2730,
          2731,
          2732,
          2733,
          2734,
          2735,
          2736,
          2737,
          2738,
          2739,
          2740,
          2741,
          2742,
          2743,
          2744,
          2745,
          2747,
          2748,
          2749,
          2751,
          2752,
          2753,
          2754,
          2756,
          2757,
          2759,
          2761,
          2762,
          2764,
          2765,
          2767,
          2769,
          2770,
          2772,
          2773,
          2776,
          2779,
          2781,
          2783,
          2790,
          2794,
          2795,
          2797,
          2798,
          2799,
          2800,
          2801,
          2804,
          2805,
          2807,
          2808,
          2809,
          2811,
          2812,
          2813,
          2814,
          2815,
          2816,
          2818,
          2820,
          2821,
          2822,
          2823,
          2824,
          2825,
          2826,
          2827,
          2828,
          2830,
          2831,
          2834,
          2835,
          2836,
          2838,
          2839,
          2871,
          2872,
          2875,
          2876,
          2878,
          2879,
          2880,
          2882,
          2884,
          2886,
          2888,
          2891,
          2893,
          2894,
          2896,
          2898,
          2900,
          2901,
          2902,
          2907,
          2910,
          2912,
          2913,
          2915,
          2917,
          2918,
          2919,
          2920,
          2921,
          2923,
          2924,
          2925,
          2926,
          2927,
          2928,
          2929,
          2930,
          2931,
          2932,
          2933,
          2934,
          2935,
          2936,
          2937,
          2938,
          2939,
          2941,
          2943,
          2944,
          2945,
          2946,
          2948,
          2949,
          2950,
          2951,
          2952,
          2953,
          2954,
          2955,
          2956,
          2958,
          2960,
          2961,
          2962,
          2963,
          2964,
          2965,
          2967,
          2969,
          2973,
          2974,
          2975,
          2976,
          2978,
          2986,
          2991,
          2998,
          2999,
          3002,
          3003,
          3006,
          3007,
          3009,
          3011,
          3013,
          3015,
          3019,
          3020,
          3022,
          3024,
          3025,
          3026,
          3027,
          3028,
          3029,
          3030,
          3031,
          3032,
          3033,
          3034,
          3035,
          3036,
          3037,
          3039,
          3041,
          3042,
          3043,
          3044,
          3045,
          3046,
          3047,
          3048,
          3050,
          3053,
          3054,
          3057,
          3059,
          3060,
          3061,
          3062,
          3063,
          3064,
          3065,
          3067,
          3068,
          3070,
          3071,
          3073,
          3077,
          3078,
          3079,
          3080,
          3083,
          3084,
          3086,
          3088,
          3091,
          3093,
          3094,
          3095,
          3096,
          3098,
          3100,
          3101,
          3102,
          3103,
          3104,
          3106,
          3107,
          3108,
          3109,
          3110,
          3111,
          3114,
          3117,
          3118,
          3119,
          3120,
          3121,
          3122,
          3123,
          3124,
          3127,
          3128,
          3129,
          3133,
          3137,
          3138,
          3140,
          3141,
          3142,
          3143,
          3148,
          3150,
          3151,
          3155,
          3156,
          3160,
          3161,
          3162,
          3164,
          3165,
          3169,
          3170,
          3171,
          3172,
          3174,
          3189,
          3191,
          3193,
          3196,
          3200,
          3201,
          3202,
          3207,
          3208,
          3209,
          3211,
          3214,
          3215,
          3218,
          3221,
          3223,
          3225,
          3226,
          3227,
          3230,
          3234,
          3237,
          3238,
          3239,
          3240,
          3241,
          3243,
          3247,
          3248,
          3250,
          3253,
          3256,
          3258,
          3260,
          3261,
          3264,
          3265,
          3266,
          3267,
          3269,
          3270,
          3271,
          3272,
          3273,
          3274,
          3275,
          3276,
          3277,
          3278,
          3281,
          3282,
          3285,
          3286,
          3287,
          3288,
          3290,
          3291,
          3294,
          3295,
          3297,
          3299,
          3300,
          3301,
          3302,
          3303,
          3305,
          3309,
          3310,
          3312,
          3314,
          3315,
          3317,
          3319,
          3324,
          3331,
          3335,
          3336,
          3337,
          3338,
          3339,
          3340,
          3342,
          3343,
          3345,
          3346,
          3347,
          3348,
          3349,
          3350,
          3352,
          3353,
          3354,
          3355,
          3356,
          3358,
          3359,
          3360,
          3361,
          3362,
          3363,
          3364,
          3365,
          3366,
          3367,
          3368,
          3369,
          3370,
          3371,
          3372,
          3373,
          3374,
          3375,
          3376,
          3377,
          3378,
          3379,
          3380,
          3381,
          3382,
          3383,
          3384,
          3385,
          3389,
          3390,
          3391,
          3402,
          3412,
          3413,
          3415,
          3416,
          3418,
          3422,
          3424,
          3426,
          3427,
          3428,
          3430,
          3431,
          3432,
          3434,
          3436,
          3437,
          3438,
          3439,
          3441,
          3443,
          3445,
          3446,
          3447,
          3448,
          3449,
          3450,
          3453,
          3458,
          3459,
          3460,
          3461,
          3462,
          3464,
          3468,
          3469,
          3471,
          3474,
          3478,
          3480,
          3482,
          3493,
          3494,
          3498,
          3500,
          3502,
          3505,
          3507,
          3525,
          3526,
          3527,
          3528,
          3529,
          3530,
          3531,
          3534,
          3535,
          3536,
          3538,
          3539,
          3541,
          3543,
          3545,
          3546,
          3547,
          3548,
          3551,
          3552,
          3553,
          3554,
          3555,
          3556,
          3557,
          3558,
          3559,
          3560,
          3561,
          3562,
          3563,
          3568,
          3572,
          3573,
          3575,
          3576,
          3577,
          3578,
          3579,
          3580,
          3581,
          3583,
          3584,
          3585,
          3588,
          3591,
          3592,
          3593,
          3594,
          3595,
          3596,
          3601,
          3606,
          3614,
          3622,
          3627,
          3628,
          3629,
          3631,
          3633,
          3635,
          3636,
          3637,
          3639,
          3640,
          3641,
          3644,
          3646,
          3647,
          3648,
          3651,
          3652,
          3653,
          3654,
          3655,
          3656,
          3657,
          3661,
          3663,
          3664,
          3665,
          3667,
          3668,
          3669,
          3670,
          3671,
          3672,
          3674,
          3676,
          3678,
          3679,
          3680,
          3681,
          3682,
          3683,
          3684,
          3685,
          3686,
          3687,
          3689,
          3690,
          3691,
          3692,
          3694,
          3695,
          3696,
          3698,
          3699,
          3700,
          3702,
          3703,
          3704,
          3705,
          3706,
          3707,
          3709,
          3710,
          3712,
          3714,
          3715,
          3716,
          3718,
          3719,
          3720,
          3721,
          3722,
          3725,
          3727,
          3731,
          3732,
          3733,
          3734,
          3735,
          3736,
          3737,
          3738,
          3739,
          3740,
          3741,
          3742,
          3743,
          3744,
          3745,
          3746,
          3747,
          3748,
          3749,
          3751,
          3752,
          3753,
          3754,
          3755,
          3756,
          3757,
          3758,
          3759,
          3761,
          3764,
          3768,
          3777,
          3786,
          3787,
          3798,
          3804,
          3806,
          3809,
          3810,
          3811,
          3812,
          3813,
          3815,
          3817,
          3818,
          3819,
          3821,
          3822,
          3824,
          3825,
          3827,
          3829,
          3833,
          3834,
          3835,
          3837,
          3841,
          3843,
          3849,
          3854,
          3870,
          3876,
          3877,
          3878,
          3881,
          3883,
          3885,
          3886,
          3887,
          3888,
          3892,
          3893,
          3894,
          3896,
          3898,
          3899,
          3900,
          3902,
          3903,
          3904,
          3905,
          3906,
          3908,
          3909,
          3910,
          3913,
          3916,
          3922,
          3926,
          3928,
          3929,
          3933,
          3935,
          3937,
          3942,
          3943,
          3945,
          3948,
          3950,
          3954,
          3955,
          3957,
          3964,
          3965,
          3968,
          3969,
          3971,
          3974,
          3976,
          3980,
          3982,
          3984,
          3985,
          3987,
          3988,
          3989,
          3990,
          3991,
          3992,
          3993,
          3999,
          4000,
          4001,
          4002,
          4003,
          4005,
          4007,
          4010,
          4015,
          4020,
          4033,
          4035,
          4038,
          4040,
          4042,
          4043,
          4044,
          4046,
          4047,
          4048,
          4050,
          4054,
          4055,
          4057,
          4059,
          4060,
          4061,
          4062,
          4065,
          4068,
          4071,
          4072,
          4073,
          4074,
          4077,
          4082,
          4083,
          4084,
          4086,
          4088,
          4091,
          4092,
          4093,
          4094,
          4096,
          4098,
          4101,
          4107,
          4109,
          4200,
          4201,
          4202,
          4206,
          4209,
          4210,
          4215,
          4218,
          4220,
          4222,
          4226,
          4227,
          4231,
          4236,
          4244,
          4247,
          4278,
          4279,
          4280,
          4285,
          4293,
          4295,
          4297,
          4308,
          4310,
          4316,
          4317,
          4321,
          4323,
          4324,
          4325,
          4328,
          4333,
          4334,
          4335,
          4336,
          4337,
          4338,
          4339,
          4340,
          4342,
          4345,
          4347,
          4348,
          4349,
          4352,
          4354,
          4356,
          4359,
          4360,
          4364,
          4369,
          4371,
          4372,
          4373,
          4376,
          4377,
          4380,
          4390,
          4407,
          4623,
          4626,
          4627,
          4629,
          4630,
          4632,
          4633,
          4634,
          4635,
          4636,
          4640,
          4644,
          4650,
          4651,
          4652,
          4653,
          4654,
          4655,
          4656,
          4661,
          4662,
          4664,
          4667,
          4671,
          4678,
          6106,
          6108,
          6126,
          6127,
          6128,
          6132,
          6134,
          6136,
          6141,
          6143,
          6153,
          6175,
          6491,
          6495,
          6496,
          6498,
          6499,
          6500,
          6501,
          6504,
          6507,
          6509,
          6511,
          6513,
          6514,
          6519,
          6524,
          6539,
          6552
         ],
         "y0": " ",
         "yaxis": "y"
        }
       ],
       "layout": {
        "boxmode": "group",
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "variable"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"819aad02-eec4-4303-aa46-c3fdda03ad22\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"819aad02-eec4-4303-aa46-c3fdda03ad22\")) {                    Plotly.newPlot(                        \"819aad02-eec4-4303-aa46-c3fdda03ad22\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\"},\"name\":\"\",\"notched\":false,\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x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x0\":\" \",\"xaxis\":\"x\",\"y\":[368,374,377,380,382,383,384,387,388,390,395,430,431,435,436,437,438,440,442,443,444,445,446,448,449,488,493,495,496,497,503,504,505,506,507,508,509,510,511,512,513,514,515,517,518,519,520,521,522,523,524,525,526,527,529,530,531,532,535,550,553,554,555,556,557,558,559,584,589,590,594,595,597,598,600,601,603,605,607,608,609,610,611,612,613,614,616,617,618,619,620,621,622,623,624,626,627,628,630,633,635,642,647,649,651,652,656,657,660,661,662,664,665,666,667,668,669,670,671,672,673,674,676,677,678,679,680,681,682,683,684,686,687,688,689,691,692,693,694,695,696,697,698,699,700,701,702,704,705,706,707,708,709,710,711,712,713,714,715,716,717,720,721,722,723,724,725,727,728,730,731,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,2231,2232,2233,2234,2235,2236,2237,2238,2239,2240,2241,2242,2243,2244,2245,2246,2247,2248,2249,2250,2251,2252,2253,2254,2255,2256,2257,2258,2259,2260,2261,2262,2263,2264,2265,2266,2267,2268,2269,2270,2271,2272,2273,2274,2275,2276,2277,2278,2279,2280,2281,2282,2283,2284,2285,2286,2287,2288,2289,2290,2291,2292,2293,2294,2295,2296,2297,2298,2299,2300,2301,2302,2303,2304,2305,2306,2307,2308,2309,2310,2311,2312,2313,2314,2315,2316,2317,2318,2319,2320,2321,2322,2323,2324,2325,2326,2327,2328,2329,2330,2331,2332,2333,2334,2335,2336,2337,2338,2339,2340,2341,2342,2343,2344,2345,2346,2347,2348,2349,2350,2351,2352,2353,2354,2355,2356,2357,2358,2359,2360,2361,2362,2363,2364,2365,2366,2367,2368,2369,2370,2371,2372,2373,2374,2375,2376,2377,2378,2379,2380,2381,2382,2383,2384,2385,2386,2387,2388,2389,2390,2391,2392,2393,2394,2395,2397,2398,2399,2400,2401,2402,2403,2404,2405,2406,2407,2408,2409,2410,2411,2412,2413,2414,2415,2416,2417,2419,2420,2421,2422,2423,2425,2426,2428,2429,2430,2431,2432,2433,2434,2435,2436,2437,2438,2439,2440,2441,2442,2443,2444,2445,2446,2447,2448,2449,2450,2451,2452,2453,2454,2455,2456,2457,2458,2459,2460,2461,2462,2463,2464,2465,2466,2468,2469,2470,2471,2472,2473,2474,2475,2476,2477,2478,2479,2480,2481,2482,2483,2484,2485,2486,2488,2489,2490,2491,2492,2494,2495,2496,2497,2498,2499,2502,2503,2504,2505,2506,2507,2508,2509,2510,2511,2512,2513,2514,2516,2518,2520,2521,2522,2523,2524,2525,2526,2527,2528,2529,2532,2533,2534,2535,2536,2537,2538,2539,2540,2541,2542,2544,2545,2546,2547,2548,2549,2550,2551,2552,2553,2554,2557,2559,2560,2561,2562,2563,2564,2565,2566,2567,2568,2569,2570,2571,2573,2575,2576,2577,2578,2579,2580,2581,2582,2583,2584,2585,2586,2587,2588,2589,2590,2591,2592,2593,2594,2595,2596,2597,2599,2601,2602,2604,2605,2608,2609,2611,2612,2613,2614,2616,2617,2618,2624,2625,2629,2631,2632,2633,2634,2635,2638,2639,2641,2642,2643,2645,2646,2647,2648,2649,2650,2651,2653,2654,2655,2656,2657,2658,2659,2660,2661,2662,2664,2665,2666,2667,2669,2670,2671,2672,2673,2674,2675,2678,2679,2682,2683,2684,2686,2689,2690,2691,2692,2693,2694,2695,2696,2697,2699,2700,2701,2702,2703,2705,2706,2707,2708,2709,2710,2711,2712,2713,2714,2715,2716,2717,2718,2719,2720,2721,2722,2723,2724,2725,2726,2727,2728,2729,2730,2731,2732,2733,2734,2735,2736,2737,2738,2739,2740,2741,2742,2743,2744,2745,2747,2748,2749,2751,2752,2753,2754,2756,2757,2759,2761,2762,2764,2765,2767,2769,2770,2772,2773,2776,2779,2781,2783,2790,2794,2795,2797,2798,2799,2800,2801,2804,2805,2807,2808,2809,2811,2812,2813,2814,2815,2816,2818,2820,2821,2822,2823,2824,2825,2826,2827,2828,2830,2831,2834,2835,2836,2838,2839,2871,2872,2875,2876,2878,2879,2880,2882,2884,2886,2888,2891,2893,2894,2896,2898,2900,2901,2902,2907,2910,2912,2913,2915,2917,2918,2919,2920,2921,2923,2924,2925,2926,2927,2928,2929,2930,2931,2932,2933,2934,2935,2936,2937,2938,2939,2941,2943,2944,2945,2946,2948,2949,2950,2951,2952,2953,2954,2955,2956,2958,2960,2961,2962,2963,2964,2965,2967,2969,2973,2974,2975,2976,2978,2986,2991,2998,2999,3002,3003,3006,3007,3009,3011,3013,3015,3019,3020,3022,3024,3025,3026,3027,3028,3029,3030,3031,3032,3033,3034,3035,3036,3037,3039,3041,3042,3043,3044,3045,3046,3047,3048,3050,3053,3054,3057,3059,3060,3061,3062,3063,3064,3065,3067,3068,3070,3071,3073,3077,3078,3079,3080,3083,3084,3086,3088,3091,3093,3094,3095,3096,3098,3100,3101,3102,3103,3104,3106,3107,3108,3109,3110,3111,3114,3117,3118,3119,3120,3121,3122,3123,3124,3127,3128,3129,3133,3137,3138,3140,3141,3142,3143,3148,3150,3151,3155,3156,3160,3161,3162,3164,3165,3169,3170,3171,3172,3174,3189,3191,3193,3196,3200,3201,3202,3207,3208,3209,3211,3214,3215,3218,3221,3223,3225,3226,3227,3230,3234,3237,3238,3239,3240,3241,3243,3247,3248,3250,3253,3256,3258,3260,3261,3264,3265,3266,3267,3269,3270,3271,3272,3273,3274,3275,3276,3277,3278,3281,3282,3285,3286,3287,3288,3290,3291,3294,3295,3297,3299,3300,3301,3302,3303,3305,3309,3310,3312,3314,3315,3317,3319,3324,3331,3335,3336,3337,3338,3339,3340,3342,3343,3345,3346,3347,3348,3349,3350,3352,3353,3354,3355,3356,3358,3359,3360,3361,3362,3363,3364,3365,3366,3367,3368,3369,3370,3371,3372,3373,3374,3375,3376,3377,3378,3379,3380,3381,3382,3383,3384,3385,3389,3390,3391,3402,3412,3413,3415,3416,3418,3422,3424,3426,3427,3428,3430,3431,3432,3434,3436,3437,3438,3439,3441,3443,3445,3446,3447,3448,3449,3450,3453,3458,3459,3460,3461,3462,3464,3468,3469,3471,3474,3478,3480,3482,3493,3494,3498,3500,3502,3505,3507,3525,3526,3527,3528,3529,3530,3531,3534,3535,3536,3538,3539,3541,3543,3545,3546,3547,3548,3551,3552,3553,3554,3555,3556,3557,3558,3559,3560,3561,3562,3563,3568,3572,3573,3575,3576,3577,3578,3579,3580,3581,3583,3584,3585,3588,3591,3592,3593,3594,3595,3596,3601,3606,3614,3622,3627,3628,3629,3631,3633,3635,3636,3637,3639,3640,3641,3644,3646,3647,3648,3651,3652,3653,3654,3655,3656,3657,3661,3663,3664,3665,3667,3668,3669,3670,3671,3672,3674,3676,3678,3679,3680,3681,3682,3683,3684,3685,3686,3687,3689,3690,3691,3692,3694,3695,3696,3698,3699,3700,3702,3703,3704,3705,3706,3707,3709,3710,3712,3714,3715,3716,3718,3719,3720,3721,3722,3725,3727,3731,3732,3733,3734,3735,3736,3737,3738,3739,3740,3741,3742,3743,3744,3745,3746,3747,3748,3749,3751,3752,3753,3754,3755,3756,3757,3758,3759,3761,3764,3768,3777,3786,3787,3798,3804,3806,3809,3810,3811,3812,3813,3815,3817,3818,3819,3821,3822,3824,3825,3827,3829,3833,3834,3835,3837,3841,3843,3849,3854,3870,3876,3877,3878,3881,3883,3885,3886,3887,3888,3892,3893,3894,3896,3898,3899,3900,3902,3903,3904,3905,3906,3908,3909,3910,3913,3916,3922,3926,3928,3929,3933,3935,3937,3942,3943,3945,3948,3950,3954,3955,3957,3964,3965,3968,3969,3971,3974,3976,3980,3982,3984,3985,3987,3988,3989,3990,3991,3992,3993,3999,4000,4001,4002,4003,4005,4007,4010,4015,4020,4033,4035,4038,4040,4042,4043,4044,4046,4047,4048,4050,4054,4055,4057,4059,4060,4061,4062,4065,4068,4071,4072,4073,4074,4077,4082,4083,4084,4086,4088,4091,4092,4093,4094,4096,4098,4101,4107,4109,4200,4201,4202,4206,4209,4210,4215,4218,4220,4222,4226,4227,4231,4236,4244,4247,4278,4279,4280,4285,4293,4295,4297,4308,4310,4316,4317,4321,4323,4324,4325,4328,4333,4334,4335,4336,4337,4338,4339,4340,4342,4345,4347,4348,4349,4352,4354,4356,4359,4360,4364,4369,4371,4372,4373,4376,4377,4380,4390,4407,4623,4626,4627,4629,4630,4632,4633,4634,4635,4636,4640,4644,4650,4651,4652,4653,4654,4655,4656,4661,4662,4664,4667,4671,4678,6106,6108,6126,6127,6128,6132,6134,6136,6141,6143,6153,6175,6491,6495,6496,6498,6499,6500,6501,6504,6507,6509,6511,6513,6514,6519,6524,6539,6552],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"variable\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"boxmode\":\"group\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('819aad02-eec4-4303-aa46-c3fdda03ad22');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs_lengths = [len(x[0])+len(x[1]) for x in zip(train_val_df['input_text_x'],\\\n",
    "                                               train_val_df['story'])]\n",
    "\n",
    "max_length_input = min(512,round(np.quantile(list(set(inputs_lengths)), .05))) \n",
    "print(f'Max length:{max_length_input}')\n",
    "\n",
    "# stride = int(max_length_input/3)\n",
    "# print(f'Stride:{stride}')\n",
    "\n",
    "fig_inputs = px.box(list(set(inputs_lengths)))\n",
    "fig_inputs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3x9P944M8SYg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "id": "3x9P944M8SYg",
    "outputId": "07a5f08d-4fe8-4dc6-b82c-919b40477cb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length (3rd quantile):160\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "variable=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa"
         },
         "name": "",
         "notched": false,
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "box",
         "x": [
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0",
          "0"
         ],
         "x0": " ",
         "xaxis": "x",
         "y": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          131,
          132,
          133,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          667,
          156,
          157,
          155,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          167,
          169,
          170,
          171,
          172,
          174,
          176,
          177,
          178,
          179,
          181,
          184,
          185,
          186,
          188,
          190,
          195,
          199,
          200,
          201,
          207,
          208,
          213,
          215,
          217,
          220,
          221,
          229,
          240,
          249,
          539,
          259,
          264,
          267,
          273,
          275,
          279,
          1819,
          291,
          297,
          333,
          379,
          408,
          429,
          461,
          466
         ],
         "y0": " ",
         "yaxis": "y"
        }
       ],
       "layout": {
        "boxmode": "group",
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "variable"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"e78c5d87-d228-4641-83fb-8e0abe5ee93b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e78c5d87-d228-4641-83fb-8e0abe5ee93b\")) {                    Plotly.newPlot(                        \"e78c5d87-d228-4641-83fb-8e0abe5ee93b\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\"},\"name\":\"\",\"notched\":false,\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\"],\"x0\":\" \",\"xaxis\":\"x\",\"y\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,131,132,133,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,667,156,157,155,159,160,161,162,163,164,165,167,169,170,171,172,174,176,177,178,179,181,184,185,186,188,190,195,199,200,201,207,208,213,215,217,220,221,229,240,249,539,259,264,267,273,275,279,1819,291,297,333,379,408,429,461,466],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"variable\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"boxmode\":\"group\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('e78c5d87-d228-4641-83fb-8e0abe5ee93b');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outputs_lengths = [len(x) for x in train_val_df['input_text_y']]\n",
    "\n",
    "max_length_answer = round(np.quantile(list(set(outputs_lengths)), .75))\n",
    "print(f'Max length (3rd quantile):{max_length_answer}')\n",
    "\n",
    "fig_inputs = px.box(list(set(outputs_lengths)))\n",
    "fig_inputs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "MSHCfua8ht_S",
   "metadata": {
    "id": "MSHCfua8ht_S"
   },
   "outputs": [],
   "source": [
    "def prepare_features(batch, tokenizer, max_length_input, max_length_answer):\n",
    "    # Tokenize the Question, Context and text columns\n",
    "    encoded_batch_inputs = tokenizer(\n",
    "        batch['question'],\n",
    "        batch['context'],\n",
    "#         data['text'],\n",
    "        add_special_tokens=False,\n",
    "        max_length=max_length_input,\n",
    "        truncation='only_second',\n",
    "        padding='max_length'\n",
    "    )\n",
    "\n",
    "    # Tokenize the Answer column\n",
    "    encoded_batch_labels = tokenizer(\n",
    "        batch['answer'],\n",
    "        max_length=max_length_answer,\n",
    "        padding='max_length'\n",
    "    )\n",
    "    \n",
    "    encoded_batch_inputs['labels'] = encoded_batch_labels.input_ids.copy()\n",
    "    encoded_batch_inputs['decoder_input_ids'] = deepcopy(encoded_batch_inputs['labels'])\n",
    "    encoded_batch_inputs['labels'] = [[-100 if token == tokenizer.pad_token_id else token\\\n",
    "                                    for token in labels]\\\n",
    "                                    for labels in encoded_batch_inputs['labels']]\n",
    "    \n",
    "    encoded_batch_inputs['labels_mask'] = encoded_batch_labels.attention_mask.copy()\n",
    "\n",
    "\n",
    "    return encoded_batch_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ung3zCz08GSF",
   "metadata": {
    "id": "Ung3zCz08GSF"
   },
   "source": [
    "* [M1] DistilRoBERTa (distilberta-base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ZR491qMJ94HJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "3d42b37411a643c5978a56ed809087ea",
      "05ebe53d65e0473a88570457b6ee4b81",
      "d5109582ad184548a9d509ee75bdb16d",
      "b5da7e076ccd49f3a5a134bdea518ed7",
      "5c5994b564a54557934ece1042abbfbc",
      "96fcb084772143adbeff35540b22e1a2",
      "8b6a209020194a6ea95fc8cad4b689c9",
      "341ea36a069e45158f4d07b4757d28e4",
      "4977a3309b6a4d0bac11e75fa6f5421c",
      "acf538aa401b4c588c306b8bc6548531",
      "e0b98fc9970e41658c7c0f4ae7ee0fd9",
      "dc714e341183474fb0c19cb22e9de938",
      "180c1b2f44d147f2823ff5cb0a2063f2",
      "a1ce12e1914641eba7cba1b2b734a20a",
      "3fbc9f4f55134457872f2501d4a293b3",
      "ef3b805f3f824311a5cc314422d8346a",
      "4665614a763f4be7ac55e447a14c8eb3",
      "7c0b26fad32a4bae9418b06ba2ae4521",
      "d4a4c8c3060f4965940435bd6aba9cef",
      "0a8e5a09437f4df48daa923c2741ed80",
      "9aee3df433a049fba93a52e8b42b2a66",
      "9527116a654e4c0f9fa137f1e264a837",
      "173f79a9dd2a4a6babd1e5eda4b1b707",
      "6841ed77a57845e5963188c332c77df8",
      "6a268946eaa74e90acb04e00b816307e",
      "eaf314ad07264f8882deb91fe7ced104",
      "bcb531b22c8d47d1a14d9a391a57fc4b",
      "1a3d26f4c50b43dab11a1ae0d8fbac7f",
      "efe5eddae1f648d288a9460f5e693584",
      "1b844edd880646afa3f99d6cb630c2af",
      "a01e71cf41a6443eb770b8d16b64935f",
      "b26fbfb8db23473d8f3f3ab0cfec53e4",
      "a23058becfb54f0eb7d8894260d66027"
     ]
    },
    "id": "ZR491qMJ94HJ",
    "outputId": "a7ccf9bc-c486-4b2d-ab13-94ee6950fd92"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:00<00:00, 72.75ba/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 76.17ba/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 78.38ba/s]\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint_M1 = 'distilroberta-base'\n",
    "tokenizer_M1 = AutoTokenizer.from_pretrained(model_checkpoint_M1)\n",
    "assert isinstance(tokenizer_M1, PreTrainedTokenizerFast)\n",
    "\n",
    "# Setting the BOS and EOS token\n",
    "tokenizer_M1.bos_token = tokenizer_M1.cls_token\n",
    "tokenizer_M1.eos_token = tokenizer_M1.sep_token\n",
    "\n",
    "tokenized_datasets_M1 = DatasetDict()\n",
    "\n",
    "# Use the `prepare_features` functions\n",
    "tokenized_datasets_M1 = dataset_COQA.map(\n",
    "    lambda batch: prepare_features(batch, tokenizer_M1, max_length_input, max_length_answer),\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    remove_columns=dataset_COQA['train'].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d-mTyZHTP9h7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d-mTyZHTP9h7",
    "outputId": "4918cd10-32e6-471e-9ac2-de53100325f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels', 'decoder_input_ids', 'labels_mask'],\n",
       "        num_rows: 848\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels', 'decoder_input_ids', 'labels_mask'],\n",
       "        num_rows: 208\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels', 'decoder_input_ids', 'labels_mask'],\n",
       "        num_rows: 64\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets_M1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5RMxNwZlRE2B",
   "metadata": {
    "id": "5RMxNwZlRE2B"
   },
   "source": [
    "* [M2] BERTTiny (bert-tiny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4nbT0QJVRYMg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "2961db3a8c4749e08a52f396b18769b9",
      "a38d08ad41c4407ab61e33f3c936bfe0",
      "7a2f8ff4946f49b1951eb45d5c5cba75",
      "9db949cbc82645c0a9c1b1cc5548eb22",
      "0ff6fea3fcd841ef87298ad119554adc",
      "8bc830bdf51b4d9da2faac3b815cc124",
      "a98c60db672743efa060077a5ec09e52",
      "55cb8a577bf14b7ea9d4beedf275d925",
      "6efa30ef9f944229bafa23299e6d1712",
      "69aabc48a6904694b44d43ca03db9424",
      "38fdabfdf00c444bbfba880f12f7d1ff",
      "c51fd4ee4f9147d987ff83e441e4143b",
      "9ef014201edf4be291626bc466479e47",
      "24d073d354e44c7c913117fe01d13fe3",
      "7043cdadfe724d27a2d8b1a20645a77e",
      "db4d4e59b43b4bd8914310b17888c023",
      "a89ffc89651e4308aee50d460cbc68b4",
      "0bb93f887cc64eaaa1d72efe2abbd0b8",
      "74ef12751bf04755bcb9111958e96c6c",
      "4ea0a052acc14c8b98dc105de2987919",
      "c9a781e2bf2c405fb5aa10cb6f38e98d",
      "fae5f893c79d49a0acd588d7dd3ac6c8",
      "7f5a16ff31f44194a598596742bd08fb",
      "fb7618f6fb254802b770f331dff3ae0e",
      "09d74d2251354991abe603f4298953c7",
      "23a2fa0acd434738acdb3294da04cd58",
      "435f0b3e62024f63a4022f3be2d0432c",
      "7e81423f9ce34d69b016df9db8194b30",
      "cba33f69af3346d09f8743d1c8e46dc4",
      "ec30998fa9a14cb5a1fe30e7cd9b2b09",
      "1a1d5e04d2a44b9087e2ac1716791a5e",
      "25ae1eb92a874541b488061ed68cbc69",
      "586f5a4ddb5d4a218844356273973463"
     ]
    },
    "id": "4nbT0QJVRYMg",
    "outputId": "95b7df50-0026-40e5-9c72-902daed1118e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:00<00:00, 71.22ba/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 72.37ba/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 65.54ba/s]\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint_M2 = 'prajjwal1/bert-tiny'\n",
    "tokenizer_M2 = AutoTokenizer.from_pretrained(model_checkpoint_M2)\n",
    "assert isinstance(tokenizer_M2, PreTrainedTokenizerFast)\n",
    "\n",
    "# Setting the BOS and EOS token\n",
    "tokenizer_M2.bos_token = tokenizer_M2.cls_token\n",
    "tokenizer_M2.eos_token = tokenizer_M2.sep_token\n",
    "\n",
    "tokenized_datasets_M2 = DatasetDict()\n",
    "\n",
    "# Use the `prepare_features` functions\n",
    "tokenized_datasets_M2 = dataset_COQA.map(\n",
    "    lambda datarow: prepare_features(datarow, tokenizer_M2, max_length_input, max_length_answer),\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    remove_columns=dataset_COQA['train'].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "LkaLnPxyRaiR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LkaLnPxyRaiR",
    "outputId": "bd3b5071-f2cd-4716-f834-9e07fd615881"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels', 'decoder_input_ids', 'labels_mask'],\n",
       "        num_rows: 848\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels', 'decoder_input_ids', 'labels_mask'],\n",
       "        num_rows: 208\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels', 'decoder_input_ids', 'labels_mask'],\n",
       "        num_rows: 64\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets_M2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230a21de",
   "metadata": {
    "id": "230a21de"
   },
   "source": [
    "## [Task 3] Model definition\n",
    "\n",
    "Write your own script to define the following transformer-based models from [huggingface](https://HuggingFace.co/).\n",
    "\n",
    "* [M1] DistilRoBERTa (distilberta-base)\n",
    "* [M2] BERTTiny (bert-tiny)\n",
    "\n",
    "**Note**: Remember to install the ```transformers``` python package!\n",
    "\n",
    "**Note**: We consider small transformer models for computational reasons!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2IvgKVHJUUuD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 498
    },
    "id": "2IvgKVHJUUuD",
    "outputId": "657b751d-b96e-4491-ee79-9feef09679da"
   },
   "outputs": [],
   "source": [
    "from transformers import TFEncoderDecoderModel\n",
    "\n",
    "class EncoderDecoder(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Custom keras model that wraps the TFEncoderDecoderModel\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_checkpoint, **kwargs):\n",
    "        super(EncoderDecoder, self).__init__(**kwargs)\n",
    "        self.model_name = model_checkpoint\n",
    "\n",
    "        # tie_encoder_decoder to share weights and half the number of parameters\n",
    "        self.model = TFEncoderDecoderModel.from_encoder_decoder_pretrained(model_checkpoint, model_checkpoint,\n",
    "                                                                           encoder_from_pt=True,\n",
    "                                                                           decoder_from_pt=True,\n",
    "                                                                           tie_encoder_decoder=True)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        loss = self.model(input_ids=inputs['input_ids'],\n",
    "                          attention_mask=inputs['attention_mask'],\n",
    "                          decoder_input_ids=inputs['decoder_input_ids'],\n",
    "                          decoder_attention_mask=inputs['labels_mask'],\n",
    "                          labels=inputs['labels']).loss\n",
    "        return loss\n",
    "\n",
    "    def generate(self, **kwargs):\n",
    "        return self.model.generate(decoder_start_token_id=self.model.config.decoder.pad_token_id,\n",
    "                                   **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EfroUy-MI33j",
   "metadata": {
    "id": "EfroUy-MI33j"
   },
   "source": [
    "When loading a pre-trained model into a target model, any layers present in the pre-trained model but not in the target model will be discarded. Conversely, any layers present in the target model but not in the pre-trained model will be initialized according to the initialization strategy of the target model.\n",
    "\n",
    "This behavior is expected when using pre-trained models, and is due to the fact that the architecture of the target model may differ from that of the pre-trained model. It is important to note that this discrepancy in architecture does not necessarily imply that the target model will perform poorly out of the box. However, it is generally necessary to fine-tune the target model on a downstream task in order to achieve good performance.\n",
    "\n",
    "* [M1] DistilRoBERTa (distilberta-base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "KxoCOQ9JKR1p",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "KxoCOQ9JKR1p",
    "outputId": "20e58a2e-f86e-40b7-df0c-b6ed5b535ca5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFRobertaModel.\n",
      "\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at C:\\Users\\Antonio\\AppData\\Local\\Temp\\tmpvyjuihuc.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n",
      "All PyTorch model weights were used when initializing TFRobertaForCausalLM.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaForCausalLM were not initialized from the PyTorch model and are newly initialized: ['roberta.encoder.layer.0.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.self.key.weight', 'roberta.encoder.layer.0.crossattention.self.key.bias', 'roberta.encoder.layer.0.crossattention.self.value.weight', 'roberta.encoder.layer.0.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.output.dense.weight', 'roberta.encoder.layer.0.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.self.query.bias', 'roberta.encoder.layer.1.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.self.key.bias', 'roberta.encoder.layer.1.crossattention.self.value.weight', 'roberta.encoder.layer.1.crossattention.self.value.bias', 'roberta.encoder.layer.1.crossattention.output.dense.weight', 'roberta.encoder.layer.1.crossattention.output.dense.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.self.query.bias', 'roberta.encoder.layer.2.crossattention.self.key.weight', 'roberta.encoder.layer.2.crossattention.self.key.bias', 'roberta.encoder.layer.2.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.output.dense.weight', 'roberta.encoder.layer.2.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.3.crossattention.self.query.weight', 'roberta.encoder.layer.3.crossattention.self.query.bias', 'roberta.encoder.layer.3.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.self.value.weight', 'roberta.encoder.layer.3.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.output.dense.bias', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.4.crossattention.self.query.weight', 'roberta.encoder.layer.4.crossattention.self.query.bias', 'roberta.encoder.layer.4.crossattention.self.key.weight', 'roberta.encoder.layer.4.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.output.dense.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.5.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.self.value.weight', 'roberta.encoder.layer.5.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.output.dense.bias', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "All model checkpoint layers were used when initializing TFRobertaForCausalLM.\n",
      "\n",
      "All the layers of TFRobertaForCausalLM were initialized from the model checkpoint at C:\\Users\\Antonio\\AppData\\Local\\Temp\\tmp1vvjrv32.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForCausalLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_M1 = EncoderDecoder(model_checkpoint=model_checkpoint_M1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "DHJ4-UMWSFiE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "DHJ4-UMWSFiE",
    "outputId": "6d0878e8-cb7b-4768-dea8-788678db7a7f"
   },
   "outputs": [],
   "source": [
    "model_M1.model.config.decoder_start_token_id = tokenizer_M1.cls_token_id\n",
    "model_M1.model.config_eos_token_id = tokenizer_M1.sep_token_id\n",
    "model_M1.model.config.pad_token_id = tokenizer_M1.pad_token_id\n",
    "model_M1.model.config.vocab_size = model_M1.model.config.encoder.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bfb166",
   "metadata": {
    "id": "WSpKlmdzYTmH"
   },
   "outputs": [],
   "source": [
    "# model_M1.model.config.num_beams = 4\n",
    "# model_M1.model.config.min_length = 1\n",
    "# model_M1.model.config.length_penalty = 3.0\n",
    "# model_M1.model.config.early_stopping = True\n",
    "# model_M1.model.config.no_repeat_ngram_size = 3\n",
    "# model_M1.model.config.max_length = max_length_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x0eG28KvQeuq",
   "metadata": {
    "id": "x0eG28KvQeuq"
   },
   "source": [
    "* [M2] BERTTiny (bert-tiny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6MVNRkkJQeEz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6MVNRkkJQeEz",
    "outputId": "4f3794be-c5ed-47d5-99f7-5dbb5fe07655"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'bert.embeddings.position_ids', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "All model checkpoint layers were used when initializing TFBertModel.\n",
      "\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at C:\\Users\\Antonio\\AppData\\Local\\Temp\\tmpugwifqlu.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertLMHeadModel: ['cls.predictions.decoder.bias', 'bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertLMHeadModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertLMHeadModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertLMHeadModel were not initialized from the PyTorch model and are newly initialized: ['bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "All model checkpoint layers were used when initializing TFBertLMHeadModel.\n",
      "\n",
      "All the layers of TFBertLMHeadModel were initialized from the model checkpoint at C:\\Users\\Antonio\\AppData\\Local\\Temp\\tmpnhnmh8e6.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertLMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_M2 = EncoderDecoder(model_checkpoint=model_checkpoint_M2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "pOtxlC82SW9y",
   "metadata": {
    "id": "pOtxlC82SW9y"
   },
   "outputs": [],
   "source": [
    "model_M2.model.config.decoder_start_token_id = tokenizer_M2.cls_token_id\n",
    "model_M2.model.config_eos_token_id = tokenizer_M2.sep_token_id\n",
    "model_M2.model.config.pad_token_id = tokenizer_M2.pad_token_id\n",
    "model_M2.model.config.vocab_size = model_M2.model.config.encoder.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kx1SCS3oYggm",
   "metadata": {
    "id": "Kx1SCS3oYggm"
   },
   "outputs": [],
   "source": [
    "# model_M2.model.config.num_beams = 4\n",
    "# model_M2.model.config.min_length = 1\n",
    "# model_M2.model.config.length_penalty = 3.0\n",
    "# model_M2.model.config.early_stopping = True\n",
    "# model_M2.model.config.no_repeat_ngram_size = 3\n",
    "# model_M2.model.config.max_length = max_length_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e83f28",
   "metadata": {
    "id": "f1e83f28"
   },
   "source": [
    "## [Task 4] Question generation with text passage $P$ and question $Q$\n",
    "\n",
    "We want to define $f_\\theta(P, Q)$. \n",
    "\n",
    "Write your own script to implement $f_\\theta$ for each model: M1 and M2.\n",
    "\n",
    "#### Formulation\n",
    "\n",
    "Consider a dialogue on text passage $P$. \n",
    "\n",
    "For each question $Q_i$ at dialogue turn $i$, your model should take $P$ and $Q_i$ and generate $A_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "iZpcgS-aIwx0",
   "metadata": {
    "id": "iZpcgS-aIwx0"
   },
   "outputs": [],
   "source": [
    "# from transformers import DefaultDataCollator, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForSeq2Seq, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vt0w5b8Htdyv",
   "metadata": {
    "id": "Vt0w5b8Htdyv"
   },
   "source": [
    "A dataset collator is a function used in data processing for deep learning models, \n",
    "especially in training and evaluation. It collates, or collects, several examples \n",
    "from a dataset into a batch and performs operations on the batch, such as padding \n",
    "or stacking. This is usually done to make the input data compatible with the model's \n",
    "batch size, which is the number of samples processed together in one forward/backward pass. \n",
    "The dataset collator takes care of the preprocessing required to format the examples in the batch, \n",
    "allowing the data to be efficiently processed by the deep learning framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "XOgSUToQJMrz",
   "metadata": {
    "id": "XOgSUToQJMrz"
   },
   "outputs": [],
   "source": [
    "data_collator_M1 = DataCollatorForSeq2Seq(tokenizer_M1, padding= 'max_length',\\\n",
    "                                           max_length=max_length_answer,return_tensors=\"tf\")\n",
    "# data_collator_M1 = DefaultDataCollator(return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "01b94e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoderTrainer(object):\n",
    "    \"\"\"\n",
    "    Simple wrapper class\n",
    "\n",
    "    train_op -> uses tf.GradientTape to compute the loss\n",
    "    batch_fit -> receives a batch and performs forward-backward passes (gradient included)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, keras_model):\n",
    "        self.keras_model = keras_model\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=5e-05)\n",
    "        \n",
    "    @tf.function\n",
    "    def compute_loss(self, inputs):\n",
    "        loss = self.keras_model(inputs=inputs)\n",
    "        return tf.reduce_mean(loss)\n",
    "\n",
    "    @tf.function\n",
    "    def train_op(self, inputs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self.compute_loss(inputs=inputs)\n",
    "\n",
    "        grads = tape.gradient(loss, self.keras_model.trainable_variables)\n",
    "        return loss, grads\n",
    "\n",
    "    @tf.function\n",
    "    def batch_fit(self, inputs):\n",
    "        loss, grads = self.train_op(inputs=inputs)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.keras_model.trainable_variables))\n",
    "        return loss\n",
    "    \n",
    "    @tf.function\n",
    "    def evaluate(self, dataset):\n",
    "        total_loss = 0.0\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        for batch in dataset:\n",
    "            print('1')\n",
    "            loss = self.compute_loss(inputs=batch)\n",
    "            print('2')\n",
    "            total_loss += loss\n",
    "            print('3')\n",
    "            generated = self.keras_model.generate(input_ids=batch['input_ids'],\n",
    "                                                 max_length=max_length_answer,\n",
    "                                                 repetition_penalty=3.,\n",
    "                                                 min_length=5,\n",
    "                                                 no_repeat_ngram_size=3,\n",
    "                                                 early_stopping=True,\n",
    "                                                 num_beams=4\n",
    "                                                 )\n",
    "            print('4')\n",
    "            generated = tokenizer_M1.batch_decode(generated, skip_special_tokens=True)\n",
    "            \n",
    "            print('5')\n",
    "            print(f'Generated: {generated}')\n",
    "            \n",
    "            print('6')\n",
    "            all_predictions.extend(generated)\n",
    "            print('7')\n",
    "            all_targets.extend(tokenizer_M1.batch_decode(batch['labels'], skip_special_tokens=True))\n",
    "\n",
    "        avg_loss = total_loss / len(dataset)\n",
    "        metrics = compute_squad_metrics(all_predictions, all_targets)\n",
    "        return avg_loss, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6LTZuLlDtZ-j",
   "metadata": {
    "id": "6LTZuLlDtZ-j"
   },
   "source": [
    "* [M1] DistilRoBERTa (distilberta-base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "12c287b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_M1 = EncoderDecoderTrainer(keras_model=model_M1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "040aaea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_M1 = tokenized_datasets_M1['train'].to_tf_dataset(batch_size=batch_size,\\\n",
    "                                                    collate_fn=data_collator_M1,\\\n",
    "                                                    drop_remainder=True)\n",
    "\n",
    "tf_val_M1 = tokenized_datasets_M1['validation'].to_tf_dataset(batch_size=batch_size,\\\n",
    "                                                    collate_fn=data_collator_M1,\\\n",
    "                                                    drop_remainder=True)\n",
    "\n",
    "tf_test_M1 = tokenized_datasets_M1['test'].to_tf_dataset(batch_size=batch_size,\\\n",
    "                                                    collate_fn=data_collator_M1,\\\n",
    "                                                    drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9158a2b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/53 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_encoder_decoder_model/encoder/roberta/pooler/dense/kernel:0', 'tf_encoder_decoder_model/encoder/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_encoder_decoder_model/encoder/roberta/pooler/dense/kernel:0', 'tf_encoder_decoder_model/encoder/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_encoder_decoder_model/encoder/roberta/pooler/dense/kernel:0', 'tf_encoder_decoder_model/encoder/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_encoder_decoder_model/encoder/roberta/pooler/dense/kernel:0', 'tf_encoder_decoder_model/encoder/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▌                                                                               | 1/53 [01:11<1:01:53, 71.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 8.864155769348145 -- Elapsed Time: 71.33 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▏                                                                               | 2/53 [01:59<49:05, 57.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 7.789313316345215 -- Elapsed Time: 48.17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▋                                                                              | 3/53 [02:51<46:02, 55.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 7.692808628082275 -- Elapsed Time: 52.25 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▎                                                                            | 4/53 [03:52<46:43, 57.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 5.9853386878967285 -- Elapsed Time: 60.22 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████▊                                                                           | 5/53 [04:56<47:43, 59.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 6.584510326385498 -- Elapsed Time: 63.98 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█████████▍                                                                         | 6/53 [05:54<46:17, 59.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 6.3280792236328125 -- Elapsed Time: 57.99 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▉                                                                        | 7/53 [06:57<46:29, 60.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 6.186530590057373 -- Elapsed Time: 63.85 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▌                                                                      | 8/53 [08:08<47:50, 63.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 5.457001209259033 -- Elapsed Time: 70.54 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|██████████████                                                                     | 9/53 [09:13<47:06, 64.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 6.1941304206848145 -- Elapsed Time: 65.22 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▍                                                                  | 10/53 [10:18<46:13, 64.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 6.519091606140137 -- Elapsed Time: 65.09 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|█████████████████                                                                 | 11/53 [11:24<45:24, 64.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 5.995038032531738 -- Elapsed Time: 65.69 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▌                                                               | 12/53 [12:29<44:27, 65.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 6.537737846374512 -- Elapsed Time: 65.46 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████                                                              | 13/53 [13:38<44:09, 66.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 6.2258195877075195 -- Elapsed Time: 68.93 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████▋                                                            | 14/53 [14:44<42:54, 66.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 5.486377239227295 -- Elapsed Time: 65.53 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|███████████████████████▏                                                          | 15/53 [15:50<41:48, 66.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 5.649102210998535 -- Elapsed Time: 66.01 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▊                                                         | 16/53 [16:56<40:42, 66.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 5.436712265014648 -- Elapsed Time: 66.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|██████████████████████████▎                                                       | 17/53 [18:01<39:25, 65.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 4.884352684020996 -- Elapsed Time: 64.97 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▊                                                      | 18/53 [19:05<37:59, 65.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 5.897516250610352 -- Elapsed Time: 63.78 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▍                                                    | 19/53 [20:14<37:33, 66.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 6.346921920776367 -- Elapsed Time: 68.97 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|██████████████████████████████▉                                                   | 20/53 [21:20<36:27, 66.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 5.787376403808594 -- Elapsed Time: 66.33 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▍                                                 | 21/53 [22:24<34:58, 65.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 5.961485862731934 -- Elapsed Time: 63.92 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|██████████████████████████████████                                                | 22/53 [23:28<33:38, 65.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 5.888381004333496 -- Elapsed Time: 64.03 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|███████████████████████████████████▌                                              | 23/53 [24:41<33:43, 67.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 4.77360725402832 -- Elapsed Time: 72.85 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|█████████████████████████████████████▏                                            | 24/53 [25:54<33:25, 69.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 5.445986270904541 -- Elapsed Time: 73.15 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|██████████████████████████████████████▋                                           | 25/53 [27:01<32:02, 68.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 4.999186038970947 -- Elapsed Time: 67.46 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████████████████████████████████████████▏                                         | 26/53 [28:06<30:21, 67.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 5.641362190246582 -- Elapsed Time: 64.71 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████████████████████████████████████████▊                                        | 27/53 [29:11<28:50, 66.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 6.148046970367432 -- Elapsed Time: 64.37 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|███████████████████████████████████████████▎                                      | 28/53 [30:15<27:25, 65.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 5.988811016082764 -- Elapsed Time: 64.11 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|████████████████████████████████████████████▊                                     | 29/53 [31:19<26:06, 65.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 5.748340129852295 -- Elapsed Time: 63.93 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|██████████████████████████████████████████████▍                                   | 30/53 [32:23<24:53, 64.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 5.11627197265625 -- Elapsed Time: 64.25 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|███████████████████████████████████████████████▉                                  | 31/53 [33:27<23:42, 64.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 5.746488571166992 -- Elapsed Time: 63.96 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▌                                | 32/53 [34:31<22:34, 64.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 5.739840984344482 -- Elapsed Time: 64.13 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|███████████████████████████████████████████████████                               | 33/53 [35:35<21:29, 64.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 5.478469371795654 -- Elapsed Time: 64.50 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|████████████████████████████████████████████████████▌                             | 34/53 [36:40<20:23, 64.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 5.540102958679199 -- Elapsed Time: 64.14 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████████████████████████████████████████████████████▏                           | 35/53 [37:44<19:16, 64.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 5.356662750244141 -- Elapsed Time: 63.91 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|███████████████████████████████████████████████████████▋                          | 36/53 [38:47<18:10, 64.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 5.224983215332031 -- Elapsed Time: 63.85 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████████████▏                        | 37/53 [39:51<17:05, 64.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 5.711575031280518 -- Elapsed Time: 64.02 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|██████████████████████████████████████████████████████████▊                       | 38/53 [40:57<16:09, 64.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 4.314576625823975 -- Elapsed Time: 65.93 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|████████████████████████████████████████████████████████████▎                     | 39/53 [42:02<15:03, 64.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 5.217354774475098 -- Elapsed Time: 64.27 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|█████████████████████████████████████████████████████████████▉                    | 40/53 [43:06<13:58, 64.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 4.623166561126709 -- Elapsed Time: 64.42 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████████████████████████████████████████████████████████████▍                  | 41/53 [44:05<12:33, 62.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 4.035751819610596 -- Elapsed Time: 58.84 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|████████████████████████████████████████████████████████████████▉                 | 42/53 [45:01<11:09, 60.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 4.308506011962891 -- Elapsed Time: 56.32 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|██████████████████████████████████████████████████████████████████▌               | 43/53 [45:57<09:53, 59.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 4.1707048416137695 -- Elapsed Time: 55.86 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████████████████████████████████████████████████████████████████              | 44/53 [46:53<08:43, 58.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 2.4980835914611816 -- Elapsed Time: 55.51 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|█████████████████████████████████████████████████████████████████████▌            | 45/53 [47:48<07:39, 57.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 3.151451349258423 -- Elapsed Time: 55.63 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|███████████████████████████████████████████████████████████████████████▏          | 46/53 [48:44<06:38, 56.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 2.9992587566375732 -- Elapsed Time: 55.95 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████████████████████████████████████████████████████████████████████▋         | 47/53 [49:41<05:40, 56.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 2.476213216781616 -- Elapsed Time: 56.35 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|██████████████████████████████████████████████████████████████████████████▎       | 48/53 [50:37<04:42, 56.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 2.3527889251708984 -- Elapsed Time: 56.12 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|███████████████████████████████████████████████████████████████████████████▊      | 49/53 [51:33<03:46, 56.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 1.5260435342788696 -- Elapsed Time: 56.34 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████████████████████████████████████████████████████████████████████████▎    | 50/53 [52:29<02:49, 56.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 1.0197683572769165 -- Elapsed Time: 56.32 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|██████████████████████████████████████████████████████████████████████████████▉   | 51/53 [53:26<01:52, 56.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 0.875504195690155 -- Elapsed Time: 56.33 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|████████████████████████████████████████████████████████████████████████████████▍ | 52/53 [54:22<00:56, 56.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 0.7910298705101013 -- Elapsed Time: 56.34 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [55:18<00:00, 62.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBatch Loss: 0.5292432308197021 -- Elapsed Time: 56.14 seconds\n",
      "Epoch 1/3 -- Average Loss: 5.0047 -- Elapsed Time: 3318.76 seconds\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "WARNING:tensorflow:From C:\\Users\\Antonio\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Antonio\\AppData\\Local\\Temp\\ipykernel_13832\\1059585463.py\", line 43, in evaluate  *\n        generated = self.keras_model.generate(input_ids=batch['input_ids'],\n    File \"C:\\Users\\Antonio\\AppData\\Local\\Temp\\ipykernel_13832\\2328410840.py\", line 28, in generate  *\n        **kwargs)\n    File \"C:\\Users\\Antonio\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\generation_tf_utils.py\", line 590, in generate  *\n        seed=model_kwargs.pop(\"seed\", None),\n    File \"C:\\Users\\Antonio\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\generation_tf_utils.py\", line 1641, in _generate  *\n        input_ids,\n    File \"C:\\Users\\Antonio\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\generation_tf_utils.py\", line 2708, in beam_search_body_fn  *\n        model_inputs = self.prepare_inputs_for_generation(flatten_beam_dim(input_token), **model_kwargs)\n    File \"C:\\Users\\Antonio\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_tf_encoder_decoder.py\", line 684, in prepare_inputs_for_generation  *\n        decoder_inputs = self.decoder.prepare_inputs_for_generation(input_ids, past=past)\n    File \"C:\\Users\\Antonio\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 1163, in prepare_inputs_for_generation  *\n        attention_mask = tf.ones(input_shape)\n\n    ValueError: Cannot convert a partially known TensorShape <unknown> to a Tensor.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13832\\2462304871.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validating...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer_M1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_val_M1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Validation Loss: {val_loss:.4f} -- Metrics: {metrics}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file5hok_ry8.py\u001b[0m in \u001b[0;36mtf__evaluate\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m     40\u001b[0m                 \u001b[0mgenerated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'generated'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'batch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m                 \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'total_loss'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'iterate_names'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'batch'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m                 \u001b[0mavg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompute_squad_metrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file5hok_ry8.py\u001b[0m in \u001b[0;36mloop_body\u001b[1;34m(itr)\u001b[0m\n\u001b[0;32m     28\u001b[0m                     \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                     \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                     \u001b[0mgenerated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input_ids'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_length_answer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepetition_penalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_repeat_ngram_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m                     \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                     \u001b[0mgenerated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer_M1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filehb8iw_0q.py\u001b[0m in \u001b[0;36mtf__generate\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_start_token_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\generation_tf_utils.py\u001b[0m in \u001b[0;36mtf__generate\u001b[1;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, num_return_sequences, attention_mask, decoder_start_token_id, use_cache, output_scores, output_attentions, output_hidden_states, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, **model_kwargs)\u001b[0m\n\u001b[0;32m    436\u001b[0m                 \u001b[0mvocab_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'vocab_size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[0mencoder_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'encoder_kwargs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m                 \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mor_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdo_sample\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_beams\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mif_body_22\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melse_body_22\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_state_22\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_state_22\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'do_return'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model_kwargs['encoder_attentions']\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model_kwargs['encoder_hidden_states']\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model_kwargs['output_attentions']\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model_kwargs['output_hidden_states']\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model_kwargs['output_scores']\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'retval_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'attention_mask'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bad_words_ids'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bos_token_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'decoder_start_token_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'early_stopping'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'encoder_outputs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'eos_token_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'forced_bos_token_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'forced_eos_token_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'input_ids'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'length_penalty'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'max_length'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'min_length'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'no_repeat_ngram_size'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'num_return_sequences'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'output_attentions'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'output_hidden_states'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'output_scores'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pad_token_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'repetition_penalty'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'return_dict_in_generate'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'temperature'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'top_k'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'top_p'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretval_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdo_return\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtf__generate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\generation_tf_utils.py\u001b[0m in \u001b[0;36mif_body_22\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                         \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                         \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdo_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_beams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_p\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepetition_penalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepetition_penalty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbad_words_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbad_words_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbos_token_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbos_token_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad_token_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meos_token_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength_penalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength_penalty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_repeat_ngram_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_repeat_ngram_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_return_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_return_sequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_start_token_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_start_token_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'seed'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_scores\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforced_bos_token_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforced_bos_token_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforced_eos_token_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforced_eos_token_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m                     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                         \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\generation_tf_utils.py\u001b[0m in \u001b[0;36mtf___generate\u001b[1;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, num_return_sequences, attention_mask, decoder_start_token_id, use_cache, seed, output_scores, output_attentions, output_hidden_states, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, **model_kwargs)\u001b[0m\n\u001b[0;32m    288\u001b[0m                     \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_sample_gen_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mif_body_15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melse_body_15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_state_15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_state_15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'do_return'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model_kwargs['attention_mask']\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model_kwargs['encoder_outputs']['last_hidden_state']\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'retval_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'input_ids'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model_kwargs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m                 \u001b[0mlogits_warper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'logits_warper'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m                 \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_greedy_gen_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mif_body_16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melse_body_16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_state_16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_state_16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'do_return'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model_kwargs['attention_mask']\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model_kwargs['encoder_outputs']['last_hidden_state']\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'retval_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'input_ids'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model_kwargs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretval_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdo_return\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtf___generate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\generation_tf_utils.py\u001b[0m in \u001b[0;36melse_body_16\u001b[1;34m()\u001b[0m\n\u001b[0;32m    286\u001b[0m                         \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_beam_gen_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mif_body_14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melse_body_14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_state_14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_state_14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'do_return'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model_kwargs['attention_mask']\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model_kwargs['encoder_outputs']['last_hidden_state']\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'retval_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'input_ids'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m                     \u001b[0mlogits_warper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'logits_warper'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m                     \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_sample_gen_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mif_body_15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melse_body_15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_state_15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_state_15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'do_return'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model_kwargs['attention_mask']\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model_kwargs['encoder_outputs']['last_hidden_state']\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'retval_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'input_ids'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model_kwargs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m                 \u001b[0mlogits_warper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'logits_warper'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_greedy_gen_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mif_body_16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melse_body_16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_state_16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_state_16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'do_return'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model_kwargs['attention_mask']\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model_kwargs['encoder_outputs']['last_hidden_state']\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'retval_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'input_ids'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model_kwargs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\generation_tf_utils.py\u001b[0m in \u001b[0;36melse_body_15\u001b[1;34m()\u001b[0m\n\u001b[0;32m    284\u001b[0m                             \u001b[1;32mnonlocal\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdo_return\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretval_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m                             \u001b[1;32mraise\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNotImplementedError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Beam sampling is currently not implemented.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m                         \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_beam_gen_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mif_body_14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melse_body_14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_state_14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_state_14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'do_return'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model_kwargs['attention_mask']\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model_kwargs['encoder_outputs']['last_hidden_state']\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'retval_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'input_ids'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m                     \u001b[0mlogits_warper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'logits_warper'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                     \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_sample_gen_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mif_body_15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melse_body_15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_state_15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_state_15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'do_return'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model_kwargs['attention_mask']\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model_kwargs['encoder_outputs']['last_hidden_state']\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'retval_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'input_ids'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model_kwargs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\generation_tf_utils.py\u001b[0m in \u001b[0;36mif_body_14\u001b[1;34m()\u001b[0m\n\u001b[0;32m    276\u001b[0m                             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m                                 \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m                                 \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeam_search\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad_token_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meos_token_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meos_token_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength_penalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength_penalty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits_processor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits_processor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_return_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_return_sequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m                             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m                                 \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\generation_tf_utils.py\u001b[0m in \u001b[0;36mtf__beam_search\u001b[1;34m(self, input_ids, max_length, pad_token_id, eos_token_id, length_penalty, early_stopping, logits_processor, num_return_sequences, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, **model_kwargs)\u001b[0m\n\u001b[0;32m    490\u001b[0m                         \u001b[1;32mreturn\u001b[0m \u001b[0mfscope_6\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretval__6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdo_return_6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m                 \u001b[0mbeam_search_body_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeam_search_body_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintermediary_running_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintermediary_running_sequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m                 \u001b[1;33m(\u001b[0m\u001b[0mcur_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_sequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_sent_finished\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeam_search_body_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrunning_sequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrunning_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_sent_finished\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m                 \u001b[1;32mdef\u001b[0m \u001b[0mget_state_21\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\generation_tf_utils.py\u001b[0m in \u001b[0;36mbeam_search_body_fn\u001b[1;34m(cur_len, running_sequences, running_scores, sequences, scores, is_sent_finished, input_ids_length, model_kwargs, intermediary_running_sequences)\u001b[0m\n\u001b[0;32m    288\u001b[0m                         \u001b[0mrunning_sequences_seq_last\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrunning_sequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope_6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope_6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m                         \u001b[0minput_token\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrunning_sequences_seq_last\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_len\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_beams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope_6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m                         \u001b[0mmodel_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflatten_beam_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_token\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope_6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope_6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m                         \u001b[0mmodel_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope_6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m                         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munflatten_beam_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_beams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope_6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_tf_encoder_decoder.py\u001b[0m in \u001b[0;36mtf__prepare_inputs_for_generation\u001b[1;34m(self, input_ids, past, attention_mask, use_cache, encoder_outputs, **kwargs)\u001b[0m\n\u001b[0;32m      8\u001b[0m                 \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                 \u001b[0mdecoder_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpast\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                 \u001b[0mdecoder_attention_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_exp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'attention_mask'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'attention_mask'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"('attention_mask' in decoder_inputs)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0mpast_key_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'past_key_values'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\u001b[0m in \u001b[0;36mtf__prepare_inputs_for_generation\u001b[1;34m(self, input_ids, past, attention_mask, **model_kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m                     \u001b[1;32mnonlocal\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_stmt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mif_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melse_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'attention_mask'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[1;32mdef\u001b[0m \u001b[0mget_state_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\u001b[0m in \u001b[0;36mif_body\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[1;32mdef\u001b[0m \u001b[0mif_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                     \u001b[1;32mnonlocal\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m                     \u001b[0mattention_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[1;32mdef\u001b[0m \u001b[0melse_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Antonio\\AppData\\Local\\Temp\\ipykernel_13832\\1059585463.py\", line 43, in evaluate  *\n        generated = self.keras_model.generate(input_ids=batch['input_ids'],\n    File \"C:\\Users\\Antonio\\AppData\\Local\\Temp\\ipykernel_13832\\2328410840.py\", line 28, in generate  *\n        **kwargs)\n    File \"C:\\Users\\Antonio\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\generation_tf_utils.py\", line 590, in generate  *\n        seed=model_kwargs.pop(\"seed\", None),\n    File \"C:\\Users\\Antonio\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\generation_tf_utils.py\", line 1641, in _generate  *\n        input_ids,\n    File \"C:\\Users\\Antonio\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\generation_tf_utils.py\", line 2708, in beam_search_body_fn  *\n        model_inputs = self.prepare_inputs_for_generation(flatten_beam_dim(input_token), **model_kwargs)\n    File \"C:\\Users\\Antonio\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\models\\encoder_decoder\\modeling_tf_encoder_decoder.py\", line 684, in prepare_inputs_for_generation  *\n        decoder_inputs = self.decoder.prepare_inputs_for_generation(input_ids, past=past)\n    File \"C:\\Users\\Antonio\\anaconda3\\envs\\NLP\\lib\\site-packages\\transformers\\models\\roberta\\modeling_tf_roberta.py\", line 1163, in prepare_inputs_for_generation  *\n        attention_mask = tf.ones(input_shape)\n\n    ValueError: Cannot convert a partially known TensorShape <unknown> to a Tensor.\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "history = []\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    start_time_epoch = time.time()\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch in tqdm(tf_train_M1):\n",
    "        start_time_batch = time.time()\n",
    "        loss = trainer_M1.batch_fit(inputs=batch)\n",
    "        end_time_batch = time.time()\n",
    "\n",
    "        elapsed_time_batch = end_time_batch - start_time_batch\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        print(f'\\tBatch Loss: {loss} -- Elapsed Time: {elapsed_time_batch:.2f} seconds')\n",
    "\n",
    "        total_loss += loss\n",
    "        num_batches += 1\n",
    "        \n",
    "    end_time_epoch = time.time()\n",
    "    elapsed_time_epoch = end_time_epoch - start_time_epoch\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Epoch {epoch+1}/{epochs} -- Average Loss: {avg_loss:.4f} -- Elapsed Time: {elapsed_time_epoch:.2f} seconds\")\n",
    "    \n",
    "    print(\"Validating...\")\n",
    "    val_loss, metrics = trainer_M1.evaluate(tf_val_M1)\n",
    "    print(f\"Validation Loss: {val_loss:.4f} -- Metrics: {metrics}\")\n",
    "    \n",
    "    history.append({'epoch': epoch+1, 'total_loss': total_loss, 'avg_loss': avg_loss,\\\n",
    "                   'elapsed_time': elapsed_time_epoch, 'val_loss': val_loss,\\\n",
    "                   'metrics': metrics})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107bd8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in history:\n",
    "    print(f\"Epoch {e['epoch']}/{epochs} -- Average Loss: {e['avg_loss']:.4f} -- Elapsed Time: {e['elapsed_time']:.2f} seconds\")\n",
    "    print(f\"\\tValidation Loss: {e['val_loss']:.4f} -- Metrics: {e['metrics']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8QD4qg7YtlBV",
   "metadata": {
    "id": "8QD4qg7YtlBV"
   },
   "source": [
    "* [M2] BERTTiny (bert-tiny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79de38a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f168DJs8Bjs1",
   "metadata": {
    "id": "f168DJs8Bjs1"
   },
   "source": [
    "## [Task 6] Train and evaluate $f_\\theta(P, Q)$\n",
    "\n",
    "Write your own script to train and evaluate your $f_\\theta(P, Q)$.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "* Perform multiple train/evaluation seed runs: [42, 2022, 1337].$^1$\n",
    "* Evaluate your models with the following metrics: SQUAD F1-score.$^2$\n",
    "* Fine-tune each transformer-based models for **3 epochs**.\n",
    "* Report evaluation SQUAD F1-score computed on the validation and test sets.\n",
    "\n",
    "$^1$ Remember what we said about code reproducibility in Tutorial 2!\n",
    "\n",
    "$^2$ You can use ```allennlp``` python package for a quick implementation of SQUAD F1-score: ```from allennlp_models.rc.tools import squad```. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9w_PIMcdlrS4",
   "metadata": {
    "id": "9w_PIMcdlrS4"
   },
   "source": [
    "* [M1] DistilRoBERTa (distilberta-base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bcd1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5HEpGp0ZkWJD",
   "metadata": {
    "id": "5HEpGp0ZkWJD"
   },
   "outputs": [],
   "source": [
    "# model_M1.save_model(f'{model_checkpoint_M1}-finetuned-coqa')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QlKMzLOyVs2w",
   "metadata": {
    "id": "QlKMzLOyVs2w"
   },
   "source": [
    "* [M2] BERTTiny (bert-tiny)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c7e98f",
   "metadata": {
    "id": "92c7e98f"
   },
   "source": [
    "## [Task 6] Error Analysis\n",
    "\n",
    "Perform a simple and short error analysis as follows:\n",
    "* Group dialogues by ```source``` and report the worst 5 model errors for each source (w.r.t. SQUAD F1-score).\n",
    "* Inspect observed results and try to provide some comments (e.g., do the models make errors when faced with a particular question type?)$^1$\n",
    "\n",
    "$^1$ Check the [paper](https://arxiv.org/pdf/1808.07042.pdf) for some valuable information about question/answer types (e.g., Table 6, Table 8) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1814004",
   "metadata": {
    "id": "f1814004"
   },
   "source": [
    "# Assignment Evaluation\n",
    "\n",
    "The following assignment points will be awarded for each task as follows:\n",
    "\n",
    "* Task 1, Pre-processing $\\rightarrow$ 0.5 points.\n",
    "* Task 2, Dataset Splitting $\\rightarrow$ 0.5 points.\n",
    "* Task 3 and 4, Models Definition $\\rightarrow$ 1.0 points.\n",
    "* Task 5 and 6, Models Training and Evaluation $\\rightarrow$ 2.0 points.\n",
    "* Task 7, Analysis $\\rightarrow$ 1.0 points.\n",
    "* Report $\\rightarrow$ 1.0 points.\n",
    "\n",
    "**Total** = 6 points <br>\n",
    "\n",
    "We may award an additional 0.5 points for outstanding submissions. \n",
    " \n",
    "**Speed Bonus** = 0.5 extra points <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a1b2b9",
   "metadata": {
    "id": "20a1b2b9"
   },
   "source": [
    "# Report\n",
    "\n",
    "We apply the rules described in Assignment 1 regarding the report.\n",
    "* Write a clear and concise report following the given overleaf template (**max 2 pages**).\n",
    "* Report validation and test results in a table.$^1$\n",
    "* **Avoid reporting** code snippets or copy-paste terminal outputs $\\rightarrow$ **Provide a clean schema** of what you want to show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0967c209",
   "metadata": {
    "id": "0967c209"
   },
   "source": [
    "# Comments and Organization\n",
    "\n",
    "Remember to properly comment your code (it is not necessary to comment each single line) and don't forget to describe your work!\n",
    "\n",
    "Structure your code for readability and maintenance. If you work with Colab, use sections. \n",
    "\n",
    "This allows you to build clean and modular code, as well as easy to read and to debug (notebooks can be quite tricky time to time)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23929660",
   "metadata": {
    "id": "23929660"
   },
   "source": [
    "# FAQ (READ THIS!)\n",
    "\n",
    "---\n",
    "\n",
    "**Question**: Does Task 3 also include data tokenization and conversion step?\n",
    "\n",
    "**Answer:** Yes! These steps are usually straightforward since ```transformers``` also offers a specific tokenizer for each model.\n",
    "\n",
    "**Example**: \n",
    "\n",
    "```\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "encoded_text = tokenizer(text)\n",
    "%% Alternatively\n",
    "inputs = tokenizer.tokenize(text, add_special_tokens=True, max_length=min(max_length, 512))\n",
    "input_ids, attention_mask = inputs['input_ids'], inputs['attention_mask']\n",
    "```\n",
    "\n",
    "**Suggestion**: Hugginface's documentation is full of tutorials and user-friendly APIs.\n",
    "\n",
    "---\n",
    "---\n",
    "\n",
    "**Question**: I'm hitting **out of memory error** when training my models, do you have any suggestions?\n",
    "\n",
    "**Answer**: Here are some common workarounds:\n",
    "\n",
    "1. Try decreasing the mini-batch size\n",
    "2. Try applying a different padding strategy (if you are applying padding): e.g. use quantiles instead of maximum sequence length\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c56a612",
   "metadata": {
    "id": "9c56a612"
   },
   "source": [
    "# Contact\n",
    "\n",
    "For any doubt, question, issue or help, you can always contact us at the following email addresses:\n",
    "\n",
    "Teaching Assistants:\n",
    "\n",
    "* Andrea Galassi -> a.galassi@unibo.it\n",
    "* Federico Ruggeri -> federico.ruggeri6@unibo.it\n",
    "\n",
    "Professor:\n",
    "\n",
    "* Paolo Torroni -> p.torroni@unibo.it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bac4b9",
   "metadata": {
    "id": "54bac4b9"
   },
   "source": [
    "# The End!\n",
    "\n",
    "Questions?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05ebe53d65e0473a88570457b6ee4b81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96fcb084772143adbeff35540b22e1a2",
      "placeholder": "​",
      "style": "IPY_MODEL_8b6a209020194a6ea95fc8cad4b689c9",
      "value": "100%"
     }
    },
    "09d74d2251354991abe603f4298953c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec30998fa9a14cb5a1fe30e7cd9b2b09",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1a1d5e04d2a44b9087e2ac1716791a5e",
      "value": 10
     }
    },
    "0a8e5a09437f4df48daa923c2741ed80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0bb93f887cc64eaaa1d72efe2abbd0b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0ff6fea3fcd841ef87298ad119554adc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "173f79a9dd2a4a6babd1e5eda4b1b707": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6841ed77a57845e5963188c332c77df8",
       "IPY_MODEL_6a268946eaa74e90acb04e00b816307e",
       "IPY_MODEL_eaf314ad07264f8882deb91fe7ced104"
      ],
      "layout": "IPY_MODEL_bcb531b22c8d47d1a14d9a391a57fc4b"
     }
    },
    "180c1b2f44d147f2823ff5cb0a2063f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4665614a763f4be7ac55e447a14c8eb3",
      "placeholder": "​",
      "style": "IPY_MODEL_7c0b26fad32a4bae9418b06ba2ae4521",
      "value": "100%"
     }
    },
    "1a1d5e04d2a44b9087e2ac1716791a5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1a3d26f4c50b43dab11a1ae0d8fbac7f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b844edd880646afa3f99d6cb630c2af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23a2fa0acd434738acdb3294da04cd58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25ae1eb92a874541b488061ed68cbc69",
      "placeholder": "​",
      "style": "IPY_MODEL_586f5a4ddb5d4a218844356273973463",
      "value": " 10/10 [00:00&lt;00:00, 14.44ba/s]"
     }
    },
    "24d073d354e44c7c913117fe01d13fe3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_74ef12751bf04755bcb9111958e96c6c",
      "max": 27,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4ea0a052acc14c8b98dc105de2987919",
      "value": 27
     }
    },
    "25ae1eb92a874541b488061ed68cbc69": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2961db3a8c4749e08a52f396b18769b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a38d08ad41c4407ab61e33f3c936bfe0",
       "IPY_MODEL_7a2f8ff4946f49b1951eb45d5c5cba75",
       "IPY_MODEL_9db949cbc82645c0a9c1b1cc5548eb22"
      ],
      "layout": "IPY_MODEL_0ff6fea3fcd841ef87298ad119554adc"
     }
    },
    "341ea36a069e45158f4d07b4757d28e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38fdabfdf00c444bbfba880f12f7d1ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d42b37411a643c5978a56ed809087ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_05ebe53d65e0473a88570457b6ee4b81",
       "IPY_MODEL_d5109582ad184548a9d509ee75bdb16d",
       "IPY_MODEL_b5da7e076ccd49f3a5a134bdea518ed7"
      ],
      "layout": "IPY_MODEL_5c5994b564a54557934ece1042abbfbc"
     }
    },
    "3fbc9f4f55134457872f2501d4a293b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9aee3df433a049fba93a52e8b42b2a66",
      "placeholder": "​",
      "style": "IPY_MODEL_9527116a654e4c0f9fa137f1e264a837",
      "value": " 27/27 [00:01&lt;00:00, 26.07ba/s]"
     }
    },
    "435f0b3e62024f63a4022f3be2d0432c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4665614a763f4be7ac55e447a14c8eb3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4977a3309b6a4d0bac11e75fa6f5421c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4ea0a052acc14c8b98dc105de2987919": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "55cb8a577bf14b7ea9d4beedf275d925": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "586f5a4ddb5d4a218844356273973463": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5c5994b564a54557934ece1042abbfbc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6841ed77a57845e5963188c332c77df8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a3d26f4c50b43dab11a1ae0d8fbac7f",
      "placeholder": "​",
      "style": "IPY_MODEL_efe5eddae1f648d288a9460f5e693584",
      "value": "100%"
     }
    },
    "69aabc48a6904694b44d43ca03db9424": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a268946eaa74e90acb04e00b816307e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b844edd880646afa3f99d6cb630c2af",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a01e71cf41a6443eb770b8d16b64935f",
      "value": 10
     }
    },
    "6efa30ef9f944229bafa23299e6d1712": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7043cdadfe724d27a2d8b1a20645a77e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9a781e2bf2c405fb5aa10cb6f38e98d",
      "placeholder": "​",
      "style": "IPY_MODEL_fae5f893c79d49a0acd588d7dd3ac6c8",
      "value": " 27/27 [00:01&lt;00:00, 13.55ba/s]"
     }
    },
    "74ef12751bf04755bcb9111958e96c6c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a2f8ff4946f49b1951eb45d5c5cba75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55cb8a577bf14b7ea9d4beedf275d925",
      "max": 108,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6efa30ef9f944229bafa23299e6d1712",
      "value": 108
     }
    },
    "7c0b26fad32a4bae9418b06ba2ae4521": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7e81423f9ce34d69b016df9db8194b30": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7f5a16ff31f44194a598596742bd08fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fb7618f6fb254802b770f331dff3ae0e",
       "IPY_MODEL_09d74d2251354991abe603f4298953c7",
       "IPY_MODEL_23a2fa0acd434738acdb3294da04cd58"
      ],
      "layout": "IPY_MODEL_435f0b3e62024f63a4022f3be2d0432c"
     }
    },
    "8b6a209020194a6ea95fc8cad4b689c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8bc830bdf51b4d9da2faac3b815cc124": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9527116a654e4c0f9fa137f1e264a837": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "96fcb084772143adbeff35540b22e1a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9aee3df433a049fba93a52e8b42b2a66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9db949cbc82645c0a9c1b1cc5548eb22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69aabc48a6904694b44d43ca03db9424",
      "placeholder": "​",
      "style": "IPY_MODEL_38fdabfdf00c444bbfba880f12f7d1ff",
      "value": " 108/108 [00:06&lt;00:00, 17.32ba/s]"
     }
    },
    "9ef014201edf4be291626bc466479e47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a89ffc89651e4308aee50d460cbc68b4",
      "placeholder": "​",
      "style": "IPY_MODEL_0bb93f887cc64eaaa1d72efe2abbd0b8",
      "value": "100%"
     }
    },
    "a01e71cf41a6443eb770b8d16b64935f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a1ce12e1914641eba7cba1b2b734a20a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d4a4c8c3060f4965940435bd6aba9cef",
      "max": 27,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0a8e5a09437f4df48daa923c2741ed80",
      "value": 27
     }
    },
    "a23058becfb54f0eb7d8894260d66027": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a38d08ad41c4407ab61e33f3c936bfe0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8bc830bdf51b4d9da2faac3b815cc124",
      "placeholder": "​",
      "style": "IPY_MODEL_a98c60db672743efa060077a5ec09e52",
      "value": "100%"
     }
    },
    "a89ffc89651e4308aee50d460cbc68b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a98c60db672743efa060077a5ec09e52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "acf538aa401b4c588c306b8bc6548531": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b26fbfb8db23473d8f3f3ab0cfec53e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5da7e076ccd49f3a5a134bdea518ed7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_acf538aa401b4c588c306b8bc6548531",
      "placeholder": "​",
      "style": "IPY_MODEL_e0b98fc9970e41658c7c0f4ae7ee0fd9",
      "value": " 108/108 [00:03&lt;00:00, 26.74ba/s]"
     }
    },
    "bcb531b22c8d47d1a14d9a391a57fc4b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c51fd4ee4f9147d987ff83e441e4143b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9ef014201edf4be291626bc466479e47",
       "IPY_MODEL_24d073d354e44c7c913117fe01d13fe3",
       "IPY_MODEL_7043cdadfe724d27a2d8b1a20645a77e"
      ],
      "layout": "IPY_MODEL_db4d4e59b43b4bd8914310b17888c023"
     }
    },
    "c9a781e2bf2c405fb5aa10cb6f38e98d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cba33f69af3346d09f8743d1c8e46dc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d4a4c8c3060f4965940435bd6aba9cef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d5109582ad184548a9d509ee75bdb16d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_341ea36a069e45158f4d07b4757d28e4",
      "max": 108,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4977a3309b6a4d0bac11e75fa6f5421c",
      "value": 108
     }
    },
    "db4d4e59b43b4bd8914310b17888c023": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc714e341183474fb0c19cb22e9de938": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_180c1b2f44d147f2823ff5cb0a2063f2",
       "IPY_MODEL_a1ce12e1914641eba7cba1b2b734a20a",
       "IPY_MODEL_3fbc9f4f55134457872f2501d4a293b3"
      ],
      "layout": "IPY_MODEL_ef3b805f3f824311a5cc314422d8346a"
     }
    },
    "e0b98fc9970e41658c7c0f4ae7ee0fd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eaf314ad07264f8882deb91fe7ced104": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b26fbfb8db23473d8f3f3ab0cfec53e4",
      "placeholder": "​",
      "style": "IPY_MODEL_a23058becfb54f0eb7d8894260d66027",
      "value": " 10/10 [00:00&lt;00:00, 24.65ba/s]"
     }
    },
    "ec30998fa9a14cb5a1fe30e7cd9b2b09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef3b805f3f824311a5cc314422d8346a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efe5eddae1f648d288a9460f5e693584": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fae5f893c79d49a0acd588d7dd3ac6c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb7618f6fb254802b770f331dff3ae0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e81423f9ce34d69b016df9db8194b30",
      "placeholder": "​",
      "style": "IPY_MODEL_cba33f69af3346d09f8743d1c8e46dc4",
      "value": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
