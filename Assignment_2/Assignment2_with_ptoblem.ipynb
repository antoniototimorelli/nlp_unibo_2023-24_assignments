{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WeCeITXoxLf"
      },
      "source": [
        "# Assignment 2\n",
        "\n",
        "**Credits**: Federico Ruggeri, Eleonora Mancini, Paolo Torroni\n",
        "\n",
        "**Keywords**: Human Value Detection, Multi-label classification, Transformers, BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ogkq8k2d2ajI"
      },
      "source": [
        "\n",
        "# Contact\n",
        "\n",
        "For any doubt, question, issue or help, you can always contact us at the following email addresses:\n",
        "\n",
        "Teaching Assistants:\n",
        "\n",
        "* Federico Ruggeri -> federico.ruggeri6@unibo.it\n",
        "* Eleonora Mancini -> e.mancini@unibo.it\n",
        "\n",
        "Professor:\n",
        "\n",
        "* Paolo Torroni -> p.torroni@unibo.it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr-Z4UB42ajI"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "You are tasked to address the [Human Value Detection challenge](https://aclanthology.org/2022.acl-long.306/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzFRoMqn2ajI"
      },
      "source": [
        "## Problem definition\n",
        "\n",
        "Arguments are paired with their conveyed human values.\n",
        "\n",
        "Arguments are in the form of **premise** $\\rightarrow$ **conclusion**.\n",
        "\n",
        "### Example:\n",
        "\n",
        "**Premise**: *``fast food should be banned because it is really bad for your health and is costly''*\n",
        "\n",
        "**Conclusion**: *``We should ban fast food''*\n",
        "\n",
        "**Stance**: *in favour of*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOSaByQ_2ajJ"
      },
      "source": [
        "<center>\n",
        "    <img src=\"images/human_values.png\" alt=\"human values\" />\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzkcfF1f2ajJ"
      },
      "source": [
        "# [Task 1 - 0.5 points] Corpus\n",
        "\n",
        "Check the official page of the challenge [here](https://touche.webis.de/semeval23/touche23-web/).\n",
        "\n",
        "The challenge offers several corpora for evaluation and testing.\n",
        "\n",
        "You are going to work with the standard training, validation, and test splits.\n",
        "\n",
        "#### Arguments\n",
        "* arguments-training.tsv\n",
        "* arguments-validation.tsv\n",
        "* arguments-test.tsv\n",
        "\n",
        "#### Human values\n",
        "* labels-training.tsv\n",
        "* labels-validation.tsv\n",
        "* labels-test.tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31YER8cb2ajJ"
      },
      "source": [
        "### Example\n",
        "\n",
        "#### arguments-*.tsv\n",
        "```\n",
        "\n",
        "Argument ID    A01005\n",
        "\n",
        "Conclusion     We should ban fast food\n",
        "\n",
        "Stance         in favor of\n",
        "\n",
        "Premise        fast food should be banned because it is really bad for your health and is costly.\n",
        "```\n",
        "\n",
        "#### labels-*.tsv\n",
        "\n",
        "```\n",
        "Argument ID                A01005\n",
        "\n",
        "Self-direction: thought    0\n",
        "Self-direction: action     0\n",
        "...\n",
        "Universalism: objectivity: 0\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s9Bic-M2ajJ"
      },
      "source": [
        "### Splits\n",
        "\n",
        "The standard splits contain\n",
        "\n",
        "   * **Train**: 5393 arguments\n",
        "   * **Validation**: 1896 arguments\n",
        "   * **Test**: 1576 arguments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWLareV72ajK"
      },
      "source": [
        "### Annotations\n",
        "\n",
        "In this assignment, you are tasked to address a multi-label classification problem.\n",
        "\n",
        "You are going to consider **level 3** categories:\n",
        "\n",
        "* Openness to change\n",
        "* Self-enhancement\n",
        "* Conversation\n",
        "* Self-transcendence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nJykuNU2ajK"
      },
      "source": [
        "**How to do that?**\n",
        "\n",
        "You have to merge (**logical OR**) annotations of level 2 categories belonging to the same level 3 category.\n",
        "\n",
        "**Pay attention to shared level 2 categories** (e.g., Hedonism). $\\rightarrow$ [see Table 1 in the original paper.](https://aclanthology.org/2022.acl-long.306/)\n",
        "\n",
        "#### Example\n",
        "\n",
        "```\n",
        "Self-direction: thought:    0\n",
        "Self-direction: action:     1\n",
        "Stimulation:                0\n",
        "Hedonism:                   1\n",
        "\n",
        "Openess to change           1\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vJczhTt2ajK"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* **Download** the specificed training, validation, and test files.\n",
        "* **Encode** split files into a pandas.DataFrame object.\n",
        "* For each split, **merge** the arguments and labels dataframes into a single dataframe.\n",
        "* **Merge** level 2 annotations to level 3 categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvAzfUy62ajK"
      },
      "source": [
        "# [Task 2 - 2.0 points] Model definition\n",
        "\n",
        "You are tasked to define several neural models for multi-label classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEBPbxLa2ajK"
      },
      "source": [
        "<center>\n",
        "    <img src=\"images/model_schema.png\" alt=\"model_schema\" />\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S5dq2Z32ajL"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* **Baseline**: implement a random uniform classifier (an individual classifier per category).\n",
        "* **Baseline**: implement a majority classifier (an individual classifier per category).\n",
        "\n",
        "<br/>\n",
        "\n",
        "* **BERT w/ C**: define a BERT-based classifier that receives an argument **conclusion** as input.\n",
        "* **BERT w/ CP**: add argument **premise** as an additional input.\n",
        "* **BERT w/ CPS**: add argument premise-to-conclusion **stance** as an additional input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBuvDDjp8p_a",
        "outputId": "25ba7f72-6f72-4ae7-ffc0-f82b84b5bc00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-24.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Qfb4NpU3wLL",
        "outputId": "68e4a46d-0a15-4935-d5b6-75ad545555a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.18.0 dill-0.3.8 multiprocess-0.70.16 xxhash-3.4.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d4jIWLS3zyy",
        "outputId": "26f34427-59a7-4d86-a476-cf967d3dc448"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.28.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHJU0guw8V6a",
        "outputId": "5b6b331b-c354-4e6a-ef06-247b5ef04615"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.28.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.99)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "U5j7JUCb2b65"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import transformers\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import accelerate\n",
        "from datasets import *\n",
        "from transformers import AutoTokenizer, BertForSequenceClassification, PreTrainedTokenizerFast, DefaultDataCollator, Trainer, TrainingArguments\n",
        "from transformers.optimization import AdamW\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers.optimization import get_scheduler\n",
        "import matplotlib.colors as mcolors\n",
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score,  precision_recall_fscore_support\n",
        "from sklearn.utils import class_weight\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import tqdm.notebook as tq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7KR608_2e7X",
        "outputId": "45edd171-f39f-41c6-f72b-5cd65eb3a25a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')\n",
        "\n",
        "#HYPERPARAMETERS\n",
        "model_checkpoint = 'prajjwal1/bert-tiny'\n",
        "#MAX_LEN = 200\n",
        "NUM_LABELS = 4\n",
        "TRAIN_BATCH_SIZE = 64\n",
        "VALID_BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 1e-05\n",
        "DROPOUT = 0.2\n",
        "WEIGHT_DECAY = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "86Rb-ITS2e97"
      },
      "outputs": [],
      "source": [
        "def set_reproducibility(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    transformers.set_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "90a93e1ee71043da80ea4760de8aa151",
            "ba1a2521b32e410997317127ddb86381",
            "28078ca9170d4a8f89168bba57152c22",
            "b6ca127845d94aa5bd734b78b1d7ee01",
            "a34f9f0760934f4b86ed6abc14a1441a",
            "5c77a031d104480199aa0f2a3956961f",
            "4e3ad51603a14f9eb632cc54825814a9",
            "fea43eb46acb488b836a633877a6f4e3",
            "caa81c5b500b4ef9a0c23440691c7275",
            "2d4eb796eeab472a96e53fd506e49958",
            "4f016a5c6e184992a3365504d25cd2a3",
            "1e5852b3fda047269222f5666b6b561c",
            "a009f2b4f5d74939a349c128d136379f",
            "7cda398281ca49a6a1bd67b3ee00d189",
            "472373acfe0440e3ad05b776b5da07ca",
            "ce78af612ab340a6ac46659eecb8778e",
            "266de6bf73aa4a958c73aaf96419d3c7",
            "9d72cb78c1c14dab9847dffde5a517c1",
            "43747684e6414f6abfe265a9a9fc0264",
            "c4be755fe13c4afb85afd78950752c48",
            "f23ebb9cce3d45a4acf2d3d808690011",
            "b9e83467550f46bdbd963f18593e94e5"
          ]
        },
        "id": "y1jhsy_O2fAo",
        "outputId": "156cb772-f8b8-4c4a-c249-55cc6ffdb1f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading tokenizer ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/285 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90a93e1ee71043da80ea4760de8aa151"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e5852b3fda047269222f5666b6b561c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer loaded.\n"
          ]
        }
      ],
      "source": [
        "# Load the tokenizer\n",
        "print(f'Loading tokenizer ...')\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "assert isinstance(tokenizer, PreTrainedTokenizerFast)\n",
        "print('Tokenizer loaded.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "oy6EdFEw2fC4",
        "outputId": "94802d9b-aefd-464f-e539-b19d2ee84248"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9d5100c3-3fe5-485e-80c7-7f7b79b100c4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9d5100c3-3fe5-485e-80c7-7f7b79b100c4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving files_ass2.zip to files_ass2.zip\n"
          ]
        }
      ],
      "source": [
        "#for colab\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "\n",
        "zip_filename = next(iter(uploaded))\n",
        "\n",
        "\n",
        "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pbjjw-qX2fFG",
        "outputId": "bdaecc6c-802c-4d19-c0e8-600cdceb41ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Data loaded.\n"
          ]
        }
      ],
      "source": [
        "#for colab\n",
        "print(f\"Loading data...\")\n",
        "path_labels_data = \"./labels_data\"\n",
        "path_arguments_data = \"./arguments_data\"\n",
        "\n",
        "\n",
        "def load_file():\n",
        "    '''Load the file and return the data and labels for training, testing and validation'''\n",
        "\n",
        "    train_data = pd.read_csv(os.path.join(path_arguments_data, 'arguments-training.tsv'), sep='\\t')\n",
        "    test_data = pd.read_csv(os.path.join(path_arguments_data, 'arguments-test.tsv'), sep='\\t')\n",
        "    valid_data = pd.read_csv(os.path.join(path_arguments_data, 'arguments-validation.tsv'), sep='\\t')\n",
        "    train_labels = pd.read_csv(os.path.join(path_labels_data, 'labels-training.tsv'),sep='\\t')\n",
        "    test_labels = pd.read_csv(os.path.join(path_labels_data, 'labels-test.tsv'),sep='\\t')\n",
        "    valid_labels = pd.read_csv(os.path.join(path_labels_data, 'labels-validation.tsv'),sep='\\t')\n",
        "\n",
        "    return (train_data,train_labels), (test_data,test_labels), (valid_data,valid_labels)\n",
        "\n",
        "\n",
        "\n",
        "(train_data,train_labels), (test_data,test_labels), (valid_data,valid_labels) = load_file()\n",
        "print(\"Data loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVTxVU1vv5nn",
        "outputId": "c428b8aa-ccd1-4c44-c7ad-6907a3cad48d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Data loaded.\n"
          ]
        }
      ],
      "source": [
        "print(f\"Loading data...\")\n",
        "def load_file():\n",
        "    '''Load the file and return the data and labels for training, testing and validation'''\n",
        "    train_data = pd.read_csv('arguments-training.tsv', sep='\\t')\n",
        "    test_data = pd.read_csv('arguments-test.tsv', sep='\\t')\n",
        "    valid_data = pd.read_csv('arguments-validation.tsv', sep='\\t')\n",
        "    train_labels = pd.read_csv('labels-training.tsv',sep='\\t')\n",
        "    test_labels = pd.read_csv('labels-test.tsv',sep='\\t')\n",
        "    valid_labels = pd.read_csv('labels-validation.tsv',sep='\\t')\n",
        "    return (train_data,train_labels), (test_data,test_labels), (valid_data,valid_labels)\n",
        "(train_data,train_labels), (test_data,test_labels), (valid_data,valid_labels) = load_file()\n",
        "print(\"Data loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ipe8-iPa2fH8"
      },
      "outputs": [],
      "source": [
        "# Merge the data and labels\n",
        "def merge_df(data, labels):\n",
        "    return pd.merge(data, labels, on='Argument ID')\n",
        "\n",
        "train_df_merged = merge_df(train_data, train_labels)\n",
        "val_df_merged = merge_df(valid_data, valid_labels)\n",
        "test_df_merged = merge_df(test_data, test_labels)\n",
        "\n",
        "level2_to_level3 = {\n",
        "    'openness_to_change':[\"Self-direction: thought\", \"Self-direction: action\",\"Stimulation\", \"Hedonism\"],\n",
        "    'self_enhancement':['Hedonism','Achievement', 'Power: dominance', 'Power: resources','Face'],\n",
        "    'conservation': ['Face', 'Security: personal', 'Security: societal', 'Tradition', 'Conformity: rules', 'Conformity: interpersonal','Humility'],\n",
        "    'self_transcendence':['Humility', 'Benevolence: caring', 'Benevolence: dependability','Universalism: concern', 'Universalism: nature','Universalism: tolerance', 'Universalism: objectivity']\n",
        "}\n",
        "\n",
        "def lv3_labels(df):\n",
        "    \"\"\"\n",
        "    Function to aggregate specified columns by taking the logical OR between their values.\n",
        "\n",
        "    Parameters:\n",
        "        df (pandas.DataFrame): The input DataFrame.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: A new DataFrame with aggregated values.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a new DataFrame to store aggregated values\n",
        "    new_df = pd.DataFrame()\n",
        "\n",
        "    # Iterate over the mapping and compute logical OR for each set of columns\n",
        "    for new_column, columns_to_aggregate in level2_to_level3.items():\n",
        "        new_df[new_column] = df[columns_to_aggregate].apply(lambda row: any(row), axis=1).astype(int)  # Convert boolean to int\n",
        "\n",
        "    # Drop the original columns used for aggregation\n",
        "    df.drop(columns=[col for cols in level2_to_level3.values() for col in cols], inplace=True)\n",
        "\n",
        "    # Concatenate new DataFrame with the remaining columns of the original DataFrame\n",
        "    new_df = pd.concat([df, new_df], axis=1)\n",
        "\n",
        "    return new_df\n",
        "\n",
        "df_train = lv3_labels(train_df_merged)\n",
        "df_val = lv3_labels(val_df_merged)\n",
        "df_test = lv3_labels(test_df_merged)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nqrP4YRJ2fJz"
      },
      "outputs": [],
      "source": [
        "def refine_df(df):\n",
        "    new_df = df.copy()\n",
        "    new_df[\"Stance\"] = df['Stance'].replace({'in favor of': 1, 'against': 0})\n",
        "    new_df.drop(df.columns[4:], axis=1, inplace=True)\n",
        "    new_df['labels'] = df.iloc[:, 4:].apply(lambda x: np.array(list(x)), axis=1)\n",
        "    return new_df\n",
        "\n",
        "df_train = refine_df(df_train)\n",
        "df_test = refine_df(df_test)\n",
        "df_val = refine_df(df_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "03BfAH2B2fNe"
      },
      "outputs": [],
      "source": [
        "featurez = ['Conclusion', 'Premise', 'Stance', 'labels']\n",
        "\n",
        "# Dataframes to Datasets\n",
        "train_df_to_ds = df_train[featurez]\n",
        "val_df_to_ds = df_val[featurez]\n",
        "test_df_to_ds = df_test[featurez]\n",
        "\n",
        "train_df_to_ds = train_df_to_ds.rename(columns={'Conclusion': 'conclusion', 'Premise': 'premise', 'Stance': 'stance'})\n",
        "val_df_to_ds = val_df_to_ds.rename(columns={'Conclusion': 'conclusion', 'Premise': 'premise', 'Stance': 'stance'})\n",
        "test_df_to_ds = test_df_to_ds.rename(columns={'Conclusion': 'conclusion', 'Premise': 'premise', 'Stance': 'stance'})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7AsLzRrj3BNX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbd41e7f-512f-46b4-d964-43a7a0a86e74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38\n",
            "198\n",
            "200\n"
          ]
        }
      ],
      "source": [
        "tclengths = [len(tokenizer(x)[\"input_ids\"]) for x in train_df_to_ds['conclusion']]\n",
        "tplengths = [len(tokenizer(x)[\"input_ids\"]) for x in train_df_to_ds['premise']]\n",
        "\n",
        "vclengths = [len(tokenizer(x)[\"input_ids\"]) for x in val_df_to_ds['conclusion']]\n",
        "vplengths = [len(tokenizer(x)[\"input_ids\"]) for x in val_df_to_ds['premise']]\n",
        "\n",
        "WC_MAX_LEN = max(tclengths+vclengths)\n",
        "WCP_MAX_LEN = WC_MAX_LEN + max(tplengths+tplengths) + 1\n",
        "WCPS_MAX_LEN = WCP_MAX_LEN + 2\n",
        "\n",
        "print(WC_MAX_LEN)\n",
        "print(WCP_MAX_LEN)\n",
        "print(WCPS_MAX_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "5CsqdNuT3BRH"
      },
      "outputs": [],
      "source": [
        "#define BertDataset:\n",
        "\n",
        "class MultilabelDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,df:pd.DataFrame, tokenizer:AutoTokenizer, max_len:int):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.df = df\n",
        "        self.conclusion = df.conclusion\n",
        "        self.premise = df.premise\n",
        "        self.stance = torch.tensor(df['stance'].values.astype(float), dtype=torch.float)\n",
        "        self.max_len = max_len\n",
        "        self.labels = torch.tensor(np.stack(df['labels'].tolist()), dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        conclusion = self.conclusion[index]\n",
        "        premise = self.premise[index]\n",
        "\n",
        "        inputs_c = self.tokenizer.encode_plus(\n",
        "            conclusion,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        inputs_p = self.tokenizer.encode_plus(\n",
        "            premise,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        ids_c = inputs_c['input_ids'].flatten()\n",
        "        mask_c = inputs_c['attention_mask'].flatten()\n",
        "        token_type_ids_c = inputs_c['token_type_ids'].flatten()\n",
        "\n",
        "        ids_p = inputs_p['input_ids'].flatten()\n",
        "        mask_p = inputs_p['attention_mask'].flatten()\n",
        "        token_type_ids_p = inputs_p['token_type_ids'].flatten()\n",
        "\n",
        "        '''\n",
        "        return {'ids_c' : torch.tensor(ids_c, dtype=torch.long),\n",
        "                'mask_c' : torch.tensor(mask_c, dtype=torch.long),\n",
        "                'token_type_ids_c' : torch.tensor(token_type_ids_c, dtype=torch.long),\n",
        "                'ids_p':torch.tensor(ids_p, dtype=torch.long),\n",
        "                'mask_p':torch.tensor(mask_p, dtype=torch.long),\n",
        "                'token_type_ids_p': torch.tensor(token_type_ids_p, dtype=torch.long),\n",
        "                'stance' : self.stance[index],\n",
        "                'labels' : self.labels[index]}\n",
        "        '''\n",
        "        return {'ids_c' : ids_c,\n",
        "                'mask_c' : mask_c,\n",
        "                'token_type_ids_c' : token_type_ids_c,\n",
        "                'ids_p':ids_p,\n",
        "                'mask_p':mask_p,\n",
        "                'token_type_ids_p': token_type_ids_p,\n",
        "                'stance' : self.stance[index],\n",
        "                'labels' : self.labels[index]}\n",
        "\n",
        "wc_datasets = DatasetDict()\n",
        "wc_datasets['train'] = MultilabelDataset(train_df_to_ds, tokenizer, WC_MAX_LEN)\n",
        "wc_datasets['validation'] = MultilabelDataset(val_df_to_ds, tokenizer, WC_MAX_LEN)\n",
        "wc_datasets['test'] = MultilabelDataset(test_df_to_ds, tokenizer, WC_MAX_LEN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "I9Bm43qlZiYe"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(wc_datasets['train'], batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(wc_datasets['validation'], batch_size=VALID_BATCH_SIZE, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_loader))\n",
        "print(batch.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McHylqXhBKui",
        "outputId": "82b91da5-eadd-43b5-a4ae-e229956d38b8"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['ids_c', 'mask_c', 'token_type_ids_c', 'ids_p', 'mask_p', 'token_type_ids_p', 'stance', 'labels'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "wVmiFA-C3Smu"
      },
      "outputs": [],
      "source": [
        "# define f1-score metric\n",
        "def compute_metrics(eval_predictions):\n",
        "    predictions, labels = eval_predictions.predictions, eval_predictions.label_ids\n",
        "    macro_f1_score = compute_f1_macro(labels, predictions)\n",
        "    return {\"macro_f1\": macro_f1_score}\n",
        "\n",
        "def compute_f1_macro(labels, predictions, threshold=0.5, print_per_category=False):\n",
        "    binary_predictions = (predictions > threshold).astype(int)\n",
        "    f1_macro = f1_score(y_true=labels, y_pred=binary_predictions, average='macro')\n",
        "    if print_per_category:\n",
        "        per_category_scores = precision_recall_fscore_support(labels, binary_predictions, average=None)\n",
        "        print(\"Per-category F1 scores:\")\n",
        "        for i, score in enumerate(per_category_scores[2]):\n",
        "            print(f\"Category {i+1}: {score}\")\n",
        "    return f1_macro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TPHm-HI83XGS"
      },
      "outputs": [],
      "source": [
        "# Class Weights\n",
        "def compute_class_weights_from_df(df):\n",
        "    # Extracting labels\n",
        "    labels = df['labels'].tolist()\n",
        "\n",
        "    # Convert labels to 2D array\n",
        "    labels_array = np.array([np.array(label) for label in labels])\n",
        "\n",
        "    # Compute class frequencies\n",
        "    class_frequencies = np.sum(labels_array, axis=0) / len(labels_array)\n",
        "\n",
        "    # Compute inverse class frequencies\n",
        "    inverse_class_frequencies = 1 / class_frequencies\n",
        "\n",
        "    print(\"Inverse Class Frequencies:\", inverse_class_frequencies)\n",
        "\n",
        "    return inverse_class_frequencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "npGYkZE3v5np"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertForSequenceClassification,BertModel\n",
        "\n",
        "class MultilabelClassifier(nn.Module):\n",
        "    def __init__(self, num_labels, drop_out=0.1, model_type=\"base\"):\n",
        "        super(MultilabelClassifier, self).__init__()\n",
        "        self.num_labels = num_labels\n",
        "        self.model_type = model_type\n",
        "\n",
        "        self.bert_conclusion = BertForSequenceClassification.from_pretrained(model_checkpoint, num_labels=self.num_labels,output_hidden_states=True)\n",
        "\n",
        "        if model_type != \"base\":\n",
        "            self.bert_premise = BertForSequenceClassification.from_pretrained(model_checkpoint, num_labels=self.num_labels,output_hidden_states=True)\n",
        "\n",
        "        if model_type == \"bert_w_cp\":\n",
        "            self.hidden_dim = self.bert_conclusion.config.hidden_size * 2\n",
        "\n",
        "        elif model_type == \"bert_w_cps\":\n",
        "            self.hidden_dim = (self.bert_conclusion.config.hidden_size * 2) + 1\n",
        "\n",
        "        else:\n",
        "            self.hidden_dim = self.bert_conclusion.config.hidden_size\n",
        "\n",
        "\n",
        "        self.dropout = nn.Dropout(drop_out)\n",
        "        self.dense = nn.Linear(self.hidden_dim, num_labels)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # Extracting data for conclusion\n",
        "        ids_c = inputs['ids_c'].to(device)\n",
        "        mask_c = inputs['mask_c'].to(device)\n",
        "        token_type_ids_c = inputs['token_type_ids_c'].to(device)\n",
        "\n",
        "        # Extracting data for premise\n",
        "        ids_p = inputs['ids_p'].to(device)\n",
        "        mask_p = inputs['mask_p'].to(device)\n",
        "        token_type_ids_p = inputs['token_type_ids_p'].to(device)\n",
        "\n",
        "        conclusion_outputs = self.bert_conclusion(input_ids=ids_c, attention_mask=mask_c, token_type_ids=token_type_ids_c)\n",
        "        pooled_output_c = conclusion_outputs.hidden_states[-1][:, 0, :]\n",
        "\n",
        "\n",
        "        if self.model_type != \"base\":\n",
        "            premise_outputs = self.bert_premise(input_ids=ids_p, attention_mask=mask_p, token_type_ids=token_type_ids_p)\n",
        "            pooled_output_cp = premise_outputs.hidden_states[-1][:, 0, :]\n",
        "\n",
        "        if self.model_type == \"bert_w_cp\":\n",
        "            output = torch.cat((pooled_output_c, pooled_output_cp), dim=1)\n",
        "        elif self.model_type == \"bert_w_cps\":\n",
        "            stance = inputs['stance']\n",
        "            output = torch.cat((pooled_output_c, pooled_output_cp, stance), dim=1)\n",
        "        else:\n",
        "            output = pooled_output_c\n",
        "\n",
        "\n",
        "        output = self.dropout(output)\n",
        "        output = self.dense(output)\n",
        "        output = self.sigmoid(output)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNRGrTOWc96d"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "5G6QZbhD3cRG"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def __init__(self, *args, class_weights=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.class_weights = torch.tensor(class_weights, dtype=torch.float32) if class_weights is not None else None\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        print(\"INPUTS\",inputs)\n",
        "        labels = inputs.pop(\"labels\").to(device)\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss = self.weighted_loss(logits, labels, self.class_weights)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "    @staticmethod\n",
        "    def weighted_loss(logits, labels, class_weights):\n",
        "        loss = torch.nn.functional.binary_cross_entropy_with_logits(logits, labels, weight=class_weights.to(device))\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def _prepare_inputs(self, inputs):\n",
        "        print(\"INPUTS\",inputs)\n",
        "        print(\"INPUTS KEYS:\",inputs.keys())\n",
        "        return {\n",
        "            'input_ids': inputs['ids_c'].to(self.args.device),\n",
        "            'attention_mask': inputs['mask_c'].to(self.args.device),\n",
        "            'token_type_ids': inputs['token_type_ids_c'].to(self.args.device),\n",
        "            'input_ids_p': inputs['ids_p'].to(self.args.device),\n",
        "            'attention_mask_p': inputs['mask_p'].to(self.args.device),\n",
        "            'token_type_ids_p': inputs['token_type_ids_p'].to(self.args.device),\n",
        "            'stance': inputs['stance'].to(self.args.device)\n",
        "        }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "qpujljt83cTq"
      },
      "outputs": [],
      "source": [
        "def train(epoch, model,datasets,load_model:False):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    data_collator = DefaultDataCollator()\n",
        "\n",
        "    class_weights = compute_class_weights_from_df(train_df_to_ds)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='./Model_Checkpoints',\n",
        "        overwrite_output_dir=True,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
        "        per_device_eval_batch_size=VALID_BATCH_SIZE,\n",
        "        fp16=True if device == 'cuda' else False,\n",
        "        num_train_epochs=EPOCHS,\n",
        "        logging_steps=100,\n",
        "        logging_dir='./logs',\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        save_strategy='epoch',\n",
        "        metric_for_best_model='macro_f1',\n",
        "        load_best_model_at_end=True,\n",
        "        save_total_limit=1,\n",
        "        )\n",
        "\n",
        "\n",
        "    print(\"OPTIMIZER AND SCHEDULER INSTANTIATION\")\n",
        "    optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "    scheduler = get_scheduler(\n",
        "        \"linear\",\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=len(datasets['train']) // TRAIN_BATCH_SIZE * EPOCHS,\n",
        "    )\n",
        "    print(\"Done !\")\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "    trainer = CustomTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        compute_metrics=compute_metrics,\n",
        "        train_dataset=datasets['train'],\n",
        "        eval_dataset=datasets['validation'],\n",
        "        data_collator=data_collator,\n",
        "        optimizers=(optimizer, scheduler),\n",
        "        class_weights=class_weights,\n",
        "        )\n",
        "\n",
        "    if not load_model:\n",
        "        # Start the training\n",
        "        trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "FHAmUxRr2iZe",
        "outputId": "9df74580-303f-4aef-8e65-d3ad0cc9c00b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "########################### Run with seed: 0 ########################################\n",
            "Setting seed for reproducibility\n",
            "Done\n",
            "\n",
            "SELECTED HYPERPARAMETERS\n",
            "run_num: 0  epochs: 10, batch_size: 64, dropout: 0.2,lr : 1e-05,\n",
            "\n",
            "MODEL CREATION\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n",
            "\n",
            "START TRAINING\n",
            "\n",
            "Inverse Class Frequencies: [2.72511369 2.16673363 1.31312393 1.3137637 ]\n",
            "OPTIMIZER AND SCHEDULER INSTANTIATION\n",
            "Done !\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The batch received was empty, your model won't be able to train on it. Double-check that your training dataset contains keys expected by the model: inputs,label_ids,label.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-9b7db2ed7570>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"START TRAINING\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m       \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwc_datasets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cleaning GPU memory...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-90-aa109eebe56b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, model, datasets, load_model)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# Start the training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1624\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1625\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1961\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2893\u001b[0m         \"\"\"\n\u001b[1;32m   2894\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_sagemaker_mp_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_prepare_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2847\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2849\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2850\u001b[0m                 \u001b[0;34m\"The batch received was empty, your model won't be able to train on it. Double-check that your \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m                 \u001b[0;34mf\"training dataset contains keys expected by the model: {','.join(self._signature_columns)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The batch received was empty, your model won't be able to train on it. Double-check that your training dataset contains keys expected by the model: inputs,label_ids,label."
          ]
        }
      ],
      "source": [
        "SEED = [0,42,121]\n",
        "\n",
        "for seed in SEED:\n",
        "      print(\"-\"*100)\n",
        "      print(f\"########################### Run with seed: {seed} ########################################\")\n",
        "\n",
        "      print(f\"Setting seed for reproducibility\")\n",
        "      set_reproducibility(seed)\n",
        "      print(\"Done\")\n",
        "      print()\n",
        "\n",
        "      print(\"SELECTED HYPERPARAMETERS\")\n",
        "      hyp_str = f\"run_num: {seed}  epochs: {EPOCHS}, batch_size: {TRAIN_BATCH_SIZE}, dropout: {DROPOUT},lr : {LEARNING_RATE},\"\n",
        "      print(hyp_str)\n",
        "      print()\n",
        "\n",
        "      print(\"MODEL CREATION\")\n",
        "      model = MultilabelClassifier(drop_out=DROPOUT, num_labels = NUM_LABELS, model_type=\"base\")\n",
        "      model.to(device)\n",
        "      print(\"Done\")\n",
        "      print()\n",
        "\n",
        "      print(\"START TRAINING\")\n",
        "      print()\n",
        "      train(EPOCHS,model,wc_datasets,load_model=False)\n",
        "      print(\"Cleaning GPU memory...\")\n",
        "      print()\n",
        "      del model\n",
        "      torch.cuda.empty_cache()\n",
        "      print(\"Cleaning Done!\")\n",
        "\n",
        "\n",
        "      print(f\"############################## Training {seed} done. #######################################################\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUiz2Y3N3jRy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TI7yaEe83jT9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLFexJny3jXi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPdxrpWD2ajM"
      },
      "source": [
        "### Notes\n",
        "\n",
        "**Do not mix models**. Each model has its own instructions.\n",
        "\n",
        "You are **free** to select the BERT-based model card from huggingface."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RiznOeg2ajN"
      },
      "source": [
        "#### Examples\n",
        "\n",
        "```\n",
        "bert-base-uncased\n",
        "prajjwal1/bert-tiny\n",
        "distilbert-base-uncased\n",
        "roberta-base\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XojpASbz2ajN"
      },
      "source": [
        "### BERT w/ C\n",
        "\n",
        "<center>\n",
        "    <img src=\"images/bert_c.png\" alt=\"BERT w/ C\" />\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mh-gUIwR2ajN"
      },
      "source": [
        "### BERT w/ CP\n",
        "\n",
        "<center>\n",
        "    <img src=\"images/bert_cp.png\" alt=\"BERT w/ CP\" />\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUZ6_ISM2ajN"
      },
      "source": [
        "### BERT w/ CPS\n",
        "\n",
        "<center>\n",
        "    <img src=\"images/bert_cps.png\" alt=\"BERT w/ CPS\" />\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOZPInso2ajN"
      },
      "source": [
        "### Input concatenation\n",
        "\n",
        "<center>\n",
        "    <img src=\"images/input_merging.png\" alt=\"Input merging\" />\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs7gCExe2ajN"
      },
      "source": [
        "### Notes\n",
        "\n",
        "The **stance** input has to be encoded into a numerical format.\n",
        "\n",
        "You **should** use the same model instance to encode **premise** and **conclusion** inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59FVISJm2ajN"
      },
      "source": [
        "# [Task 3 - 0.5 points] Metrics\n",
        "\n",
        "Before training the models, you are tasked to define the evaluation metrics for comparison."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D-PAV2D2ajO"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Evaluate your models using per-category binary F1-score.\n",
        "* Compute the average binary F1-score over all categories (macro F1-score)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3JgvmpJ2ajO"
      },
      "source": [
        "### Example\n",
        "\n",
        "You start with individual predictions ($\\rightarrow$ samples).\n",
        "\n",
        "```\n",
        "Openess to change:    0 0 1 0 1 1 0 ...\n",
        "Self-enhancement:     1 0 0 0 1 0 1 ...\n",
        "Conversation:         0 0 0 1 1 0 1 ...\n",
        "Self-transcendence:   1 1 0 1 0 1 0 ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOTBZton2ajO"
      },
      "source": [
        "You compute per-category binary F1-score.\n",
        "\n",
        "```\n",
        "Openess to change F1:    0.35\n",
        "Self-enhancement F1:     0.55\n",
        "Conversation F1:         0.80\n",
        "Self-transcendence F1:   0.21\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZhooJGG2ajO"
      },
      "source": [
        "You then average per-category scores.\n",
        "```\n",
        "Average F1: ~0.48\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08XTDS1A2ajO"
      },
      "source": [
        "# [Task 4 - 1.0 points] Training and Evaluation\n",
        "\n",
        "You are now tasked to train and evaluate **all** defined models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_qe5f962ajO"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Train **all** models on the train set.\n",
        "* Evaluate **all** models on the validation set.\n",
        "* Pick **at least** three seeds for robust estimation.\n",
        "* Compute metrics on the validation set.\n",
        "* Report **per-category** and **macro** F1-score for comparison."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKiVdoh12ajO"
      },
      "source": [
        "# [Task 5 - 1.0 points] Error Analysis\n",
        "\n",
        "You are tasked to discuss your results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPhILqNK2ajO"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* **Compare** classification performance of BERT-based models with respect to baselines.\n",
        "* Discuss **difference in prediction** between the best performing BERT-based model and its variants."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVaC4zXz2ajP"
      },
      "source": [
        "### Notes\n",
        "\n",
        "You can check the [original paper](https://aclanthology.org/2022.acl-long.306/) for suggestions on how to perform comparisons (e.g., plots, tables, etc...)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-6v17_Q2ajP"
      },
      "source": [
        "# [Task 6 - 1.0 points] Report\n",
        "\n",
        "Wrap up your experiment in a short report (up to 2 pages)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tgfwd5W82ajP"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Use the NLP course report template.\n",
        "* Summarize each task in the report following the provided template."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LqPc8gD2ajP"
      },
      "source": [
        "### Recommendations\n",
        "\n",
        "The report is not a copy-paste of graphs, tables, and command outputs.\n",
        "\n",
        "* Summarize classification performance in Table format.\n",
        "* **Do not** report command outputs or screenshots.\n",
        "* Report learning curves in Figure format.\n",
        "* The error analysis section should summarize your findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaOSt5uZ2ajP"
      },
      "source": [
        "# Submission\n",
        "\n",
        "* **Submit** your report in PDF format.\n",
        "* **Submit** your python notebook.\n",
        "* Make sure your notebook is **well organized**, with no temporary code, commented sections, tests, etc...\n",
        "* You can upload **model weights** in a cloud repository and report the link in the report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVnWGmhI2ajP"
      },
      "source": [
        "# FAQ\n",
        "\n",
        "Please check this frequently asked questions before contacting us"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDyYN88B2ajP"
      },
      "source": [
        "### Model card\n",
        "\n",
        "You are **free** to choose the BERT-base model card you like from huggingface."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tbYZ0662ajP"
      },
      "source": [
        "### Model architecture\n",
        "\n",
        "You **should not** change the architecture of a model (i.e., its layers).\n",
        "\n",
        "However, you are **free** to play with their hyper-parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sri7gepf2ajQ"
      },
      "source": [
        "### Model Training\n",
        "\n",
        "You are **free** to choose training hyper-parameters for BERT-based models (e.g., number of epochs, etc...)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUUCKM132ajQ"
      },
      "source": [
        "### Neural Libraries\n",
        "\n",
        "You are **free** to use any library of your choice to address the assignment (e.g., Keras, Tensorflow, PyTorch, JAX, etc...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIEGeRnu2ajQ"
      },
      "source": [
        "### Error Analysis\n",
        "\n",
        "Some topics for discussion include:\n",
        "   * Model performance on most/less frequent classes.\n",
        "   * Precision/Recall curves.\n",
        "   * Confusion matrices.\n",
        "   * Specific misclassified samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB_ycBlR2ajQ"
      },
      "source": [
        "# The End"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "celltoolbar": "Slideshow",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "90a93e1ee71043da80ea4760de8aa151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba1a2521b32e410997317127ddb86381",
              "IPY_MODEL_28078ca9170d4a8f89168bba57152c22",
              "IPY_MODEL_b6ca127845d94aa5bd734b78b1d7ee01"
            ],
            "layout": "IPY_MODEL_a34f9f0760934f4b86ed6abc14a1441a"
          }
        },
        "ba1a2521b32e410997317127ddb86381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c77a031d104480199aa0f2a3956961f",
            "placeholder": "​",
            "style": "IPY_MODEL_4e3ad51603a14f9eb632cc54825814a9",
            "value": "config.json: 100%"
          }
        },
        "28078ca9170d4a8f89168bba57152c22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fea43eb46acb488b836a633877a6f4e3",
            "max": 285,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_caa81c5b500b4ef9a0c23440691c7275",
            "value": 285
          }
        },
        "b6ca127845d94aa5bd734b78b1d7ee01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d4eb796eeab472a96e53fd506e49958",
            "placeholder": "​",
            "style": "IPY_MODEL_4f016a5c6e184992a3365504d25cd2a3",
            "value": " 285/285 [00:00&lt;00:00, 19.2kB/s]"
          }
        },
        "a34f9f0760934f4b86ed6abc14a1441a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c77a031d104480199aa0f2a3956961f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e3ad51603a14f9eb632cc54825814a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fea43eb46acb488b836a633877a6f4e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caa81c5b500b4ef9a0c23440691c7275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d4eb796eeab472a96e53fd506e49958": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f016a5c6e184992a3365504d25cd2a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e5852b3fda047269222f5666b6b561c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a009f2b4f5d74939a349c128d136379f",
              "IPY_MODEL_7cda398281ca49a6a1bd67b3ee00d189",
              "IPY_MODEL_472373acfe0440e3ad05b776b5da07ca"
            ],
            "layout": "IPY_MODEL_ce78af612ab340a6ac46659eecb8778e"
          }
        },
        "a009f2b4f5d74939a349c128d136379f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_266de6bf73aa4a958c73aaf96419d3c7",
            "placeholder": "​",
            "style": "IPY_MODEL_9d72cb78c1c14dab9847dffde5a517c1",
            "value": "vocab.txt: 100%"
          }
        },
        "7cda398281ca49a6a1bd67b3ee00d189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43747684e6414f6abfe265a9a9fc0264",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4be755fe13c4afb85afd78950752c48",
            "value": 231508
          }
        },
        "472373acfe0440e3ad05b776b5da07ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f23ebb9cce3d45a4acf2d3d808690011",
            "placeholder": "​",
            "style": "IPY_MODEL_b9e83467550f46bdbd963f18593e94e5",
            "value": " 232k/232k [00:00&lt;00:00, 3.09MB/s]"
          }
        },
        "ce78af612ab340a6ac46659eecb8778e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "266de6bf73aa4a958c73aaf96419d3c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d72cb78c1c14dab9847dffde5a517c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43747684e6414f6abfe265a9a9fc0264": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4be755fe13c4afb85afd78950752c48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f23ebb9cce3d45a4acf2d3d808690011": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9e83467550f46bdbd963f18593e94e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}