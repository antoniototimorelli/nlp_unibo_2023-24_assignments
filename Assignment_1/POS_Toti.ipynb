{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WeCeITXoxLf"
      },
      "source": [
        "# Assignment 1\n",
        "\n",
        "**Due to**: 11/01/2022 (dd/mm/yyyy)\n",
        "\n",
        "If you deliver it by 11/12/2021 your assignment will be graded by 11/01/2022.\n",
        "\n",
        "\n",
        "**Credits**: Andrea Galassi, Federico Ruggeri, Paolo Torroni\n",
        "\n",
        "**Summary**: Part-of Speech (POS) tagging as Sequence Labelling using Recurrent Neural Architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4_wqPdlBcKS"
      },
      "source": [
        "# Execution\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "nltk.corpus.download('treebank')"
      ],
      "metadata": {
        "id": "Bk3FPDTGw_4A"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Corpus Pre-processing\n",
        "### 1.1 Vocabulary"
      ],
      "metadata": {
        "id": "pJVKURDWIGMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fileids = nltk.corpus.treebank.fileids()\n",
        "\n",
        "\n",
        "# Train\n",
        "train_tagged_words = nltk.corpus.treebank.tagged_words(fileids[:101])\n",
        "vocabulary_1 = list(set(train_tagged_words))\n",
        "\n",
        "print('Train set:')\n",
        "print('\\t',len(train_tagged_words))\n",
        "print('\\t',len(vocabulary_1))\n",
        "\n",
        "# train_freqs = nltk.FreqDist(tag for (word, tag) in train_tagged_words)\n",
        "# print(train_freqs.most_common())\n",
        "# print(train_freqs.tabulate())\n",
        "\n",
        "# Val\n",
        "val_tagged_words = nltk.corpus.treebank.tagged_words(fileids[101:151])\n",
        "vocabulary_2 = list(set(val_tagged_words))\n",
        "\n",
        "print('Validation set:')\n",
        "print('\\t',len(val_tagged_words))\n",
        "print('\\t',len(vocabulary_2))\n",
        "\n",
        "# val_freqs = nltk.FreqDist(tag for (word, tag) in val_tagged_words)\n",
        "# print(val_freqs.most_common())\n",
        "\n",
        "# Test\n",
        "test_tagged_words = nltk.corpus.treebank.tagged_words(fileids[151:])\n",
        "vocabulary_3 = list(set(test_tagged_words))\n",
        "\n",
        "print('Test set:')\n",
        "print('\\t',len(test_tagged_words))\n",
        "print('\\t',len(vocabulary_3))\n",
        "\n",
        "# test_freqs = nltk.FreqDist(tag for (word, tag) in test_tagged_words)\n",
        "# print(test_freqs.most_common())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DjxkoiXIJ5g",
        "outputId": "b22cf934-25b2-48a2-e1ec-252151c06e46"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['#', '$', \"''\", ',', '-LRB-', '-NONE-', '-RRB-', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', '``']\n",
            "Train set:\n",
            "\t 51625\n",
            "\t 9374\n",
            "Validation set:\n",
            "\t 32629\n",
            "\t 6473\n",
            "Test set:\n",
            "\t 16422\n",
            "\t 3852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tags = sorted(list(set([x[1] for x in vocabulary_1])))\n",
        "tags = zip(tags, list(range(len(tags))))\n",
        "tags_dict = dict(tags)\n",
        "\n",
        "\n",
        "vocabulary_1_idx = [(x[0], tags_dict[x[1]]) for x in vocabulary_1]\n",
        "vocabulary_2_idx = [(x[0], tags_dict[x[1]]) for x in vocabulary_2]\n",
        "vocabulary_3_idx = [(x[0], tags_dict[x[1]]) for x in vocabulary_3]\n",
        "\n",
        "# print(vocabulary_1[:5])\n",
        "# print(vocabulary_1_idx[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcWXCxkcjsha",
        "outputId": "3588f502-6ad2-4774-f7ed-367be8861fce"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Bretz', 'NNP'), ('*T*-34', '-NONE-'), ('attempting', 'VBG'), ('caused', 'VBN'), ('*T*-201', '-NONE-')]\n",
            "[('Bretz', 21), ('*T*-34', 5), ('attempting', 37), ('caused', 38), ('*T*-201', 5)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.2 Train test split"
      ],
      "metadata": {
        "id": "WjIVKo-zH0AA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NZ3b2n89qEa",
        "outputId": "e0289134-6ef3-449a-f39e-fbd749b1c1b7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "( (S \n",
            "    (NP-SBJ \n",
            "      (NP (NNP Pierr\n"
          ]
        }
      ]
    }
  ]
}