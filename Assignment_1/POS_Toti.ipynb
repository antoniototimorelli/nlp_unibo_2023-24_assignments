{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WeCeITXoxLf"
      },
      "source": [
        "# Assignment 1\n",
        "\n",
        "**Due to**: 11/01/2022 (dd/mm/yyyy)\n",
        "\n",
        "If you deliver it by 11/12/2021 your assignment will be graded by 11/01/2022.\n",
        "\n",
        "\n",
        "**Credits**: Andrea Galassi, Federico Ruggeri, Paolo Torroni\n",
        "\n",
        "**Summary**: Part-of Speech (POS) tagging as Sequence Labelling using Recurrent Neural Architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4_wqPdlBcKS"
      },
      "source": [
        "# Execution\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import progressbar\n",
        "\n",
        "import nltk\n",
        "import sklearn\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, GRU\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "nltk.download('treebank')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "Bk3FPDTGw_4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3b40d6e-d3f9-4113-fe46-19227939a77d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_process(df,string):\n",
        "  def text_pre_process(text):\n",
        "      ret = re.sub(\"RT @(.)+?:\\s|(&#[0-9]+;)|@([\\w\\-]+)|(#)\\S+|(http)s?\\S+|&gt;|^\\s+|\\b\\s+|\\n\", \"\", text)\n",
        "      ret = re.sub(\"\\s\\s+|[^a-zA-Z\\d\\s:]\" , \" \", ret).rstrip().lower()\n",
        "      return ret\n",
        "  return df[string].apply(text_pre_process)\n",
        "\n",
        "def Encoding(df,Tags):\n",
        "  label_encoder = sklearn.preprocessing.LabelEncoder()\n",
        "  X_lab = label_encoder.fit_transform(df)\n",
        "  OneHot_encoder = sklearn.preprocessing.OneHotEncoder()\n",
        "  X = OneHot_encoder.fit_transform(X_lab.reshape(-1,1)).toarray()\n",
        "  dfOneHot = pd.DataFrame(X, columns = [i for i in Tags])\n",
        "  df.reset_index(inplace=True,drop=True)\n",
        "  df = pd.concat([df,dfOneHot],axis=1)\n",
        "  return df\n",
        "\n",
        "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
        "  vocab_size = len(word_index)+1\n",
        "  embedding_matrix = np.zeros((vocab_size,embedding_dim))\n",
        "\n",
        "  with open(filepath, encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "      word, *vector = line.split()\n",
        "      if word in word_index:\n",
        "        idx = word_index[word]\n",
        "        embedding_matrix[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]\n",
        "  return embedding_matrix"
      ],
      "metadata": {
        "id": "Kx5qPakFMJFw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Corpus\n",
        "### 1.1 Pre-processing\n",
        "\n",
        "From the original tags list we removed all the symbols and english punctuation plus:\n",
        "- FW, Foreign Word, because there are no examples in the test set;\n",
        "- UH, Interjection, because there are no examples in the test set;\n",
        "- LS, List Item Marker, because there are no examples in the test set (and because it marks symbols too);"
      ],
      "metadata": {
        "id": "pJVKURDWIGMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the files' list\n",
        "fileids = nltk.corpus.treebank.fileids()\n",
        "\n",
        "# Get the Penn Treebank corpus and tokenize the text\n",
        "train_corpus = nltk.corpus.treebank.tagged_sents(fileids[:100])\n",
        "val_corpus = nltk.corpus.treebank.tagged_sents(fileids[100:150])\n",
        "test_corpus = nltk.corpus.treebank.tagged_sents(fileids[150:])\n",
        "\n",
        "# Flatten the lists\n",
        "train_corpus = [item for sublist in train_corpus for item in sublist if item[1] != '-NONE-']\n",
        "val_corpus = [item for sublist in val_corpus for item in sublist if item[1] != '-NONE-']\n",
        "test_corpus = [item for sublist in test_corpus for item in sublist if item[1] != '-NONE-']"
      ],
      "metadata": {
        "id": "4DjxkoiXIJ5g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.DataFrame(train_corpus, columns = ['word', 'tag'])\n",
        "\n",
        "train_df['word'] = pre_process(train_df,'word')\n",
        "\n",
        "remove = [':', '#', '\"', '$', '-LRB-', '-RRB-', ',', '.', \"''\", '``', 'SYM']\n",
        "for r in remove:\n",
        "  train_df['tag'].replace(r, np.nan, inplace=True)\n",
        "train_df.dropna(inplace=True)\n",
        "\n",
        "\n",
        "tags_train = sorted(list(set([x for x in train_df.tag])))\n",
        "\n",
        "print(train_df.shape)\n",
        "train_df.describe()"
      ],
      "metadata": {
        "id": "LTx_uTCIjRbt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "2b958914-9e29-42c5-8d1d-184b272b2b5b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(41274, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         word    tag\n",
              "count   41274  41274\n",
              "unique   7359     35\n",
              "top       the     NN\n",
              "freq     2329   6270"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a5e73197-838e-4581-8646-389682c6dd98\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>41274</td>\n",
              "      <td>41274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>7359</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>the</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>2329</td>\n",
              "      <td>6270</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5e73197-838e-4581-8646-389682c6dd98')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a5e73197-838e-4581-8646-389682c6dd98 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a5e73197-838e-4581-8646-389682c6dd98');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_df = pd.DataFrame(val_corpus, columns = ['word', 'tag'])\n",
        "\n",
        "val_df['word'] = pre_process(val_df,'word')\n",
        "\n",
        "remove = [':', '#', '\"', '$', '-LRB-', '-RRB-', ',', '.', \"''\", '``', 'SYM']\n",
        "for r in remove:\n",
        "  val_df['tag'].replace(r, np.nan, inplace=True)\n",
        "val_df.dropna(inplace=True)\n",
        "\n",
        "\n",
        "tags_val = sorted(list(set([x for x in val_df.tag])))\n",
        "\n",
        "print(val_df.shape)\n",
        "val_df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "9fYRqQK7QYW8",
        "outputId": "71f4861e-a588-4c0a-d7f0-e97dc46b8fc8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(27418, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         word    tag\n",
              "count   27418  27418\n",
              "unique   5385     35\n",
              "top       the     NN\n",
              "freq     1670   4513"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cacb9e52-ab44-442a-a0c6-fe186749d23e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>27418</td>\n",
              "      <td>27418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>5385</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>the</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1670</td>\n",
              "      <td>4513</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cacb9e52-ab44-442a-a0c6-fe186749d23e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cacb9e52-ab44-442a-a0c6-fe186749d23e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cacb9e52-ab44-442a-a0c6-fe186749d23e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.DataFrame(test_corpus, columns = ['word', 'tag'])\n",
        "\n",
        "test_df['word'] = pre_process(test_df,'word')\n",
        "\n",
        "remove = [':', '#', '\"', '$', '-LRB-', '-RRB-', ',', '.', \"''\", '``', 'SYM']\n",
        "for r in remove:\n",
        "  test_df['tag'].replace(r, np.nan, inplace=True)\n",
        "test_df.dropna(inplace=True)\n",
        "\n",
        "\n",
        "tags_test = sorted(list(set([x for x in test_df.tag])))\n",
        "\n",
        "print(test_df.shape)\n",
        "test_df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "egACcyleOvPK",
        "outputId": "58423766-3032-4d81-8c93-83472ac137fc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13676, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         word    tag\n",
              "count   13676  13676\n",
              "unique   3383     32\n",
              "top       the     NN\n",
              "freq      765   2383"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a396e95c-9901-46a8-b980-51737701bf9f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>13676</td>\n",
              "      <td>13676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>3383</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>the</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>765</td>\n",
              "      <td>2383</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a396e95c-9901-46a8-b980-51737701bf9f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a396e95c-9901-46a8-b980-51737701bf9f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a396e95c-9901-46a8-b980-51737701bf9f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train:',len(tags_train))\n",
        "print('Val:',len(tags_val))\n",
        "print('Test:',len(tags_test))\n",
        "\n",
        "if len(tags_test) != len(tags_val) or len(tags_test) != len(tags_train):\n",
        "  print('Mismatching number of classes.')\n",
        "else:\n",
        "  print('\\nTags:')\n",
        "  for tag in tags_train:\n",
        "    print(f'-{tag}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgW-xj7fRI2u",
        "outputId": "c4621df1-fc69-4f6d-a131-70b29fdf88a4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 35\n",
            "Val: 35\n",
            "Test: 32\n",
            "Mismatching number of classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing_classes_train = [x for x in tags_train if x not in tags_test]\n",
        "missing_classes_val   = [x for x in tags_val if x not in tags_test]\n",
        "\n",
        "missing_classes = list(set(missing_classes_train + missing_classes_val))\n",
        "\n",
        "for cl in missing_classes:\n",
        "  train_df = test_df[test_df.tag != cl]\n",
        "  val_df = test_df[test_df.tag != cl]\n",
        "\n",
        "tags_train = sorted(list(set([x for x in train_df.tag])))\n",
        "tags_val = sorted(list(set([x for x in val_df.tag])))\n",
        "tags_test = sorted(list(set([x for x in test_df.tag])))\n",
        "\n",
        "print('Train:',len(tags_train))\n",
        "print('Val:',len(tags_val))\n",
        "print('Test:',len(tags_test))\n",
        "\n",
        "if len(tags_test) != len(tags_val) or len(tags_test) != len(tags_train):\n",
        "  print('Mismatching number of classes.')\n",
        "else:\n",
        "  print('\\nTags:')\n",
        "  for tag in tags_train:\n",
        "    print(f'-{tag}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMG8vmucW8vy",
        "outputId": "a458c64b-0bb1-48df-a243-850f00af14e4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 32\n",
            "Val: 32\n",
            "Test: 32\n",
            "\n",
            "Tags:\n",
            "-CC\n",
            "-CD\n",
            "-DT\n",
            "-EX\n",
            "-IN\n",
            "-JJ\n",
            "-JJR\n",
            "-JJS\n",
            "-MD\n",
            "-NN\n",
            "-NNP\n",
            "-NNPS\n",
            "-NNS\n",
            "-PDT\n",
            "-POS\n",
            "-PRP\n",
            "-PRP$\n",
            "-RB\n",
            "-RBR\n",
            "-RBS\n",
            "-RP\n",
            "-TO\n",
            "-VB\n",
            "-VBD\n",
            "-VBG\n",
            "-VBN\n",
            "-VBP\n",
            "-VBZ\n",
            "-WDT\n",
            "-WP\n",
            "-WP$\n",
            "-WRB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "\n",
        "train_df['tag'] = label_encoder.fit_transform(train_df['tag'])\n",
        "test_df['tag']  = label_encoder.fit_transform(test_df['tag'])\n",
        "val_df['tag']   = label_encoder.fit_transform(val_df['tag'])\n",
        "\n",
        "print(train_df['tag'].unique())\n",
        "print(val_df['tag'].unique())\n",
        "print(test_df['tag'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NhdgM6UVi-T",
        "outputId": "ea1d29f8-6ecb-4527-f368-9c5045c74c84"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10 23 15  1 12  0  4  9 16  5  2 27 14 21  8 22 24 17 25 29 26 31 28  6\n",
            "  7 20 11 18  3 19 30 13]\n",
            "[10 23 15  1 12  0  4  9 16  5  2 27 14 21  8 22 24 17 25 29 26 31 28  6\n",
            "  7 20 11 18  3 19 30 13]\n",
            "[10 23 15  1 12  0  4  9 16  5  2 27 14 21  8 22 24 17 25 29 26 31 28  6\n",
            "  7 20 11 18  3 19 30 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_df.word\n",
        "y_train = train_df.tag\n",
        "y_train = Encoding(y_train, tags_train)\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_train.head())\n",
        "\n",
        "X_val = val_df.word\n",
        "y_val = val_df.tag\n",
        "y_val = Encoding(y_val, tags_val)\n",
        "print(y_val.shape)\n",
        "print(y_val.head())\n",
        "\n",
        "X_test = test_df.word\n",
        "y_test = test_df.tag\n",
        "y_test = Encoding(y_test, tags_test)\n",
        "print(y_test.shape)\n",
        "print(y_test.head())\n",
        "\n",
        "y_train.drop('tag',inplace=True,axis=1)\n",
        "y_test.drop('tag',inplace=True,axis=1)\n",
        "y_val.drop('tag',inplace=True,axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iETje_H_RvIC",
        "outputId": "fbd41284-acfb-453c-ef15-4c57046b6cbd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13676, 33)\n",
            "   tag   CC   CD   DT   EX   IN   JJ  JJR  JJS   MD  ...   VB  VBD  VBG  VBN  \\\n",
            "0   10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
            "1   10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
            "2   10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
            "3   10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
            "4   10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
            "\n",
            "   VBP  VBZ  WDT   WP  WP$  WRB  \n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "\n",
            "[5 rows x 33 columns]\n",
            "(13676, 33)\n",
            "   tag   CC   CD   DT   EX   IN   JJ  JJR  JJS   MD  ...   VB  VBD  VBG  VBN  \\\n",
            "0   10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
            "1   10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
            "2   10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
            "3   10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
            "4   10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
            "\n",
            "   VBP  VBZ  WDT   WP  WP$  WRB  \n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "\n",
            "[5 rows x 33 columns]\n",
            "(13676, 33)\n",
            "   tag   CC   CD   DT   EX   IN   JJ  JJR  JJS   MD  ...   VB  VBD  VBG  VBN  \\\n",
            "0   10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
            "1   10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
            "2   10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
            "3   10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
            "4   10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
            "\n",
            "   VBP  VBZ  WDT   WP  WP$  WRB  \n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "\n",
            "[5 rows x 33 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "num_words = 9000\n",
        "tokenizer.word_index = {e:i for e,i in tokenizer.word_index.items() if i <= num_words}\n",
        "tokenizer.word_index[tokenizer.oov_token] = num_words + 1\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "DYlL3zP1aErC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 50\n",
        "X_train = pad_sequences(X_train,padding='post',maxlen=max_len)\n",
        "X_val = pad_sequences(X_val,padding='post',maxlen=max_len)\n",
        "X_test = pad_sequences(X_test,padding='post',maxlen=max_len)"
      ],
      "metadata": {
        "id": "wRuwom1nZhlp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. GloVe "
      ],
      "metadata": {
        "id": "WjIVKo-zH0AA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pbar = None\n",
        "def show_progress(block_num, block_size, total_size):\n",
        "    global pbar\n",
        "    if pbar is None:\n",
        "        pbar = progressbar.ProgressBar(maxval=total_size)\n",
        "        pbar.start()\n",
        "\n",
        "    downloaded = block_num * block_size\n",
        "    if downloaded < total_size:\n",
        "        pbar.update(downloaded)\n",
        "    else:\n",
        "        pbar.finish()\n",
        "        pbar = None\n",
        "\n",
        "# Download the GloVe embeddings file\n",
        "url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
        "urllib.request.urlretrieve(url, 'glove.6B.zip', show_progress)\n",
        "\n",
        "# Extract the zip file\n",
        "zip_ref = zipfile.ZipFile('glove.6B.zip', 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whkzW_UI9Amy",
        "outputId": "40a7e1c2-b90b-4aa9-c38d-6c8322261816"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100% (862182613 of 862182613) |##########| Elapsed Time: 0:02:39 Time:  0:02:39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the GloVe embeddings into a dictionary\n",
        "embedding_dict = {}\n",
        "with open('glove.6B.50d.txt', 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embedding_dict[word] = coefs\n",
        "\n",
        "# Print the number of words in the embeddings dictionary\n",
        "print(f'Found {len(embedding_dict)} word vectors.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHAd-w3p9V-u",
        "outputId": "8b15d8a2-9152-4411-bb79-b21e1897ad4c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_closest_embeddings(embedding):\n",
        "    return sorted(embedding_dict.keys(), key=lambda word: np.linalg.norm(embedding_dict[word]- embedding))[:5]\n",
        "\n",
        "find_closest_embeddings(embedding_dict['iphone'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Icops2y7-fNz",
        "outputId": "270a025c-63f5-471d-8a8e-d782a0b89aec"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['iphone', 'ipad', 'smartphone', 'ipod', 'android']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = X_train.shape[1]\n",
        "embedding_dim = 50\n",
        "embedding_matrix = create_embedding_matrix(f'glove.6B.{embedding_dim}d.txt', tokenizer.word_index, embedding_dim)"
      ],
      "metadata": {
        "id": "uSgIkyfvaaHi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Model\n",
        "### 3.1 Baseline"
      ],
      "metadata": {
        "id": "hcBHOgcP3OW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = tf.keras.Sequential(name='Baseline')\n",
        "\n",
        "# Add the Embedding layer\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, \\\n",
        "                    weights = [embedding_matrix], input_length = max_len, trainable=True))\n",
        "\n",
        "# Add the Bidirectional LSTM layer\n",
        "model.add(Bidirectional(LSTM(units=128)))\n",
        "\n",
        "# Add the Dense/Fully-Connected layer\n",
        "model.add(Dense(units=len(tags_train), activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "RTDDziCuKz0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "851b88af-a72d-40ab-a1c7-927dcb6470ef"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Baseline\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 50, 50)            158450    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 256)              183296    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                8224      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 349,970\n",
            "Trainable params: 349,970\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(X_train, y_train, epochs=10, verbose = True, validation_data=(X_val,y_val), batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlB64WAzDr_p",
        "outputId": "5aeacd27-f509-4ba6-92a6-16f6f2972cd8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "428/428 [==============================] - 74s 163ms/step - loss: 1.4815 - accuracy: 0.5900 - val_loss: 0.7953 - val_accuracy: 0.7686\n",
            "Epoch 2/10\n",
            "428/428 [==============================] - 67s 156ms/step - loss: 0.6641 - accuracy: 0.8099 - val_loss: 0.5059 - val_accuracy: 0.8475\n",
            "Epoch 3/10\n",
            "428/428 [==============================] - 68s 160ms/step - loss: 0.4616 - accuracy: 0.8670 - val_loss: 0.3728 - val_accuracy: 0.8930\n",
            "Epoch 4/10\n",
            "428/428 [==============================] - 67s 156ms/step - loss: 0.3474 - accuracy: 0.8987 - val_loss: 0.2770 - val_accuracy: 0.9209\n",
            "Epoch 5/10\n",
            "428/428 [==============================] - 68s 160ms/step - loss: 0.2792 - accuracy: 0.9157 - val_loss: 0.2249 - val_accuracy: 0.9305\n",
            "Epoch 6/10\n",
            "428/428 [==============================] - 71s 166ms/step - loss: 0.2316 - accuracy: 0.9273 - val_loss: 0.1887 - val_accuracy: 0.9412\n",
            "Epoch 7/10\n",
            "428/428 [==============================] - 68s 160ms/step - loss: 0.1992 - accuracy: 0.9340 - val_loss: 0.1661 - val_accuracy: 0.9440\n",
            "Epoch 8/10\n",
            "428/428 [==============================] - 67s 157ms/step - loss: 0.1787 - accuracy: 0.9392 - val_loss: 0.1545 - val_accuracy: 0.9457\n",
            "Epoch 9/10\n",
            "428/428 [==============================] - 68s 159ms/step - loss: 0.1653 - accuracy: 0.9410 - val_loss: 0.1398 - val_accuracy: 0.9493\n",
            "Epoch 10/10\n",
            "428/428 [==============================] - 67s 158ms/step - loss: 0.1542 - accuracy: 0.9437 - val_loss: 0.1337 - val_accuracy: 0.9501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ko3L8znnFWPx",
        "outputId": "aaa95383-8b37-442a-ed62-7297290f1682"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "428/428 [==============================] - 19s 41ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHnq3xfWOKFF",
        "outputId": "5a11d1a2-0f89-46b0-dd2d-742d4b044549"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13676, 32)\n",
            "(13676, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "th = 0.1\n",
        "y_pred[y_pred >= th] = 1 \n",
        "y_pred[y_pred  < th] = 0\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names = tags_train, zero_division=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRAL4g-wOHjo",
        "outputId": "9ce21c74-59d5-4157-cc9f-045f8e7a83df"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CC       1.00      0.96      0.98       366\n",
            "          CD       1.00      1.00      1.00       858\n",
            "          DT       0.99      0.99      0.99      1335\n",
            "          EX       0.83      1.00      0.91         5\n",
            "          IN       0.93      1.00      0.96      1630\n",
            "          JJ       0.82      1.00      0.90       918\n",
            "         JJR       0.79      1.00      0.88        59\n",
            "         JJS       0.91      1.00      0.95        31\n",
            "          MD       0.96      1.00      0.98       167\n",
            "          NN       0.88      0.99      0.93      2383\n",
            "         NNP       0.81      0.98      0.89      1504\n",
            "        NNPS       0.84      0.84      0.84        44\n",
            "         NNS       0.93      1.00      0.96       941\n",
            "         PDT       0.12      0.50      0.20         4\n",
            "         POS       0.94      0.95      0.94       152\n",
            "         PRP       1.00      1.00      1.00       192\n",
            "        PRP$       0.99      1.00      0.99        99\n",
            "          RB       0.89      0.93      0.91       381\n",
            "         RBR       0.29      1.00      0.45        15\n",
            "         RBS       0.25      1.00      0.40         3\n",
            "          RP       0.35      0.88      0.50        33\n",
            "          TO       1.00      1.00      1.00       386\n",
            "          VB       0.69      0.98      0.81       403\n",
            "         VBD       0.85      0.99      0.91       634\n",
            "         VBG       0.85      0.99      0.91       221\n",
            "         VBN       0.65      0.98      0.78       366\n",
            "         VBP       0.73      0.91      0.81       134\n",
            "         VBZ       0.96      0.97      0.96       280\n",
            "         WDT       0.46      1.00      0.63        84\n",
            "          WP       1.00      1.00      1.00        20\n",
            "         WP$       1.00      1.00      1.00         4\n",
            "         WRB       1.00      1.00      1.00        24\n",
            "\n",
            "   micro avg       0.87      0.99      0.93     13676\n",
            "   macro avg       0.80      0.96      0.86     13676\n",
            "weighted avg       0.89      0.99      0.93     13676\n",
            " samples avg       0.93      0.99      0.95     13676\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 GRU "
      ],
      "metadata": {
        "id": "MZ88BEh9qBkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = tf.keras.Sequential(name='GRU')\n",
        "\n",
        "# Add the Embedding layer\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, \\\n",
        "                    weights = [embedding_matrix], input_length = max_len, trainable=True))\n",
        "\n",
        "# Add the GRU layer\n",
        "model.add(GRU(units=128))\n",
        "\n",
        "# Add the Dense/Fully-Connected layer\n",
        "model.add(Dense(units=len(tags_train), activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b66b7433-d5aa-481a-879e-6b7972e0e37f",
        "id": "IazFXPFgyMf3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 50, 50)            158450    \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 128)               69120     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 231,698\n",
            "Trainable params: 231,698\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(X_train, y_train, epochs=10, verbose = True, validation_data=(X_val,y_val), batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1197df1a-8ffb-4a2b-ec45-46b22f81d411",
        "id": "Y5JzsycPyMf5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "428/428 [==============================] - 30s 64ms/step - loss: 2.5828 - accuracy: 0.2299 - val_loss: 1.5992 - val_accuracy: 0.4822\n",
            "Epoch 2/10\n",
            "428/428 [==============================] - 27s 63ms/step - loss: 1.2154 - accuracy: 0.6350 - val_loss: 0.8675 - val_accuracy: 0.7553\n",
            "Epoch 3/10\n",
            "428/428 [==============================] - 27s 64ms/step - loss: 0.7528 - accuracy: 0.7803 - val_loss: 0.5757 - val_accuracy: 0.8326\n",
            "Epoch 4/10\n",
            "428/428 [==============================] - 27s 63ms/step - loss: 0.5274 - accuracy: 0.8469 - val_loss: 0.4086 - val_accuracy: 0.8840\n",
            "Epoch 5/10\n",
            "428/428 [==============================] - 28s 66ms/step - loss: 0.4034 - accuracy: 0.8838 - val_loss: 0.3411 - val_accuracy: 0.9006\n",
            "Epoch 6/10\n",
            "428/428 [==============================] - 28s 65ms/step - loss: 0.3315 - accuracy: 0.9012 - val_loss: 0.2775 - val_accuracy: 0.9141\n",
            "Epoch 7/10\n",
            "428/428 [==============================] - 28s 64ms/step - loss: 0.2847 - accuracy: 0.9158 - val_loss: 0.2477 - val_accuracy: 0.9261\n",
            "Epoch 8/10\n",
            "428/428 [==============================] - 27s 64ms/step - loss: 0.2466 - accuracy: 0.9233 - val_loss: 0.2148 - val_accuracy: 0.9330\n",
            "Epoch 9/10\n",
            "428/428 [==============================] - 38s 88ms/step - loss: 0.2240 - accuracy: 0.9283 - val_loss: 0.2153 - val_accuracy: 0.9309\n",
            "Epoch 10/10\n",
            "428/428 [==============================] - 29s 68ms/step - loss: 0.2066 - accuracy: 0.9319 - val_loss: 0.1750 - val_accuracy: 0.9407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e5587e9-28f5-46dc-9e5a-0007212f3bad",
        "id": "hPIRHnThyMf6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "428/428 [==============================] - 6s 14ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de54f184-67aa-4cab-ccba-7ed2780f4c74",
        "id": "Yf-H3SAuyMf7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13676, 32)\n",
            "(13676, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "th = 0.1\n",
        "y_pred[y_pred >= th] = 1 \n",
        "y_pred[y_pred  < th] = 0\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names = tags_train, zero_division=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87e0e86f-88cc-4099-b48b-a8a1edfeef16",
        "id": "o47IL2wJyMf8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.78      0.99      0.87       366\n",
            "          CD       0.99      1.00      1.00       858\n",
            "          DT       0.99      0.99      0.99      1335\n",
            "          EX       0.83      1.00      0.91         5\n",
            "          IN       0.93      0.99      0.96      1630\n",
            "          JJ       0.80      0.99      0.88       918\n",
            "         JJR       0.70      0.97      0.81        59\n",
            "         JJS       0.64      0.97      0.77        31\n",
            "          MD       0.89      1.00      0.94       167\n",
            "          NN       0.87      0.99      0.93      2383\n",
            "         NNP       0.80      0.98      0.88      1504\n",
            "        NNPS       0.76      0.84      0.80        44\n",
            "         NNS       0.93      0.99      0.96       941\n",
            "         PDT       1.00      0.00      0.00         4\n",
            "         POS       0.89      0.95      0.92       152\n",
            "         PRP       0.90      0.98      0.94       192\n",
            "        PRP$       0.95      1.00      0.98        99\n",
            "          RB       0.72      0.91      0.81       381\n",
            "         RBR       0.38      0.80      0.51        15\n",
            "         RBS       0.25      1.00      0.40         3\n",
            "          RP       0.62      0.48      0.54        33\n",
            "          TO       1.00      1.00      1.00       386\n",
            "          VB       0.66      0.96      0.78       403\n",
            "         VBD       0.83      0.98      0.90       634\n",
            "         VBG       0.75      0.94      0.83       221\n",
            "         VBN       0.66      0.95      0.78       366\n",
            "         VBP       0.55      0.88      0.68       134\n",
            "         VBZ       0.82      0.97      0.89       280\n",
            "         WDT       0.45      1.00      0.62        84\n",
            "          WP       1.00      0.85      0.92        20\n",
            "         WP$       1.00      1.00      1.00         4\n",
            "         WRB       0.75      0.75      0.75        24\n",
            "\n",
            "   micro avg       0.85      0.98      0.91     13676\n",
            "   macro avg       0.78      0.91      0.81     13676\n",
            "weighted avg       0.86      0.98      0.91     13676\n",
            " samples avg       0.91      0.98      0.93     13676\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Additional LSTM layer "
      ],
      "metadata": {
        "id": "V0DshbMkqj2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = tf.keras.Sequential(name='Baseline')\n",
        "\n",
        "# Add the Embedding layer\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, \\\n",
        "                    weights = [embedding_matrix], input_length = max_len, trainable=True))\n",
        "\n",
        "# Add the Bidirectional LSTM layer\n",
        "model.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
        "\n",
        "# Add another LSTM layer\n",
        "model.add(LSTM(units=128))\n",
        "\n",
        "# Add the Dense/Fully-Connected layer\n",
        "model.add(Dense(units=len(tags_train), activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "286efbf5-fece-4472-eb0b-d4d082f90fb7",
        "id": "bHg9dRXf018R"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Baseline\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 50, 50)            158450    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 50, 256)          183296    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 128)               197120    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 542,994\n",
            "Trainable params: 542,994\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(X_train, y_train, epochs=10, verbose = True, validation_data=(X_val,y_val), batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2f7bbfb-19f9-40bc-afd2-4025ee10638b",
        "id": "cvMOu5xe018T"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "428/428 [==============================] - 139s 310ms/step - loss: 2.7716 - accuracy: 0.1692 - val_loss: 2.7603 - val_accuracy: 0.1742\n",
            "Epoch 2/10\n",
            "428/428 [==============================] - 133s 311ms/step - loss: 2.7485 - accuracy: 0.1742 - val_loss: 2.7436 - val_accuracy: 0.1742\n",
            "Epoch 3/10\n",
            "428/428 [==============================] - 132s 308ms/step - loss: 2.7446 - accuracy: 0.1727 - val_loss: 2.7306 - val_accuracy: 0.1742\n",
            "Epoch 4/10\n",
            "428/428 [==============================] - 133s 312ms/step - loss: 2.7344 - accuracy: 0.1742 - val_loss: 2.7310 - val_accuracy: 0.1739\n",
            "Epoch 5/10\n",
            "428/428 [==============================] - 137s 321ms/step - loss: 2.7322 - accuracy: 0.1741 - val_loss: 2.7315 - val_accuracy: 0.1742\n",
            "Epoch 6/10\n",
            "428/428 [==============================] - 134s 313ms/step - loss: 2.7322 - accuracy: 0.1744 - val_loss: 2.7276 - val_accuracy: 0.1750\n",
            "Epoch 7/10\n",
            "428/428 [==============================] - 136s 318ms/step - loss: 2.7328 - accuracy: 0.1737 - val_loss: 2.7308 - val_accuracy: 0.1745\n",
            "Epoch 8/10\n",
            "428/428 [==============================] - 135s 315ms/step - loss: 2.7332 - accuracy: 0.1739 - val_loss: 2.7331 - val_accuracy: 0.1747\n",
            "Epoch 9/10\n",
            "428/428 [==============================] - 136s 318ms/step - loss: 2.7339 - accuracy: 0.1749 - val_loss: 2.7342 - val_accuracy: 0.1756\n",
            "Epoch 10/10\n",
            "428/428 [==============================] - 147s 344ms/step - loss: 2.7345 - accuracy: 0.1742 - val_loss: 2.7289 - val_accuracy: 0.1762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aad0f741-155c-4562-be43-b088dc6968b7",
        "id": "uShCzDvl018U"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "428/428 [==============================] - 34s 76ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7c60c59-2bd0-425a-ece4-8aa7f60189a9",
        "id": "p_ymcxJD018V"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13676, 32)\n",
            "(13676, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "th = 0.1\n",
        "y_pred[y_pred >= th] = 1 \n",
        "y_pred[y_pred  < th] = 0\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names = tags_train, zero_division=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31f75721-244b-44e9-c7bf-701450b928da",
        "id": "ogdkHUtd018V"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CC       1.00      0.00      0.00       366\n",
            "          CD       1.00      0.00      0.00       858\n",
            "          DT       1.00      0.00      0.00      1335\n",
            "          EX       1.00      0.00      0.00         5\n",
            "          IN       0.12      1.00      0.21      1630\n",
            "          JJ       0.14      0.02      0.04       918\n",
            "         JJR       1.00      0.00      0.00        59\n",
            "         JJS       1.00      0.00      0.00        31\n",
            "          MD       1.00      0.00      0.00       167\n",
            "          NN       0.17      1.00      0.30      2383\n",
            "         NNP       0.11      1.00      0.20      1504\n",
            "        NNPS       1.00      0.00      0.00        44\n",
            "         NNS       0.29      0.04      0.07       941\n",
            "         PDT       1.00      0.00      0.00         4\n",
            "         POS       1.00      0.00      0.00       152\n",
            "         PRP       1.00      0.00      0.00       192\n",
            "        PRP$       1.00      0.00      0.00        99\n",
            "          RB       1.00      0.00      0.00       381\n",
            "         RBR       1.00      0.00      0.00        15\n",
            "         RBS       1.00      0.00      0.00         3\n",
            "          RP       1.00      0.00      0.00        33\n",
            "          TO       1.00      0.00      0.00       386\n",
            "          VB       0.22      0.07      0.11       403\n",
            "         VBD       1.00      0.00      0.00       634\n",
            "         VBG       1.00      0.00      0.00       221\n",
            "         VBN       1.00      0.00      0.00       366\n",
            "         VBP       1.00      0.00      0.00       134\n",
            "         VBZ       1.00      0.00      0.00       280\n",
            "         WDT       1.00      0.00      0.00        84\n",
            "          WP       1.00      0.00      0.00        20\n",
            "         WP$       1.00      0.00      0.00         4\n",
            "         WRB       1.00      0.00      0.00        24\n",
            "\n",
            "   micro avg       0.14      0.41      0.20     13676\n",
            "   macro avg       0.85      0.10      0.03     13676\n",
            "weighted avg       0.52      0.41      0.11     13676\n",
            " samples avg       0.14      0.41      0.20     13676\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 3.4 Additional dense layer"
      ],
      "metadata": {
        "id": "kpmMUtH4qnsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = tf.keras.Sequential(name='Baseline')\n",
        "\n",
        "# Add the Embedding layer\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, \\\n",
        "                    weights = [embedding_matrix], input_length = max_len, trainable=True))\n",
        "\n",
        "# Add the Bidirectional LSTM layer\n",
        "model.add(Bidirectional(LSTM(units=128)))\n",
        "\n",
        "# Add another Dense layer\n",
        "model.add(Dense(units=256, activation='softmax'))\n",
        "\n",
        "# Add the Dense/Fully-Connected layer\n",
        "model.add(Dense(units=len(tags_train), activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f94c8a5-313b-4e3a-e5cc-3da98454071c",
        "id": "E7o-z-q502ea"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Baseline\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 50, 50)            158450    \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 256)              183296    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                8224      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 415,762\n",
            "Trainable params: 415,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(X_train, y_train, epochs=10, verbose = True, validation_data=(X_val,y_val), batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ee74f72-d986-4cc9-b667-77626319ac81",
        "id": "97QAgS-D02ec"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "428/428 [==============================] - 75s 166ms/step - loss: 3.1090 - accuracy: 0.2137 - val_loss: 2.8658 - val_accuracy: 0.2635\n",
            "Epoch 2/10\n",
            "428/428 [==============================] - 69s 161ms/step - loss: 2.7300 - accuracy: 0.2666 - val_loss: 2.6208 - val_accuracy: 0.2692\n",
            "Epoch 3/10\n",
            "428/428 [==============================] - 70s 163ms/step - loss: 2.5557 - accuracy: 0.2690 - val_loss: 2.4826 - val_accuracy: 0.2698\n",
            "Epoch 4/10\n",
            "428/428 [==============================] - 69s 160ms/step - loss: 2.3923 - accuracy: 0.2741 - val_loss: 2.2995 - val_accuracy: 0.2911\n",
            "Epoch 5/10\n",
            "428/428 [==============================] - 70s 164ms/step - loss: 2.2426 - accuracy: 0.2971 - val_loss: 2.1781 - val_accuracy: 0.3090\n",
            "Epoch 6/10\n",
            "428/428 [==============================] - 69s 161ms/step - loss: 2.1371 - accuracy: 0.3138 - val_loss: 2.0898 - val_accuracy: 0.3224\n",
            "Epoch 7/10\n",
            "428/428 [==============================] - 70s 164ms/step - loss: 2.0605 - accuracy: 0.3220 - val_loss: 2.0215 - val_accuracy: 0.3242\n",
            "Epoch 8/10\n",
            "428/428 [==============================] - 69s 161ms/step - loss: 1.9986 - accuracy: 0.3246 - val_loss: 1.9686 - val_accuracy: 0.3294\n",
            "Epoch 9/10\n",
            "428/428 [==============================] - 70s 163ms/step - loss: 1.9482 - accuracy: 0.3274 - val_loss: 1.9190 - val_accuracy: 0.3290\n",
            "Epoch 10/10\n",
            "428/428 [==============================] - 69s 161ms/step - loss: 1.9052 - accuracy: 0.3286 - val_loss: 1.8789 - val_accuracy: 0.3307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "539f2163-7815-424b-ef4f-954a9eb29408",
        "id": "GgLsDktF02ec"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "428/428 [==============================] - 18s 39ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43725eee-ee16-4961-c689-1c8d81c12794",
        "id": "dT1murqs02ed"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13676, 32)\n",
            "(13676, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "th = 0.1\n",
        "y_pred[y_pred >= th] = 1 \n",
        "y_pred[y_pred  < th] = 0\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names = tags_train, zero_division=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90da37eb-caab-4049-8341-fce8a28053dd",
        "id": "TExtgi5i02ee"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.19      0.96      0.32       366\n",
            "          CD       0.14      0.99      0.24       858\n",
            "          DT       0.58      0.99      0.73      1335\n",
            "          EX       1.00      0.00      0.00         5\n",
            "          IN       0.22      0.99      0.36      1630\n",
            "          JJ       0.21      0.93      0.35       918\n",
            "         JJR       1.00      0.00      0.00        59\n",
            "         JJS       1.00      0.00      0.00        31\n",
            "          MD       1.00      0.00      0.00       167\n",
            "          NN       0.30      0.98      0.46      2383\n",
            "         NNP       0.20      0.97      0.33      1504\n",
            "        NNPS       1.00      0.00      0.00        44\n",
            "         NNS       0.63      0.96      0.76       941\n",
            "         PDT       1.00      0.00      0.00         4\n",
            "         POS       1.00      0.00      0.00       152\n",
            "         PRP       1.00      0.00      0.00       192\n",
            "        PRP$       1.00      0.00      0.00        99\n",
            "          RB       0.15      0.86      0.25       381\n",
            "         RBR       1.00      0.00      0.00        15\n",
            "         RBS       1.00      0.00      0.00         3\n",
            "          RP       1.00      0.00      0.00        33\n",
            "          TO       1.00      0.00      0.00       386\n",
            "          VB       0.15      0.77      0.25       403\n",
            "         VBD       0.47      0.94      0.63       634\n",
            "         VBG       1.00      0.00      0.00       221\n",
            "         VBN       1.00      0.00      0.00       366\n",
            "         VBP       1.00      0.00      0.00       134\n",
            "         VBZ       0.71      0.85      0.77       280\n",
            "         WDT       1.00      0.00      0.00        84\n",
            "          WP       1.00      0.00      0.00        20\n",
            "         WP$       1.00      0.00      0.00         4\n",
            "         WRB       1.00      0.00      0.00        24\n",
            "\n",
            "   micro avg       0.25      0.82      0.39     13676\n",
            "   macro avg       0.75      0.35      0.17     13676\n",
            "weighted avg       0.42      0.82      0.39     13676\n",
            " samples avg       0.27      0.82      0.39     13676\n",
            "\n"
          ]
        }
      ]
    }
  ]
}