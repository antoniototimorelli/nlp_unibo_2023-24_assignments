{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WeCeITXoxLf"
      },
      "source": [
        "# Assignment 1\n",
        "\n",
        "**Due to**: 11/01/2022 (dd/mm/yyyy)\n",
        "\n",
        "If you deliver it by 11/12/2021 your assignment will be graded by 11/01/2022.\n",
        "\n",
        "\n",
        "**Credits**: Andrea Galassi, Federico Ruggeri, Paolo Torroni\n",
        "\n",
        "**Summary**: Part-of Speech (POS) tagging as Sequence Labelling using Recurrent Neural Architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4_wqPdlBcKS"
      },
      "source": [
        "# Execution\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('treebank')"
      ],
      "metadata": {
        "id": "Bk3FPDTGw_4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "604eb374-385c-4b9a-d38e-e3c48cb7072e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Corpus Pre-processing\n",
        "NOTA: MOLTE COSE NON HANNO SENSO STO SPERIMENTANDO FUNZIONI PER VEDERE DI CAPIRCI QUALCOSA.\n",
        "### 1.1 Vocabulary\n",
        "\n",
        "Qui creo i tre sets taggati, un vocabolario per ognuno ed una lista di frequenze per ogni tag. Rimuovo i tag \"-NONE-\".\n",
        "\n",
        "Nella cella successiva creo tre vocabolari con i tag codificati da un numero, non so per quale motivo ma lo faceva fabio. Online pare che utilizzino la lista di frequenze in questo caso, sostituendo il tag con la sua frequenza. \n",
        "\n",
        "Nella cella ancora successiva creo tre dataframe perché così chiesto dalla traccia."
      ],
      "metadata": {
        "id": "pJVKURDWIGMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fileids = nltk.corpus.treebank.fileids()\n",
        "\n",
        "\n",
        "# Train\n",
        "train_tagged_words = nltk.corpus.treebank.tagged_words(fileids[:101])\n",
        "train_tagged_words = [t for t in train_tagged_words if t[1] != '-NONE-']\n",
        "vocabulary_1 = list(set(train_tagged_words))\n",
        "\n",
        "print('Train set:')\n",
        "print('\\t',len(train_tagged_words))\n",
        "print('\\t',len(vocabulary_1))\n",
        "\n",
        "train_freqs = nltk.FreqDist(tag for (word, tag) in train_tagged_words)\n",
        "# print(train_freqs.most_common())\n",
        "# print(train_freqs.tabulate())\n",
        "\n",
        "# Validation\n",
        "val_tagged_words = nltk.corpus.treebank.tagged_words(fileids[101:151])\n",
        "val_tagged_words = [t for t in val_tagged_words if t[1] != '-NONE-']\n",
        "vocabulary_2 = list(set(val_tagged_words))\n",
        "\n",
        "print('Validation set:')\n",
        "print('\\t',len(val_tagged_words))\n",
        "print('\\t',len(vocabulary_2))\n",
        "\n",
        "val_freqs = nltk.FreqDist(tag for (word, tag) in val_tagged_words)\n",
        "# print(val_freqs.most_common())\n",
        "\n",
        "# Test\n",
        "test_tagged_words = nltk.corpus.treebank.tagged_words(fileids[151:])\n",
        "test_tagged_words = [t for t in test_tagged_words if t[1] != '-NONE-']\n",
        "vocabulary_3 = list(set(test_tagged_words))\n",
        "\n",
        "print('Test set:')\n",
        "print('\\t',len(test_tagged_words))\n",
        "print('\\t',len(vocabulary_3))\n",
        "\n",
        "test_freqs = nltk.FreqDist(tag for (word, tag) in test_tagged_words)\n",
        "# print(test_freqs.most_common())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DjxkoiXIJ5g",
        "outputId": "e6d1973a-8095-4c94-de50-3680a95da37d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set:\n",
            "\t 48183\n",
            "\t 8941\n",
            "Validation set:\n",
            "\t 30576\n",
            "\t 6306\n",
            "Test set:\n",
            "\t 15325\n",
            "\t 3827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tags = sorted(list(set([x[1] for x in vocabulary_1])))\n",
        "tags = zip(tags, list(range(len(tags))))\n",
        "tags_dict = dict(tags)\n",
        "\n",
        "\n",
        "vocabulary_1_idx = [(x[0], tags_dict[x[1]]) for x in vocabulary_1]\n",
        "vocabulary_2_idx = [(x[0], tags_dict[x[1]]) for x in vocabulary_2]\n",
        "vocabulary_3_idx = [(x[0], tags_dict[x[1]]) for x in vocabulary_3]"
      ],
      "metadata": {
        "id": "hcWXCxkcjsha"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.DataFrame(train_tagged_words, columns =['word', 'tag'])\n",
        "df_val = pd.DataFrame(val_tagged_words, columns =['word', 'tag'])\n",
        "df_test = pd.DataFrame(test_tagged_words, columns =['word', 'tag'])"
      ],
      "metadata": {
        "id": "LTx_uTCIjRbt"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_freqs))\n",
        "print(len(train_tagged_words))\n",
        "print(len(vocabulary_1))\n",
        "\n",
        "for t in train_freqs.most_common():\n",
        "  print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxe_qkqZmkdP",
        "outputId": "1f32f486-3ca1-4948-ac3f-de0c67bc651f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45\n",
            "48183\n",
            "8941\n",
            "('NN', 6394)\n",
            "('NNP', 5287)\n",
            "('IN', 5051)\n",
            "('DT', 4178)\n",
            "('JJ', 3055)\n",
            "('NNS', 3044)\n",
            "(',', 2606)\n",
            "('.', 1981)\n",
            "('VBD', 1562)\n",
            "('RB', 1515)\n",
            "('CD', 1476)\n",
            "('VB', 1211)\n",
            "('CC', 1166)\n",
            "('VBZ', 1153)\n",
            "('VBN', 1059)\n",
            "('TO', 1051)\n",
            "('PRP', 957)\n",
            "('VBG', 781)\n",
            "('VBP', 734)\n",
            "('MD', 419)\n",
            "('PRP$', 412)\n",
            "('``', 409)\n",
            "('POS', 405)\n",
            "(\"''\", 399)\n",
            "('$', 355)\n",
            "(':', 294)\n",
            "('WDT', 207)\n",
            "('JJR', 160)\n",
            "('WP', 142)\n",
            "('RP', 140)\n",
            "('NNPS', 98)\n",
            "('JJS', 94)\n",
            "('WRB', 92)\n",
            "('RBR', 88)\n",
            "('-RRB-', 56)\n",
            "('-LRB-', 53)\n",
            "('EX', 49)\n",
            "('RBS', 20)\n",
            "('LS', 10)\n",
            "('PDT', 9)\n",
            "('WP$', 6)\n",
            "('FW', 2)\n",
            "('UH', 1)\n",
            "('SYM', 1)\n",
            "('#', 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.2 GloVe "
      ],
      "metadata": {
        "id": "WjIVKo-zH0AA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import gensim.downloader as gloader\n",
        "\n",
        "emb_model = gloader.load('glove-wiki-gigaword-100')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NZ3b2n89qEa",
        "outputId": "5f6ec355-f394-4a1e-8157-8c1078e2771b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[=================================================-] 99.6% 127.5/128.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YzpW1XSz23th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3 Model"
      ],
      "metadata": {
        "id": "hcBHOgcP3OW7"
      }
    }
  ]
}