{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "013gFxfmSmXR"
      },
      "source": [
        "https://github.com/pranavphoenix/BiLSTM-POS-Tagging/blob/main/BiLSTM_POS_Tagging.ipynb\n",
        "\n",
        "https://linguistics.stackexchange.com/questions/16897/unable-to-understand-meaning-of-tag-none-1-in-penn-treebank-example\n",
        "\n",
        "TODO:\n",
        "- Cacasburo\n",
        "- Guardare creazione dizionario, bisogna rispettare i punti dell'assignment;\n",
        "- Non togliere punctuation e symbols ma evitare di utilizzarli nel calcolo delle metriche, magari utilizzando l'array di pesi 'sample_weight' che si trova nell'altro notebook;\n",
        "- Provare se i risultati migliorano con preprocessing (e.g. lowerando le parole);\n",
        "- Aggiustare il notebook perch√© fa cagare;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0BInycOeQL6"
      },
      "source": [
        "# Assignment 1\n",
        "\n",
        "**Due to**: 11/01/2022 (dd/mm/yyyy)\n",
        "\n",
        "If you deliver it by 11/12/2021 your assignment will be graded by 11/01/2022.\n",
        "\n",
        "\n",
        "**Credits**: Andrea Galassi, Federico Ruggeri, Paolo Torroni\n",
        "\n",
        "**Summary**: Part-of Speech (POS) tagging as Sequence Labelling using Recurrent Neural Architectures\n",
        "\n",
        "# Execution\n",
        "## 0.1 Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iZyCAH8nVzwS"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from collections import defaultdict, OrderedDict\n",
        "\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, GRU\n",
        "from keras.layers import Embedding, Activation\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import progressbar\n",
        "from IPython.display import display_html\n",
        "from itertools import chain,cycle\n",
        "import plotly.graph_objs as go"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6adQpSgiV3A3"
      },
      "source": [
        "## 0.2 Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "sxL2umB0D19Y"
      },
      "outputs": [],
      "source": [
        "# Preprocessing of words\n",
        "def pre_process(df,string):\n",
        "    def text_pre_process(text):\n",
        "        ret = re.sub('RT @(.)+?:\\s|(&#[0-9]+;)|@([\\w\\-]+)|(#)\\S+|(http)s?\\S+|&gt;|^\\s+|\\b\\s+|\\n', '', text)\n",
        "        ret = re.sub('\\s\\s+|[^a-zA-Z\\d\\s:]' , ' ', ret).rstrip().lower()\n",
        "        return ret\n",
        "    return df[string].apply(text_pre_process)\n",
        "\n",
        "# Downloading Glove Word Embeddings\n",
        "pbar = None\n",
        "def show_progress(block_num, block_size, total_size):\n",
        "    global pbar\n",
        "    if pbar is None:\n",
        "        pbar = progressbar.ProgressBar(maxval=total_size)\n",
        "        pbar.start()\n",
        "\n",
        "    downloaded = block_num * block_size\n",
        "    if downloaded < total_size:\n",
        "        pbar.update(downloaded)\n",
        "    else:\n",
        "        pbar.finish()\n",
        "        pbar = None\n",
        "\n",
        "# Display dataframes\n",
        "def display(*args,titles=cycle([''])):\n",
        "    html_str=''\n",
        "    for df,title in zip(args, chain(titles,cycle(['</br>'])) ):\n",
        "        html_str+='<th style=\"text-align:left\"><td style=\"vertical-align:top\">'\n",
        "        html_str+=f'<h4 style=\"text-align: left;\">{title}</h2>'\n",
        "        html_str+=df.to_html().replace('table','table style=\"display:inline\"')\n",
        "        html_str+='</td></th>'\n",
        "    display_html(html_str,raw=True)\n",
        "\n",
        "\n",
        "# Custom accuracy metric\n",
        "def ignore_class_accuracy(classes=[0]):\n",
        "    def ignore_accuracy(y_true, y_pred):\n",
        "        y_true_class = K.argmax(y_true, axis=-1)\n",
        "        y_pred_class = K.argmax(y_pred, axis=-1)\n",
        "        \n",
        "        matches = K.cast(K.equal(y_true_class, y_pred_class), 'int32')\n",
        "        for to_ignore in classes:\n",
        "          ignore_mask = K.cast(K.not_equal(y_pred_class, to_ignore), 'int32')\n",
        "          matches = matches * ignore_mask\n",
        "        accuracy = K.sum(matches) / K.maximum(K.sum(ignore_mask), 1)\n",
        "        return accuracy\n",
        "    return ignore_accuracy\n",
        "\n",
        "# Vocabulary update\n",
        "def update_vocab(df,embeddings_index,embedding_dim):\n",
        "  oov_c = 0\n",
        "  dict_words = list(embeddings_index.keys())\n",
        "\n",
        "  for idx,row in df.iterrows():\n",
        "    if row['word'] not in dict_words:\n",
        "      same_w = 0\n",
        "\n",
        "      words_with_same_tag = list(df[df.tag == row['tag']]['word'])[:100]\n",
        "      oov_vector = np.zeros(embedding_dim)\n",
        "      for w in words_with_same_tag:\n",
        "        if w in dict_words:\n",
        "          same_w += 1\n",
        "          oov_vector += embeddings_index[w]\n",
        "\n",
        "      oov_vector = oov_vector/same_w\n",
        "\n",
        "      # words_with_same_tag = [w for w in words_with_same_tag if w in list(embeddings_index.keys())]\n",
        "      # print(len(words_with_same_tag))\n",
        "      \n",
        "      # random_embed = np.random.rand(embedding_dim)\n",
        "      # embeddings_index[word] = random_embed\n",
        "      embeddings_index[word] = oov_vector\n",
        "  print(\"Added\",oov_c,\"OOV words + respective embeddings to the vocabulary.\")\n",
        "  return embeddings_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUWmRON8D80m",
        "outputId": "5648a3bb-45de-41a5-df9c-c8daa524a70d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "100% (862182613 of 862182613) |##########| Elapsed Time: 0:02:38 Time:  0:02:38\n"
          ]
        }
      ],
      "source": [
        "# Downloading the dataset\n",
        "nltk.download('treebank')\n",
        "\n",
        "# Download the GloVe embeddings file\n",
        "url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
        "urllib.request.urlretrieve(url, 'glove.6B.zip', show_progress)\n",
        "\n",
        "# Extract the zip file\n",
        "zip_ref = zipfile.ZipFile('glove.6B.zip', 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5filE0ydeiga"
      },
      "source": [
        "## 1. Corpus\n",
        "### 1.1 Pre-processing\n",
        "\n",
        "From the original tags list we removed all the symbols and english punctuation plus:\n",
        "- FW, Foreign Word, because there are no examples in the test set;\n",
        "- UH, Interjection, because there are no examples in the test set;\n",
        "- LS, List Item Marker, because there are no examples in the test set (and because it denotes symbols as well);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "-ulx6UMBHint",
        "outputId": "5e95a12f-6b07-468b-a75a-6b3ef6f99a83"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<th style=\"text-align:left\"><td style=\"vertical-align:top\"><h4 style=\"text-align: left;\">Training set (47356, 3)</h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>47356</td>\n",
              "      <td>47356</td>\n",
              "      <td>47356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>8009</td>\n",
              "      <td>45</td>\n",
              "      <td>1963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>,</td>\n",
              "      <td>NN</td>\n",
              "      <td>1854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>2570</td>\n",
              "      <td>6270</td>\n",
              "      <td>249</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table style=\"display:inline\"></td></th><th style=\"text-align:left\"><td style=\"vertical-align:top\"><h4 style=\"text-align: left;\">Validation set (31183, 3)</h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>31183</td>\n",
              "      <td>31183</td>\n",
              "      <td>31183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>5892</td>\n",
              "      <td>44</td>\n",
              "      <td>1299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>,</td>\n",
              "      <td>NN</td>\n",
              "      <td>339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1528</td>\n",
              "      <td>4513</td>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table style=\"display:inline\"></td></th><th style=\"text-align:left\"><td style=\"vertical-align:top\"><h4 style=\"text-align: left;\">Test set (15545, 3)</h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>15545</td>\n",
              "      <td>15545</td>\n",
              "      <td>15545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>3623</td>\n",
              "      <td>40</td>\n",
              "      <td>652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>,</td>\n",
              "      <td>NN</td>\n",
              "      <td>232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>787</td>\n",
              "      <td>2383</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table style=\"display:inline\"></td></th>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Get the files' list\n",
        "fileids = nltk.corpus.treebank.fileids()\n",
        "\n",
        "# Get the Penn Treebank tagged sentences\n",
        "train_corpus = nltk.corpus.treebank.tagged_sents(fileids[:100])\n",
        "val_corpus = nltk.corpus.treebank.tagged_sents(fileids[100:150])\n",
        "test_corpus = nltk.corpus.treebank.tagged_sents(fileids[150:])\n",
        "\n",
        "# Flatten the lists\n",
        "\n",
        "train_corpus = [tuple(list(item)+[str(idx)]) for idx,sublist in enumerate(train_corpus) for item in sublist if item[1] != '-NONE-']\n",
        "val_corpus = [tuple(list(item)+[str(idx)]) for idx,sublist in enumerate(val_corpus) for item in sublist if item[1] != '-NONE-']\n",
        "test_corpus = [tuple(list(item)+[str(idx)]) for idx,sublist in enumerate(test_corpus) for item in sublist if item[1] != '-NONE-']\n",
        "\n",
        "# train_corpus = [tuple(list(item)+[str(idx)]) for idx,sublist in enumerate(train_corpus) for item in sublist if item[1] not in ignore]\n",
        "# val_corpus = [tuple(list(item)+[str(idx)]) for idx,sublist in enumerate(val_corpus) for item in sublist if item[1] not in ignore]\n",
        "# test_corpus = [tuple(list(item)+[str(idx)]) for idx,sublist in enumerate(test_corpus) for item in sublist if item[1] not in ignore]\n",
        "\n",
        "#train_corpus = [tuple(list(item)+[str(idx)]) for idx,sublist in enumerate(train_corpus) for item in sublist]\n",
        "#val_corpus = [tuple(list(item)+[str(idx)]) for idx,sublist in enumerate(val_corpus) for item in sublist]\n",
        "#test_corpus = [tuple(list(item)+[str(idx)]) for idx,sublist in enumerate(test_corpus) for item in sublist]\n",
        "\n",
        "train_df = pd.DataFrame(train_corpus, columns = ['word', 'tag', 'sentence'])\n",
        "#train_df['word'] = train_df['word'].str.lower()\n",
        "# train_df['word'] = pre_process(train_df,'word')\n",
        "\n",
        "val_df = pd.DataFrame(val_corpus, columns = ['word', 'tag', 'sentence'])\n",
        "#val_df['word'] = val_df['word'].str.lower()\n",
        "# val_df['word'] = pre_process(val_df,'word')\n",
        "\n",
        "test_df = pd.DataFrame(test_corpus, columns = ['word', 'tag', 'sentence'])\n",
        "#test_df['word'] = test_df['word'].str.lower()\n",
        "# test_df['word'] = pre_process(test_df,'word')\n",
        "\n",
        "display(train_df.describe(), val_df.describe(), test_df.describe(), titles = [f'Training set {train_df.shape}', f'Validation set {val_df.shape}', f'Test set {test_df.shape}'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKteoO2I-Le7"
      },
      "outputs": [],
      "source": [
        "#lowercase to all classes but NNS and NNPS\n",
        "\n",
        "#for index, row in train_df.iterrows():\n",
        "#  if row['tag'] != 'NNP' or 'NNPS':\n",
        "#    row['word'] = row['word'].lower()\n",
        "#\n",
        "#for index, row in val_df.iterrows():\n",
        "#  if row['tag'] != 'NNP' or 'NNPS':\n",
        "#     row['word'] = row['word'].lower()\n",
        "\n",
        "# for index, row in test_df.iterrows():\n",
        "#   if row['tag'] != 'NNP' or 'NNPS':\n",
        "#     row['word'] = row['word'].lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6MOWORPI8Va",
        "outputId": "a6a001f5-65a3-4d35-88e0-93092d96a1a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train tags number: 45\n",
            "Train tags list: ['#', '$', \"''\", ',', '-LRB-', '-RRB-', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', '``']\n",
            "\tClasses in training set for which there are no samples in validation set: ['SYM']\n",
            "\tClasses in training set for which there are no samples in test set: ['#', 'FW', 'LS', 'SYM', 'UH']\n",
            "\n",
            "Validation tags number: 44\n",
            "Validation tags list: ['#', '$', \"''\", ',', '-LRB-', '-RRB-', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', '``']\n",
            "\tClasses in validation set for which there are no samples in test set: ['#', 'FW', 'LS', 'UH']\n",
            "\n",
            "Test tags number: 40\n",
            "Test tags list: ['$', \"''\", ',', '-LRB-', '-RRB-', '.', ':', 'CC', 'CD', 'DT', 'EX', 'IN', 'JJ', 'JJR', 'JJS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'TO', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', '``']\n"
          ]
        }
      ],
      "source": [
        "tags_train = sorted(list(set([x for x in train_df.tag])))\n",
        "tags_val = sorted(list(set([x for x in val_df.tag])))\n",
        "tags_test = sorted(list(set([x for x in test_df.tag])))\n",
        "\n",
        "max_tags_list = max([len(tags_train),len(tags_val),len(tags_test)])\n",
        "\n",
        "# Training set tags list\n",
        "print(f'Train tags number: {len(tags_train)}')\n",
        "print(f'Train tags list: {tags_train}')\n",
        "\n",
        "exceeding_validation = [el for el in tags_train if el not in tags_val]\n",
        "if exceeding_validation != []:\n",
        "  print(f'\\tClasses in training set for which there are no samples in validation set: {exceeding_validation}')\n",
        "\n",
        "exceeding_test = [el for el in tags_train if el not in tags_test]\n",
        "\n",
        "if exceeding_test != []:\n",
        "  print(f'\\tClasses in training set for which there are no samples in test set: {exceeding_test}')\n",
        "\n",
        "\n",
        "# Validation set tags list\n",
        "print(f'\\nValidation tags number: {len(tags_val)}')\n",
        "print(f'Validation tags list: {tags_val}')\n",
        "\n",
        "exceeding_training = [el for el in tags_val if el not in tags_train]\n",
        "if exceeding_training != []:\n",
        "  print(f'\\tClasses in validation set for which there are no samples in training set: {exceeding_training}')\n",
        "\n",
        "exceeding_test = [el for el in tags_val if el not in tags_test]\n",
        "if exceeding_test != []:\n",
        "  print(f'\\tClasses in validation set for which there are no samples in test set: {exceeding_test}')\n",
        "\n",
        "# Validation set tags list\n",
        "print(f'\\nTest tags number: {len(tags_test)}')\n",
        "print(f'Test tags list: {tags_test}')\n",
        "\n",
        "exceeding_training = [el for el in tags_test if el not in tags_train]\n",
        "if exceeding_training != []:\n",
        "  print(f'\\tClasses in test set for which there are no samples in training set: {exceeding_training}')\n",
        "\n",
        "exceeding_val = [el for el in tags_test if el not in tags_val]\n",
        "if exceeding_val != []:\n",
        "  print(f'\\tClasses in test set set for which there are no samples in validation set: {exceeding_val}')\n",
        "\n",
        "conf_mat_df = pd.DataFrame(columns=tags_train, index=tags_train)\n",
        "conf_mat_df = conf_mat_df.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5nfdsia2tDY",
        "outputId": "e67d1711-b96a-44e9-c337-d52a4bf46d08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN       6270\n",
            "NNP      5202\n",
            "IN       4952\n",
            "DT       4076\n",
            "NNS      3004\n",
            "JJ       2992\n",
            ",        2571\n",
            ".        1959\n",
            "VBD      1548\n",
            "RB       1490\n",
            "CD       1439\n",
            "VB       1195\n",
            "CC       1141\n",
            "VBZ      1133\n",
            "VBN      1031\n",
            "TO       1028\n",
            "PRP       954\n",
            "VBG       763\n",
            "VBP       727\n",
            "MD        413\n",
            "PRP$      409\n",
            "``        409\n",
            "POS       403\n",
            "''        399\n",
            "$         342\n",
            ":         293\n",
            "WDT       204\n",
            "JJR       157\n",
            "WP        141\n",
            "RP        140\n",
            "NNPS       95\n",
            "JJS        93\n",
            "WRB        92\n",
            "RBR        86\n",
            "-RRB-      55\n",
            "-LRB-      52\n",
            "EX         49\n",
            "RBS        19\n",
            "LS         10\n",
            "PDT         9\n",
            "WP$         6\n",
            "FW          2\n",
            "UH          1\n",
            "SYM         1\n",
            "#           1\n",
            "Name: tag, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(train_df['tag'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jlBmUbmIlG0o"
      },
      "outputs": [],
      "source": [
        "# Retriving prepocessed data\n",
        "X_train_raw = train_df.groupby('sentence').word.apply(list).reset_index()['word']\n",
        "X_val_raw = val_df.groupby('sentence').word.apply(list).reset_index()['word']\n",
        "X_test_raw = test_df.groupby('sentence').word.apply(list).reset_index()['word']\n",
        "\n",
        "y_train_raw = train_df.groupby('sentence').tag.apply(list).reset_index()['tag']\n",
        "y_val_raw = val_df.groupby('sentence').tag.apply(list).reset_index()['tag']\n",
        "y_test_raw = test_df.groupby('sentence').tag.apply(list).reset_index()['tag']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5kuIrRML6i2"
      },
      "source": [
        "##-Vocabulary part-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W8oM6e9LIMt"
      },
      "source": [
        "GloVe Vocabulary (V1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "675MhAFGFQNj",
        "outputId": "049cb9b7-202a-4d45-bda7-7d78aeaeba87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "#Use the 300 dimensional GLove Word Embeddings\n",
        "glove_dir = './'\n",
        "embedding_dim = 300\n",
        "embedding_dict = {} #initialize dictionary\n",
        "f = open(os.path.join(glove_dir, f'glove.6B.{embedding_dim}d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embedding_dict[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embedding_dict))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tag_dict = {tag:np.zeros(embedding_dim) for tag in tags_train}\n",
        "tag_count = {tag:0 for tag in tags_train}\n",
        "\n",
        "for idx, row in train_df.iterrows():\n",
        "  for tag in tags_train:\n",
        "    if tag == row['tag']:\n",
        "      if row['word'] in embedding_dict:\n",
        "          tag_count[tag] += 1\n",
        "          tag_dict[tag] += embedding_dict[row['word']]\n",
        "\n",
        "for tag in tags_train:\n",
        "  if np.all(tag_dict[tag]):\n",
        "    tag_dict[tag] = tag_dict[tag] / tag_count[tag]"
      ],
      "metadata": {
        "id": "UvZxgmYgcRp2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i896YzW_LSxU"
      },
      "source": [
        "V1 + Training set OOV (V2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGUNPlD0LYzI",
        "outputId": "04b99c36-a186-4e03-b27f-04ca00af33f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 555 OOV words + respective embeddings to the vocabulary.\n"
          ]
        }
      ],
      "source": [
        "def update_vocab(df,embeddings_index,embedding_dim): \n",
        "  oov_c = 0 \n",
        "  # for word in df.word: \n",
        "  for idx, row in df.iterrows(): \n",
        "    if row['word'].lower() not in embeddings_index: \n",
        "      oov_c += 1\n",
        "      noise = np.random.normal(0,1,embedding_dim)\n",
        "      embeddings_index[row['word']] = tag_dict[row['tag']] + noise       \n",
        "    else: \n",
        "      embeddings_index[row['word']] = embeddings_index[row['word'].lower()]  \n",
        "  print(\"Added\",oov_c,\"OOV words + respective embeddings to the vocabulary.\") \n",
        "  return embeddings_index\n",
        "\n",
        "embedding_dict = update_vocab(train_df,embedding_dict,embedding_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y0leABCLdUN"
      },
      "source": [
        "V2 + Validation set OOV (V3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8t-ArNTCLeKY",
        "outputId": "ec9057f6-1be4-4be1-c60d-d4b1f40194b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 305 OOV words + respective embeddings to the vocabulary.\n"
          ]
        }
      ],
      "source": [
        "embedding_dict = update_vocab(val_df,embedding_dict,embedding_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOF5z9auLf7z"
      },
      "source": [
        "V3 + Test set OOV (V4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_JWqKoDLjBD",
        "outputId": "2fe54340-01bd-4762-c412-99f0f923a3c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 214 OOV words + respective embeddings to the vocabulary.\n"
          ]
        }
      ],
      "source": [
        "embedding_dict = update_vocab(test_df,embedding_dict,embedding_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKuxUTPNLkhz",
        "outputId": "8929ba32-737b-400e-809a-6895a4c76158"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Debug] Index -> Word vocabulary size: 403745\n",
            "[Debug] Word -> Index vocabulary size: 403745\n"
          ]
        }
      ],
      "source": [
        "#Building the actual word vocabulary\n",
        "\n",
        "index2word = OrderedDict()\n",
        "word2index = OrderedDict()\n",
        "\n",
        "curr_idx = 0\n",
        "for key in embedding_dict.keys():\n",
        "  word2index[key] = curr_idx\n",
        "  index2word[curr_idx] = key\n",
        "  curr_idx += 1\n",
        "\n",
        "vocab_length = len(word2index) \n",
        "print(f'[Debug] Index -> Word vocabulary size: {len(index2word)}')\n",
        "print(f'[Debug] Word -> Index vocabulary size: {len(word2index)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aKNy1vALyWm",
        "outputId": "7ed16b30-6928-49d0-8f53-1f6155e67ef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Debug] Index -> Tag vocabulary size: 45\n",
            "[Debug] Tag -> Index vocabulary size: 45\n"
          ]
        }
      ],
      "source": [
        "#Tag vocabulary\n",
        "\n",
        "tag2index = OrderedDict()\n",
        "index2tag = OrderedDict()\n",
        "\n",
        "curr_id = 0\n",
        "for tag in tags_train:\n",
        "  tag2index[tag] = curr_id\n",
        "  index2tag[curr_id] = tag\n",
        "  curr_id += 1\n",
        "\n",
        "print(f'[Debug] Index -> Tag vocabulary size: {len(index2tag)}')\n",
        "print(f'[Debug] Tag -> Index vocabulary size: {len(tag2index)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKZGDveoMIUI"
      },
      "source": [
        "###da qua continua il preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlvH2AwynXAk",
        "outputId": "906da325-3073-4f48-f545-7c4bdc3d1b2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-Not encoded\n",
            "\t ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n",
            "\t ['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'CD', '.']\n",
            "-Encoded\n",
            "\t [400000, 400001, 1, 4978, 82, 167, 1, 43, 1429, 0, 534, 19, 7, 128564, 369, 400002, 1263, 2]\n",
            "\t [20, 20, 3, 9, 22, 14, 3, 18, 34, 10, 19, 13, 10, 14, 19, 20, 9, 6]\n"
          ]
        }
      ],
      "source": [
        "# Tokenising words and tags by their indexes in vocabulary\n",
        "X_train_np, X_val_np, X_test_np, y_train_np, y_val_np, y_test_np = [], [], [], [], [], []\n",
        "\n",
        "# Encode X\n",
        "for sentence in X_train_raw:\n",
        "    sent_int = []\n",
        "    for word in sentence:\n",
        "            sent_int.append(word2index[word])\n",
        "    X_train_np.append(sent_int)\n",
        "\n",
        "for sentence in X_val_raw:\n",
        "    sent_int = []\n",
        "    for word in sentence:\n",
        "            sent_int.append(word2index[word])\n",
        "    X_val_np.append(sent_int)\n",
        "\n",
        "for sentence in X_test_raw:\n",
        "    sent_int = []\n",
        "    for word in sentence:\n",
        "            sent_int.append(word2index[word])\n",
        "    X_test_np.append(sent_int)\n",
        "\n",
        "# Encode Y\n",
        "for sent_tags in y_train_raw:\n",
        "    y_train_np.append([tag2index[tag] for tag in sent_tags])\n",
        "\n",
        "for sent_tags in y_val_raw:\n",
        "    y_val_np.append([tag2index[tag] for tag in sent_tags])\n",
        "\n",
        "for sent_tags in y_test_raw:\n",
        "    y_test_np.append([tag2index[tag] for tag in sent_tags])\n",
        "\n",
        "print('-Not encoded')\n",
        "print('\\t',X_train_raw[0]) \n",
        "print('\\t',y_train_raw[0])\n",
        "print('-Encoded')\n",
        "print('\\t',X_train_np[0])\n",
        "print('\\t',y_train_np[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "TWdnd4hWmKee",
        "outputId": "04913310-ae92-466e-8508-74366ff3f006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f60726a37f0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD4CAYAAADSIzzWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAALuklEQVR4nO3dX4iddX7H8c8vmezWjSutcVFJlox2FlZBaG0oe7EsGrTNnwvbOy8kuSgI2sZU6IXVXOQiCi20YEMppHQhKbV705buRRKqVehVtx2Lq67R7tk10gT/bYTNGu2uSZ5ezJk0ZuYkk5Nz5pvMvF4QMvOc33me58tz8s6c50RsXdcFgMW3ovoEAJYrAQYoIsAARQQYoIgAAxSZuJzFN910Uzc5OTmmUwFYml5++eWfdF33lQu3X1aAJycnMz09PbqzAlgGWmvvzLfdLQiAIgIMUESAAYoIMEARAQYoIsAARQQYoIgAAxQRYIAiAgxQRIABiggwQBEBBigiwABFBBigiAADFBFggCICDFBEgAGKXNb/E67a3r170+v1Lrrm+PHjSZK1a9decn9TU1PZsWPHSM4N4HJdUwHu9Xp55fUjOfOlGweuWfnJT5Mk7/384qOt/OSjkZ4bwOW6pgKcJGe+dGM+/fqWgY9f9+bBJLnomvPXAVRxDxigiAADFBFggCICDFBEgAGKCDBAEQEGKCLAAEUEGKCIAAMUEWCAIgIMUESAAYoIMEARAQYoIsAARQQYoIgAAxQRYIAiAgxQRIABiggwQBEBBigiwABFBBigiAADFBFggCICDFBEgAGKCDBAEQEGKCLAAEUEGKCIAAMUEWCAIgIMUESAAYoIMEARAQYoIsAARQQYoMiiBHjv3r3Zu3fvYhzqqrTc5wfmN7EYB+n1eotxmKvWcp8fmJ9bEABFBBigiAADFBFggCICDFBEgAGKCDBAEQEGKCLAAEUEGKCIAAMUEWCAIgIMUESAAYoIMEARAQYoIsAARQQYoIgAAxQRYIAiAgxQRIABiggwQBEBBigiwABFBBigiAADFBFggCICDFBEgAGKCDBAEQEGKCLAAEUEGKCIAAMUEWCAIgIMUESAAYoI8CI5efJk7r333jz44IPZuHFjXnrppTz00EO555578txzz2Xr1q3p9XpJkl6vl61bt2Z6ejqPPfZYTpw4kRMnTuSRRx7Jo48+eu772ccGWciaUT1vVMcadj8wLuN8TQrwInnnnXfSdV3ee++9nD17Nk8//XSOHTuWJNm3b19OnTqVPXv2JEn27NmTU6dOZffu3Xnttddy4MCB7N+/P0eOHMkbb7xx7vvZxwZZyJpRPW9Uxxp2PzAu43xNCvAiOHnyZM6ePfu5badPn56z7ujRo3nxxRdz9OjRJMnHH3+cruty6NChHDp06Ny6gwcP5vDhw+m6LocPH573b+YTJ05ccs18hnneqI7V6/WG2g+My7Cv7YWaGOneBjh+/Hg+/fTT7Ny584r20+v1suIX3UjOacX/nkyv97MrPqeFePvttxe89plnnpmz7bPPPkvXdZ/7vrWWJDlz5kwOHDiQxx9//HPP2b9//7noD1ozn2GeN6pj7dmzZ6j9wLgM+9peqEv+BNxae7i1Nt1am/7www9HdmDmN99PxufH98Jtp0+fzvPPPz/n8RdeeOHcvgatmc8wzxvVsY4ePTrUfmBchn1tL9QlfwLuum5fkn1JsmHDhqF+/Fy7dm2S5Nlnnx3m6efs3LkzL//4/Svax6yzv3RDpm6/+YrPaSE2btw45xbEIBMTE3Mi3FqbE+HZbRMTE7n//vvn7Oe+++7LwYMHc/r06YFr5jPM80Z1rHXr1uXYsWOXvR8Yl2Ff2wvlHvAiWL9+/YLXPvnkk3O2rVq1KqtWrZr3+5UrV2bbtm1znrN9+/asWLHiomvmM8zzRnWsXbt2DbUfGJdhX9sLJcCL4IYbbjh3EWdNTMx98zE5OZmNGzdmcnIySXL99dentZbNmzdn8+bN59Zt2bIlmzZtSmstmzZtypo1a+bsa82aNZdcM59hnjeqY01NTQ21HxiXYV/bCyXAi2T9+vVpreWWW27JihUr8tRTT2XdunVJkocffjirV6/Orl27kiS7du3K6tWrs3v37tx1113Ztm1btm/fnjvuuCN33nnnue9nHxtkIWtG9bxRHWvY/cC4jPM12eb7gGeQDRs2dNPT05d9kNl/aTCqe8Cffn3LwDXXvXkwSS66ZnbdbyzSPeBRzQ9cm1prL3ddt+HC7X4CBigiwABFBBigiAADFBFggCICDFBEgAGKCDBAEQEGKCLAAEUEGKCIAAMUEWCAIgIMUESAAYoIMEARAQYoIsAARQQYoIgAAxQRYIAiAgxQRIABiggwQBEBBigiwABFBBigiAADFBFggCICDFBEgAGKCDBAEQEGKCLAAEUEGKCIAAMUEWCAIgIMUGRiMQ4yNTW1GIe5ai33+YH5LUqAd+zYsRiHuWot9/mB+bkFAVBEgAGKCDBAEQEGKCLAAEUEGKCIAAMUEWCAIgIMUESAAYoIMEARAQYoIsAARQQYoIgAAxQRYIAiAgxQRIABiggwQBEBBigiwABFBBigiAADFBFggCICDFBEgAGKCDBAEQEGKCLAAEUEGKCIAAMUEWCAIgIMUESAAYoIMEARAQYoIsAARQQYoIgAAxQRYIAiE9UncLlWfvJRrnvz4EUeP5EkF10zu5/k5lGeGsBluaYCPDU1dck1x4+fTpKsXXupuN68oP0BjMs1FeAdO3ZUnwLAyLgHDFBEgAGKCDBAEQEGKCLAAEUEGKCIAAMUEWCAIgIMUESAAYoIMEARAQYoIsAARQQYoIgAAxQRYIAiAgxQRIABiggwQBEBBijSuq5b+OLWPkzyzhDHuSnJT4Z43rXMzMvHcpx7Oc6cDD/3+q7rvnLhxssK8LBaa9Nd120Y+4GuImZePpbj3Mtx5mT0c7sFAVBEgAGKLFaA9y3Sca4mZl4+luPcy3HmZMRzL8o9YADmcgsCoIgAAxQZa4Bba5taa2+11nqttSfGeaxqrbWjrbXXWmuvtNam+9tubK0931r7Yf/3X6k+zyvRWvt2a+2D1trr522bd8Y24y/61/7V1trddWc+vAEz726tHe9f61daa1vOe+yP+zO/1Vr77ZqzvjKtta+21l5qrb3RWvtBa21nf/tSv9aD5h7f9e66biy/kqxM8qMktyf5QpLvJ7lzXMer/pXkaJKbLtj2p0me6H/9RJI/qT7PK5zxW0nuTvL6pWZMsiXJoSQtyTeSfK/6/Ec48+4kfzTP2jv7r/MvJrmt//pfWT3DEDPfmuTu/tdfTvLf/dmW+rUeNPfYrvc4fwL+zSS9rut+3HXdL5J8J8kDYzze1eiBJPv7X+9P8juF53LFuq77tyQfXbB50IwPJDnQzfj3JL/cWrt1cc50dAbMPMgDSb7Tdd3Pu657O0kvM38Orild173bdd1/9b/+WZIjSdZm6V/rQXMPcsXXe5wBXpvkf877/lguPsy1rkvyL621l1trD/e33dx13bv9r99LcnPNqY3VoBmX+vX/g/7b7W+fd2tpyc3cWptM8utJvpdldK0vmDsZ0/X2IdzofLPruruTbE7y+621b53/YDfznmVJ/5u/5TBj318l+dUkv5bk3SR/Vns649Fauz7JPyT5w67rTp7/2FK+1vPMPbbrPc4AH0/y1fO+X9fftiR1XXe8//sHSf4pM29F3p99K9b//YO6MxybQTMu2evfdd37Xded6brubJK/zv+/7VwyM7fWVmUmQn/Xdd0/9jcv+Ws939zjvN7jDPB/Jvlaa+221toXkjyY5LtjPF6Z1trq1tqXZ79O8ltJXs/MvNv7y7Yn+eeaMxyrQTN+N8m2/ifk30jy0/Pevl7TLri/+buZudbJzMwPtta+2Fq7LcnXkvzHYp/flWqttSR/k+RI13V/ft5DS/paD5p7rNd7zJ8qbsnMJ4k/SvJU9aecY5zz9sx8Gvr9JD+YnTXJmiT/muSHSV5IcmP1uV7hnH+fmbdgn2XmftfvDZoxM5+I/2X/2r+WZEP1+Y9w5r/tz/Rq/w/hreetf6o/81tJNlef/5AzfzMztxdeTfJK/9eWZXCtB809tuvtP0UGKOJDOIAiAgxQRIABiggwQBEBBigiwABFBBigyP8Br/f4gSSOsAoAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "lengths = [len(sentence) for sentence in X_train_raw]\n",
        "lengths.sort()\n",
        "\n",
        "sns.boxplot(lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRSBSBqosWyK",
        "outputId": "94d1d454-ae34-48ad-c10b-8dfae89c12ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of longest sentence: 249\n",
            "Second longest sentence length: 114\n",
            "-Padded\n",
            "\tX: [400000 400001      1   4978     82    167      1     43   1429      0\n",
            "    534     19      7 128564    369 400002   1263      2      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0]\n",
            "\n",
            "\ty: [20 20  3  9 22 14  3 18 34 10 19 13 10 14 19 20  9  6  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
          ]
        }
      ],
      "source": [
        "MAX_LENGTH = lengths[-1] # maximum words in a sentence\n",
        "\n",
        "PAD_LENGTH = lengths[-2]\n",
        "\n",
        "\n",
        "print(f'Length of longest sentence: {MAX_LENGTH}')\n",
        "print(f'Second longest sentence length: {PAD_LENGTH}')\n",
        "\n",
        "\n",
        "X_train = pad_sequences(X_train_np, maxlen=PAD_LENGTH, padding='post')\n",
        "X_val = pad_sequences(X_val_np, maxlen=PAD_LENGTH, padding='post')\n",
        "X_test = pad_sequences(X_test_np, maxlen=PAD_LENGTH, padding='post')\n",
        "\n",
        "y_train = pad_sequences(y_train_np, maxlen=PAD_LENGTH, padding='post')\n",
        "y_val = pad_sequences(y_val_np, maxlen=PAD_LENGTH, padding='post')\n",
        "y_test = pad_sequences(y_test_np, maxlen=PAD_LENGTH, padding='post')\n",
        "print('-Padded')\n",
        "print('\\tX:',X_train[0])\n",
        "print('\\n\\ty:',y_train[0])\n",
        "\n",
        "# List of tags to ignore\n",
        "ignore = [':', '#', '$', '-LRB-', '-RRB-', ',', '.', \"''\", '``', 'SYM']\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train_raw[0])\n",
        "print(y_train[0])\n",
        "\n",
        "print(y_val_raw[0])\n",
        "print(y_val[0])\n",
        "\n",
        "print('debussy')\n",
        "print(y_train_one_hot[0][0])\n",
        "\n",
        "print('debussy')\n",
        "print(y_val_one_hot[0][12])\n",
        "\n",
        "\n",
        "# for sentence in y_train_one_hot:\n",
        "#   print(sentence)\n",
        "#   for word in sentence:\n",
        "#     print(word)\n",
        "\n",
        "#     break\n",
        "\n",
        "print(index2tag[1])\n",
        "print(predictions_bl_one_hot_encode[0][12])\n",
        "print(predictions_bl[0][12])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWloSvLyke_l",
        "outputId": "9525707a-7677-45ea-fa46-84369abcf725"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'CD', '.']\n",
            "[20 20  3  9 22 14  3 18 34 10 19 13 10 14 19 20  9  6  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "['DT', 'NNP', 'NN', 'VBD', 'JJ', 'NNS', 'IN', 'DT', 'NN', 'IN', 'JJR', 'IN', '$', 'CD', 'CD', 'IN', 'JJ', 'NN', 'IN', 'NNP', 'WDT', 'VBZ', 'RB', 'IN', '$', 'CD', 'CD', 'IN', 'NN', 'CC', 'NN', 'NNS', 'IN', 'JJ', 'CD', 'IN', 'NNS', 'IN', 'VBG', 'JJ', 'NN', 'CC', 'NN', '.']\n",
            "[10 20 19 35 14 22 13 10 19 13 15 13  1  9  9 13 14 19 13 20 40 39 27 13\n",
            "  1  9  9 13 19  8 19 22 13 14  9 13 22 13 36 14 19  8 19  6  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "debussy\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "debussy\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "$\n",
            "[1.04875584e-08 9.99758959e-01 1.03092639e-11 5.11529485e-09\n",
            " 2.94303515e-09 2.62598970e-10 3.68137592e-08 4.89066110e-07\n",
            " 4.18573975e-08 2.04948694e-04 1.16922266e-07 8.17486800e-10\n",
            " 1.35100187e-09 1.21348205e-06 8.96017767e-08 5.10538190e-09\n",
            " 9.51231485e-08 1.16296391e-07 3.13643200e-09 7.41466602e-06\n",
            " 2.56523854e-05 6.89733781e-09 1.06694842e-09 1.49739314e-08\n",
            " 7.76502029e-10 2.45762209e-07 3.48362028e-09 5.89837121e-08\n",
            " 2.19370433e-09 4.39025205e-11 1.80033410e-07 1.21619925e-09\n",
            " 4.77589062e-08 5.57966950e-10 3.88876575e-09 2.16006573e-08\n",
            " 5.90511973e-10 1.93779641e-08 1.27249633e-09 4.72555328e-09\n",
            " 8.09909295e-08 1.91688124e-10 1.64397329e-10 9.36383193e-10\n",
            " 2.13655607e-10]\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Tt3IPOjD1AER"
      },
      "outputs": [],
      "source": [
        "y_train_one_hot = to_categorical(y_train, len(tag2index))\n",
        "y_val_one_hot = to_categorical(y_val, len(tag2index))\n",
        "y_test_one_hot = to_categorical(y_test, len(tag2index))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SqOgc6v1DfB"
      },
      "source": [
        "## 2. GloVe \n",
        "GloVe (Global Vectors for Word Representation) is a method for learning vector representations of words, called \"word embeddings,\" from a large corpus of text. Word embeddings are numerical representations of words that capture the semantic relationships between words in a continuous, low-dimensional space. They are commonly used as input to natural language processing models, such as language translation and language modeling.\n",
        "\n",
        "GloVe works by learning the co-occurrence statistics of words in a corpus, and using this information to learn word embeddings that capture the semantic relationships between words. The GloVe method produces word embeddings that are trained on a global corpus, as opposed to embeddings that are trained on a specific task or dataset.\n",
        "\n",
        "There are different versions of the GloVe word embeddings, including 50-dimensional, 100-dimensional, and 200-dimensional embeddings. The 50-dimensional version of GloVe embeddings may be better in some applications because they have a lower dimensionality, which can make them easier to work with and more computationally efficient.\n",
        "\n",
        "By using GloVe embeddings as the initial weights for a model, we can take advantage of these pre-trained word representations and fine-tune them for a specific task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "YcvBdLXW1QTY"
      },
      "outputs": [],
      "source": [
        "#Building the Embedding Layer \n",
        "embedding_matrix = np.zeros((len(word2index), embedding_dim))\n",
        "# embedding_matrix = np.standard(0,1,(len(word2index), embedding_dim))\n",
        "for word, i in word2index.items():\n",
        "  embedding_vector = embedding_dict.get(word)\n",
        "  embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvF_XXvV3Qxe"
      },
      "source": [
        "## 3. Model\n",
        "### 3.1 Baseline \n",
        "Bidirectional LSTM layers are able to process sequential data in both the forward and backward directions, which can allow the model to capture contextual information from both the past and the future. This can be particularly useful for natural language processing tasks, where the meaning of a word can depend on the context in which it is used.\n",
        "\n",
        "In the context of POS tagging, TimeDistributed can be used to apply a tag prediction layer to each word in a sentence. For example, you might have an RNN that processes a sequence of words in a sentence, and at each time step, the RNN outputs a hidden state. You could then apply a TimeDistributed dense layer to the hidden states, which would allow you to predict the POS tag for each word in the sentence.\n",
        "\n",
        "One advantage of using TimeDistributed for POS tagging is that it allows you to predict the POS tag for each word in the sentence simultaneously, rather than having to process the sentence one word at a time. This can be particularly useful when dealing with long sentences, as it can make the tagging process more efficient.\n",
        "\n",
        "Overall, using TimeDistributed for POS tagging can help you build more accurate and efficient models for natural language processing tasks that involve sequential data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuLsYIaYIBgn",
        "outputId": "3651250c-db05-4e2a-ea62-f469eb8cf8d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Baseline\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 114, 300)          121123500 \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirectio  (None, 114, 512)         1140736   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_5 (TimeDis  (None, 114, 45)          23085     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 122,287,321\n",
            "Trainable params: 1,163,821\n",
            "Non-trainable params: 121,123,500\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the model\n",
        "baseline_model = Sequential(name='Baseline')\n",
        "\n",
        "# Add the Embedding layer\n",
        "baseline_model.add(Embedding(input_dim=vocab_length, output_dim=embedding_dim, \\\n",
        "                    weights=[embedding_matrix], input_length=PAD_LENGTH, trainable=False,mask_zero=True))\n",
        "\n",
        "# Add the Bidirectional LSTM layer\n",
        "baseline_model.add(Bidirectional(LSTM(units=256, return_sequences=True)))\n",
        "\n",
        "# Add the Dense/Fully-Connected layer\n",
        "baseline_model.add(TimeDistributed(Dense(units=len(tag2index), activation='softmax')))\n",
        "\n",
        "# Compile the model\n",
        "baseline_model.compile(optimizer=Adam(0.01), loss='categorical_crossentropy', metrics=['accuracy',\\\n",
        "                      ignore_class_accuracy([tag2index[tag] for tag in ignore])])\n",
        "\n",
        "# Summary\n",
        "baseline_model.summary()\n",
        " \n",
        "# Callbacks \n",
        "callbacks = [ \n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_ignore_accuracy', patience=3, restore_best_weights=True,verbose=True), \n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_ignore_accuracy', factor=0.5, patience=1, verbose=True, min_lr=0.001) \n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA776HlcMC_h",
        "outputId": "d47b0193-8500-448d-8fdd-e5f89097094d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "16/16 [==============================] - 52s 3s/step - loss: 0.3867 - accuracy: 0.5116 - ignore_accuracy: 0.0838 - val_loss: 0.1631 - val_accuracy: 0.7723 - val_ignore_accuracy: 0.1303 - lr: 0.0100\n",
            "Epoch 2/15\n",
            "16/16 [==============================] - 44s 3s/step - loss: 0.1133 - accuracy: 0.8392 - ignore_accuracy: 0.1430 - val_loss: 0.0982 - val_accuracy: 0.8610 - val_ignore_accuracy: 0.1481 - lr: 0.0100\n",
            "Epoch 3/15\n",
            "16/16 [==============================] - 41s 3s/step - loss: 0.0655 - accuracy: 0.9059 - ignore_accuracy: 0.1564 - val_loss: 0.0784 - val_accuracy: 0.8837 - val_ignore_accuracy: 0.1526 - lr: 0.0100\n",
            "Epoch 4/15\n",
            "16/16 [==============================] - 39s 2s/step - loss: 0.0412 - accuracy: 0.9410 - ignore_accuracy: 0.1634 - val_loss: 0.0696 - val_accuracy: 0.8955 - val_ignore_accuracy: 0.1550 - lr: 0.0100\n",
            "Epoch 5/15\n",
            "16/16 [==============================] - 38s 2s/step - loss: 0.0259 - accuracy: 0.9662 - ignore_accuracy: 0.1687 - val_loss: 0.0654 - val_accuracy: 0.9043 - val_ignore_accuracy: 0.1568 - lr: 0.0100\n",
            "Epoch 6/15\n",
            "16/16 [==============================] - 38s 2s/step - loss: 0.0150 - accuracy: 0.9848 - ignore_accuracy: 0.1724 - val_loss: 0.0650 - val_accuracy: 0.9078 - val_ignore_accuracy: 0.1575 - lr: 0.0100\n",
            "Epoch 7/15\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9937 - ignore_accuracy: 0.1742\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "16/16 [==============================] - 38s 2s/step - loss: 0.0081 - accuracy: 0.9937 - ignore_accuracy: 0.1742 - val_loss: 0.0659 - val_accuracy: 0.9076 - val_ignore_accuracy: 0.1574 - lr: 0.0100\n",
            "Epoch 8/15\n",
            "16/16 [==============================] - 39s 2s/step - loss: 0.0044 - accuracy: 0.9983 - ignore_accuracy: 0.1754 - val_loss: 0.0672 - val_accuracy: 0.9084 - val_ignore_accuracy: 0.1576 - lr: 0.0050\n",
            "Epoch 9/15\n",
            "16/16 [==============================] - 38s 2s/step - loss: 0.0031 - accuracy: 0.9990 - ignore_accuracy: 0.1752 - val_loss: 0.0679 - val_accuracy: 0.9095 - val_ignore_accuracy: 0.1578 - lr: 0.0050\n",
            "Epoch 10/15\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9996 - ignore_accuracy: 0.1753\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "16/16 [==============================] - 39s 2s/step - loss: 0.0023 - accuracy: 0.9996 - ignore_accuracy: 0.1753 - val_loss: 0.0695 - val_accuracy: 0.9086 - val_ignore_accuracy: 0.1577 - lr: 0.0050\n",
            "Epoch 11/15\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9998 - ignore_accuracy: 0.1755\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "16/16 [==============================] - 40s 3s/step - loss: 0.0019 - accuracy: 0.9998 - ignore_accuracy: 0.1755 - val_loss: 0.0700 - val_accuracy: 0.9084 - val_ignore_accuracy: 0.1576 - lr: 0.0025\n",
            "Epoch 12/15\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9998 - ignore_accuracy: 0.1754Restoring model weights from the end of the best epoch: 9.\n",
            "\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.001.\n",
            "16/16 [==============================] - 42s 3s/step - loss: 0.0017 - accuracy: 0.9998 - ignore_accuracy: 0.1754 - val_loss: 0.0702 - val_accuracy: 0.9084 - val_ignore_accuracy: 0.1576 - lr: 0.0012\n",
            "Epoch 12: early stopping\n"
          ]
        }
      ],
      "source": [
        "results_baseline = baseline_model.fit(X_train, y_train_one_hot, validation_data=(X_val, y_val_one_hot),\\\n",
        "                                      batch_size=128, epochs=15, callbacks = callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q4shasqRWUk",
        "outputId": "7a87ea47-69e4-484f-83a4-31d3edcbc748"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 14s 335ms/step - loss: 0.0679 - accuracy: 0.9095 - ignore_accuracy: 0.1597\n",
            "41/41 [==============================] - 14s 354ms/step\n"
          ]
        }
      ],
      "source": [
        "scores_bl = baseline_model.evaluate(X_val, y_val_one_hot, return_dict = True)\n",
        "\n",
        "predictions_bl_one_hot_encode = baseline_model.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Convert the class probabilities into class labels\n",
        "predictions_bl = np.argmax(predictions_bl_one_hot_encode, axis=-1)\n",
        "\n",
        "# Create a binary mask for the classes to exclude\n",
        "mask = np.logical_not(np.isin(y_val, [tag2index[tag] for tag in ignore]))\n",
        "\n",
        "# Use the mask to exclude the classes that are in the list from the true positive, false positive, and false negative counts\n",
        "macro_f1_bl = f1_score(y_val[mask], predictions_bl[mask], average='macro')\n",
        "\n",
        "print(macro_f1_bl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRCKuhXgKK_1",
        "outputId": "ffc05a8b-e222-4c9b-9be3-7f4a9dfb8f7b"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7148666027524271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_piJrG2VEe1Z"
      },
      "source": [
        "### 3.2 GRU \n",
        "Gated Recurrent Units (GRUs) are a type of recurrent neural network (RNN) that are often used in natural language processing tasks such as part-of-speech (POS) tagging. GRUs are similar to long short-term memory (LSTM) networks, but they have a simpler structure and fewer parameters, making them easier to train and faster to run. In POS tagging, GRUs can be used to process a sequence of words and predict the POS tags for each word in the sequence. GRUs are able to take into account contextual information from the previous words in the sequence, allowing them to make more accurate predictions about the POS tags for the current word. \n",
        "\n",
        "Both BiLSTMs (Bidirectional LSTMs) and Gated Recurrent Units (GRUs) have been shown to perform well on a variety of NLP tasks, including POS tagging, but here we obtained slightly better results than with the baseline; the reason may be that LSTMs are are particularly well-suited for tasks that require the model to remember and make use of long-term dependencies in the data, while the longest sentence in the Penn Treebank dataset has only 171 words and the average of words per sentence is around 20.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHd70QrVEhOv",
        "outputId": "e26d1edb-b16b-4e50-a1fe-1ba9436fb6e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 114, 300)          121123500 \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 114, 256)          428544    \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 114, 45)          11565     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,563,609\n",
            "Trainable params: 440,109\n",
            "Non-trainable params: 121,123,500\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the model\n",
        "gru_model = tf.keras.Sequential(name='GRU')\n",
        "\n",
        "# Add the Embedding layer\n",
        "gru_model.add(Embedding(input_dim=vocab_length, output_dim=embedding_dim, \\\n",
        "                    weights = [embedding_matrix], input_length = PAD_LENGTH, trainable=False,mask_zero=True ))\n",
        "\n",
        "# Add the GRU layer\n",
        "gru_model.add(GRU(units=256, return_sequences=True))\n",
        "\n",
        "# Add the Dense/Fully-Connected layer\n",
        "gru_model.add(TimeDistributed(Dense(len(tags_train), activation='softmax')))\n",
        "\n",
        "# Compile the model\n",
        "gru_model.compile(optimizer=Adam(0.01), loss='categorical_crossentropy', metrics=['accuracy',ignore_class_accuracy([tag2index[tag] for tag in ignore])])\n",
        "\n",
        "# Summary\n",
        "gru_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBWwuzcuEk_e",
        "outputId": "4de7b8a4-94b9-43ae-b292-588e8ba8251f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "16/16 [==============================] - 27s 1s/step - loss: 0.3155 - accuracy: 0.5893 - ignore_accuracy: 0.0976 - val_loss: 0.1512 - val_accuracy: 0.7779 - val_ignore_accuracy: 0.1315 - lr: 0.0100\n",
            "Epoch 2/15\n",
            "16/16 [==============================] - 16s 1s/step - loss: 0.1101 - accuracy: 0.8423 - ignore_accuracy: 0.1440 - val_loss: 0.1068 - val_accuracy: 0.8429 - val_ignore_accuracy: 0.1446 - lr: 0.0100\n",
            "Epoch 3/15\n",
            "16/16 [==============================] - 25s 2s/step - loss: 0.0745 - accuracy: 0.8907 - ignore_accuracy: 0.1537 - val_loss: 0.0918 - val_accuracy: 0.8626 - val_ignore_accuracy: 0.1485 - lr: 0.0100\n",
            "Epoch 4/15\n",
            "16/16 [==============================] - 18s 1s/step - loss: 0.0539 - accuracy: 0.9212 - ignore_accuracy: 0.1594 - val_loss: 0.0815 - val_accuracy: 0.8782 - val_ignore_accuracy: 0.1516 - lr: 0.0100\n",
            "Epoch 5/15\n",
            "16/16 [==============================] - 16s 1s/step - loss: 0.0391 - accuracy: 0.9458 - ignore_accuracy: 0.1647 - val_loss: 0.0802 - val_accuracy: 0.8822 - val_ignore_accuracy: 0.1524 - lr: 0.0100\n",
            "Epoch 6/15\n",
            "16/16 [==============================] - 16s 1s/step - loss: 0.0280 - accuracy: 0.9640 - ignore_accuracy: 0.1681 - val_loss: 0.0768 - val_accuracy: 0.8882 - val_ignore_accuracy: 0.1536 - lr: 0.0100\n",
            "Epoch 7/15\n",
            "16/16 [==============================] - 16s 1s/step - loss: 0.0190 - accuracy: 0.9773 - ignore_accuracy: 0.1707 - val_loss: 0.0774 - val_accuracy: 0.8911 - val_ignore_accuracy: 0.1542 - lr: 0.0100\n",
            "Epoch 8/15\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.9861 - ignore_accuracy: 0.1726\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "16/16 [==============================] - 17s 1s/step - loss: 0.0132 - accuracy: 0.9861 - ignore_accuracy: 0.1726 - val_loss: 0.0789 - val_accuracy: 0.8894 - val_ignore_accuracy: 0.1539 - lr: 0.0100\n",
            "Epoch 9/15\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9934 - ignore_accuracy: 0.1741\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "16/16 [==============================] - 16s 1s/step - loss: 0.0086 - accuracy: 0.9934 - ignore_accuracy: 0.1741 - val_loss: 0.0807 - val_accuracy: 0.8905 - val_ignore_accuracy: 0.1541 - lr: 0.0050\n",
            "Epoch 10/15\n",
            "16/16 [==============================] - 15s 979ms/step - loss: 0.0063 - accuracy: 0.9958 - ignore_accuracy: 0.1747 - val_loss: 0.0804 - val_accuracy: 0.8924 - val_ignore_accuracy: 0.1544 - lr: 0.0025\n",
            "Epoch 11/15\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9969 - ignore_accuracy: 0.1748\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "16/16 [==============================] - 16s 1s/step - loss: 0.0055 - accuracy: 0.9969 - ignore_accuracy: 0.1748 - val_loss: 0.0808 - val_accuracy: 0.8918 - val_ignore_accuracy: 0.1543 - lr: 0.0025\n",
            "Epoch 12/15\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9974 - ignore_accuracy: 0.1751\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.001.\n",
            "16/16 [==============================] - 19s 1s/step - loss: 0.0049 - accuracy: 0.9974 - ignore_accuracy: 0.1751 - val_loss: 0.0808 - val_accuracy: 0.8922 - val_ignore_accuracy: 0.1544 - lr: 0.0012\n",
            "Epoch 13/15\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9976 - ignore_accuracy: 0.1749Restoring model weights from the end of the best epoch: 10.\n",
            "16/16 [==============================] - 19s 1s/step - loss: 0.0047 - accuracy: 0.9976 - ignore_accuracy: 0.1749 - val_loss: 0.0813 - val_accuracy: 0.8921 - val_ignore_accuracy: 0.1544 - lr: 0.0010\n",
            "Epoch 13: early stopping\n"
          ]
        }
      ],
      "source": [
        "results_gru = gru_model.fit(X_train, y_train_one_hot, epochs=15, verbose = True, \\\n",
        "                            validation_data=(X_val, y_val_one_hot), batch_size=128, callbacks = callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSpKe6LEEoHy",
        "outputId": "4e9f91e3-49ce-4a8b-bf4c-87856de3b5a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 5s 114ms/step - loss: 0.0804 - accuracy: 0.8924 - ignore_accuracy: 0.1562\n",
            "41/41 [==============================] - 7s 143ms/step\n"
          ]
        }
      ],
      "source": [
        "scores_gru = gru_model.evaluate(X_val, y_val_one_hot, return_dict = True)\n",
        "\n",
        "predictions_gru_one_hot_encode = gru_model.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the class probabilities into class labels\n",
        "predictions_gru = np.argmax(predictions_gru_one_hot_encode, axis=-1)\n",
        "\n",
        "# Create a binary mask for the classes to exclude\n",
        "mask = np.logical_not(np.isin(y_val, [tag2index[tag] for tag in ignore]))\n",
        "\n",
        "# Use the mask to exclude the classes that are in the list from the true positive, false positive, and false negative counts\n",
        "macro_f1_gru = f1_score(y_val[mask], predictions_gru[mask], average='macro')\n",
        "\n",
        "print(macro_f1_gru)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbWvSeqXN2T_",
        "outputId": "dc76d22d-bf45-4f18-a5f6-a6475b2b4ef7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6143390727179829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4NZ4nhpEr1K"
      },
      "source": [
        "### 3.3 Additional LSTM layer \n",
        "Using two BiLSTMs layers can allow the model to learn more complex patterns in the data and make more accurate predictions. \n",
        "However, they can increase the computational complexity of our model, which may require more computational resources to train.\n",
        "\n",
        "With the same number of epochs the results were similar to the baseline and the training process was slower; it is possible that the model with two BiLSTMs is more prone to overfitting, meaning that it is able to fit the training data very well but is less able to generalize to new data. Another possibility is that the model with two BiLSTMs simply takes longer to train. That is why we raised the training epochs to 20, obtaining better results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVntK3UwEuGS",
        "outputId": "e8ca60a4-d4e8-43df-c626-c4c926110318"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Additional_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 114, 300)          121123500 \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 114, 512)         1140736   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 114, 512)         1574912   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDis  (None, 114, 45)          23085     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 123,862,233\n",
            "Trainable params: 2,738,733\n",
            "Non-trainable params: 121,123,500\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the model\n",
        "add_lstm_model = tf.keras.Sequential(name='Additional_LSTM')\n",
        "\n",
        "# Add the Embedding layer\n",
        "add_lstm_model.add(Embedding(input_dim=vocab_length, output_dim=embedding_dim, \\\n",
        "                    weights = [embedding_matrix], input_length = PAD_LENGTH, trainable=False, mask_zero=True))\n",
        "\n",
        "# Add the Bidirectional LSTM layer\n",
        "add_lstm_model.add(Bidirectional(LSTM(units=256, return_sequences=True)))\n",
        "\n",
        "# Add another LSTM layer\n",
        "add_lstm_model.add(Bidirectional(LSTM(units=256, return_sequences=True)))\n",
        "\n",
        "# Add the Dense/Fully-Connected layer\n",
        "add_lstm_model.add(TimeDistributed(Dense(units=len(tags_train), activation='softmax')))\n",
        "\n",
        "# Compile the model\n",
        "add_lstm_model.compile(optimizer=Adam(0.01), loss='categorical_crossentropy', metrics=['accuracy',ignore_class_accuracy([tag2index[tag] for tag in ignore])])\n",
        "\n",
        "# Summary\n",
        "add_lstm_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3omzfumEv48",
        "outputId": "2f0c7dff-3db9-4fe6-ee56-3937f84afbd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 146s 8s/step - loss: 0.6918 - accuracy: 0.1415 - ignore_accuracy: 0.0292 - val_loss: 0.5241 - val_accuracy: 0.2730 - val_ignore_accuracy: 0.0464 - lr: 0.0100\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 107s 7s/step - loss: 0.3988 - accuracy: 0.4419 - ignore_accuracy: 0.0720 - val_loss: 0.2829 - val_accuracy: 0.6148 - val_ignore_accuracy: 0.1010 - lr: 0.0100\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 111s 7s/step - loss: 0.2098 - accuracy: 0.7189 - ignore_accuracy: 0.1199 - val_loss: 0.1616 - val_accuracy: 0.7758 - val_ignore_accuracy: 0.1312 - lr: 0.0100\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 106s 7s/step - loss: 0.1205 - accuracy: 0.8322 - ignore_accuracy: 0.1418 - val_loss: 0.1096 - val_accuracy: 0.8474 - val_ignore_accuracy: 0.1455 - lr: 0.0100\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 105s 7s/step - loss: 0.0777 - accuracy: 0.8914 - ignore_accuracy: 0.1535 - val_loss: 0.0869 - val_accuracy: 0.8752 - val_ignore_accuracy: 0.1510 - lr: 0.0100\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 109s 7s/step - loss: 0.0514 - accuracy: 0.9299 - ignore_accuracy: 0.1614 - val_loss: 0.0729 - val_accuracy: 0.8955 - val_ignore_accuracy: 0.1550 - lr: 0.0100\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 100s 6s/step - loss: 0.0341 - accuracy: 0.9557 - ignore_accuracy: 0.1664 - val_loss: 0.0688 - val_accuracy: 0.9022 - val_ignore_accuracy: 0.1564 - lr: 0.0100\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 99s 6s/step - loss: 0.0228 - accuracy: 0.9722 - ignore_accuracy: 0.1699 - val_loss: 0.0631 - val_accuracy: 0.9111 - val_ignore_accuracy: 0.1582 - lr: 0.0100\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9834 - ignore_accuracy: 0.1721\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "16/16 [==============================] - 101s 6s/step - loss: 0.0150 - accuracy: 0.9834 - ignore_accuracy: 0.1721 - val_loss: 0.0630 - val_accuracy: 0.9115 - val_ignore_accuracy: 0.1583 - lr: 0.0100\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 103s 7s/step - loss: 0.0092 - accuracy: 0.9915 - ignore_accuracy: 0.1738 - val_loss: 0.0633 - val_accuracy: 0.9143 - val_ignore_accuracy: 0.1588 - lr: 0.0050\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9947 - ignore_accuracy: 0.1745\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "16/16 [==============================] - 100s 6s/step - loss: 0.0067 - accuracy: 0.9947 - ignore_accuracy: 0.1745 - val_loss: 0.0632 - val_accuracy: 0.9145 - val_ignore_accuracy: 0.1589 - lr: 0.0050\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 99s 6s/step - loss: 0.0051 - accuracy: 0.9969 - ignore_accuracy: 0.1748 - val_loss: 0.0636 - val_accuracy: 0.9157 - val_ignore_accuracy: 0.1591 - lr: 0.0025\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9976 - ignore_accuracy: 0.1752\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "16/16 [==============================] - 104s 7s/step - loss: 0.0044 - accuracy: 0.9976 - ignore_accuracy: 0.1752 - val_loss: 0.0639 - val_accuracy: 0.9162 - val_ignore_accuracy: 0.1592 - lr: 0.0025\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9981 - ignore_accuracy: 0.1752\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.001.\n",
            "16/16 [==============================] - 100s 6s/step - loss: 0.0039 - accuracy: 0.9981 - ignore_accuracy: 0.1752 - val_loss: 0.0643 - val_accuracy: 0.9160 - val_ignore_accuracy: 0.1592 - lr: 0.0012\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 98s 6s/step - loss: 0.0036 - accuracy: 0.9983 - ignore_accuracy: 0.1752 - val_loss: 0.0646 - val_accuracy: 0.9156 - val_ignore_accuracy: 0.1591 - lr: 0.0010\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9985 - ignore_accuracy: 0.1751Restoring model weights from the end of the best epoch: 13.\n",
            "16/16 [==============================] - 100s 6s/step - loss: 0.0035 - accuracy: 0.9985 - ignore_accuracy: 0.1751 - val_loss: 0.0649 - val_accuracy: 0.9157 - val_ignore_accuracy: 0.1591 - lr: 0.0010\n",
            "Epoch 16: early stopping\n"
          ]
        }
      ],
      "source": [
        "results_add_lstm = add_lstm_model.fit(X_train, y_train_one_hot, epochs=20, verbose = True, \\\n",
        "                                      validation_data=(X_val, y_val_one_hot), batch_size=128, callbacks = callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ZRvFuiHCExgc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f9a0b86-89a7-418f-da46-f0bf6730f831"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 26s 644ms/step - loss: 0.0639 - accuracy: 0.9162 - ignore_accuracy: 0.1611\n",
            "41/41 [==============================] - 30s 587ms/step\n"
          ]
        }
      ],
      "source": [
        "scores_add_lstm = add_lstm_model.evaluate(X_val, y_val_one_hot, return_dict = True)\n",
        "\n",
        "predictions_add_lstm_one_hot_encode = add_lstm_model.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4FEmEZDOnwa",
        "outputId": "0d505eb9-3ec2-45e3-ab63-e567cd1f0da2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6695694551739614\n"
          ]
        }
      ],
      "source": [
        "predictions_add_lstm = np.argmax(predictions_add_lstm_one_hot_encode, axis=-1)\n",
        "\n",
        "mask = np.logical_not(np.isin(y_val, [tag2index[tag] for tag in ignore]))\n",
        "\n",
        "macro_f1_add_lstm = f1_score(y_val[mask], predictions_add_lstm[mask], average='macro')\n",
        "\n",
        "print(macro_f1_add_lstm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AtIybGnEzsP"
      },
      "source": [
        "### 3.4 Additional dense layer\n",
        "\n",
        "Using two dense layers, one with a non-linear activation function and one with a softmax activation function, is a common pattern in neural network architectures for classification tasks.\n",
        "\n",
        "The purpose of the non-linear dense layer is to introduce non-linearity into the model, which can allow the model to learn more complex patterns in the data. Common choices for the activation function in this layer include ReLU (Rectified Linear Unit), sigmoid, and tanh.\n",
        "\n",
        "The purpose of the softmax dense layer is to produce a probability distribution over the possible classes. The softmax activation function transforms the output of the preceding layer into a probability distribution, where the sum of the probabilities is equal to 1. This is useful for classification tasks, where you want to predict the probability that an input belongs to each of the possible classes. Using two dense layers in this way can allow the model to learn more complex patterns in the data and make more accurate predictions.\n",
        "\n",
        "We have increased the number of training epochs to 15 for the same reasons as before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQj_m12zE3So",
        "outputId": "50ff9840-ff9b-4156-b313-f41cce66d4dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Additional_FC\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 114, 300)          121123500 \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 114, 512)         1140736   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_3 (TimeDis  (None, 114, 114)         58482     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_4 (TimeDis  (None, 114, 45)          5175      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 122,327,893\n",
            "Trainable params: 1,204,393\n",
            "Non-trainable params: 121,123,500\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the model\n",
        "add_fc_model = tf.keras.Sequential(name='Additional_FC')\n",
        "\n",
        "# Add the Embedding layer\n",
        "add_fc_model.add(Embedding(input_dim=vocab_length, output_dim=embedding_dim, \\\n",
        "                    weights = [embedding_matrix], input_length = PAD_LENGTH, trainable=False, mask_zero=True))\n",
        "\n",
        "# Add the Bidirectional LSTM layer\n",
        "add_fc_model.add(Bidirectional(LSTM(units=256, return_sequences=True)))\n",
        "\n",
        "# Add another Dense layer\n",
        "add_fc_model.add(TimeDistributed(Dense(units=PAD_LENGTH, activation='relu')))\n",
        "\n",
        "# Add the Dense/Fully-Connected layer\n",
        "add_fc_model.add(TimeDistributed(Dense(units=len(tags_train), activation='softmax')))\n",
        "\n",
        "# Compile the model\n",
        "add_fc_model.compile(optimizer=Adam(0.01), loss='categorical_crossentropy', metrics=['accuracy',ignore_class_accuracy([tag2index[tag] for tag in ignore])])\n",
        "\n",
        "# Summary\n",
        "add_fc_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "49cnWYeiE5Jt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f3fc6da-d00f-433d-8216-4b9effdf0ebd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 63s 3s/step - loss: 0.4732 - accuracy: 0.3861 - ignore_accuracy: 0.0645 - val_loss: 0.2225 - val_accuracy: 0.6814 - val_ignore_accuracy: 0.1137 - lr: 0.0100\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 45s 3s/step - loss: 0.1474 - accuracy: 0.7978 - ignore_accuracy: 0.1353 - val_loss: 0.1110 - val_accuracy: 0.8444 - val_ignore_accuracy: 0.1448 - lr: 0.0100\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 49s 3s/step - loss: 0.0745 - accuracy: 0.8930 - ignore_accuracy: 0.1539 - val_loss: 0.0816 - val_accuracy: 0.8842 - val_ignore_accuracy: 0.1528 - lr: 0.0100\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 41s 3s/step - loss: 0.0442 - accuracy: 0.9363 - ignore_accuracy: 0.1625 - val_loss: 0.0691 - val_accuracy: 0.9020 - val_ignore_accuracy: 0.1564 - lr: 0.0100\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 44s 3s/step - loss: 0.0256 - accuracy: 0.9648 - ignore_accuracy: 0.1683 - val_loss: 0.0705 - val_accuracy: 0.9042 - val_ignore_accuracy: 0.1568 - lr: 0.0100\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 48s 3s/step - loss: 0.0156 - accuracy: 0.9801 - ignore_accuracy: 0.1715 - val_loss: 0.0704 - val_accuracy: 0.9083 - val_ignore_accuracy: 0.1576 - lr: 0.0100\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 41s 2s/step - loss: 0.0091 - accuracy: 0.9894 - ignore_accuracy: 0.1734 - val_loss: 0.0689 - val_accuracy: 0.9121 - val_ignore_accuracy: 0.1584 - lr: 0.0100\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9949 - ignore_accuracy: 0.1744\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "16/16 [==============================] - 40s 3s/step - loss: 0.0050 - accuracy: 0.9949 - ignore_accuracy: 0.1744 - val_loss: 0.0743 - val_accuracy: 0.9122 - val_ignore_accuracy: 0.1584 - lr: 0.0100\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 39s 2s/step - loss: 0.0025 - accuracy: 0.9985 - ignore_accuracy: 0.1753 - val_loss: 0.0754 - val_accuracy: 0.9137 - val_ignore_accuracy: 0.1587 - lr: 0.0050\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 39s 2s/step - loss: 0.0016 - accuracy: 0.9993 - ignore_accuracy: 0.1753 - val_loss: 0.0762 - val_accuracy: 0.9142 - val_ignore_accuracy: 0.1588 - lr: 0.0050\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996 - ignore_accuracy: 0.1755\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "16/16 [==============================] - 40s 3s/step - loss: 0.0013 - accuracy: 0.9996 - ignore_accuracy: 0.1755 - val_loss: 0.0781 - val_accuracy: 0.9142 - val_ignore_accuracy: 0.1588 - lr: 0.0050\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 0.9997 - ignore_accuracy: 0.1754\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "16/16 [==============================] - 39s 2s/step - loss: 0.0010 - accuracy: 0.9997 - ignore_accuracy: 0.1754 - val_loss: 0.0786 - val_accuracy: 0.9143 - val_ignore_accuracy: 0.1588 - lr: 0.0025\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - ETA: 0s - loss: 9.4576e-04 - accuracy: 0.9998 - ignore_accuracy: 0.1755\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.001.\n",
            "16/16 [==============================] - 43s 3s/step - loss: 9.4576e-04 - accuracy: 0.9998 - ignore_accuracy: 0.1755 - val_loss: 0.0790 - val_accuracy: 0.9141 - val_ignore_accuracy: 0.1588 - lr: 0.0012\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 40s 3s/step - loss: 9.1351e-04 - accuracy: 0.9999 - ignore_accuracy: 0.1755 - val_loss: 0.0794 - val_accuracy: 0.9140 - val_ignore_accuracy: 0.1588 - lr: 0.0010\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - ETA: 0s - loss: 8.8814e-04 - accuracy: 0.9999 - ignore_accuracy: 0.1755Restoring model weights from the end of the best epoch: 12.\n",
            "16/16 [==============================] - 39s 2s/step - loss: 8.8814e-04 - accuracy: 0.9999 - ignore_accuracy: 0.1755 - val_loss: 0.0796 - val_accuracy: 0.9141 - val_ignore_accuracy: 0.1588 - lr: 0.0010\n",
            "Epoch 15: early stopping\n"
          ]
        }
      ],
      "source": [
        "results_add_fc = add_fc_model.fit(X_train, y_train_one_hot, epochs=20, verbose = True, \\\n",
        "                                  validation_data=(X_val, y_val_one_hot), batch_size=128, callbacks = callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "dsOyrHcWE62j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "882a488d-226b-43aa-ebcd-fca1c9adc8d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 11s 275ms/step - loss: 0.0786 - accuracy: 0.9143 - ignore_accuracy: 0.1607\n",
            "41/41 [==============================] - 14s 270ms/step\n"
          ]
        }
      ],
      "source": [
        "scores_add_fc = add_fc_model.evaluate(X_val, y_val_one_hot, return_dict = True)\n",
        "\n",
        "predictions_add_fc_one_hot_encode = add_fc_model.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(ignore))\n",
        "print(ignore)\n",
        "\n",
        "print([_class for _class in tags_train if _class not in tags_val])\n",
        "\n",
        "print(tag2index)\n",
        "\n",
        "print([index2tag[tag] for tag in predicted_labels_add_fc[0]])\n",
        "\n",
        "print(index2tag[0])\n",
        "\n",
        "print(y_val[0])\n",
        "\n",
        "prova = [1 if el not in ignore else 0 for el in tags_val]\n",
        "\n",
        "print(prova)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9d0Mux5YXpr",
        "outputId": "0be2e136-d239-4ad3-e6ad-6aaf816f8b0b"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "[':', '#', '$', '-LRB-', '-RRB-', ',', '.', \"''\", '``', 'SYM']\n",
            "['SYM']\n",
            "OrderedDict([('#', 0), ('$', 1), (\"''\", 2), (',', 3), ('-LRB-', 4), ('-RRB-', 5), ('.', 6), (':', 7), ('CC', 8), ('CD', 9), ('DT', 10), ('EX', 11), ('FW', 12), ('IN', 13), ('JJ', 14), ('JJR', 15), ('JJS', 16), ('LS', 17), ('MD', 18), ('NN', 19), ('NNP', 20), ('NNPS', 21), ('NNS', 22), ('PDT', 23), ('POS', 24), ('PRP', 25), ('PRP$', 26), ('RB', 27), ('RBR', 28), ('RBS', 29), ('RP', 30), ('SYM', 31), ('TO', 32), ('UH', 33), ('VB', 34), ('VBD', 35), ('VBG', 36), ('VBN', 37), ('VBP', 38), ('VBZ', 39), ('WDT', 40), ('WP', 41), ('WP$', 42), ('WRB', 43), ('``', 44)])\n",
            "['DT', 'NN', 'NN', 'VBD', 'JJ', 'NNS', 'IN', 'DT', 'NN', 'IN', 'JJR', 'IN', '$', 'CD', 'CD', 'IN', 'JJ', 'NNS', 'IN', 'NNP', 'WDT', 'VBZ', 'RB', 'IN', '$', 'CD', 'CD', 'IN', 'NN', 'CC', 'VB', 'NN', 'IN', 'JJ', 'CD', 'IN', 'NN', 'IN', 'VBG', 'JJ', 'NN', 'CC', 'NN', '.', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP']\n",
            "#\n",
            "[10 20 19 35 14 22 13 10 19 13 15 13  1  9  9 13 14 19 13 20 40 39 27 13\n",
            "  1  9  9 13 19  8 19 22 13 14  9 13 22 13 36 14 19  8 19  6  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "7nKMHckAP4bZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "541703a8-ab7d-4998-91b7-fa4a300d3346"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-152-d08eb21bb92f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# print(predicted_labels_add_fc[mask].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels_add_fc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtags_train\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mignore\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2130\u001b[0m             )\n\u001b[1;32m   2131\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2132\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2133\u001b[0m                 \u001b[0;34m\"Number of classes, {0}, does not match size of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2134\u001b[0m                 \u001b[0;34m\"target_names, {1}. Try specifying the labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Number of classes, 39, does not match size of target_names, 35. Try specifying the labels parameter"
          ]
        }
      ],
      "source": [
        "# predicted_labels_add_fc = np.argmax(predictions_add_fc_one_hot_encode, axis=-1)\n",
        "\n",
        "# mask = np.logical_not(np.isin(y_val, [tag2index[tag] for tag in ignore]))\n",
        "\n",
        "# macro_f1_add_fc = f1_score(y_val[mask], predicted_labels_add_fc[mask], sample_weight = prova, average='macro')\n",
        "\n",
        "# print(macro_f1_add_fc)\n",
        "\n",
        "# from sklearn.metrics import classification_report\n",
        "\n",
        "# print(len(tags_train))\n",
        "\n",
        "# # meme = \n",
        "# # print(meme)\n",
        "\n",
        "# meme2 = [i for i in tags_val if i not in ignore]\n",
        "# print(len(meme2))\n",
        "\n",
        "# print(y_val.shape)\n",
        "# print(y_val[mask].shape)\n",
        "\n",
        "# print(predicted_labels_add_fc.shape)\n",
        "# print(predicted_labels_add_fc[mask].shape)\n",
        "\n",
        "print(classification_report(y_val[mask], predicted_labels_add_fc[mask], target_names = [i for i in tags_train if i not in [*ignore]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9ZTfE8sE81P"
      },
      "source": [
        "## 4. Comparisons\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "data = [macro_f1_bl,macro_f1_gru,macro_f1_add_lstm,macro_f1_add_fc]\n",
        "\n",
        "# Create figure\n",
        "fig = go.Figure(data=[go.Bar(x=['Baseline','GRU', 'Add. LSTM', 'Add. FC'], y=data)])\n",
        "\n",
        "# Set titles for axes\n",
        "fig.update_layout(title='Macro F1 Scores on validation set', xaxis_title='Models', yaxis_title='Macro F1')\n",
        "\n",
        "# Show plot\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "ShQ9GoTGzTK-",
        "outputId": "68899cc3-a5e0-4a6d-809c-025fe83f5f8c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"f69dad8e-b14e-4cd2-9596-29f98d798967\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f69dad8e-b14e-4cd2-9596-29f98d798967\")) {                    Plotly.newPlot(                        \"f69dad8e-b14e-4cd2-9596-29f98d798967\",                        [{\"x\":[\"Baseline\",\"GRU\",\"Add. LSTM\",\"Add. FC\"],\"y\":[0.7880790187142547,0.6143390727179829,0.6695694551739614,0.703094026562529],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Macro F1 Scores on validation set\"},\"xaxis\":{\"title\":{\"text\":\"Models\"}},\"yaxis\":{\"title\":{\"text\":\"Macro F1\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f69dad8e-b14e-4cd2-9596-29f98d798967');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60fNmjrgpCE3",
        "outputId": "402d67c6-af69-4289-c6b9-1abe1ba0a7b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([(0, '#'), (1, '$'), (2, \"''\"), (3, ','), (4, '-LRB-'), (5, '-NONE-'), (6, '-RRB-'), (7, '.'), (8, ':'), (9, 'CC'), (10, 'CD'), (11, 'DT'), (12, 'EX'), (13, 'FW'), (14, 'IN'), (15, 'JJ'), (16, 'JJR'), (17, 'JJS'), (18, 'LS'), (19, 'MD'), (20, 'NN'), (21, 'NNP'), (22, 'NNPS'), (23, 'NNS'), (24, 'PDT'), (25, 'POS'), (26, 'PRP'), (27, 'PRP$'), (28, 'RB'), (29, 'RBR'), (30, 'RBS'), (31, 'RP'), (32, 'SYM'), (33, 'TO'), (34, 'UH'), (35, 'VB'), (36, 'VBD'), (37, 'VBG'), (38, 'VBN'), (39, 'VBP'), (40, 'VBZ'), (41, 'WDT'), (42, 'WP'), (43, 'WP$'), (44, 'WRB'), (45, '``')])\n"
          ]
        }
      ],
      "source": [
        "print(index2tag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKhtcyT-cf6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a428975-455f-4790-adec-61fa2c2d3660"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test sentence: ['The', 'sad', 'reality', 'is', 'that', 'the', 'retail', 'investor', 'continues', 'to', 'pursue', 'stellar', 'performers', 'first', ',', 'while', 'leaving', 'institutions', 'to', 'grapple', 'with', 'basis', 'points', 'of', 'performance', 'on', 'large', 'sums', 'of', 'money', 'quarter', 'by', 'quarter', '.']\n",
            "Ground truth tags: ['DT', 'JJ', 'NN', 'VBZ', 'IN', 'DT', 'JJ', 'NN', 'VBZ', 'TO', 'VB', 'JJ', 'NNS', 'RB', ',', 'IN', 'VBG', 'NNS', 'TO', 'VB', 'IN', 'NN', 'NNS', 'IN', 'NN', 'IN', 'JJ', 'NNS', 'IN', 'NN', 'NN', 'IN', 'NN', '.']\n",
            "Baseline predictions: ['DT', 'NN', 'NN', 'VBZ', 'IN', '.', 'JJ', 'NN', 'VBZ', 'TO', 'VB', 'JJ', 'NNS', 'JJ', ',', 'IN', 'VBG', 'NNS', 'TO', 'VB', 'IN', 'JJ', 'NNS', 'IN', 'NN', 'IN', 'JJ', 'NNS', 'IN', 'NN', 'NN', 'IN', 'NN', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
            "GRU predictions: ['DT', 'JJ', 'NN', 'VBZ', 'IN', 'IN', 'NN', 'NN', 'VBZ', 'TO', 'VB', 'JJ', 'NNS', 'JJ', ',', 'IN', 'VBG', 'NNS', 'TO', 'VB', 'IN', 'JJ', 'NNS', 'IN', 'NN', 'IN', 'JJ', 'NNS', 'IN', 'NN', 'VBD', 'IN', 'NN', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
            "Additional LSTM layer predictions: ['DT', 'JJ', 'NN', 'VBZ', 'IN', '.', 'JJ', 'NN', 'VBZ', 'TO', 'VB', 'JJ', 'NNS', 'JJ', ',', 'IN', 'VBG', 'NNS', 'TO', 'VB', 'IN', 'JJ', 'NNS', 'IN', 'NN', 'IN', 'JJ', 'NNS', 'IN', 'NN', 'NN', 'IN', 'NN', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
            "Additional FC layer predictions: ['DT', 'NN', 'NN', 'VBZ', 'IN', 'NNP', 'JJ', 'NN', 'VBZ', 'TO', 'VB', 'JJ', 'NNS', 'JJ', ',', 'IN', 'VBG', 'NNS', 'TO', 'VB', 'IN', 'JJ', 'NNS', 'IN', 'NN', 'IN', 'JJ', 'NNS', 'IN', 'NN', 'VBN', 'IN', 'NN', '.', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP']\n"
          ]
        }
      ],
      "source": [
        "#Test phrase\n",
        "np.random.seed(41)\n",
        "idx = np.random.randint(0, len(X_val_np))\n",
        "\n",
        "print(f'Test sentence: {[index2word[word] for word in X_val_np[idx]]}') \n",
        "\n",
        "#ground truth\n",
        "print(f'Ground truth tags: {[index2tag[tag] for tag in y_val_np[idx]]}')\n",
        "\n",
        "#test bl\n",
        "print(f'Baseline predictions: {[index2tag[tag] for tag in predicted_labels_bl[idx]]}')\n",
        "#test gru\n",
        "print(f'GRU predictions: {[index2tag[tag] for tag in predicted_labels_gru[idx]]}')\n",
        "#test add lstm\n",
        "print(f'Additional LSTM layer predictions: {[index2tag[tag] for tag in predicted_labels_add_lstm[idx]]}')\n",
        "#test add fc\n",
        "print(f'Additional FC layer predictions: {[index2tag[tag] for tag in predicted_labels_add_fc[idx]]}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmH-ZgHak9ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e372d948-3ea0-495d-99a5-7cdc844ffe48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 12s 565ms/step\n",
            "No true positive for tag: PDT\n",
            "0\n",
            "0\n",
            "4\n",
            "\n",
            "MACRO F1-score: 0.8937388742557075\n"
          ]
        }
      ],
      "source": [
        "#Computing macro scores on test set\n",
        "#Additional LSTM layer\n",
        "predictions_add_lstm_test = add_lstm_model.predict(X_test)\n",
        "\n",
        "predicted_labels_add_lstm_test = np.argmax(predictions_add_lstm_test, axis=-1)\n",
        "\n",
        "true_pos_add_lstm_test, false_pos_add_lstm_test, false_neg_add_lstm_test, precision_add_lstm_test, recall_add_lstm_test, f1score_add_lstm_test = compute_metrics(predicted_labels_add_lstm_test, tags_test, ignore, y_test, index2tag)\n",
        "\n",
        "macro_f1_add_lstm_test = macro_f1_score(f1score_add_lstm_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Computing macro scores on test set\n",
        "#Additional FC layer\n",
        "predictions_add_fc_test = add_fc_model.predict(X_test)\n",
        "\n",
        "predicted_labels_add_fc_test = np.argmax(predictions_add_fc_test, axis=-1)\n",
        "\n",
        "true_pos_add_fc_test, false_pos_add_fc_test, false_neg_add_fc_test, precision_add_fc_test, recall_add_fc_test, f1score_add_fc_test = compute_metrics(predicted_labels_add_fc_test, tags_test, ignore, y_test, index2tag)\n",
        "\n",
        "macro_f1_add_fc_test = macro_f1_score(f1score_add_fc_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ErUcAHqIEWY",
        "outputId": "d77d3e5c-bea7-4c95-8b14-e739a0b08bc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 6s 263ms/step\n",
            "No true positive for tag: PDT\n",
            "0\n",
            "0\n",
            "4\n",
            "\n",
            "MACRO F1-score: 0.8614731552341435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxBqGcszE-Ui",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6dcde811-8c17-4406-d4ae-4816668d2791"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"a650ada9-fb4c-4254-b5cc-7bc012244f32\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a650ada9-fb4c-4254-b5cc-7bc012244f32\")) {                    Plotly.newPlot(                        \"a650ada9-fb4c-4254-b5cc-7bc012244f32\",                        [{\"mode\":\"lines+markers\",\"name\":\"Baseline - BiLSTM Model\",\"x\":[1,2,3,4,5,6,7,8,9,10],\"y\":[0.7688378095626831,0.8578342199325562,0.8796128034591675,0.9003495573997498,0.9071385264396667,0.9067688584327698,0.9112052321434021,0.9106338620185852,0.9090878367424011,0.9098272323608398],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"GRU Model\",\"x\":[1,2,3,4,5,6,7,8,9,10],\"y\":[0.7904819250106812,0.8498353362083435,0.8672783374786377,0.8810580372810364,0.8854944109916687,0.8918128609657288,0.892417848110199,0.8925522565841675,0.8946696519851685,0.8947368264198303,0.8951737284660339,0.8944343328475952,0.8947368264198303,0.894804060459137],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a650ada9-fb4c-4254-b5cc-7bc012244f32');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"f2a8ea14-86fd-4a16-b934-ca54ff61bac1\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f2a8ea14-86fd-4a16-b934-ca54ff61bac1\")) {                    Plotly.newPlot(                        \"f2a8ea14-86fd-4a16-b934-ca54ff61bac1\",                        [{\"mode\":\"lines+markers\",\"name\":\"2 BiLSTMs Model\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\"y\":[0.33027490973472595,0.6584324836730957,0.7994555234909058,0.8369295001029968,0.8760166764259338,0.8956443071365356,0.9102977514266968,0.9168851375579834,0.9181286692619324,0.9200779795646667,0.9192713499069214,0.9217584133148193,0.9238085746765137,0.9230355620384216,0.9237749576568604,0.923842191696167,0.9239429831504822,0.9241110682487488,0.9241446256637573,0.9243463277816772],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"2 FCs Model\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\"y\":[0.7192646265029907,0.846340000629425,0.8844861388206482,0.9028366208076477,0.9129865169525146,0.9137594699859619,0.9175572991371155,0.9175236821174622,0.9170195460319519,0.9180614352226257,0.9171540141105652,0.917422890663147,0.9173556566238403],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f2a8ea14-86fd-4a16-b934-ca54ff61bac1');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# # Create a list of epochs (i.e., the x-axis data)\n",
        "epochs = list(range(1, len(results_baseline.history['val_accuracy'])+1))\n",
        "\n",
        "# # Create a Plotly line plot using the epochs and validation accuracy data\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=epochs, y=results_baseline.history['val_accuracy'], name='Baseline - BiLSTM Model', mode='lines+markers'))\n",
        "fig.add_trace(go.Scatter(x=epochs, y=results_gru.history['val_accuracy'], name='GRU Model', mode='lines+markers'))\n",
        "fig.show()\n",
        "\n",
        "# Create a list of epochs (i.e., the x-axis data)\n",
        "epochs = list(range(1, len(results_add_lstm.history['val_accuracy'])+1))\n",
        "\n",
        "fig2 = go.Figure()\n",
        "fig2.add_trace(go.Scatter(x=epochs, y=results_add_lstm.history['val_accuracy'], name='2 BiLSTMs Model', mode='lines+markers'))\n",
        "fig2.add_trace(go.Scatter(x=epochs, y=results_add_fc.history['val_accuracy'], name='2 FCs Model', mode='lines+markers'))\n",
        "fig2.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}