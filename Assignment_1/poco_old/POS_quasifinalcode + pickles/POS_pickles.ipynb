{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "013gFxfmSmXR"
      },
      "source": [
        "https://github.com/pranavphoenix/BiLSTM-POS-Tagging/blob/main/BiLSTM_POS_Tagging.ipynb\n",
        "\n",
        "https://linguistics.stackexchange.com/questions/16897/unable-to-understand-meaning-of-tag-none-1-in-penn-treebank-example\n",
        "\n",
        "TODO:\n",
        "- Cacasburo\n",
        "- Guardare creazione dizionario, bisogna rispettare i punti dell'assignment;\n",
        "- Non togliere punctuation e symbols ma evitare di utilizzarli nel calcolo delle metriche, magari utilizzando l'array di pesi 'sample_weight' che si trova nell'altro notebook;\n",
        "- Provare se i risultati migliorano con preprocessing (e.g. lowerando le parole);\n",
        "- Aggiustare il notebook perché fa cagare;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0BInycOeQL6"
      },
      "source": [
        "# Assignment 1\n",
        "\n",
        "**Due to**: 11/01/2022 (dd/mm/yyyy)\n",
        "\n",
        "If you deliver it by 11/12/2021 your assignment will be graded by 11/01/2022.\n",
        "\n",
        "\n",
        "**Credits**: Andrea Galassi, Federico Ruggeri, Paolo Torroni\n",
        "\n",
        "**Summary**: Part-of Speech (POS) tagging as Sequence Labelling using Recurrent Neural Architectures\n",
        "\n",
        "# Execution\n",
        "## 0.1 Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG34ukA4kQZB",
        "outputId": "dbe8ae50-987d-4ffb-e001-43b24e20ba94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting progressbar\n",
            "  Using cached progressbar-2.5.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: progressbar\n",
            "  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12081 sha256=04f273d81affd1b3688c149730e9531bada2e12f950a4b37b9ffcc5c5782bb8e\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/67/ed/d84123843c937d7e7f5ba88a270d11036473144143355e2747\n",
            "Successfully built progressbar\n",
            "Installing collected packages: progressbar\n",
            "Successfully installed progressbar-2.5\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras_preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from keras_preprocessing) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.8/dist-packages (from keras_preprocessing) (1.21.6)\n",
            "Installing collected packages: keras_preprocessing\n",
            "Successfully installed keras_preprocessing-1.1.2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install progressbar\n",
        "\n",
        "!pip install keras_preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZyCAH8nVzwS"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from collections import defaultdict, OrderedDict\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, GRU, Embedding, Activation\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import progressbar\n",
        "from IPython.display import display_html\n",
        "from itertools import chain,cycle\n",
        "\n",
        "import plotly.graph_objs as go\n",
        "import plotly.express as px\n",
        "\n",
        "import pickle\n",
        "import gc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6adQpSgiV3A3"
      },
      "source": [
        "## 0.2 Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9933jZXvV9M"
      },
      "source": [
        "### Utils - data analysis - plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJC6GZcWvQcl"
      },
      "outputs": [],
      "source": [
        "# Progress bar\n",
        "pbar = None\n",
        "def show_progress(block_num, block_size, total_size):\n",
        "    global pbar\n",
        "    if pbar is None:\n",
        "        pbar = progressbar.ProgressBar(maxval=total_size)\n",
        "        pbar.start()\n",
        "\n",
        "    downloaded = block_num * block_size\n",
        "    if downloaded < total_size:\n",
        "        pbar.update(downloaded)\n",
        "    else:\n",
        "        pbar.finish()\n",
        "        pbar = None\n",
        "\n",
        "# Setting the seeds\n",
        "def set_reproducibility(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "           \n",
        "# Display dataframes\n",
        "def display(*args,titles=cycle([''])):\n",
        "    html_str=''\n",
        "    for df,title in zip(args, chain(titles,cycle(['</br>'])) ):\n",
        "        html_str+='<th style=\"text-align:left\"><td style=\"vertical-align:top\">'\n",
        "        html_str+=f'<h4 style=\"text-align: left;\">{title}</h2>'\n",
        "        html_str+=df.to_html().replace('table','table style=\"display:inline\"')\n",
        "        html_str+='</td></th>'\n",
        "    display_html(html_str,raw=True)\n",
        "\n",
        "# Show mismatches of classes in different sets\n",
        "def tags_mismatch(tags1,tags2,tags3,name1,name2,name3):\n",
        "\n",
        "  print(f'{name1} tags number: {len(tags1)}')\n",
        "  print(f'{name1} tags list: {tags1}')\n",
        "\n",
        "  exceeding_validation = [el for el in tags1 if el not in tags2]\n",
        "  if exceeding_validation != []:\n",
        "    print(f'\\tClasses in {name1} set for which there are no samples in {name2} set: {exceeding_validation}')\n",
        "\n",
        "  exceeding_test = [el for el in tags1 if el not in tags3]\n",
        "\n",
        "  if exceeding_test != []:\n",
        "    print(f'\\tClasses in {name1} set for which there are no samples in {name3} set: {exceeding_test}\\n')\n",
        "\n",
        "\n",
        "# Histograms of occurencies of words by tag\n",
        "def plot_value_counts(df, key, name):\n",
        "    values = df[key].value_counts()\n",
        "    fig = px.bar(x=values.index, y=values.values)\n",
        "    fig.update_layout(xaxis_title=key,\n",
        "                      yaxis_title='Occurencies of words',\n",
        "                      title=f'{name} set words per tag')\n",
        "    fig.show()\n",
        "\n",
        "# Plot tag distribution per sentence   \n",
        "def plot_tag_distribution(tag_lists,name):\n",
        "    tag_counts = []\n",
        "    for tags in tag_lists:\n",
        "        tag_dict = {}\n",
        "        for tag in tags:\n",
        "            if tag in tag_dict:\n",
        "                tag_dict[tag] += 1\n",
        "            else:\n",
        "                tag_dict[tag] = 1\n",
        "        tag_counts.append(tag_dict)\n",
        "    \n",
        "    df = pd.DataFrame(tag_counts)\n",
        "    df = df.fillna(0)\n",
        "    df = df.apply(lambda x: x / sum(x) * 100)\n",
        "    \n",
        "    fig = px.line(df, title=f'Tag Distribution per {name} Sentence')\n",
        "    fig.show()\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVK6uNmSvKyp"
      },
      "source": [
        "### Vocabulary and OOV handling\n",
        "\n",
        "To compute the embeddings for out-of-vocabulary (OOV) words, we took the mean of existing embeddings related to the words with the same part of speech (POS) tag and addded noise. This approach is based on the assumption that words with similar POS tags are semantically similar, and therefore, their embeddings should also be similar. Taking the mean of the existing embeddings provides a general representation of the semantic space of the words with similar POS tags, and adding noise helps to avoid overfitting by making the embeddings for the OOV words slightly different from each other.\n",
        "\n",
        "This approach can be effective in some cases, especially if the number of OOV words is small and their semantic similarity to the in-vocabulary (IV) words is high. However, it's important to keep in mind that this approach may not always be the best option, as the quality of the OOV word embeddings depends on the quality and diversity of the IV word embeddings used to compute the mean. If the IV word embeddings are not representative of the words with similar POS tags, the OOV word embeddings may not be of good quality.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxL2umB0D19Y"
      },
      "outputs": [],
      "source": [
        "# Compute embeddings based on the respective tag means.\n",
        "def mean_embed4tag(df, tags, embedding_dict, embedding_dim):\n",
        "  tag_dict = {tag:np.zeros(embedding_dim) for tag in tags}\n",
        "  tag_count = {tag:0 for tag in tags}\n",
        "  count = 0\n",
        "\n",
        "  for idx, row in df.iterrows():\n",
        "    for tag in tags:\n",
        "      if tag == row['tag']:\n",
        "        if row['word'].lower() in embedding_dict:\n",
        "            tag_count[tag] += 1\n",
        "            tag_dict[tag] += embedding_dict[row['word'].lower()]\n",
        "\n",
        "  for tag in tags:\n",
        "    if np.all(tag_dict[tag]):\n",
        "      tag_dict[tag] = tag_dict[tag] / tag_count[tag]\n",
        "  print(f'Computed mean embeddings for {len(tags)} tags.')\n",
        "  return tag_dict\n",
        "   \n",
        "#Update vocabulary\n",
        "def update_vocab(df,embeddings_index,tag_dict,embedding_dim,seed=42): \n",
        "  oov_c = 0 \n",
        "  cap_oov = 0\n",
        "  np.random.seed(seed)\n",
        "  for idx, row in df.iterrows():\n",
        "    if row['word'] not in embeddings_index:\n",
        "      if row['word'].lower() not in embeddings_index:\n",
        "        oov_c += 1\n",
        "        noise = np.random.normal(0, 0.0001, size=embedding_dim)\n",
        "        embeddings_index[row['word']] = tag_dict[row['tag']] + noise       \n",
        "      else:\n",
        "        cap_oov += 1  \n",
        "        embeddings_index[row['word']] = embeddings_index[row['word'].lower()]\n",
        "\n",
        "  counts = [oov_c,cap_oov,0]\n",
        "  print(f'Added {oov_c} OOV words + respective embeddings to the vocabulary.')\n",
        "  print(f'Added {cap_oov} Capitalized words + respective embeddings to the vocabulary.')\n",
        "  return embeddings_index, counts\n",
        "\n",
        "# Encode sentences and tags\n",
        "def encode_sentences(raw_sentences,raw_tags,vocab,tags):\n",
        "  encoded_sentences = []\n",
        "  encoded_tags = []\n",
        "  for sentence in raw_sentences:\n",
        "      sent_int = []\n",
        "      for word in sentence:\n",
        "            sent_int.append(vocab[word])\n",
        "      encoded_sentences.append(sent_int)\n",
        "\n",
        "  for sent_tags in raw_tags:\n",
        "    encoded_tags.append([tags[tag] for tag in sent_tags])\n",
        "\n",
        "  return encoded_sentences, encoded_tags"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmVdrR1Lw54R"
      },
      "source": [
        "### Custom metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fU_LPuN7xn3l"
      },
      "source": [
        "This function first computes the per-sample accuracy, which is a binary tensor indicating whether the prediction for each sample is correct or not. Then, it multiplies the per-sample accuracy with the weights for the corresponding true class to obtain a weighted per-sample accuracy.\n",
        "\n",
        "Next, it creates a binary ignore mask indicating which samples should be ignored in the computation of the overall accuracy. The mask is initialized as all ones and then updated to exclude the samples with the class labels specified in the classes argument.\n",
        "\n",
        "Finally, it computes the overall weighted accuracy by summing the weighted per-sample accuracy and dividing by the number of non-ignored samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gir7yWDHw8eZ"
      },
      "outputs": [],
      "source": [
        "# Custom metric\n",
        "# Weighted ignore class accuracy\n",
        "\n",
        "def ignore_class_accuracy(weights, classes=[]):\n",
        "  \n",
        "    @tf.function\n",
        "    def weighted_ignore_accuracy(y_true, y_pred):\n",
        "        y_true_class = K.argmax(y_true, axis=-1)\n",
        "        y_pred_class = K.argmax(y_pred, axis=-1)\n",
        "        \n",
        "        per_sample_accuracies = K.cast(K.equal(y_true_class, y_pred_class), 'float32')\n",
        "        weighted_per_sample_accuracies = per_sample_accuracies * K.gather(weights, y_true_class)\n",
        "        \n",
        "        ignore_mask = K.ones_like(y_pred_class, dtype='int32')\n",
        "        for to_ignore in classes:\n",
        "          ignore_mask = K.cast(K.not_equal(y_pred_class, to_ignore), 'int32') * ignore_mask\n",
        "        \n",
        "        weighted_acc = K.sum(weighted_per_sample_accuracies * K.cast(ignore_mask, 'float32')) / K.maximum(K.cast(K.sum(ignore_mask), 'float32'), 1)\n",
        "\n",
        "\n",
        "        return weighted_acc\n",
        "    return weighted_ignore_accuracy\n",
        "\n",
        "\n",
        "    \n",
        "# Compute the mean of the metrics\n",
        "def mean_metrics(models):\n",
        "  ignore_values = {\n",
        "    'macro_f1': [r['macro_f1'] for r in models],\n",
        "    'weighted_ignore_accuracy': [r['scores']['weighted_ignore_accuracy'] for r in models]\n",
        "  }\n",
        "\n",
        "  mean_ignore_values = {k: np.mean(v) for k, v in ignore_values.items()}\n",
        "\n",
        "  print(\"Mean values:\", mean_ignore_values)\n",
        "\n",
        "  return mean_ignore_values\n",
        "\n",
        "def compute_weights(df, ignore, tag2index):\n",
        "    # Words per tag in train set\n",
        "    tag_counts = df['tag'].value_counts()\n",
        "    # Encoding and sorting by the tag vocab index\n",
        "    index = tag_counts.index.map(lambda x: tag2index.get(x, 0))\n",
        "    encoded_tc = pd.DataFrame(tag_counts.values, index=index)\n",
        "    encoded_tc = encoded_tc.sort_index()\n",
        "    sorted_tc = encoded_tc.values\n",
        "    # Normalizing the values\n",
        "    weights = sorted_tc / sorted_tc.sum()\n",
        "    # Adding the pad weight\n",
        "    weights = np.insert(weights, 0, 0.01)\n",
        "    # Reversing the values for weights\n",
        "    weights = [1 - i for i in weights]\n",
        "    print('Weights: ')\n",
        "    print(weights)\n",
        "\n",
        "    return weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMzKWnhEylAm"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yv_HHpAhWLic"
      },
      "outputs": [],
      "source": [
        "# Main function to run models/evaluations/predictions/scores.\n",
        "def run_models(name,layer_params,embedding_params,training_params,metrics,LR,seeds):\n",
        "  model_recaps = []\n",
        "\n",
        "  for seed in seeds:\n",
        "      print(f'Running with seed: {seed}')\n",
        "      set_reproducibility(seed)\n",
        "      \n",
        "      # Define the model\n",
        "      tf.keras.backend.clear_session()\n",
        "      names = f'{name}_{seed}'\n",
        "      model = Sequential(name=names)\n",
        "      \n",
        "      # Add the Embedding layer\n",
        "      model.add(Embedding(**embedding_params, trainable=False))\n",
        "\n",
        "      # Add layers\n",
        "      for layer_param in layer_params:\n",
        "          layer_type = layer_param['layer_type']\n",
        "          layer_kwargs = layer_param['layer_kwargs']\n",
        "          if layer_type == \"Bidirectional\":\n",
        "                layer = Bidirectional(LSTM(**layer_kwargs,return_sequences=True))\n",
        "          elif layer_type == \"Dense\":\n",
        "                layer = TimeDistributed(Dense(**layer_kwargs))\n",
        "          elif layer_type == \"GRU\":\n",
        "                layer = GRU(**layer_kwargs,return_sequences=True)\n",
        "          model.add(layer)\n",
        "\n",
        "      # Compile the model\n",
        "      model.compile(optimizer=Adam(LR), loss='categorical_crossentropy', metrics=metrics)\n",
        "\n",
        "      # Summary\n",
        "      model.summary()\n",
        "      \n",
        "      # Fitting the model\n",
        "      print(f'\\nFitting the {name} (seed {seed}) model...')\n",
        "      history = model.fit(**training_params)\n",
        "      \n",
        "      # Obtain the predictions made by the model on the validation set\n",
        "      print(f'Evaluating the {name} (seed {seed}) model...')\n",
        "      scores = model.evaluate(X_val, y_val_one_hot, return_dict = True)\n",
        "\n",
        "      print(f'Obtaining predictions from the {name} (seed {seed}) model...')\n",
        "      predictions_one_hot_encode = model.predict(X_val)\n",
        "\n",
        "      # Convert the class probabilities into class labels\n",
        "      predictions = np.argmax(predictions_one_hot_encode, axis=-1)\n",
        "\n",
        "      # Create a binary mask for the classes to exclude\n",
        "      mask = np.logical_not(np.isin(y_val, [tag2index[tag] for tag in ignore]))\n",
        "\n",
        "      # Use the mask to exclude the classes that are in the list from the true positive, false positive, and false negative counts\n",
        "      macro_f1= f1_score(y_val[mask], predictions[mask], average='macro')\n",
        "\n",
        "      model_recap = {\n",
        "          \"name\": names,\n",
        "          \"model\": model,\n",
        "          \"history\": history,\n",
        "          \"scores\": scores,\n",
        "          \"predictions\": predictions,\n",
        "          \"macro_f1\": macro_f1\n",
        "      }\n",
        "\n",
        "      model_recaps.append(model_recap)\n",
        "\n",
        "      print(f'\\nMacro f1 score: {macro_f1}\\n')\n",
        "      \n",
        "      \n",
        "      print(f'Garbage collection: {gc.collect()}')\n",
        "\n",
        "  return model_recaps\n",
        "\n",
        "# Test function\n",
        "def test_f(model_recaps,X_test,X_test_np,y_test,y_test_one_hot,tag2index,index2tag,ignore):\n",
        "  mean_test = []\n",
        "  for i in range(len(model_recaps)):\n",
        "    print(f'Evaluating model {i+1} with the Test set:')\n",
        "    scores_add_lstm = model_recaps[i][\"model\"].evaluate(X_test, y_test_one_hot, return_dict = True)\n",
        "\n",
        "    predictions_one_hot_encode = model_recaps[i][\"model\"].predict(X_test)\n",
        "\n",
        "    # Convert the class probabilities into class labels\n",
        "    predictions = np.argmax(predictions_one_hot_encode, axis=-1)\n",
        "\n",
        "    # Create a binary mask for the classes to exclude\n",
        "    mask = np.logical_not(np.isin(y_test, [tag2index[tag] for tag in ignore]))\n",
        "\n",
        "    # Use the mask to exclude the classes that are in the list from the true positive, false positive, and false negative counts\n",
        "    macro_f1 = f1_score(y_test[mask], predictions[mask], average='macro')\n",
        "    mean_test.append(macro_f1)\n",
        "    print(f'Macro f1 score for model {i+1}: {macro_f1}\\n')\n",
        "\n",
        "  print(f'Mean macro f1 score on test set: {np.mean(mean_test)}\\n')\n",
        "\n",
        "  # POS-tagging a random test phrase\n",
        "  idx = np.random.randint(0, len(X_test_np))\n",
        "\n",
        "  print(f'Test sentence: {[index2word[word] for word in X_test_np[idx]]}') \n",
        "\n",
        "  # Ground truth\n",
        "  print(f'Ground truth tags: {[index2tag[tag] for tag in y_test_np[idx]]}')\n",
        "\n",
        "  # Test \n",
        "  print(f'Predictions: {[index2tag[tag] for tag in predictions[idx] if index2tag[tag] != \"-PAD-\"]}')\n",
        "\n",
        "  return mean_test, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUWmRON8D80m",
        "outputId": "b087d586-f656-4976-bb8f-1b8e6b7be602"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Downloading the dataset\n",
        "nltk.download('treebank')\n",
        "\n",
        "# Download the GloVe embeddings file\n",
        "url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
        "urllib.request.urlretrieve(url, 'glove.6B.zip', show_progress)\n",
        "\n",
        "# Extract the zip file\n",
        "zip_ref = zipfile.ZipFile('glove.6B.zip', 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5filE0ydeiga"
      },
      "source": [
        "## 1. Corpus\n",
        "### 1.1 Pre-processing\n",
        "\n",
        "The `-NONE-` tag in the Natural Language Toolkit (NLTK) is used to represent words or tokens that do not have a specific Part-of-Speech (POS) tag. Removing these occurances from the data can be useful for a POS-tagging task as it reduces the noise in the data and improves the quality of the results. By removing the `-NONE-` tags, the model will have fewer examples of unstructured data to learn from and can instead focus on the examples that are more relevant to the task of POS-tagging. This can help the model learn more accurate patterns and relationships between words and their corresponding POS tags, leading to more accurate results in the end."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ulx6UMBHint"
      },
      "outputs": [],
      "source": [
        "# Get the files' list\n",
        "fileids = nltk.corpus.treebank.fileids()\n",
        "\n",
        "# Get the Penn Treebank tagged sentences\n",
        "train_corpus = nltk.corpus.treebank.tagged_sents(fileids[:100])\n",
        "val_corpus = nltk.corpus.treebank.tagged_sents(fileids[100:150])\n",
        "test_corpus = nltk.corpus.treebank.tagged_sents(fileids[150:])\n",
        "\n",
        "# Flatten the lists\n",
        "train_corpus = [tuple(list(item)+[str(idx)]) for idx,sublist in enumerate(train_corpus) for item in sublist if item[1] != '-NONE-']\n",
        "val_corpus = [tuple(list(item)+[str(idx)]) for idx,sublist in enumerate(val_corpus) for item in sublist if item[1] != '-NONE-']\n",
        "test_corpus = [tuple(list(item)+[str(idx)]) for idx,sublist in enumerate(test_corpus) for item in sublist if item[1] != '-NONE-']\n",
        "\n",
        "# Create the Dataframes\n",
        "train_df = pd.DataFrame(train_corpus, columns = ['word', 'tag', 'sentence'])\n",
        "val_df = pd.DataFrame(val_corpus, columns = ['word', 'tag', 'sentence'])\n",
        "test_df = pd.DataFrame(test_corpus, columns = ['word', 'tag', 'sentence'])\n",
        "\n",
        "# Summary of the created Dataframes\n",
        "display(train_df.describe(), val_df.describe(), test_df.describe(), titles = [f'Training set {train_df.shape}', f'Validation set {val_df.shape}', f'Test set {test_df.shape}'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txf7hXzJNYmq"
      },
      "source": [
        "The number of words and in particular unique words in each set is different, with the training set having the most and the test set having the least.\n",
        "\n",
        "The most frequent word in each set is `,` and the most frequent tag is `NN` (noun, singular or mass). This suggests that the datasets might have a large number of common words and that nouns might be the most frequent part of speech in the text, apart from the comma that will be ignored in the final scores computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6MOWORPI8Va",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Ordering tags in the sets\n",
        "tags_train = sorted(list(set([x for x in train_df.tag])))\n",
        "tags_val = sorted(list(set([x for x in val_df.tag])))\n",
        "tags_test = sorted(list(set([x for x in test_df.tag])))\n",
        "\n",
        "max_tags_list = max([len(tags_train),len(tags_val),len(tags_test)])\n",
        "\n",
        "# Training set tags list\n",
        "tags_mismatch(tags_train,tags_val,tags_test,'Training','Validation','Test')\n",
        "\n",
        "# Validation set tags list\n",
        "tags_mismatch(tags_val,tags_train,tags_test,'Validation','Training','Test')\n",
        "\n",
        "# Test set tags list\n",
        "tags_mismatch(tags_test,tags_train,tags_val,'Test','Training','Validation')\n",
        "\n",
        "# Histograms of occurencies of words per tag   \n",
        "plot_value_counts(train_df, 'tag', 'Training')\n",
        "plot_value_counts(val_df, 'tag', 'Validation')\n",
        "plot_value_counts(test_df, 'tag', 'Test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbM0D6KxRn_V"
      },
      "source": [
        "The most frequent tags in each set are similar, with Nouns (NN) being the most frequent, followed by prepositions (IN), determiners (DT), and proper nouns (NNP), this suggests that nouns and prepositions are the most frequent parts of speech in the text, and that the datasets are similar in terms of the distribution of tags.\n",
        "\n",
        "The analysis of these distributions will be crucial in setting the weights to counteract the unbalanceness of the datasets while looking at the metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlBmUbmIlG0o"
      },
      "outputs": [],
      "source": [
        "# Retriving prepocessed data and grouping in sentences\n",
        "X_train_raw = train_df.groupby('sentence').word.apply(list).reset_index()['word']\n",
        "X_val_raw = val_df.groupby('sentence').word.apply(list).reset_index()['word']\n",
        "X_test_raw = test_df.groupby('sentence').word.apply(list).reset_index()['word']\n",
        "\n",
        "y_train_raw = train_df.groupby('sentence').tag.apply(list).reset_index()['tag']\n",
        "y_val_raw = val_df.groupby('sentence').tag.apply(list).reset_index()['tag']\n",
        "y_test_raw = test_df.groupby('sentence').tag.apply(list).reset_index()['tag']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9P26syf0c8W7"
      },
      "outputs": [],
      "source": [
        "# Plot tag distributions per sentence\n",
        "plot_tag_distribution(y_train_raw,'Training')\n",
        "plot_tag_distribution(y_val_raw,'Validation')\n",
        "plot_tag_distribution(y_test_raw,'Test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVQuhEkqk8xo"
      },
      "source": [
        "As expected, looking at the tag distribution per sentence plots, the minority classes in the dataset have occurences only in some sentences in all the three datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5kuIrRML6i2"
      },
      "source": [
        "##-Vocabulary part-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W8oM6e9LIMt"
      },
      "source": [
        "GloVe Vocabulary (V1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "675MhAFGFQNj",
        "outputId": "174de8d2-7760-4460-da27-7166a40b1266"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n",
            "Computed mean embeddings for 45 tags.\n"
          ]
        }
      ],
      "source": [
        "#Use the 300 dimensional GLove Word Embeddings\n",
        "glove_dir = './'\n",
        "embedding_dim = 300\n",
        "embedding_dict = {} #initialize dictionary\n",
        "f = open(os.path.join(glove_dir, f'glove.6B.{embedding_dim}d.txt'), encoding=\"utf8\")\n",
        "lines = f.readlines()\n",
        "f.close()\n",
        "\n",
        "pbar = progressbar.ProgressBar()\n",
        "for line in pbar(lines):\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embedding_dict[word] = coefs\n",
        "\n",
        "print('Found %s word vectors.' % len(embedding_dict))\n",
        "\n",
        "# Computing mean embeddings per tag\n",
        "tag_dict = mean_embed4tag(train_df, tags_train, embedding_dict, embedding_dim)\n",
        "\n",
        "counts = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i896YzW_LSxU"
      },
      "source": [
        "V1 + Training set OOV (V2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XGUNPlD0LYzI",
        "outputId": "703280ad-4f79-4c11-d2ea-2ef0720a750f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added 363 OOV words + respective embeddings to the vocabulary.\n",
            "Added 1983 Capitalized words + respective embeddings to the vocabulary.\n"
          ]
        }
      ],
      "source": [
        "# Computing the embeddings for the OOV words found in training set\n",
        "embedding_dict, counts_1 = update_vocab(train_df,embedding_dict,tag_dict,embedding_dim)\n",
        "counts.append(counts_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y0leABCLdUN"
      },
      "source": [
        "V2 + Validation set OOV (V3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8t-ArNTCLeKY",
        "outputId": "0dc12a0b-d27d-4bad-b104-b7cc4a4236c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added 190 OOV words + respective embeddings to the vocabulary.\n",
            "Added 754 Capitalized words + respective embeddings to the vocabulary.\n"
          ]
        }
      ],
      "source": [
        "# Computing the embeddings for the OOV words found in validation set\n",
        "embedding_dict, counts_2 = update_vocab(val_df,embedding_dict,tag_dict,embedding_dim)\n",
        "counts.append(counts_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOF5z9auLf7z"
      },
      "source": [
        "V3 + Test set OOV (V4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "I_JWqKoDLjBD",
        "outputId": "7d723a64-c02c-42bf-c5b4-3227e5a655f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added 129 OOV words + respective embeddings to the vocabulary.\n",
            "Added 326 Capitalized words + respective embeddings to the vocabulary.\n"
          ]
        }
      ],
      "source": [
        "# Computing the embeddings for the OOV words found in test set\n",
        "embedding_dict, counts_3 = update_vocab(test_df,embedding_dict,tag_dict,embedding_dim)\n",
        "counts.append(counts_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FKuxUTPNLkhz",
        "outputId": "573703fc-4e87-46b0-ae96-07235a81ba52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Debug] Index -> Word vocabulary size: 403746\n",
            "[Debug] Word -> Index vocabulary size: 403746\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"e2a5630f-c151-4fa6-8a41-5132d3eee61f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e2a5630f-c151-4fa6-8a41-5132d3eee61f\")) {                    Plotly.newPlot(                        \"e2a5630f-c151-4fa6-8a41-5132d3eee61f\",                        [{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"hovertemplate\":\"label=%{label}<br>value=%{value}<extra></extra>\",\"labels\":[\"OOV words\",\"Cap. words\",\"IV words\"],\"legendgroup\":\"\",\"name\":\"\",\"showlegend\":true,\"values\":[682,3063,400000],\"type\":\"pie\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e2a5630f-c151-4fa6-8a41-5132d3eee61f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Building the actual word vocabulary\n",
        "index2word = OrderedDict()\n",
        "word2index = OrderedDict()\n",
        "\n",
        "# Adding the entry for padding\n",
        "index2word[0] = '-PAD-'\n",
        "word2index['-PAD-'] = 0\n",
        "\n",
        "curr_idx = 1\n",
        "for key in embedding_dict.keys():\n",
        "  word2index[key] = curr_idx\n",
        "  index2word[curr_idx] = key\n",
        "  curr_idx += 1\n",
        "\n",
        "vocab_length = len(word2index) \n",
        "print(f'[Debug] Index -> Word vocabulary size: {len(index2word)}')\n",
        "print(f'[Debug] Word -> Index vocabulary size: {len(word2index)}')\n",
        "\n",
        "\n",
        "counts_sum = [sum(x) for x in zip(*counts)]\n",
        "counts_sum[2] = vocab_length - counts_sum[0] - counts_sum[1] -1\n",
        "fig = px.pie(values=counts_sum, names=['OOV words','Cap. words','IV words'])\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "-aKNy1vALyWm",
        "outputId": "e80472a8-5f2d-4061-bae7-44f944550c78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Debug] Index -> Tag vocabulary size: 46\n",
            "[Debug] Tag -> Index vocabulary size: 46\n"
          ]
        }
      ],
      "source": [
        "# Tag vocabulary\n",
        "\n",
        "tag2index = OrderedDict()\n",
        "index2tag = OrderedDict()\n",
        "\n",
        "# Adding the entry for padding\n",
        "index2tag[0] = '-PAD-'\n",
        "tag2index['-PAD-'] = 0\n",
        "\n",
        "curr_id = 1\n",
        "for tag in tags_train:\n",
        "  tag2index[tag] = curr_id\n",
        "  index2tag[curr_id] = tag\n",
        "  curr_id += 1\n",
        "\n",
        "print(f'[Debug] Index -> Tag vocabulary size: {len(index2tag)}')\n",
        "print(f'[Debug] Tag -> Index vocabulary size: {len(tag2index)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "PlvH2AwynXAk",
        "outputId": "b54f5d19-a246-48dd-9b3c-3293ce0c926e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-Not encoded\n",
            "\t ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n",
            "\t ['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'CD', '.']\n",
            "-Encoded\n",
            "\t [400001, 400002, 2, 4979, 83, 168, 2, 44, 1430, 1, 535, 20, 8, 128565, 370, 400003, 1264, 3]\n",
            "\t [21, 21, 4, 10, 23, 15, 4, 19, 35, 11, 20, 14, 11, 15, 20, 21, 10, 7]\n"
          ]
        }
      ],
      "source": [
        "# Tokenising words and tags by their indexes in vocabulary\n",
        "X_train_np, y_train_np = encode_sentences(X_train_raw,y_train_raw,word2index,tag2index)\n",
        "X_val_np, y_val_np = encode_sentences(X_val_raw,y_val_raw,word2index,tag2index) \n",
        "X_test_np, y_test_np = encode_sentences(X_test_raw,y_test_raw,word2index,tag2index) \n",
        "\n",
        "# Examples\n",
        "print('-Not encoded')\n",
        "print('\\t',X_train_raw[0]) \n",
        "print('\\t',y_train_raw[0])\n",
        "print('-Encoded')\n",
        "print('\\t',X_train_np[0])\n",
        "print('\\t',y_train_np[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "TWdnd4hWmKee",
        "outputId": "86a092fe-0aa7-47ae-8081-956e02fa7992"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"1519d950-50a3-4509-86b6-d4987c115f1d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1519d950-50a3-4509-86b6-d4987c115f1d\")) {                    Plotly.newPlot(                        \"1519d950-50a3-4509-86b6-d4987c115f1d\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"variable=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\"},\"name\":\"\",\"notched\":false,\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x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x0\":\" \",\"xaxis\":\"x\",\"y\":[1,2,2,2,2,2,2,2,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,40,40,40,40,40,40,40,40,40,40,40,40,40,40,41,41,41,41,41,41,41,41,41,41,41,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,43,43,43,43,43,43,43,43,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,45,45,45,45,45,45,45,45,45,45,45,45,45,46,46,46,46,46,46,46,46,46,46,46,47,47,47,47,47,47,48,48,48,48,48,48,48,48,48,49,49,49,49,49,49,49,49,49,49,49,50,50,50,51,51,51,51,52,52,52,53,53,53,54,54,54,55,56,56,56,57,58,58,58,58,60,60,63,63,65,67,68,70,78,89,100,111,114,249],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"boxmode\":\"group\",\"title\":{\"text\":\"Words per sentence\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1519d950-50a3-4509-86b6-d4987c115f1d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Checking the lengths of the sentences\n",
        "lengths = [len(sentence) for sentence in X_train_raw]\n",
        "lengths.sort()\n",
        "\n",
        "# Showing a boxplot of the lengths of the sentences\n",
        "fig = px.box(lengths)\n",
        "fig.update_layout(xaxis_title='',\n",
        "                  yaxis_title='',\n",
        "                  title='Words per sentence')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRSBSBqosWyK",
        "outputId": "907195ae-5d32-4594-fb2a-7ffcc423b37b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of longest sentence: 249\n",
            "Second longest sentence length: 114\n",
            "-Padded\n",
            "\tX: [400001 400002      2   4979     83    168      2     44   1430      1\n",
            "    535     20      8 128565    370 400003   1264      3      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0      0      0      0      0      0      0\n",
            "      0      0      0      0]\n",
            "\n",
            "\ty: [21 21  4 10 23 15  4 19 35 11 20 14 11 15 20 21 10  7  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
          ]
        }
      ],
      "source": [
        "# Maximum words in a sentence\n",
        "MAX_LENGTH = lengths[-1] \n",
        "# Second longest sentence \n",
        "PAD_LENGTH = lengths[-2] \n",
        "\n",
        "print(f'Length of longest sentence: {MAX_LENGTH}')\n",
        "print(f'Second longest sentence length: {PAD_LENGTH}')\n",
        "\n",
        "# Padding the sequences\n",
        "X_train = pad_sequences(X_train_np, maxlen=PAD_LENGTH, padding='post')\n",
        "X_val = pad_sequences(X_val_np, maxlen=PAD_LENGTH, padding='post')\n",
        "X_test = pad_sequences(X_test_np, maxlen=PAD_LENGTH, padding='post')\n",
        "\n",
        "y_train = pad_sequences(y_train_np, maxlen=PAD_LENGTH, padding='post')\n",
        "y_val = pad_sequences(y_val_np, maxlen=PAD_LENGTH, padding='post')\n",
        "y_test = pad_sequences(y_test_np, maxlen=PAD_LENGTH, padding='post')\n",
        "\n",
        "print('-Padded')\n",
        "print('\\tX:',X_train[0])\n",
        "print('\\n\\ty:',y_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Tt3IPOjD1AER"
      },
      "outputs": [],
      "source": [
        "# One hot encoding the sets\n",
        "y_train_one_hot = to_categorical(y_train, len(tag2index))\n",
        "y_val_one_hot = to_categorical(y_val, len(tag2index))\n",
        "y_test_one_hot = to_categorical(y_test, len(tag2index))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SqOgc6v1DfB"
      },
      "source": [
        "## 2. GloVe \n",
        "GloVe (Global Vectors for Word Representation) is a method for learning vector representations of words, called \"word embeddings,\" from a large corpus of text. Word embeddings are numerical representations of words that capture the semantic relationships between words in a continuous, low-dimensional space. They are commonly used as input to natural language processing models, such as language translation and language modeling.\n",
        "\n",
        "GloVe works by learning the co-occurrence statistics of words in a corpus, and using this information to learn word embeddings that capture the semantic relationships between words. The GloVe method produces word embeddings that are trained on a global corpus, as opposed to embeddings that are trained on a specific task or dataset.\n",
        "\n",
        "There are different versions of the GloVe word embeddings, including 50-dimensional, 100-dimensional, and 200-dimensional embeddings. The 50-dimensional version of GloVe embeddings may be better in some applications because they have a lower dimensionality, which can make them easier to work with and more computationally efficient.\n",
        "\n",
        "By using GloVe embeddings as the initial weights for a model, we can take advantage of these pre-trained word representations and fine-tune them for a specific task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YcvBdLXW1QTY"
      },
      "outputs": [],
      "source": [
        "#Building the Embedding Layer \n",
        "embedding_matrix = np.zeros((len(word2index), embedding_dim))\n",
        "for word, i in word2index.items():\n",
        "  if word != '-PAD-':\n",
        "    embedding_vector = embedding_dict.get(word)\n",
        "    embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lpL8lfEZiWH",
        "outputId": "c6880fd1-0bbc-4748-e828-5ae0a3cff346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Garbage Collection: 5107\n"
          ]
        }
      ],
      "source": [
        "if 'embedding_dict' in globals():\n",
        "    del embedding_dict\n",
        "    print(f'Garbage Collection: {gc.collect()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvF_XXvV3Qxe"
      },
      "source": [
        "## 3. Model\n",
        "### 3.1 Baseline \n",
        "Bidirectional LSTM layers are able to process sequential data in both the forward and backward directions, which can allow the model to capture contextual information from both the past and the future. This can be particularly useful for natural language processing tasks, where the meaning of a word can depend on the context in which it is used.\n",
        "\n",
        "In the context of POS tagging, TimeDistributed can be used to apply a tag prediction layer to each word in a sentence. For example, you might have an RNN that processes a sequence of words in a sentence, and at each time step, the RNN outputs a hidden state. You could then apply a TimeDistributed dense layer to the hidden states, which would allow you to predict the POS tag for each word in the sentence.\n",
        "\n",
        "One advantage of using TimeDistributed for POS tagging is that it allows you to predict the POS tag for each word in the sentence simultaneously, rather than having to process the sentence one word at a time. This can be particularly useful when dealing with long sentences, as it can make the tagging process more efficient.\n",
        "\n",
        "Overall, using TimeDistributed for POS tagging can help you build more accurate and efficient models for natural language processing tasks that involve sequential data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApCdkSw6jSY3",
        "outputId": "748584ac-d80c-4a73-fa9c-509c933b1dd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights: \n",
            "[0.99, 0.9999788833516344, 0.9927781062589746, 0.991574457302137, 0.9457090970521159, 0.9989019342849903, 0.9988385843398936, 0.9586324858518456, 0.9938128220288875, 0.975905904214883, 0.9696131430019427, 0.9139285412619309, 0.998965284230087, 0.9999577667032689, 0.8954303572936904, 0.9368189880902104, 0.9966846862066053, 0.9980361517020019, 0.9997888335163443, 0.991278824225019, 0.8675986147478673, 0.8901511952022975, 0.9979939184052707, 0.9365655883098235, 0.9998099501647099, 0.9914899907086747, 0.9798547174592449, 0.9913632908184813, 0.9685361939352986, 0.9981839682405609, 0.9995987836810541, 0.99704366922882, 0.9999788833516344, 0.9782920854801925, 0.9999788833516344, 0.9747656052031421, 0.9673114283300954, 0.983887997297069, 0.9782287355350958, 0.9846481966382296, 0.9760748374018076, 0.9956922037334235, 0.9970225525804545, 0.9998733001098066, 0.9980572683503675, 0.9913632908184813]\n"
          ]
        }
      ],
      "source": [
        "# Tags to ignore from the metrics\n",
        "ignore = [':', '#', '$', '-LRB-', '-RRB-', ',', '.', \"''\", '``', 'SYM','LS','-PAD-']\n",
        "\n",
        "# Computing the weights for the classes\n",
        "weights = compute_weights(train_df,ignore,tag2index)\n",
        "\n",
        "# Custom metrics ignoring classes\n",
        "w_accuracy = ignore_class_accuracy(weights,[tag2index[tag] for tag in ignore])\n",
        "metrics = [w_accuracy]\n",
        "\n",
        "# Embedding layer parameters\n",
        "embedding_params = {'input_dim': vocab_length,'output_dim': embedding_dim,\n",
        "                    'weights': [embedding_matrix],'input_length': PAD_LENGTH}\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    \n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True,verbose=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.33, patience=2, verbose=True, min_lr=0.001)\n",
        "]\n",
        "\n",
        "# Seeds\n",
        "seeds = [3,42,192]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J8eOwk4VPzkE",
        "outputId": "c0203510-6f7c-41a2-dfa9-8bb1a691a08a",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running with seed: 3\n",
            "Model: \"Baseline_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 114, 300)          121123800 \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 114, 256)         439296    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 114, 46)          11822     \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,574,918\n",
            "Trainable params: 451,118\n",
            "Non-trainable params: 121,123,800\n",
            "_________________________________________________________________\n",
            "\n",
            "Fitting the Baseline (seed 3) model...\n",
            "Epoch 1/15\n",
            "62/62 [==============================] - 6s 32ms/step - loss: 0.3190 - weighted_ignore_accuracy: 0.6262 - val_loss: 0.1088 - val_weighted_ignore_accuracy: 0.7738 - lr: 0.0300\n",
            "Epoch 2/15\n",
            "62/62 [==============================] - 1s 21ms/step - loss: 0.0696 - weighted_ignore_accuracy: 0.8282 - val_loss: 0.0756 - val_weighted_ignore_accuracy: 0.8203 - lr: 0.0300\n",
            "Epoch 3/15\n",
            "62/62 [==============================] - 1s 21ms/step - loss: 0.0385 - weighted_ignore_accuracy: 0.8728 - val_loss: 0.0693 - val_weighted_ignore_accuracy: 0.8295 - lr: 0.0300\n",
            "Epoch 4/15\n",
            "62/62 [==============================] - 1s 23ms/step - loss: 0.0250 - weighted_ignore_accuracy: 0.8921 - val_loss: 0.0660 - val_weighted_ignore_accuracy: 0.8400 - lr: 0.0300\n",
            "Epoch 5/15\n",
            "62/62 [==============================] - 1s 19ms/step - loss: 0.0165 - weighted_ignore_accuracy: 0.9052 - val_loss: 0.0690 - val_weighted_ignore_accuracy: 0.8389 - lr: 0.0300\n",
            "Epoch 6/15\n",
            "61/62 [============================>.] - ETA: 0s - loss: 0.0115 - weighted_ignore_accuracy: 0.9123\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.009899999778717757.\n",
            "62/62 [==============================] - 1s 18ms/step - loss: 0.0115 - weighted_ignore_accuracy: 0.9122 - val_loss: 0.0675 - val_weighted_ignore_accuracy: 0.8417 - lr: 0.0300\n",
            "Epoch 7/15\n",
            "62/62 [==============================] - 1s 21ms/step - loss: 0.0058 - weighted_ignore_accuracy: 0.9217 - val_loss: 0.0654 - val_weighted_ignore_accuracy: 0.8474 - lr: 0.0099\n",
            "Epoch 8/15\n",
            "62/62 [==============================] - 1s 18ms/step - loss: 0.0038 - weighted_ignore_accuracy: 0.9246 - val_loss: 0.0666 - val_weighted_ignore_accuracy: 0.8477 - lr: 0.0099\n",
            "Epoch 9/15\n",
            "61/62 [============================>.] - ETA: 0s - loss: 0.0030 - weighted_ignore_accuracy: 0.9258\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0032669999822974205.\n",
            "62/62 [==============================] - 1s 18ms/step - loss: 0.0030 - weighted_ignore_accuracy: 0.9258 - val_loss: 0.0674 - val_weighted_ignore_accuracy: 0.8480 - lr: 0.0099\n",
            "Epoch 10/15\n",
            "61/62 [============================>.] - ETA: 0s - loss: 0.0024 - weighted_ignore_accuracy: 0.9268Restoring model weights from the end of the best epoch: 7.\n",
            "62/62 [==============================] - 1s 19ms/step - loss: 0.0024 - weighted_ignore_accuracy: 0.9268 - val_loss: 0.0680 - val_weighted_ignore_accuracy: 0.8474 - lr: 0.0033\n",
            "Epoch 10: early stopping\n",
            "Evaluating the Baseline (seed 3) model...\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 0.0654 - weighted_ignore_accuracy: 0.8474\n",
            "Obtaining predictions from the Baseline (seed 3) model...\n",
            "41/41 [==============================] - 1s 5ms/step\n",
            "\n",
            "Macro f1 score: 0.6605287753141137\n",
            "\n",
            "Garbage collection: 9898\n",
            "Running with seed: 42\n",
            "Model: \"Baseline_42\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 114, 300)          121123800 \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 114, 256)         439296    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 114, 46)          11822     \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,574,918\n",
            "Trainable params: 451,118\n",
            "Non-trainable params: 121,123,800\n",
            "_________________________________________________________________\n",
            "\n",
            "Fitting the Baseline (seed 42) model...\n",
            "Epoch 1/15\n",
            "62/62 [==============================] - 3s 33ms/step - loss: 0.3323 - weighted_ignore_accuracy: 0.6466 - val_loss: 0.0915 - val_weighted_ignore_accuracy: 0.7996 - lr: 0.0300\n",
            "Epoch 2/15\n",
            "62/62 [==============================] - 1s 21ms/step - loss: 0.0607 - weighted_ignore_accuracy: 0.8422 - val_loss: 0.0649 - val_weighted_ignore_accuracy: 0.8338 - lr: 0.0300\n",
            "Epoch 3/15\n",
            "62/62 [==============================] - 1s 21ms/step - loss: 0.0338 - weighted_ignore_accuracy: 0.8789 - val_loss: 0.0585 - val_weighted_ignore_accuracy: 0.8467 - lr: 0.0300\n",
            "Epoch 4/15\n",
            "62/62 [==============================] - 1s 18ms/step - loss: 0.0231 - weighted_ignore_accuracy: 0.8951 - val_loss: 0.0593 - val_weighted_ignore_accuracy: 0.8439 - lr: 0.0300\n",
            "Epoch 5/15\n",
            "61/62 [============================>.] - ETA: 0s - loss: 0.0160 - weighted_ignore_accuracy: 0.9051\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.009899999778717757.\n",
            "62/62 [==============================] - 1s 18ms/step - loss: 0.0160 - weighted_ignore_accuracy: 0.9052 - val_loss: 0.0589 - val_weighted_ignore_accuracy: 0.8509 - lr: 0.0300\n",
            "Epoch 6/15\n",
            "62/62 [==============================] - 1s 21ms/step - loss: 0.0098 - weighted_ignore_accuracy: 0.9152 - val_loss: 0.0555 - val_weighted_ignore_accuracy: 0.8559 - lr: 0.0099\n",
            "Epoch 7/15\n",
            "62/62 [==============================] - 1s 21ms/step - loss: 0.0069 - weighted_ignore_accuracy: 0.9198 - val_loss: 0.0553 - val_weighted_ignore_accuracy: 0.8579 - lr: 0.0099\n",
            "Epoch 8/15\n",
            "62/62 [==============================] - 1s 18ms/step - loss: 0.0057 - weighted_ignore_accuracy: 0.9214 - val_loss: 0.0572 - val_weighted_ignore_accuracy: 0.8569 - lr: 0.0099\n",
            "Epoch 9/15\n",
            "61/62 [============================>.] - ETA: 0s - loss: 0.0050 - weighted_ignore_accuracy: 0.9228\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0032669999822974205.\n",
            "62/62 [==============================] - 1s 17ms/step - loss: 0.0050 - weighted_ignore_accuracy: 0.9227 - val_loss: 0.0578 - val_weighted_ignore_accuracy: 0.8578 - lr: 0.0099\n",
            "Epoch 10/15\n",
            "61/62 [============================>.] - ETA: 0s - loss: 0.0039 - weighted_ignore_accuracy: 0.9246Restoring model weights from the end of the best epoch: 7.\n",
            "62/62 [==============================] - 1s 18ms/step - loss: 0.0040 - weighted_ignore_accuracy: 0.9245 - val_loss: 0.0573 - val_weighted_ignore_accuracy: 0.8585 - lr: 0.0033\n",
            "Epoch 10: early stopping\n",
            "Evaluating the Baseline (seed 42) model...\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 0.0553 - weighted_ignore_accuracy: 0.8579\n",
            "Obtaining predictions from the Baseline (seed 42) model...\n",
            "41/41 [==============================] - 1s 5ms/step\n",
            "\n",
            "Macro f1 score: 0.70649748501005\n",
            "\n",
            "Garbage collection: 8614\n",
            "Running with seed: 192\n",
            "Model: \"Baseline_192\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 114, 300)          121123800 \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 114, 256)         439296    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 114, 46)          11822     \n",
            " ibuted)                                                         \n",
            "                                                                 \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================================================\n",
            "Total params: 121,574,918\n",
            "Trainable params: 451,118\n",
            "Non-trainable params: 121,123,800\n",
            "_________________________________________________________________\n",
            "\n",
            "Fitting the Baseline (seed 192) model...\n",
            "Epoch 1/15\n",
            "62/62 [==============================] - 4s 34ms/step - loss: 0.3199 - weighted_ignore_accuracy: 0.6607 - val_loss: 0.0871 - val_weighted_ignore_accuracy: 0.8017 - lr: 0.0300\n",
            "Epoch 2/15\n",
            "62/62 [==============================] - 1s 24ms/step - loss: 0.0549 - weighted_ignore_accuracy: 0.8476 - val_loss: 0.0636 - val_weighted_ignore_accuracy: 0.8345 - lr: 0.0300\n",
            "Epoch 3/15\n",
            "62/62 [==============================] - 1s 22ms/step - loss: 0.0315 - weighted_ignore_accuracy: 0.8819 - val_loss: 0.0610 - val_weighted_ignore_accuracy: 0.8424 - lr: 0.0300\n",
            "Epoch 4/15\n",
            "62/62 [==============================] - 1s 19ms/step - loss: 0.0206 - weighted_ignore_accuracy: 0.8975 - val_loss: 0.0651 - val_weighted_ignore_accuracy: 0.8401 - lr: 0.0300\n",
            "Epoch 5/15\n",
            "61/62 [============================>.] - ETA: 0s - loss: 0.0148 - weighted_ignore_accuracy: 0.9064\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.009899999778717757.\n",
            "62/62 [==============================] - 1s 18ms/step - loss: 0.0147 - weighted_ignore_accuracy: 0.9064 - val_loss: 0.0620 - val_weighted_ignore_accuracy: 0.8451 - lr: 0.0300\n",
            "Epoch 6/15\n",
            "62/62 [==============================] - 1s 21ms/step - loss: 0.0074 - weighted_ignore_accuracy: 0.9178 - val_loss: 0.0586 - val_weighted_ignore_accuracy: 0.8525 - lr: 0.0099\n",
            "Epoch 7/15\n",
            "62/62 [==============================] - 1s 19ms/step - loss: 0.0046 - weighted_ignore_accuracy: 0.9224 - val_loss: 0.0591 - val_weighted_ignore_accuracy: 0.8543 - lr: 0.0099\n",
            "Epoch 8/15\n",
            "61/62 [============================>.] - ETA: 0s - loss: 0.0036 - weighted_ignore_accuracy: 0.9239\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0032669999822974205.\n",
            "62/62 [==============================] - 1s 18ms/step - loss: 0.0036 - weighted_ignore_accuracy: 0.9239 - val_loss: 0.0606 - val_weighted_ignore_accuracy: 0.8531 - lr: 0.0099\n",
            "Epoch 9/15\n",
            "61/62 [============================>.] - ETA: 0s - loss: 0.0028 - weighted_ignore_accuracy: 0.9257Restoring model weights from the end of the best epoch: 6.\n",
            "62/62 [==============================] - 1s 19ms/step - loss: 0.0028 - weighted_ignore_accuracy: 0.9257 - val_loss: 0.0607 - val_weighted_ignore_accuracy: 0.8537 - lr: 0.0033\n",
            "Epoch 9: early stopping\n",
            "Evaluating the Baseline (seed 192) model...\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 0.0586 - weighted_ignore_accuracy: 0.8525\n",
            "Obtaining predictions from the Baseline (seed 192) model...\n",
            "41/41 [==============================] - 1s 6ms/step\n",
            "\n",
            "Macro f1 score: 0.7013206232550928\n",
            "\n",
            "Garbage collection: 8614\n"
          ]
        }
      ],
      "source": [
        "# Learning Rate\n",
        "LR = 0.03\n",
        "\n",
        "baseline_layer_params = [{'layer_type': 'Bidirectional',\n",
        "                          'layer_kwargs': {'units': 128}},\n",
        "                         {'layer_type': 'Dense',\n",
        "                          'layer_kwargs':{'units': len(tag2index),'activation': 'softmax'}}]\n",
        "\n",
        "bl_training_params = {'x': X_train, 'y': y_train_one_hot, 'validation_data': (X_val, y_val_one_hot),\n",
        "                  'batch_size': 32, 'epochs': 15, 'callbacks': callbacks} \n",
        "\n",
        "\n",
        "baseline_model_recaps = run_models('Baseline',baseline_layer_params,embedding_params,bl_training_params,metrics,LR,seeds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McZp9BOcL5n9",
        "outputId": "9400e45d-1b63-4f3c-f207-cca1b9ab6c46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean values: {'macro_f1': 0.6894489611930855, 'weighted_ignore_accuracy': 0.852584183216095}\n"
          ]
        }
      ],
      "source": [
        "mean_metrics_bl = mean_metrics(baseline_model_recaps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu4VIZ4pokCv"
      },
      "source": [
        "Different combinations of hyperparameters have been taken in consideration during the tuning phase.\n",
        "\n",
        "The most evident changes in the scores were due to the `units` used in the LSTM layer and the `batch_size`:\n",
        "\n",
        "*  Generally, a larger number of units in the LSTM layer means that the model has more capacity to learn complex representations. However, having too many units can lead to overfitting, where the model memorizes the training data instead of learning general patterns. On the other hand, having too few units can lead to underfitting, where the model is not able to capture important features of the data.\n",
        "In our case, using fewer units (from 256 to 128) may be helping to prevent the model from memorizing the training data, resulting in a more generalizable model that is better able to generalize to new data. \n",
        "\n",
        "*   The reason for seeing better results with a batch size of `32` compared to bigger sizes, could be due to a phenomenon called \"*batch normalization instability*\". Larger batch sizes can lead to a higher variance in the estimated mean and variance used in batch normalization, making the normalization less stable and leading to worse results. Smaller batch sizes, on the other hand, can provide a more stable estimate of the mean and variance and lead to improved results.\n",
        "Using an unbalanced dataset like ours can lead to a bias towards the class with more samples. When the batch size is small, the model is more likely to see a diverse range of samples in each batch, which can help mitigate the impact of the class imbalance. On the other hand, if the batch size is too large, the model may not see enough samples from the minority class to learn to accurately classify them. In such cases, using a smaller batch size could help alleviate the problem and improve performance.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_piJrG2VEe1Z"
      },
      "source": [
        "### 3.2 GRU \n",
        "Gated Recurrent Units (GRUs) are a type of recurrent neural network (RNN) that are often used in natural language processing tasks such as part-of-speech (POS) tagging. GRUs are similar to long short-term memory (LSTM) networks, but they have a simpler structure and fewer parameters, making them easier to train and faster to run. In POS tagging, GRUs can be used to process a sequence of words and predict the POS tags for each word in the sequence. GRUs are able to take into account contextual information from the previous words in the sequence, allowing them to make more accurate predictions about the POS tags for the current word. \n",
        "\n",
        "................"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_R276ECOY2cH",
        "outputId": "06efd550-c6a0-4688-ed91-5272112a9a93",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running with seed: 3\n",
            "Model: \"GRU_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 114, 300)          121123800 \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 114, 128)          165120    \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 114, 46)          5934      \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,294,854\n",
            "Trainable params: 171,054\n",
            "Non-trainable params: 121,123,800\n",
            "_________________________________________________________________\n",
            "\n",
            "Fitting the GRU (seed 3) model...\n",
            "Epoch 1/15\n",
            "62/62 [==============================] - 2s 21ms/step - loss: 0.2545 - weighted_ignore_accuracy: 0.7154 - val_loss: 0.0902 - val_weighted_ignore_accuracy: 0.7989 - lr: 0.0300\n",
            "Epoch 2/15\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.0603 - weighted_ignore_accuracy: 0.8371 - val_loss: 0.0787 - val_weighted_ignore_accuracy: 0.8172 - lr: 0.0300\n",
            "Epoch 3/15\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.0431 - weighted_ignore_accuracy: 0.8621 - val_loss: 0.0802 - val_weighted_ignore_accuracy: 0.8156 - lr: 0.0300\n",
            "Epoch 4/15\n",
            "58/62 [===========================>..] - ETA: 0s - loss: 0.0359 - weighted_ignore_accuracy: 0.8729\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.009899999778717757.\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.0359 - weighted_ignore_accuracy: 0.8727 - val_loss: 0.0791 - val_weighted_ignore_accuracy: 0.8246 - lr: 0.0300\n",
            "Epoch 5/15\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.0204 - weighted_ignore_accuracy: 0.8977 - val_loss: 0.0723 - val_weighted_ignore_accuracy: 0.8354 - lr: 0.0099\n",
            "Epoch 6/15\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.0118 - weighted_ignore_accuracy: 0.9120 - val_loss: 0.0741 - val_weighted_ignore_accuracy: 0.8350 - lr: 0.0099\n",
            "Epoch 7/15\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.0084 - weighted_ignore_accuracy: 0.9180\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0032669999822974205.\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.0084 - weighted_ignore_accuracy: 0.9180 - val_loss: 0.0755 - val_weighted_ignore_accuracy: 0.8363 - lr: 0.0099\n",
            "Epoch 8/15\n",
            "61/62 [============================>.] - ETA: 0s - loss: 0.0059 - weighted_ignore_accuracy: 0.9223Restoring model weights from the end of the best epoch: 5.\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.0059 - weighted_ignore_accuracy: 0.9223 - val_loss: 0.0758 - val_weighted_ignore_accuracy: 0.8358 - lr: 0.0033\n",
            "Epoch 8: early stopping\n",
            "Evaluating the GRU (seed 3) model...\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0723 - weighted_ignore_accuracy: 0.8354\n",
            "Obtaining predictions from the GRU (seed 3) model...\n",
            "41/41 [==============================] - 0s 3ms/step\n",
            "\n",
            "Macro f1 score: 0.620749671851989\n",
            "\n",
            "Garbage collection: 2211\n",
            "Running with seed: 42\n",
            "Model: \"GRU_42\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 114, 300)          121123800 \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 114, 128)          165120    \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 114, 46)          5934      \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,294,854\n",
            "Trainable params: 171,054\n",
            "Non-trainable params: 121,123,800\n",
            "_________________________________________________________________\n",
            "\n",
            "Fitting the GRU (seed 42) model...\n",
            "Epoch 1/15\n",
            "62/62 [==============================] - 2s 23ms/step - loss: 0.2769 - weighted_ignore_accuracy: 0.6930 - val_loss: 0.0952 - val_weighted_ignore_accuracy: 0.7964 - lr: 0.0300\n",
            "Epoch 2/15\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 0.0625 - weighted_ignore_accuracy: 0.8374 - val_loss: 0.0801 - val_weighted_ignore_accuracy: 0.8131 - lr: 0.0300\n",
            "Epoch 3/15\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 0.0435 - weighted_ignore_accuracy: 0.8619 - val_loss: 0.0761 - val_weighted_ignore_accuracy: 0.8225 - lr: 0.0300\n",
            "Epoch 4/15\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.0323 - weighted_ignore_accuracy: 0.8785 - val_loss: 0.0844 - val_weighted_ignore_accuracy: 0.8175 - lr: 0.0300\n",
            "Epoch 5/15\n",
            "56/62 [==========================>...] - ETA: 0s - loss: 0.0270 - weighted_ignore_accuracy: 0.8858\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.009899999778717757.\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.0273 - weighted_ignore_accuracy: 0.8848 - val_loss: 0.0835 - val_weighted_ignore_accuracy: 0.8253 - lr: 0.0300\n",
            "Epoch 6/15\n",
            "60/62 [============================>.] - ETA: 0s - loss: 0.0162 - weighted_ignore_accuracy: 0.9039Restoring model weights from the end of the best epoch: 3.\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.0161 - weighted_ignore_accuracy: 0.9037 - val_loss: 0.0775 - val_weighted_ignore_accuracy: 0.8334 - lr: 0.0099\n",
            "Epoch 6: early stopping\n",
            "Evaluating the GRU (seed 42) model...\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0761 - weighted_ignore_accuracy: 0.8225\n",
            "Obtaining predictions from the GRU (seed 42) model...\n",
            "41/41 [==============================] - 0s 3ms/step\n",
            "\n",
            "Macro f1 score: 0.5828767755249035\n",
            "\n",
            "Garbage collection: 2211\n",
            "Running with seed: 192\n",
            "Model: \"GRU_192\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 114, 300)          121123800 \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 114, 128)          165120    \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 114, 46)          5934      \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,294,854\n",
            "Trainable params: 171,054\n",
            "Non-trainable params: 121,123,800\n",
            "_________________________________________________________________\n",
            "\n",
            "Fitting the GRU (seed 192) model...\n",
            "Epoch 1/15\n",
            "62/62 [==============================] - 2s 23ms/step - loss: 0.2821 - weighted_ignore_accuracy: 0.6968 - val_loss: 0.0960 - val_weighted_ignore_accuracy: 0.7968 - lr: 0.0300\n",
            "Epoch 2/15\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 0.0631 - weighted_ignore_accuracy: 0.8357 - val_loss: 0.0802 - val_weighted_ignore_accuracy: 0.8156 - lr: 0.0300\n",
            "Epoch 3/15\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.0425 - weighted_ignore_accuracy: 0.8646 - val_loss: 0.0794 - val_weighted_ignore_accuracy: 0.8207 - lr: 0.0300\n",
            "Epoch 4/15\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.0326 - weighted_ignore_accuracy: 0.8781 - val_loss: 0.0792 - val_weighted_ignore_accuracy: 0.8256 - lr: 0.0300\n",
            "Epoch 5/15\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.0254 - weighted_ignore_accuracy: 0.8886 - val_loss: 0.0819 - val_weighted_ignore_accuracy: 0.8250 - lr: 0.0300\n",
            "Epoch 6/15\n",
            "61/62 [============================>.] - ETA: 0s - loss: 0.0235 - weighted_ignore_accuracy: 0.8912\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.009899999778717757.\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.0236 - weighted_ignore_accuracy: 0.8909 - val_loss: 0.0883 - val_weighted_ignore_accuracy: 0.8223 - lr: 0.0300\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/15\n",
            "61/62 [============================>.] - ETA: 0s - loss: 0.0139 - weighted_ignore_accuracy: 0.9072Restoring model weights from the end of the best epoch: 4.\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.0139 - weighted_ignore_accuracy: 0.9073 - val_loss: 0.0792 - val_weighted_ignore_accuracy: 0.8363 - lr: 0.0099\n",
            "Epoch 7: early stopping\n",
            "Evaluating the GRU (seed 192) model...\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 0.0792 - weighted_ignore_accuracy: 0.8256\n",
            "Obtaining predictions from the GRU (seed 192) model...\n",
            "41/41 [==============================] - 0s 3ms/step\n",
            "\n",
            "Macro f1 score: 0.5934388089315207\n",
            "\n",
            "Garbage collection: 2211\n"
          ]
        }
      ],
      "source": [
        "# Learning Rate\n",
        "LR = 0.03\n",
        "\n",
        "gru_layer_params = [{'layer_type': 'GRU',\n",
        "                     'layer_kwargs': {'units': 128}},\n",
        "                    {'layer_type': 'Dense',\n",
        "                     'layer_kwargs':{'units': len(tag2index),'activation': 'softmax'}}]\n",
        "\n",
        "gru_training_params = {'x': X_train, 'y': y_train_one_hot, 'validation_data': (X_val, y_val_one_hot),\n",
        "                  'batch_size': 32, 'epochs': 15, 'callbacks': callbacks} \n",
        "\n",
        "gru_model_recaps = run_models('GRU',gru_layer_params,embedding_params,gru_training_params,metrics,LR,seeds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHd70QrVEhOv",
        "outputId": "6efdd293-0c06-4d4d-9c07-805edac7e608"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean values: {'macro_f1': 0.5990217521028044, 'weighted_ignore_accuracy': 0.8278176784515381}\n"
          ]
        }
      ],
      "source": [
        "mean_metrics_gru = mean_metrics(gru_model_recaps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1dvvPO7AnyK"
      },
      "source": [
        "As it's noticeable by the scores obtained, the simple LSTM architecture used as baseline perform better than this (equally simple) one.\n",
        " \n",
        "LSTM has a more complex structure compared to GRU, which allows it to model more complex dependencies in the data. This makes LSTM more suitable for tasks like POS-tagging where the relationships between words can be very complex.\n",
        "\n",
        "The results may also be affected by the suitability of the data for the GRU architecture. If the data contains long-term dependencies that are better captured by LSTM, then the GRU architecture may not perform as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4NZ4nhpEr1K"
      },
      "source": [
        "### 3.3 Additional LSTM layer \n",
        "The second biLSTM layer increases the capacity of the network, allowing it to model more complex dependencies in the data. This can lead to better performance on tasks like POS-tagging where the relationships between words can be very complex. Moreover, the second biLSTM layer can also help improve representation learning by capturing higher-level abstractions of the input data. This can lead to better generalization and improved performance on the target task.\n",
        "\n",
        "The biLSTM architecture is known to be good at handling long-term dependencies, and adding a second biLSTM layer can help further improve this ability. This can be especially beneficial for tasks like POS-tagging where the relationships between words can span multiple time steps.\n",
        "\n",
        "However, it's also possible that adding a second biLSTM layer could lead to overfitting, especially if the model is already sufficiently large to model the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9CrbXiJbfaF",
        "outputId": "11729e77-ca0f-4818-8d38-9947510cf02a",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running with seed: 3\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"Additional_LSTM_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 114, 300)          121123800 \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 114, 256)         439296    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 114, 256)         394240    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 114, 46)          11822     \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,969,158\n",
            "Trainable params: 845,358\n",
            "Non-trainable params: 121,123,800\n",
            "_________________________________________________________________\n",
            "\n",
            "Fitting the Additional_LSTM (seed 3) model...\n",
            "Epoch 1/20\n",
            "62/62 [==============================] - 39s 564ms/step - loss: 0.6144 - weighted_ignore_accuracy: 0.3228 - val_loss: 0.2217 - val_weighted_ignore_accuracy: 0.6331 - lr: 0.0100\n",
            "Epoch 2/20\n",
            "62/62 [==============================] - 34s 548ms/step - loss: 0.1341 - weighted_ignore_accuracy: 0.7436 - val_loss: 0.0893 - val_weighted_ignore_accuracy: 0.8033 - lr: 0.0100\n",
            "Epoch 3/20\n",
            "62/62 [==============================] - 36s 578ms/step - loss: 0.0703 - weighted_ignore_accuracy: 0.8272 - val_loss: 0.0688 - val_weighted_ignore_accuracy: 0.8281 - lr: 0.0100\n",
            "Epoch 4/20\n",
            "62/62 [==============================] - 36s 581ms/step - loss: 0.0472 - weighted_ignore_accuracy: 0.8584 - val_loss: 0.0557 - val_weighted_ignore_accuracy: 0.8485 - lr: 0.0100\n",
            "Epoch 5/20\n",
            "62/62 [==============================] - 34s 557ms/step - loss: 0.0354 - weighted_ignore_accuracy: 0.8745 - val_loss: 0.0531 - val_weighted_ignore_accuracy: 0.8507 - lr: 0.0100\n",
            "Epoch 6/20\n",
            "62/62 [==============================] - 34s 555ms/step - loss: 0.0265 - weighted_ignore_accuracy: 0.8877 - val_loss: 0.0516 - val_weighted_ignore_accuracy: 0.8571 - lr: 0.0100\n",
            "Epoch 7/20\n",
            "62/62 [==============================] - 34s 545ms/step - loss: 0.0216 - weighted_ignore_accuracy: 0.8959 - val_loss: 0.0520 - val_weighted_ignore_accuracy: 0.8589 - lr: 0.0100\n",
            "Epoch 8/20\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.0181 - weighted_ignore_accuracy: 0.8997\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.003299999926239252.\n",
            "62/62 [==============================] - 34s 552ms/step - loss: 0.0181 - weighted_ignore_accuracy: 0.8997 - val_loss: 0.0517 - val_weighted_ignore_accuracy: 0.8602 - lr: 0.0100\n",
            "Epoch 9/20\n",
            "62/62 [==============================] - 34s 550ms/step - loss: 0.0123 - weighted_ignore_accuracy: 0.9090 - val_loss: 0.0505 - val_weighted_ignore_accuracy: 0.8652 - lr: 0.0033\n",
            "Epoch 10/20\n",
            "62/62 [==============================] - 35s 566ms/step - loss: 0.0097 - weighted_ignore_accuracy: 0.9135 - val_loss: 0.0515 - val_weighted_ignore_accuracy: 0.8638 - lr: 0.0033\n",
            "Epoch 11/20\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.0089 - weighted_ignore_accuracy: 0.9147\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0010889999940991402.\n",
            "62/62 [==============================] - 35s 572ms/step - loss: 0.0089 - weighted_ignore_accuracy: 0.9147 - val_loss: 0.0517 - val_weighted_ignore_accuracy: 0.8651 - lr: 0.0033\n",
            "Epoch 12/20\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.0073 - weighted_ignore_accuracy: 0.9179Restoring model weights from the end of the best epoch: 9.\n",
            "62/62 [==============================] - 37s 600ms/step - loss: 0.0073 - weighted_ignore_accuracy: 0.9179 - val_loss: 0.0519 - val_weighted_ignore_accuracy: 0.8655 - lr: 0.0011\n",
            "Epoch 12: early stopping\n",
            "Evaluating the Additional_LSTM (seed 3) model...\n",
            "41/41 [==============================] - 3s 73ms/step - loss: 0.0505 - weighted_ignore_accuracy: 0.8652\n",
            "Obtaining predictions from the Additional_LSTM (seed 3) model...\n",
            "41/41 [==============================] - 3s 70ms/step\n",
            "\n",
            "Macro f1 score: 0.773669670213452\n",
            "\n",
            "Garbage collection: 2141\n",
            "Running with seed: 42\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"Additional_LSTM_42\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 114, 300)          121123800 \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 114, 256)         439296    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 114, 256)         394240    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 114, 46)          11822     \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,969,158\n",
            "Trainable params: 845,358\n",
            "Non-trainable params: 121,123,800\n",
            "_________________________________________________________________\n",
            "\n",
            "Fitting the Additional_LSTM (seed 42) model...\n",
            "Epoch 1/20\n",
            "62/62 [==============================] - 42s 615ms/step - loss: 0.5776 - weighted_ignore_accuracy: 0.3475 - val_loss: 0.1997 - val_weighted_ignore_accuracy: 0.6609 - lr: 0.0100\n",
            "Epoch 2/20\n",
            "62/62 [==============================] - 39s 623ms/step - loss: 0.1318 - weighted_ignore_accuracy: 0.7483 - val_loss: 0.0932 - val_weighted_ignore_accuracy: 0.7982 - lr: 0.0100\n",
            "Epoch 3/20\n",
            "62/62 [==============================] - 36s 586ms/step - loss: 0.0703 - weighted_ignore_accuracy: 0.8256 - val_loss: 0.0658 - val_weighted_ignore_accuracy: 0.8320 - lr: 0.0100\n",
            "Epoch 4/20\n",
            "62/62 [==============================] - 37s 594ms/step - loss: 0.0481 - weighted_ignore_accuracy: 0.8567 - val_loss: 0.0565 - val_weighted_ignore_accuracy: 0.8463 - lr: 0.0100\n",
            "Epoch 5/20\n",
            "62/62 [==============================] - 36s 581ms/step - loss: 0.0344 - weighted_ignore_accuracy: 0.8775 - val_loss: 0.0540 - val_weighted_ignore_accuracy: 0.8507 - lr: 0.0100\n",
            "Epoch 6/20\n",
            "62/62 [==============================] - 34s 552ms/step - loss: 0.0295 - weighted_ignore_accuracy: 0.8838 - val_loss: 0.0571 - val_weighted_ignore_accuracy: 0.8489 - lr: 0.0100\n",
            "Epoch 7/20\n",
            "62/62 [==============================] - 35s 559ms/step - loss: 0.0232 - weighted_ignore_accuracy: 0.8912 - val_loss: 0.0502 - val_weighted_ignore_accuracy: 0.8581 - lr: 0.0100\n",
            "Epoch 8/20\n",
            "62/62 [==============================] - 35s 558ms/step - loss: 0.0182 - weighted_ignore_accuracy: 0.8995 - val_loss: 0.0542 - val_weighted_ignore_accuracy: 0.8570 - lr: 0.0100\n",
            "Epoch 9/20\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.0157 - weighted_ignore_accuracy: 0.9042\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.003299999926239252.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - 34s 557ms/step - loss: 0.0157 - weighted_ignore_accuracy: 0.9042 - val_loss: 0.0533 - val_weighted_ignore_accuracy: 0.8592 - lr: 0.0100\n",
            "Epoch 10/20\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.0104 - weighted_ignore_accuracy: 0.9116Restoring model weights from the end of the best epoch: 7.\n",
            "62/62 [==============================] - 34s 555ms/step - loss: 0.0104 - weighted_ignore_accuracy: 0.9116 - val_loss: 0.0505 - val_weighted_ignore_accuracy: 0.8627 - lr: 0.0033\n",
            "Epoch 10: early stopping\n",
            "Evaluating the Additional_LSTM (seed 42) model...\n",
            "41/41 [==============================] - 3s 69ms/step - loss: 0.0502 - weighted_ignore_accuracy: 0.8581\n",
            "Obtaining predictions from the Additional_LSTM (seed 42) model...\n",
            "41/41 [==============================] - 3s 68ms/step\n",
            "\n",
            "Macro f1 score: 0.7032264296687384\n",
            "\n",
            "Garbage collection: 12362\n",
            "Running with seed: 192\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"Additional_LSTM_192\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 114, 300)          121123800 \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 114, 256)         439296    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 114, 256)         394240    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 114, 46)          11822     \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,969,158\n",
            "Trainable params: 845,358\n",
            "Non-trainable params: 121,123,800\n",
            "_________________________________________________________________\n",
            "\n",
            "Fitting the Additional_LSTM (seed 192) model...\n",
            "Epoch 1/20\n",
            "62/62 [==============================] - 42s 620ms/step - loss: 0.5770 - weighted_ignore_accuracy: 0.3366 - val_loss: 0.2005 - val_weighted_ignore_accuracy: 0.6534 - lr: 0.0100\n",
            "Epoch 2/20\n",
            "62/62 [==============================] - 36s 576ms/step - loss: 0.1370 - weighted_ignore_accuracy: 0.7433 - val_loss: 0.0920 - val_weighted_ignore_accuracy: 0.7991 - lr: 0.0100\n",
            "Epoch 3/20\n",
            "62/62 [==============================] - 37s 590ms/step - loss: 0.0721 - weighted_ignore_accuracy: 0.8259 - val_loss: 0.0668 - val_weighted_ignore_accuracy: 0.8307 - lr: 0.0100\n",
            "Epoch 4/20\n",
            "62/62 [==============================] - 36s 579ms/step - loss: 0.0489 - weighted_ignore_accuracy: 0.8554 - val_loss: 0.0576 - val_weighted_ignore_accuracy: 0.8455 - lr: 0.0100\n",
            "Epoch 5/20\n",
            "62/62 [==============================] - 35s 568ms/step - loss: 0.0363 - weighted_ignore_accuracy: 0.8735 - val_loss: 0.0517 - val_weighted_ignore_accuracy: 0.8549 - lr: 0.0100\n",
            "Epoch 6/20\n",
            "62/62 [==============================] - 36s 582ms/step - loss: 0.0285 - weighted_ignore_accuracy: 0.8849 - val_loss: 0.0497 - val_weighted_ignore_accuracy: 0.8578 - lr: 0.0100\n",
            "Epoch 7/20\n",
            "62/62 [==============================] - 38s 606ms/step - loss: 0.0227 - weighted_ignore_accuracy: 0.8940 - val_loss: 0.0504 - val_weighted_ignore_accuracy: 0.8595 - lr: 0.0100\n",
            "Epoch 8/20\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.0191 - weighted_ignore_accuracy: 0.8984\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.003299999926239252.\n",
            "62/62 [==============================] - 37s 591ms/step - loss: 0.0191 - weighted_ignore_accuracy: 0.8984 - val_loss: 0.0537 - val_weighted_ignore_accuracy: 0.8579 - lr: 0.0100\n",
            "Epoch 9/20\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.0135 - weighted_ignore_accuracy: 0.9076Restoring model weights from the end of the best epoch: 6.\n",
            "62/62 [==============================] - 36s 585ms/step - loss: 0.0135 - weighted_ignore_accuracy: 0.9076 - val_loss: 0.0502 - val_weighted_ignore_accuracy: 0.8641 - lr: 0.0033\n",
            "Epoch 9: early stopping\n",
            "Evaluating the Additional_LSTM (seed 192) model...\n",
            "41/41 [==============================] - 3s 71ms/step - loss: 0.0497 - weighted_ignore_accuracy: 0.8578\n",
            "Obtaining predictions from the Additional_LSTM (seed 192) model...\n",
            "41/41 [==============================] - 3s 69ms/step\n",
            "\n",
            "Macro f1 score: 0.7407615105334335\n",
            "\n",
            "Garbage collection: 12362\n"
          ]
        }
      ],
      "source": [
        "LR = 0.01\n",
        "\n",
        "add_lstm_layer_params = [{'layer_type': 'Bidirectional',\n",
        "                          'layer_kwargs': {'units': 128, 'dropout': 0.2}},\n",
        "                         {'layer_type': 'Bidirectional',\n",
        "                          'layer_kwargs': {'units': 128, 'recurrent_dropout': 0.2}},\n",
        "                         {'layer_type': 'Dense',\n",
        "                          'layer_kwargs':{'units': len(tag2index),'activation': 'softmax'}}]\n",
        "\n",
        "add_lstm_training_params = {'x': X_train, 'y': y_train_one_hot, 'validation_data': (X_val, y_val_one_hot),\n",
        "                  'batch_size': 32, 'epochs': 20, 'callbacks': callbacks} \n",
        "\n",
        "add_lstm_model_recaps = run_models('Additional_LSTM',add_lstm_layer_params,embedding_params,add_lstm_training_params,metrics,LR,seeds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRvFuiHCExgc",
        "outputId": "8e239514-95dd-4505-e7d9-24418ba388ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean values: {'macro_f1': 0.7392192034718746, 'weighted_ignore_accuracy': 0.8603646357854208}\n"
          ]
        }
      ],
      "source": [
        "mean_metrics_add_lstm = mean_metrics(add_lstm_model_recaps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmnJLWoTZfPG"
      },
      "source": [
        "Due to the constraints to the layers in our architecture, a Dropout layer was not applicable. In that case, the dropout is applied after the current layer's output, i.e., the dropout is applied to the activations of the LSTM layer. This means that the dropout rate you specify for the Dropout layer will apply to the output of the LSTM layer, and some of the activations will be set to zero during each forward pass with a probability specified by the dropout rate.\n",
        "\n",
        "Instead, when using the `dropout` parameter in the LSTM layer, the dropout is applied to the input of the LSTM layer. This means that the dropout rate specified for the `dropout` parameter will apply to the input connections, and some of the connections will be set to zero during each forward pass with a probability specified by the dropout rate.\n",
        "\n",
        "Similarly works the `recurrent_dropout` parameter, but it applies dropout to the recurrent connections of the LSTM layer, rather than the input connections.\n",
        "\n",
        "Using both the parameters in an LSTM layer can be effective in preventing overfitting and improving the generalization of the network, but they can slow down the convergence of the network, making it more difficult to train and can lead to an increase in the variance of the gradients, which can make the training process more unstable.\n",
        "\n",
        "In our case, by setting low values (0.1) to both `dropout` and `recurrent_dropout` worked the best in terms of macro f1 scores obtained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AtIybGnEzsP"
      },
      "source": [
        "### 3.4 Additional dense layer\n",
        "\n",
        "Using two dense layers, one with a non-linear activation function and one with a softmax activation function, is a common pattern in neural network architectures for classification tasks.\n",
        "\n",
        "The purpose of the non-linear dense layer is to introduce non-linearity into the model, which can allow the model to learn more complex patterns in the data. Common choices for the activation function in this layer include ReLU (Rectified Linear Unit) or (sigmoid/tanh) as activation functions.\n",
        "\n",
        "The purpose of the softmax dense layer is to produce a probability distribution over the possible classes. The softmax activation function transforms the output of the preceding layer into a probability distribution, where the sum of the probabilities is equal to 1. This is useful for classification tasks, where you want to predict the probability that an input belongs to each of the possible classes. Using two dense layers in this way can allow the model to learn more complex patterns in the data and make more accurate predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-dsrXi5cMjk",
        "outputId": "1cdc4614-4c2d-4af5-d141-05ecff502948"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running with seed: 3\n",
            "Model: \"Additional_FC_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 114, 300)          121123800 \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 114, 256)         439296    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 114, 114)         29298     \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 114, 46)          5290      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,597,684\n",
            "Trainable params: 473,884\n",
            "Non-trainable params: 121,123,800\n",
            "_________________________________________________________________\n",
            "\n",
            "Fitting the Additional_FC (seed 3) model...\n",
            "Epoch 1/25\n",
            "62/62 [==============================] - 4s 36ms/step - loss: 0.3986 - weighted_ignore_accuracy: 0.5651 - val_loss: 0.1127 - val_weighted_ignore_accuracy: 0.7679 - lr: 0.0100\n",
            "Epoch 2/25\n",
            "62/62 [==============================] - 1s 21ms/step - loss: 0.0809 - weighted_ignore_accuracy: 0.8097 - val_loss: 0.0687 - val_weighted_ignore_accuracy: 0.8271 - lr: 0.0100\n",
            "Epoch 3/25\n",
            "62/62 [==============================] - 1s 24ms/step - loss: 0.0498 - weighted_ignore_accuracy: 0.8534 - val_loss: 0.0621 - val_weighted_ignore_accuracy: 0.8376 - lr: 0.0100\n",
            "Epoch 4/25\n",
            "62/62 [==============================] - 1s 22ms/step - loss: 0.0365 - weighted_ignore_accuracy: 0.8714 - val_loss: 0.0594 - val_weighted_ignore_accuracy: 0.8455 - lr: 0.0100\n",
            "Epoch 5/25\n",
            "62/62 [==============================] - 1s 21ms/step - loss: 0.0280 - weighted_ignore_accuracy: 0.8834 - val_loss: 0.0578 - val_weighted_ignore_accuracy: 0.8487 - lr: 0.0100\n",
            "Epoch 6/25\n",
            "62/62 [==============================] - 1s 18ms/step - loss: 0.0221 - weighted_ignore_accuracy: 0.8919 - val_loss: 0.0588 - val_weighted_ignore_accuracy: 0.8517 - lr: 0.0100\n",
            "Epoch 7/25\n",
            "61/62 [============================>.] - ETA: 0s - loss: 0.0172 - weighted_ignore_accuracy: 0.9004\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.003299999926239252.\n",
            "62/62 [==============================] - 1s 18ms/step - loss: 0.0172 - weighted_ignore_accuracy: 0.9004 - val_loss: 0.0607 - val_weighted_ignore_accuracy: 0.8549 - lr: 0.0100\n",
            "Epoch 8/25\n",
            "62/62 [==============================] - 1s 21ms/step - loss: 0.0111 - weighted_ignore_accuracy: 0.9100 - val_loss: 0.0568 - val_weighted_ignore_accuracy: 0.8586 - lr: 0.0033\n",
            "Epoch 9/25\n",
            "62/62 [==============================] - 1s 18ms/step - loss: 0.0081 - weighted_ignore_accuracy: 0.9152 - val_loss: 0.0587 - val_weighted_ignore_accuracy: 0.8599 - lr: 0.0033\n",
            "Epoch 10/25\n",
            "61/62 [============================>.] - ETA: 0s - loss: 0.0069 - weighted_ignore_accuracy: 0.9181\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0010889999940991402.\n",
            "62/62 [==============================] - 1s 18ms/step - loss: 0.0069 - weighted_ignore_accuracy: 0.9181 - val_loss: 0.0597 - val_weighted_ignore_accuracy: 0.8595 - lr: 0.0033\n",
            "Epoch 11/25\n",
            "61/62 [============================>.] - ETA: 0s - loss: 0.0057 - weighted_ignore_accuracy: 0.9199Restoring model weights from the end of the best epoch: 8.\n",
            "62/62 [==============================] - 1s 18ms/step - loss: 0.0057 - weighted_ignore_accuracy: 0.9199 - val_loss: 0.0604 - val_weighted_ignore_accuracy: 0.8607 - lr: 0.0011\n",
            "Epoch 11: early stopping\n",
            "Evaluating the Additional_FC (seed 3) model...\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 0.0568 - weighted_ignore_accuracy: 0.8586\n",
            "Obtaining predictions from the Additional_FC (seed 3) model...\n",
            "41/41 [==============================] - 1s 6ms/step\n",
            "\n",
            "Macro f1 score: 0.7464047231692486\n",
            "\n",
            "Garbage collection: 8677\n",
            "Running with seed: 42\n",
            "Model: \"Additional_FC_42\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 114, 300)          121123800 \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 114, 256)         439296    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 114, 114)         29298     \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 114, 46)          5290      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,597,684\n",
            "Trainable params: 473,884\n",
            "Non-trainable params: 121,123,800\n",
            "_________________________________________________________________\n",
            "\n",
            "Fitting the Additional_FC (seed 42) model...\n",
            "Epoch 1/25\n",
            "62/62 [==============================] - 4s 37ms/step - loss: 0.3835 - weighted_ignore_accuracy: 0.5725 - val_loss: 0.1103 - val_weighted_ignore_accuracy: 0.7709 - lr: 0.0100\n",
            "Epoch 2/25\n",
            "62/62 [==============================] - 1s 22ms/step - loss: 0.0798 - weighted_ignore_accuracy: 0.8098 - val_loss: 0.0706 - val_weighted_ignore_accuracy: 0.8232 - lr: 0.0100\n",
            "Epoch 3/25\n",
            "62/62 [==============================] - 1s 22ms/step - loss: 0.0494 - weighted_ignore_accuracy: 0.8538 - val_loss: 0.0597 - val_weighted_ignore_accuracy: 0.8411 - lr: 0.0100\n",
            "Epoch 4/25\n",
            "62/62 [==============================] - 1s 23ms/step - loss: 0.0351 - weighted_ignore_accuracy: 0.8755 - val_loss: 0.0594 - val_weighted_ignore_accuracy: 0.8451 - lr: 0.0100\n",
            "Epoch 5/25\n",
            "62/62 [==============================] - 1s 21ms/step - loss: 0.0260 - weighted_ignore_accuracy: 0.8888 - val_loss: 0.0588 - val_weighted_ignore_accuracy: 0.8518 - lr: 0.0100\n",
            "Epoch 6/25\n",
            "62/62 [==============================] - 1s 21ms/step - loss: 0.0205 - weighted_ignore_accuracy: 0.8965 - val_loss: 0.0650 - val_weighted_ignore_accuracy: 0.8471 - lr: 0.0100\n",
            "Epoch 7/25\n",
            "62/62 [==============================] - ETA: 0s - loss: 0.0181 - weighted_ignore_accuracy: 0.8991\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.003299999926239252.\n",
            "62/62 [==============================] - 1s 21ms/step - loss: 0.0181 - weighted_ignore_accuracy: 0.8991 - val_loss: 0.0631 - val_weighted_ignore_accuracy: 0.8529 - lr: 0.0100\n",
            "Epoch 8/25\n",
            "59/62 [===========================>..] - ETA: 0s - loss: 0.0112 - weighted_ignore_accuracy: 0.9121Restoring model weights from the end of the best epoch: 5.\n",
            "62/62 [==============================] - 1s 22ms/step - loss: 0.0112 - weighted_ignore_accuracy: 0.9115 - val_loss: 0.0606 - val_weighted_ignore_accuracy: 0.8562 - lr: 0.0033\n",
            "Epoch 8: early stopping\n",
            "Evaluating the Additional_FC (seed 42) model...\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 0.0588 - weighted_ignore_accuracy: 0.8518\n",
            "Obtaining predictions from the Additional_FC (seed 42) model...\n",
            "41/41 [==============================] - 1s 6ms/step\n",
            "\n",
            "Macro f1 score: 0.6695683942036211\n",
            "\n",
            "Garbage collection: 8677\n",
            "Running with seed: 192\n",
            "Model: \"Additional_FC_192\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 114, 300)          121123800 \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 114, 256)         439296    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 114, 114)         29298     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ibuted)                                                         \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 114, 46)          5290      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,597,684\n",
            "Trainable params: 473,884\n",
            "Non-trainable params: 121,123,800\n",
            "_________________________________________________________________\n",
            "\n",
            "Fitting the Additional_FC (seed 192) model...\n",
            "Epoch 1/25\n",
            "62/62 [==============================] - 4s 38ms/step - loss: 0.4115 - weighted_ignore_accuracy: 0.5494 - val_loss: 0.1185 - val_weighted_ignore_accuracy: 0.7584 - lr: 0.0100\n",
            "Epoch 2/25\n",
            "62/62 [==============================] - 1s 23ms/step - loss: 0.0828 - weighted_ignore_accuracy: 0.8060 - val_loss: 0.0723 - val_weighted_ignore_accuracy: 0.8224 - lr: 0.0100\n",
            "Epoch 3/25\n",
            "62/62 [==============================] - 1s 23ms/step - loss: 0.0514 - weighted_ignore_accuracy: 0.8520 - val_loss: 0.0623 - val_weighted_ignore_accuracy: 0.8392 - lr: 0.0100\n",
            "Epoch 4/25\n",
            "62/62 [==============================] - 1s 19ms/step - loss: 0.0356 - weighted_ignore_accuracy: 0.8729 - val_loss: 0.0666 - val_weighted_ignore_accuracy: 0.8399 - lr: 0.0100\n",
            "Epoch 5/25\n",
            "61/62 [============================>.] - ETA: 0s - loss: 0.0284 - weighted_ignore_accuracy: 0.8822\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.003299999926239252.\n",
            "62/62 [==============================] - 1s 18ms/step - loss: 0.0285 - weighted_ignore_accuracy: 0.8821 - val_loss: 0.0636 - val_weighted_ignore_accuracy: 0.8476 - lr: 0.0100\n",
            "Epoch 6/25\n",
            "62/62 [==============================] - 1s 22ms/step - loss: 0.0174 - weighted_ignore_accuracy: 0.9012 - val_loss: 0.0589 - val_weighted_ignore_accuracy: 0.8557 - lr: 0.0033\n",
            "Epoch 7/25\n",
            "62/62 [==============================] - 1s 20ms/step - loss: 0.0134 - weighted_ignore_accuracy: 0.9073 - val_loss: 0.0607 - val_weighted_ignore_accuracy: 0.8558 - lr: 0.0033\n",
            "Epoch 8/25\n",
            "60/62 [============================>.] - ETA: 0s - loss: 0.0119 - weighted_ignore_accuracy: 0.9103\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0010889999940991402.\n",
            "62/62 [==============================] - 1s 21ms/step - loss: 0.0118 - weighted_ignore_accuracy: 0.9105 - val_loss: 0.0619 - val_weighted_ignore_accuracy: 0.8550 - lr: 0.0033\n",
            "Epoch 9/25\n",
            "59/62 [===========================>..] - ETA: 0s - loss: 0.0091 - weighted_ignore_accuracy: 0.9148Restoring model weights from the end of the best epoch: 6.\n",
            "62/62 [==============================] - 1s 22ms/step - loss: 0.0092 - weighted_ignore_accuracy: 0.9143 - val_loss: 0.0624 - val_weighted_ignore_accuracy: 0.8573 - lr: 0.0011\n",
            "Epoch 9: early stopping\n",
            "Evaluating the Additional_FC (seed 192) model...\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 0.0589 - weighted_ignore_accuracy: 0.8557\n",
            "Obtaining predictions from the Additional_FC (seed 192) model...\n",
            "41/41 [==============================] - 1s 6ms/step\n",
            "\n",
            "Macro f1 score: 0.6811702700428166\n",
            "\n",
            "Garbage collection: 8677\n"
          ]
        }
      ],
      "source": [
        "LR = 0.01\n",
        "\n",
        "add_fc_layer_params = [{'layer_type': 'Bidirectional',\n",
        "                          'layer_kwargs': {'units': 128, 'dropout': 0.2}},\n",
        "                         {'layer_type': 'Dense',\n",
        "                          'layer_kwargs':{'units': PAD_LENGTH,'activation': 'relu'}},\n",
        "                         {'layer_type': 'Dense',\n",
        "                          'layer_kwargs':{'units': len(tag2index),'activation': 'softmax'}}]\n",
        "\n",
        "add_fc_training_params = {'x': X_train, 'y': y_train_one_hot, 'validation_data': (X_val, y_val_one_hot),\n",
        "                          'batch_size': 32, 'epochs': 25, 'callbacks': callbacks} \n",
        "\n",
        "add_fc_model_recaps = run_models('Additional_FC',add_fc_layer_params,embedding_params,add_fc_training_params,metrics,LR,seeds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49cnWYeiE5Jt",
        "outputId": "1931ddec-92a9-4078-e1d4-6298aa0f3097"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean values: {'macro_f1': 0.6990477958052287, 'weighted_ignore_accuracy': 0.8553839524586996}\n"
          ]
        }
      ],
      "source": [
        "mean_metrics_add_fc = mean_metrics(add_fc_model_recaps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9ZTfE8sE81P"
      },
      "source": [
        "## 4. Comparisons\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWl1-ZxrskCX"
      },
      "source": [
        "### Val Weighted Ignore Accuracy during training "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open('baseline_model_recaps_hist.pkl', 'rb') as f:\n",
        "    baseline_model_recaps_hist = pickle.load(f)\n",
        "with open('gru_model_recaps_hist.pkl', 'rb') as f:\n",
        "    gru_model_recaps_hist = pickle.load(f)\n",
        "with open('add_lstm_model_recaps_hist.pkl', 'rb') as f:\n",
        "    add_lstm_model_recaps_hist = pickle.load(f)\n",
        "with open('add_fc_model_recaps_hist.pkl', 'rb') as f:\n",
        "    add_fc_model_recaps_hist = pickle.load(f)\n",
        "with open('mean_metrics_bl.pkl', 'rb') as f:\n",
        "    mean_metrics_bl = pickle.load(f)\n",
        "with open('mean_metrics_gru.pkl', 'rb') as f:\n",
        "    mean_metrics_gru = pickle.load(f)\n",
        "with open('mean_metrics_add_lstm.pkl', 'rb') as f:\n",
        "    mean_metrics_add_lstm = pickle.load(f)\n",
        "with open('mean_metrics_add_fc.pkl', 'rb') as f:\n",
        "    mean_metrics_add_fc = pickle.load(f)"
      ],
      "metadata": {
        "id": "4z9-2DjqpGmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "TDnmX0BUc6-P",
        "outputId": "c72bdc04-ab28-49f3-cd68-b2b3f5df515b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"49bd451c-1c6e-40c9-9452-87984bbe6348\" class=\"plotly-graph-div\" style=\"height:750px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"49bd451c-1c6e-40c9-9452-87984bbe6348\")) {                    Plotly.newPlot(                        \"49bd451c-1c6e-40c9-9452-87984bbe6348\",                        [{\"marker\":{\"color\":\"rgb(250,0,0)\"},\"mode\":\"lines+markers\",\"name\":\"Baseline_3\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14],\"y\":[0.7737600803375244,0.8203478455543518,0.8294687271118164,0.8399600386619568,0.8388607501983643,0.8417167663574219,0.8474260568618774,0.847672164440155,0.8479531407356262,0.8474137783050537],\"type\":\"scatter\"},{\"marker\":{\"color\":\"rgb(250,90,0)\"},\"mode\":\"lines+markers\",\"name\":\"Baseline_42\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14],\"y\":[0.7996222972869873,0.833838939666748,0.8466767072677612,0.8439153432846069,0.8509407043457031,0.8559019565582275,0.8578589558601379,0.8568549752235413,0.8578383922576904,0.8585007786750793],\"type\":\"scatter\"},{\"marker\":{\"color\":\"rgb(250,180,0)\"},\"mode\":\"lines+markers\",\"name\":\"Baseline_192\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14],\"y\":[0.8016875386238098,0.834534227848053,0.8423513770103455,0.8400574922561646,0.8450725674629211,0.8524675369262695,0.8542929887771606,0.8530943989753723,0.8536797761917114],\"type\":\"scatter\"},{\"marker\":{\"color\":\"rgb(0,0,250)\"},\"mode\":\"lines+markers\",\"name\":\"GRU_3\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14],\"y\":[0.7989295125007629,0.8171910643577576,0.8156329989433289,0.8245922327041626,0.835440456867218,0.8349905014038086,0.8362833261489868,0.8358380198478699],\"type\":\"scatter\"},{\"marker\":{\"color\":\"rgb(0,90,250)\"},\"mode\":\"lines+markers\",\"name\":\"GRU_42\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14],\"y\":[0.7964211702346802,0.8130742311477661,0.8224613070487976,0.8175317645072937,0.8252518773078918,0.8334004282951355],\"type\":\"scatter\"},{\"marker\":{\"color\":\"rgb(0,180,250)\"},\"mode\":\"lines+markers\",\"name\":\"GRU_192\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14],\"y\":[0.7968113422393799,0.8155515789985657,0.820733904838562,0.8255512714385986,0.8250254988670349,0.8223458528518677,0.8363438844680786],\"type\":\"scatter\"},{\"marker\":{\"color\":\"rgb(120,0,200)\"},\"mode\":\"lines+markers\",\"name\":\"Add_LSTM_3\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14],\"y\":[0.6330718398094177,0.803310751914978,0.828132152557373,0.8485379219055176,0.8506749868392944,0.8570908308029175,0.8589391112327576,0.8601530194282532,0.8651735186576843,0.8637582659721375,0.8651292324066162,0.8655218482017517],\"type\":\"scatter\"},{\"marker\":{\"color\":\"rgb(120,50,200)\"},\"mode\":\"lines+markers\",\"name\":\"Add_LSTM_42\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14],\"y\":[0.6609323620796204,0.7982437610626221,0.8319770097732544,0.8462731838226318,0.850744366645813,0.8488758206367493,0.8581433892250061,0.8570107221603394,0.8591881990432739,0.8627155423164368],\"type\":\"scatter\"},{\"marker\":{\"color\":\"rgb(120,100,200)\"},\"mode\":\"lines+markers\",\"name\":\"Add_LSTM_192\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14],\"y\":[0.6533921957015991,0.7990991473197937,0.8307368755340576,0.8455026149749756,0.8549399971961975,0.8577769994735718,0.8595378398895264,0.8579433560371399,0.8641337752342224],\"type\":\"scatter\"},{\"marker\":{\"color\":\"rgb(0,250,0)\"},\"mode\":\"lines+markers\",\"name\":\"Add_FC_3\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14],\"y\":[0.7679364681243896,0.8271157145500183,0.8375957608222961,0.8454533219337463,0.8487140536308289,0.8517109155654907,0.8549109697341919,0.858622670173645,0.8599466681480408,0.8595374226570129,0.8607000112533569],\"type\":\"scatter\"},{\"marker\":{\"color\":\"rgb(0,250,90)\"},\"mode\":\"lines+markers\",\"name\":\"Add_FC_42\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14],\"y\":[0.770926296710968,0.8231741786003113,0.841126024723053,0.8451448082923889,0.8518242239952087,0.8470529913902283,0.8528898358345032,0.8561707735061646],\"type\":\"scatter\"},{\"marker\":{\"color\":\"rgb(0,250,180)\"},\"mode\":\"lines+markers\",\"name\":\"Add_FC_192\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14],\"y\":[0.7583704590797424,0.82237309217453,0.8392422199249268,0.8399344682693481,0.8476008176803589,0.8557049632072449,0.855843722820282,0.8550358414649963,0.8572863936424255],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"val_weighted_accuracy during training\"},\"height\":750},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('49bd451c-1c6e-40c9-9452-87984bbe6348');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def plot_train(baseline_model_recaps,gru_model_recaps,add_lstm_model_recaps,add_fc_model_recaps,metric,ep=15):\n",
        "  epochs = np.arange(1,ep,1)\n",
        "  seedz = [3,42,192]\n",
        "  fig = go.Figure()\n",
        "  for i in range(len(baseline_model_recaps)):\n",
        "    fig.add_trace(go.Scatter(x=epochs, y=baseline_model_recaps[i], name=f'Baseline_{seedz[i]}', mode='lines+markers',marker=dict(color=f'rgb(250,{i*90},0)')))\n",
        "  for i in range(len(gru_model_recaps)):\n",
        "    fig.add_trace(go.Scatter(x=epochs, y=gru_model_recaps[i], name=f'GRU_{seedz[i]}', mode='lines+markers',marker=dict(color=f'rgb(0,{i*90},250)')))\n",
        "  for i in range(len(add_lstm_model_recaps)):\n",
        "    fig.add_trace(go.Scatter(x=epochs, y=add_lstm_model_recaps[i], name=f'Add_LSTM_{seedz[i]}', mode='lines+markers',marker=dict(color=f'rgb(120,{i*50},200)')))\n",
        "  for i in range(len(add_fc_model_recaps)):\n",
        "    fig.add_trace(go.Scatter(x=epochs, y=add_fc_model_recaps[i], name=f'Add_FC_{seedz[i]}', mode='lines+markers',marker=dict(color=f'rgb(0,250,{i*90})')))\n",
        "  fig.update_layout(title=f'{metric} during training',\n",
        "                    height=750)\n",
        "\n",
        "  fig.show()\n",
        "\n",
        "plot_train(baseline_model_recaps_hist,gru_model_recaps_hist,add_lstm_model_recaps_hist,add_fc_model_recaps_hist,'val_weighted_accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nb_IhG4pZiWJ",
        "outputId": "8fe99c92-0946-40a3-d381-f00b41c73831"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "marker": {
                    "color": "rgb(120,0,200)"
                  },
                  "mode": "lines+markers",
                  "name": "Additional_LSTM_3",
                  "type": "scatter",
                  "x": [
                    1,
                    2,
                    3,
                    4,
                    5,
                    6,
                    7,
                    8,
                    9,
                    10,
                    11,
                    12,
                    13,
                    14
                  ],
                  "y": [
                    0.6330718398094177,
                    0.803310751914978,
                    0.828132152557373,
                    0.8485379219055176,
                    0.8506749868392944,
                    0.8570908308029175,
                    0.8589391112327576,
                    0.8601530194282532,
                    0.8651735186576843,
                    0.8637582659721375,
                    0.8651292324066162,
                    0.8655218482017517
                  ]
                },
                {
                  "marker": {
                    "color": "rgb(120,50,200)"
                  },
                  "mode": "lines+markers",
                  "name": "Additional_LSTM_42",
                  "type": "scatter",
                  "x": [
                    1,
                    2,
                    3,
                    4,
                    5,
                    6,
                    7,
                    8,
                    9,
                    10,
                    11,
                    12,
                    13,
                    14
                  ],
                  "y": [
                    0.6609323620796204,
                    0.7982437610626221,
                    0.8319770097732544,
                    0.8462731838226318,
                    0.850744366645813,
                    0.8488758206367493,
                    0.8581433892250061,
                    0.8570107221603394,
                    0.8591881990432739,
                    0.8627155423164368
                  ]
                },
                {
                  "marker": {
                    "color": "rgb(120,100,200)"
                  },
                  "mode": "lines+markers",
                  "name": "Additional_LSTM_192",
                  "type": "scatter",
                  "x": [
                    1,
                    2,
                    3,
                    4,
                    5,
                    6,
                    7,
                    8,
                    9,
                    10,
                    11,
                    12,
                    13,
                    14
                  ],
                  "y": [
                    0.6533921957015991,
                    0.7990991473197937,
                    0.8307368755340576,
                    0.8455026149749756,
                    0.8549399971961975,
                    0.8577769994735718,
                    0.8595378398895264,
                    0.8579433560371399,
                    0.8641337752342224
                  ]
                },
                {
                  "marker": {
                    "color": "rgb(0,250,0)"
                  },
                  "mode": "lines+markers",
                  "name": "Additional_FC_3",
                  "type": "scatter",
                  "x": [
                    1,
                    2,
                    3,
                    4,
                    5,
                    6,
                    7,
                    8,
                    9,
                    10,
                    11,
                    12,
                    13,
                    14
                  ],
                  "y": [
                    0.7679364681243896,
                    0.8271157145500183,
                    0.8375957608222961,
                    0.8454533219337463,
                    0.8487140536308289,
                    0.8517109155654907,
                    0.8549109697341919,
                    0.858622670173645,
                    0.8599466681480408,
                    0.8595374226570129,
                    0.8607000112533569
                  ]
                },
                {
                  "marker": {
                    "color": "rgb(0,250,90)"
                  },
                  "mode": "lines+markers",
                  "name": "Additional_FC_42",
                  "type": "scatter",
                  "x": [
                    1,
                    2,
                    3,
                    4,
                    5,
                    6,
                    7,
                    8,
                    9,
                    10,
                    11,
                    12,
                    13,
                    14
                  ],
                  "y": [
                    0.7679364681243896,
                    0.8271157145500183,
                    0.8375957608222961,
                    0.8454533219337463,
                    0.8487140536308289,
                    0.8517109155654907,
                    0.8549109697341919,
                    0.858622670173645,
                    0.8599466681480408,
                    0.8595374226570129,
                    0.8607000112533569
                  ]
                },
                {
                  "marker": {
                    "color": "rgb(0,250,180)"
                  },
                  "mode": "lines+markers",
                  "name": "Additional_FC_192",
                  "type": "scatter",
                  "x": [
                    1,
                    2,
                    3,
                    4,
                    5,
                    6,
                    7,
                    8,
                    9,
                    10,
                    11,
                    12,
                    13,
                    14
                  ],
                  "y": [
                    0.7679364681243896,
                    0.8271157145500183,
                    0.8375957608222961,
                    0.8454533219337463,
                    0.8487140536308289,
                    0.8517109155654907,
                    0.8549109697341919,
                    0.858622670173645,
                    0.8599466681480408,
                    0.8595374226570129,
                    0.8607000112533569
                  ]
                }
              ],
              "layout": {
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "heatmapgl": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmapgl"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "val_weighted_ignore_accuracy during training"
                }
              }
            },
            "text/html": [
              "<div>                            <div id=\"8d3b0307-dea6-4dbd-8a8d-6902cbaab65f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8d3b0307-dea6-4dbd-8a8d-6902cbaab65f\")) {                    Plotly.newPlot(                        \"8d3b0307-dea6-4dbd-8a8d-6902cbaab65f\",                        [{\"marker\":{\"color\":\"rgb(120,0,200)\"},\"mode\":\"lines+markers\",\"name\":\"Additional_LSTM_3\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14],\"y\":[0.6330718398094177,0.803310751914978,0.828132152557373,0.8485379219055176,0.8506749868392944,0.8570908308029175,0.8589391112327576,0.8601530194282532,0.8651735186576843,0.8637582659721375,0.8651292324066162,0.8655218482017517],\"type\":\"scatter\"},{\"marker\":{\"color\":\"rgb(120,50,200)\"},\"mode\":\"lines+markers\",\"name\":\"Additional_LSTM_42\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14],\"y\":[0.6609323620796204,0.7982437610626221,0.8319770097732544,0.8462731838226318,0.850744366645813,0.8488758206367493,0.8581433892250061,0.8570107221603394,0.8591881990432739,0.8627155423164368],\"type\":\"scatter\"},{\"marker\":{\"color\":\"rgb(120,100,200)\"},\"mode\":\"lines+markers\",\"name\":\"Additional_LSTM_192\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14],\"y\":[0.6533921957015991,0.7990991473197937,0.8307368755340576,0.8455026149749756,0.8549399971961975,0.8577769994735718,0.8595378398895264,0.8579433560371399,0.8641337752342224],\"type\":\"scatter\"},{\"marker\":{\"color\":\"rgb(0,250,0)\"},\"mode\":\"lines+markers\",\"name\":\"Additional_FC_3\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14],\"y\":[0.7679364681243896,0.8271157145500183,0.8375957608222961,0.8454533219337463,0.8487140536308289,0.8517109155654907,0.8549109697341919,0.858622670173645,0.8599466681480408,0.8595374226570129,0.8607000112533569],\"type\":\"scatter\"},{\"marker\":{\"color\":\"rgb(0,250,90)\"},\"mode\":\"lines+markers\",\"name\":\"Additional_FC_42\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14],\"y\":[0.7679364681243896,0.8271157145500183,0.8375957608222961,0.8454533219337463,0.8487140536308289,0.8517109155654907,0.8549109697341919,0.858622670173645,0.8599466681480408,0.8595374226570129,0.8607000112533569],\"type\":\"scatter\"},{\"marker\":{\"color\":\"rgb(0,250,180)\"},\"mode\":\"lines+markers\",\"name\":\"Additional_FC_192\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14],\"y\":[0.7679364681243896,0.8271157145500183,0.8375957608222961,0.8454533219337463,0.8487140536308289,0.8517109155654907,0.8549109697341919,0.858622670173645,0.8599466681480408,0.8595374226570129,0.8607000112533569],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"val_weighted_ignore_accuracy during training\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8d3b0307-dea6-4dbd-8a8d-6902cbaab65f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                });            </script>        </div>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_train(baseline_model_recaps,gru_model_recaps,add_lstm_model_recaps,add_fc_model_recaps,metric,ep=15):\n",
        "  epochs = np.arange(1,ep,1)\n",
        "  fig = go.Figure()\n",
        "  for i in range(len(baseline_model_recaps)):\n",
        "    fig.add_trace(go.Scatter(x=epochs, y=baseline_model_recaps[i]['history'].history[metric], name=baseline_model_recaps[i]['name'], mode='lines+markers',marker=dict(color=f'rgb(250,{i*90},0)')))\n",
        "  for i in range(len(gru_model_recaps)):\n",
        "    fig.add_trace(go.Scatter(x=epochs, y=gru_model_recaps[i]['history'].history[metric], name=gru_model_recaps[i]['name'], mode='lines+markers',marker=dict(color=f'rgb(0,{i*90},250)')))\n",
        "  for i in range(len(add_lstm_model_recaps)):\n",
        "    fig.add_trace(go.Scatter(x=epochs, y=add_lstm_model_recaps[i]['history'].history[metric], name=add_lstm_model_recaps[i]['name'], mode='lines+markers',marker=dict(color=f'rgb(120,{i*50},200)')))\n",
        "  for i in range(len(add_fc_model_recaps)):\n",
        "    fig.add_trace(go.Scatter(x=epochs, y=add_fc_model_recaps[0]['history'].history[metric], name=add_fc_model_recaps[i]['name'], mode='lines+markers',marker=dict(color=f'rgb(0,250,{i*90})')))\n",
        "  fig.update_layout(title=f'{metric} during training')\n",
        "\n",
        "  fig.show()\n",
        "\n",
        "plot_train(baseline_model_recaps,gru_model_recaps,add_lstm_model_recaps,add_fc_model_recaps,'val_weighted_accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33o-CkV1svbM"
      },
      "source": [
        "### Average Macro F1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ShQ9GoTGzTK-",
        "outputId": "63a60255-34b8-4371-d4d1-dc164515d574",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"8dd80cac-a264-4f9e-812b-7f8e8efeef84\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8dd80cac-a264-4f9e-812b-7f8e8efeef84\")) {                    Plotly.newPlot(                        \"8dd80cac-a264-4f9e-812b-7f8e8efeef84\",                        [{\"x\":[\"Baseline\",\"GRU\",\"Add. LSTM\",\"Add. FC\"],\"y\":[0.6894489611930855,0.5990217521028044,0.7392192034718746,0.6990477958052287],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"title\":{\"text\":\"Model type\"}},\"yaxis\":{\"title\":{\"text\":\"Mean Macro F1\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8dd80cac-a264-4f9e-812b-7f8e8efeef84');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Sample data\n",
        "data = [mean_metrics_bl['macro_f1'], mean_metrics_gru['macro_f1'],\n",
        "        mean_metrics_add_lstm['macro_f1'], mean_metrics_add_fc['macro_f1']]\n",
        "\n",
        "# Create figure\n",
        "fig = go.Figure(data=[go.Bar(x=['Baseline','GRU', 'Add. LSTM', 'Add. FC'], y=data)])\n",
        "\n",
        "# Set titles for axes\n",
        "fig.update_layout(xaxis_title='Model type', yaxis_title='Mean Macro F1')\n",
        "\n",
        "# Show plot\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkAKkPz_tPxP"
      },
      "source": [
        "### Macro F1 scores and predictions on test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDuwt4K8tXCw"
      },
      "source": [
        "#### Additional LSTM layer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmH-ZgHak9ae",
        "outputId": "46d50fb1-d2c8-4577-810d-2c0a89b1f400"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating model 1 with the Test set:\n",
            "21/21 [==============================] - 2s 76ms/step - loss: 0.0422 - weighted_ignore_accuracy: 0.8700\n",
            "21/21 [==============================] - 2s 70ms/step\n",
            "Macro f1 score for model 1: 0.8427775668588268\n",
            "\n",
            "Evaluating model 2 with the Test set:\n",
            "21/21 [==============================] - 2s 69ms/step - loss: 0.0451 - weighted_ignore_accuracy: 0.8628\n",
            "21/21 [==============================] - 2s 68ms/step\n",
            "Macro f1 score for model 2: 0.7661198838989877\n",
            "\n",
            "Evaluating model 3 with the Test set:\n",
            "21/21 [==============================] - 2s 70ms/step - loss: 0.0434 - weighted_ignore_accuracy: 0.8620\n",
            "21/21 [==============================] - 2s 68ms/step\n",
            "Macro f1 score for model 3: 0.8050100723190999\n",
            "\n",
            "Mean macro f1 score on test set: 0.8046358410256381\n",
            "\n",
            "Test sentence: ['Freeport-McMoRan', 'Inc.', 'said', 'it', 'will', 'convert', 'its', 'Freeport-McMoRan', 'Energy', 'Partners', 'Ltd.', 'partnership', 'into', 'a', 'publicly', 'traded', 'company', 'through', 'the', 'exchange', 'of', 'units', 'of', 'the', 'partnership', 'for', 'common', 'shares', '.']\n",
            "Ground truth tags: ['NNP', 'NNP', 'VBD', 'PRP', 'MD', 'VB', 'PRP$', 'NNP', 'NNP', 'NNPS', 'NNP', 'NN', 'IN', 'DT', 'RB', 'VBN', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNS', 'IN', 'DT', 'NN', 'IN', 'JJ', 'NNS', '.']\n",
            "Predictions: ['NNP', 'NNP', 'VBD', 'PRP', 'MD', 'VB', 'PRP$', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'IN', 'DT', 'RB', 'VBN', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNS', 'IN', 'DT', 'NN', 'IN', 'JJ', 'NNS', '.']\n"
          ]
        }
      ],
      "source": [
        "add_lstm_test, predictions_add_lstm = test_f(add_lstm_model_recaps,X_test,X_test_np,y_test,y_test_one_hot,tag2index,index2tag,ignore)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSveDD3Dtfid"
      },
      "source": [
        "#### Additional Dense layer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ErUcAHqIEWY",
        "outputId": "d5877738-7e0f-4ff6-a054-fcaa006df8c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating model 1 with the Test set:\n",
            "21/21 [==============================] - 0s 16ms/step - loss: 0.0488 - weighted_ignore_accuracy: 0.8646\n",
            "21/21 [==============================] - 0s 6ms/step\n",
            "Macro f1 score for model 1: 0.7783077113332886\n",
            "\n",
            "Evaluating model 2 with the Test set:\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0508 - weighted_ignore_accuracy: 0.8587\n",
            "21/21 [==============================] - 0s 6ms/step\n",
            "Macro f1 score for model 2: 0.7374301280504473\n",
            "\n",
            "Evaluating model 3 with the Test set:\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.0451 - weighted_ignore_accuracy: 0.8649\n",
            "21/21 [==============================] - 0s 6ms/step\n",
            "Macro f1 score for model 3: 0.7828975745879597\n",
            "\n",
            "Mean macro f1 score on test set: 0.7662118046572318\n",
            "\n",
            "Test sentence: ['New', 'rules', 'force', 'thrifts', 'to', 'write', 'down', 'their', 'junk', 'to', 'market', 'value', ',', 'then', 'sell', 'the', 'bonds', 'over', 'five', 'years', '.']\n",
            "Ground truth tags: ['JJ', 'NNS', 'VBP', 'NNS', 'TO', 'VB', 'RP', 'PRP$', 'NN', 'TO', 'NN', 'NN', ',', 'RB', 'VB', 'DT', 'NNS', 'IN', 'CD', 'NNS', '.']\n",
            "Predictions: ['NNP', 'NNS', 'NN', 'NNS', 'TO', 'VB', 'RP', 'PRP$', 'NN', 'TO', 'NN', 'NN', ',', 'RB', 'VBP', 'DT', 'NNS', 'IN', 'CD', 'NNS', '.']\n"
          ]
        }
      ],
      "source": [
        "add_fc_test, predictions_add_fc = test_f(add_fc_model_recaps,X_test,X_test_np,y_test,y_test_one_hot,tag2index,index2tag,ignore)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yA9K9bx3QoOz"
      },
      "source": [
        "###Test the model with a keyboard-input sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox81pkqx-1vN",
        "outputId": "12170b62-0dcc-45cb-960e-a2a6306e6978"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter a sentence: I hope I am correctly performing part of speech tagging .\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Sentence: ['I', 'hope', 'I', 'am', 'correctly', 'performing', 'part', 'of', 'speech', 'tagging', '.']\n",
            "Predicted pos tags: ['PRP', 'VBP', 'PRP', 'VBP', 'RB', 'VBG', 'NN', 'IN', 'NN', 'VBG', '.']\n"
          ]
        }
      ],
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', split=' ', lower=False, char_level=False, oov_token=False)\n",
        "tokenizer.word_index = word2index\n",
        "\n",
        "sentence = input(\"Please enter a sentence: \")\n",
        "encoded_sentence = tokenizer.texts_to_sequences([sentence])\n",
        "padded_sentence = pad_sequences(sequences=encoded_sentence,dtype='float32',maxlen=PAD_LENGTH, padding='post')\n",
        "prediction = add_fc_model_recaps[0][\"model\"].predict(padded_sentence)\n",
        "prediction = np.argmax(prediction, axis=-1)\n",
        "\n",
        "print(f'Sentence: {[index2word[word] for word in encoded_sentence[0]]}')\n",
        "print(f'Predicted pos tags: {[index2tag[tag] for tag in prediction[0] if index2tag[tag] != \"-PAD-\"]}') \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbH-fGCYZiWK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}