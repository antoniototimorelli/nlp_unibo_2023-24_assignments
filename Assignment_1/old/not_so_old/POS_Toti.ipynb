{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WeCeITXoxLf"
      },
      "source": [
        "# Assignment 1\n",
        "\n",
        "**Due to**: 11/01/2022 (dd/mm/yyyy)\n",
        "\n",
        "If you deliver it by 11/12/2021 your assignment will be graded by 11/01/2022.\n",
        "\n",
        "\n",
        "**Credits**: Andrea Galassi, Federico Ruggeri, Paolo Torroni\n",
        "\n",
        "**Summary**: Part-of Speech (POS) tagging as Sequence Labelling using Recurrent Neural Architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4_wqPdlBcKS"
      },
      "source": [
        "# Execution\n",
        "## 0. Utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import absl.logging\n",
        "absl.logging.set_verbosity(absl.logging.ERROR)\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import progressbar\n",
        "\n",
        "import nltk\n",
        "import sklearn\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, GRU, TimeDistributed\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "nltk.download('treebank')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "Bk3FPDTGw_4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cf30d34-2af2-4096-fb6c-b3763b3eb22f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "An embedding matrix is a matrix of numerical vectors that represents the words in a vocabulary as low-dimensional dense vectors. These vectors are often used to initialize the weights of a neural network model, such as a long short-term memory (LSTM) network or a Gated Recurrent Unit (GRU)."
      ],
      "metadata": {
        "id": "5cP3vRKzC5ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
        "  vocab_size = len(word_index)+1\n",
        "  # Words that are not in the GloVe vocabulary will have a zero embedding\n",
        "  embedding_matrix = np.zeros((vocab_size,embedding_dim))\n",
        "\n",
        "  with open(filepath, encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "      word, *vector = line.split()\n",
        "      # Words that are in the GloVe vocabulary will have a non-zero embedding\n",
        "      if word in word_index:\n",
        "        idx = word_index[word]\n",
        "        embedding_matrix[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]\n",
        "  return embedding_matrix"
      ],
      "metadata": {
        "id": "Kx5qPakFMJFw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Corpus\n",
        "### 1.1 Pre-processing\n",
        "\n",
        "From the original tags list we removed all the symbols and english punctuation plus:\n",
        "- FW, Foreign Word, because there are no examples in the test set;\n",
        "- UH, Interjection, because there are no examples in the test set;\n",
        "- LS, List Item Marker, because there are no examples in the test set (and because it denotes symbols as well);"
      ],
      "metadata": {
        "id": "pJVKURDWIGMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the files' list\n",
        "fileids = nltk.corpus.treebank.fileids()\n",
        "\n",
        "# Get the Penn Treebank corpus and tokenize the text\n",
        "train_corpus = nltk.corpus.treebank.tagged_sents(fileids[:100])\n",
        "val_corpus = nltk.corpus.treebank.tagged_sents(fileids[100:150])\n",
        "test_corpus = nltk.corpus.treebank.tagged_sents(fileids[150:])\n",
        "\n",
        "# Flatten the lists\n",
        "remove = [':', '#', '\"', '$', '-LRB-', '-RRB-', ',', '.', \"''\", '``', 'SYM', '-NONE-']\n",
        "\n",
        "train_corpus = [tuple(list(item)+[str(idx)]) for idx,sublist in enumerate(train_corpus) for item in sublist if item[1] not in remove]\n",
        "val_corpus = [tuple(list(item)+[str(idx)]) for idx,sublist in enumerate(val_corpus) for item in sublist if item[1] not in remove]\n",
        "test_corpus = [tuple(list(item)+[str(idx)]) for idx,sublist in enumerate(test_corpus) for item in sublist if item[1] not in remove]"
      ],
      "metadata": {
        "id": "4DjxkoiXIJ5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.DataFrame(train_corpus, columns = ['word', 'tag', 'sentence'])\n",
        "# train_df['word'] = pre_process(train_df,'word')\n",
        "\n",
        "print(train_df.shape)\n",
        "train_df.describe()"
      ],
      "metadata": {
        "id": "LTx_uTCIjRbt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "598ea879-f82b-4cd2-c1c0-0b60bf2a0089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(41274, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         word    tag sentence\n",
              "count   41274  41274    41274\n",
              "unique   7989     35     1963\n",
              "top       the     NN     1854\n",
              "freq     1981   6270      171"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c5559eed-1257-4c33-af54-aa49f7d4a68d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>41274</td>\n",
              "      <td>41274</td>\n",
              "      <td>41274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>7989</td>\n",
              "      <td>35</td>\n",
              "      <td>1963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>the</td>\n",
              "      <td>NN</td>\n",
              "      <td>1854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1981</td>\n",
              "      <td>6270</td>\n",
              "      <td>171</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5559eed-1257-4c33-af54-aa49f7d4a68d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c5559eed-1257-4c33-af54-aa49f7d4a68d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c5559eed-1257-4c33-af54-aa49f7d4a68d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_df = pd.DataFrame(val_corpus, columns = ['word', 'tag', 'sentence'])\n",
        "# val_df['word'] = pre_process(val_df,'word')\n",
        "\n",
        "print(val_df.shape)\n",
        "val_df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "9fYRqQK7QYW8",
        "outputId": "e6c6e600-4781-4992-a756-5998afebac60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(27418, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         word    tag sentence\n",
              "count   27418  27418    27418\n",
              "unique   5873     35     1299\n",
              "top       the     NN      339\n",
              "freq     1429   4513       75"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c003d0e-55be-49a7-8cb6-8dca85d776a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>27418</td>\n",
              "      <td>27418</td>\n",
              "      <td>27418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>5873</td>\n",
              "      <td>35</td>\n",
              "      <td>1299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>the</td>\n",
              "      <td>NN</td>\n",
              "      <td>339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1429</td>\n",
              "      <td>4513</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c003d0e-55be-49a7-8cb6-8dca85d776a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c003d0e-55be-49a7-8cb6-8dca85d776a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c003d0e-55be-49a7-8cb6-8dca85d776a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.DataFrame(test_corpus, columns = ['word', 'tag', 'sentence'])\n",
        "# test_df['word'] = pre_process(test_df,'word')\n",
        "\n",
        "print(test_df.shape)\n",
        "test_df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "egACcyleOvPK",
        "outputId": "533a7f8f-8551-4edd-b98d-dd04b5975a57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13676, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         word    tag sentence\n",
              "count   13676  13676    13676\n",
              "unique   3608     32      652\n",
              "top       the     NN      231\n",
              "freq      635   2383       51"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ef3ec71-03f8-4c94-b100-74bddae2a731\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>tag</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>13676</td>\n",
              "      <td>13676</td>\n",
              "      <td>13676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>3608</td>\n",
              "      <td>32</td>\n",
              "      <td>652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>the</td>\n",
              "      <td>NN</td>\n",
              "      <td>231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>635</td>\n",
              "      <td>2383</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ef3ec71-03f8-4c94-b100-74bddae2a731')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6ef3ec71-03f8-4c94-b100-74bddae2a731 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6ef3ec71-03f8-4c94-b100-74bddae2a731');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tags_train = sorted(list(set([x for x in train_df.tag])))\n",
        "tags_val = sorted(list(set([x for x in val_df.tag])))\n",
        "tags_test = sorted(list(set([x for x in test_df.tag])))\n",
        "\n",
        "print('Train tags number:',len(tags_train))\n",
        "print('Val tags number:',len(tags_val))\n",
        "print('Test tags number:',len(tags_test))\n",
        "\n",
        "if len(tags_test) != len(tags_val) or len(tags_test) != len(tags_train):\n",
        "  print('\\nMismatching numbers.')\n",
        "  print('Removing extra classes:')\n",
        "\n",
        "  missing_classes_train = [x for x in tags_train if x not in tags_test]\n",
        "  missing_classes_val   = [x for x in tags_val if x not in tags_test]\n",
        "\n",
        "  missing_classes = list(set(missing_classes_train + missing_classes_val))\n",
        "  print(missing_classes)\n",
        "\n",
        "  for cl in missing_classes:\n",
        "    train_df = train_df[train_df.tag != cl]\n",
        "    val_df = val_df[val_df.tag != cl]\n",
        "\n",
        "  tags_train = sorted(list(set([x for x in train_df.tag])))\n",
        "  tags_val = sorted(list(set([x for x in val_df.tag])))\n",
        "  tags_test = sorted(list(set([x for x in test_df.tag])))\n",
        "\n",
        "  print('\\nNew Train tags number:',len(tags_train))\n",
        "  print('New Val tags number:',len(tags_val))\n",
        "  print('New Test tags number:',len(tags_test))\n",
        "\n",
        "print('\\nTags:')\n",
        "for tag in tags_train:\n",
        "  print(f'-{tag}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgW-xj7fRI2u",
        "outputId": "c417149c-ad75-4794-876b-50a8c9b32a6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train tags number: 35\n",
            "Val tags number: 35\n",
            "Test tags number: 32\n",
            "\n",
            "Mismatching numbers.\n",
            "Removing extra classes:\n",
            "['FW', 'UH', 'LS']\n",
            "\n",
            "New Train tags number: 32\n",
            "New Val tags number: 32\n",
            "New Test tags number: 32\n",
            "\n",
            "Tags:\n",
            "-CC\n",
            "-CD\n",
            "-DT\n",
            "-EX\n",
            "-IN\n",
            "-JJ\n",
            "-JJR\n",
            "-JJS\n",
            "-MD\n",
            "-NN\n",
            "-NNP\n",
            "-NNPS\n",
            "-NNS\n",
            "-PDT\n",
            "-POS\n",
            "-PRP\n",
            "-PRP$\n",
            "-RB\n",
            "-RBR\n",
            "-RBS\n",
            "-RP\n",
            "-TO\n",
            "-VB\n",
            "-VBD\n",
            "-VBG\n",
            "-VBN\n",
            "-VBP\n",
            "-VBZ\n",
            "-WDT\n",
            "-WP\n",
            "-WP$\n",
            "-WRB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_raw = train_df.groupby('sentence').word.apply(list).reset_index()['word']\n",
        "y_train_raw = train_df.groupby('sentence').tag.apply(list).reset_index()['tag']\n",
        "\n",
        "X_val_raw = val_df.groupby('sentence').word.apply(list).reset_index()['word']\n",
        "y_val_raw = val_df.groupby('sentence').tag.apply(list).reset_index()['tag']\n",
        "\n",
        "X_test_raw = test_df.groupby('sentence').word.apply(list).reset_index()['word']\n",
        "y_test_raw = test_df.groupby('sentence').tag.apply(list).reset_index()['tag']\n",
        "\n",
        "X = [*X_train_raw, *X_val_raw, *X_test_raw]\n",
        "y = [*y_train_raw, *y_val_raw, *y_test_raw]"
      ],
      "metadata": {
        "id": "NRTzmF0MTJog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode X\n",
        "\n",
        "word_tokenizer = Tokenizer()\n",
        "word_tokenizer.fit_on_texts(X)\n",
        "\n",
        "num_words = 9000\n",
        "word_tokenizer.word_index = {e:i for e,i in word_tokenizer.word_index.items() if i <= num_words}\n",
        "word_tokenizer.word_index[word_tokenizer.oov_token] = num_words + 1\n",
        "\n",
        "X_train = word_tokenizer.texts_to_sequences(X_train_raw)\n",
        "X_val = word_tokenizer.texts_to_sequences(X_val_raw)\n",
        "X_test = word_tokenizer.texts_to_sequences(X_test_raw)\n",
        "\n",
        "vocab_size = len(word_tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "DYlL3zP1aErC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode Y\n",
        "\n",
        "tag_tokenizer = Tokenizer()\n",
        "tag_tokenizer.fit_on_texts(y)\n",
        "\n",
        "y_train = tag_tokenizer.texts_to_sequences(y_train_raw)\n",
        "y_val = tag_tokenizer.texts_to_sequences(y_val_raw)\n",
        "y_test = tag_tokenizer.texts_to_sequences(y_test_raw)"
      ],
      "metadata": {
        "id": "qD3cHHqiXnTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('-Not encoded')\n",
        "print('\\t',X_train_raw[0]) \n",
        "print('\\t',y_train_raw[0])\n",
        "print('-Encoded')\n",
        "print('\\t',X_train[0])\n",
        "print('\\t',y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fa96Z_7YDkb",
        "outputId": "46be8ddb-ab37-4a7e-8ccd-26c2a5d29a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-Not encoded\n",
            "\t ['Pierre', 'Vinken', '61', 'years', 'old', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29']\n",
            "\t ['NNP', 'NNP', 'CD', 'NNS', 'JJ', 'MD', 'VB', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'CD']\n",
            "-Encoded\n",
            "\t [5398, 3694, 1987, 70, 305, 34, 2366, 1, 112, 17, 4, 1988, 306, 433, 1989]\n",
            "\t [3, 3, 7, 5, 6, 18, 10, 4, 1, 2, 4, 6, 1, 3, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check length of longest sentence\n",
        "lengths = [len(seq) for seq in X_train+X_test+X_val]\n",
        "print(\"Length of longest sentence: {}\".format(max(lengths)))\n",
        "print(\"Average length: {}\".format(sum(lengths)/len(lengths)))\n",
        "\n",
        "max_len = max(lengths)\n",
        "X_train = pad_sequences(X_train,padding='post',maxlen=max_len)\n",
        "X_val = pad_sequences(X_val,padding='post',maxlen=max_len)\n",
        "X_test = pad_sequences(X_test,padding='post',maxlen=max_len)\n",
        "\n",
        "y_train = pad_sequences(y_train,padding='post',maxlen=max_len)\n",
        "y_val = pad_sequences(y_val,padding='post',maxlen=max_len)\n",
        "y_test = pad_sequences(y_test,padding='post',maxlen=max_len)\n",
        "\n",
        "print('-Padded')\n",
        "print('\\tX:',X_train[0])\n",
        "print('\\n\\ty:',y_train[0])"
      ],
      "metadata": {
        "id": "wRuwom1nZhlp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5aa34dd-560a-418f-f5c1-3c3b7946c186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of longest sentence: 171\n",
            "Average length: 20.548288196218703\n",
            "-Padded\n",
            "\tX: [5398 3694 1987   70  305   34 2366    1  112   17    4 1988  306  433\n",
            " 1989    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0]\n",
            "\n",
            "\ty: [ 3  3  7  5  6 18 10  4  1  2  4  6  1  3  7  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "WlpXFvLaaAZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. GloVe \n",
        "GloVe (Global Vectors for Word Representation) is a method for learning vector representations of words, called \"word embeddings,\" from a large corpus of text. Word embeddings are numerical representations of words that capture the semantic relationships between words in a continuous, low-dimensional space. They are commonly used as input to natural language processing models, such as language translation and language modeling.\n",
        "\n",
        "GloVe works by learning the co-occurrence statistics of words in a corpus, and using this information to learn word embeddings that capture the semantic relationships between words. The GloVe method produces word embeddings that are trained on a global corpus, as opposed to embeddings that are trained on a specific task or dataset.\n",
        "\n",
        "There are different versions of the GloVe word embeddings, including 50-dimensional, 100-dimensional, and 200-dimensional embeddings. The 50-dimensional version of GloVe embeddings may be better in some applications because they have a lower dimensionality, which can make them easier to work with and more computationally efficient.\n",
        "\n",
        "By using GloVe embeddings as the initial weights for a model, we can take advantage of these pre-trained word representations and fine-tune them for a specific task."
      ],
      "metadata": {
        "id": "WjIVKo-zH0AA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pbar = None\n",
        "def show_progress(block_num, block_size, total_size):\n",
        "    global pbar\n",
        "    if pbar is None:\n",
        "        pbar = progressbar.ProgressBar(maxval=total_size)\n",
        "        pbar.start()\n",
        "\n",
        "    downloaded = block_num * block_size\n",
        "    if downloaded < total_size:\n",
        "        pbar.update(downloaded)\n",
        "    else:\n",
        "        pbar.finish()\n",
        "        pbar = None\n",
        "\n",
        "# Download the GloVe embeddings file\n",
        "url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
        "urllib.request.urlretrieve(url, 'glove.6B.zip', show_progress)\n",
        "\n",
        "# Extract the zip file\n",
        "zip_ref = zipfile.ZipFile('glove.6B.zip', 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whkzW_UI9Amy",
        "outputId": "259716e2-15b1-4cab-91be-17b24880ac2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100% (862182613 of 862182613) |##########| Elapsed Time: 0:02:38 Time:  0:02:38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the GloVe embeddings into a dictionary\n",
        "embedding_dict = {}\n",
        "embedding_dim = 300\n",
        "with open(f'glove.6B.{embedding_dim}d.txt', 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embedding_dict[word] = coefs\n",
        "\n",
        "# Print the number of words in the embeddings dictionary\n",
        "print(f'Found {len(embedding_dict)} word vectors.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHAd-w3p9V-u",
        "outputId": "7581d36c-4971-4336-96b7-e824aece93f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = X_train.shape[1]\n",
        "embedding_dim = 300\n",
        "embedding_matrix = create_embedding_matrix(f'glove.6B.{embedding_dim}d.txt', word_tokenizer.word_index, embedding_dim)"
      ],
      "metadata": {
        "id": "uSgIkyfvaaHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Model\n",
        "### 3.1 Baseline (MACRO f1 0.952)\n",
        "Bidirectional LSTM layers are able to process sequential data in both the forward and backward directions, which can allow the model to capture contextual information from both the past and the future. This can be particularly useful for natural language processing tasks, where the meaning of a word can depend on the context in which it is used.\n",
        "\n",
        "In the context of POS tagging, TimeDistributed can be used to apply a tag prediction layer to each word in a sentence. For example, you might have an RNN that processes a sequence of words in a sentence, and at each time step, the RNN outputs a hidden state. You could then apply a TimeDistributed dense layer to the hidden states, which would allow you to predict the POS tag for each word in the sentence.\n",
        "\n",
        "One advantage of using TimeDistributed for POS tagging is that it allows you to predict the POS tag for each word in the sentence simultaneously, rather than having to process the sentence one word at a time. This can be particularly useful when dealing with long sentences, as it can make the tagging process more efficient.\n",
        "\n",
        "Overall, using TimeDistributed for POS tagging can help you build more accurate and efficient models for natural language processing tasks that involve sequential data."
      ],
      "metadata": {
        "id": "hcBHOgcP3OW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "baseline_model = tf.keras.Sequential(name='Baseline')\n",
        "\n",
        "# Add the Embedding layer\n",
        "baseline_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, \\\n",
        "                    weights = [embedding_matrix], input_length = max_len, trainable=True))\n",
        "\n",
        "# Add the Bidirectional LSTM layer\n",
        "baseline_model.add(Bidirectional(LSTM(units=64, return_sequences=True)))\n",
        "\n",
        "# Add the Dense/Fully-Connected layer\n",
        "baseline_model.add(TimeDistributed(Dense(units=len(tags_train)+1, activation='softmax')))\n",
        "\n",
        "# Compile the model\n",
        "baseline_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summary\n",
        "baseline_model.summary()"
      ],
      "metadata": {
        "id": "RTDDziCuKz0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19ce1876-1a68-4095-a0bc-119bde3e6dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Baseline\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 171, 300)          2700600   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 171, 128)         186880    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 171, 33)          4257      \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,891,737\n",
            "Trainable params: 2,891,737\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_baseline = baseline_model.fit(X_train, y_train, epochs=10, verbose = True, validation_data=(X_val,y_val), batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlB64WAzDr_p",
        "outputId": "b0b3cb83-e03a-4712-eb48-4c6eac07f2ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 23s 1s/step - loss: 2.7149 - accuracy: 0.8551 - val_loss: 0.6498 - val_accuracy: 0.8867\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 18s 1s/step - loss: 0.4639 - accuracy: 0.8919 - val_loss: 0.3760 - val_accuracy: 0.8991\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 18s 1s/step - loss: 0.3393 - accuracy: 0.9126 - val_loss: 0.3406 - val_accuracy: 0.9119\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 18s 1s/step - loss: 0.3061 - accuracy: 0.9237 - val_loss: 0.3206 - val_accuracy: 0.9159\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 18s 1s/step - loss: 0.2774 - accuracy: 0.9291 - val_loss: 0.3012 - val_accuracy: 0.9205\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 18s 1s/step - loss: 0.2500 - accuracy: 0.9346 - val_loss: 0.2836 - val_accuracy: 0.9252\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 18s 1s/step - loss: 0.2237 - accuracy: 0.9412 - val_loss: 0.2686 - val_accuracy: 0.9310\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 18s 1s/step - loss: 0.1987 - accuracy: 0.9500 - val_loss: 0.2555 - val_accuracy: 0.9370\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 18s 1s/step - loss: 0.1751 - accuracy: 0.9587 - val_loss: 0.2443 - val_accuracy: 0.9410\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 18s 1s/step - loss: 0.1530 - accuracy: 0.9651 - val_loss: 0.2352 - val_accuracy: 0.9449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = baseline_model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ko3L8znnFWPx",
        "outputId": "24711cf3-4a36-475a-d2eb-7a567ae4dc8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 3s 115ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the predictions and the true labels to 1D arrays\n",
        "predictions = y_pred.flatten()\n",
        "y_true = y_test.flatten()\n",
        "\n",
        "th = 0.1\n",
        "predictions[predictions >= th] = 1 \n",
        "predictions[predictions  < th] = 0\n",
        "\n",
        "# Compute the F1 score\n",
        "f1_baseline = f1_score(y_true, predictions, average = 'macro')\n",
        "\n",
        "print(\"Macro-F1 score:\", round(f1_baseline,3))\n",
        "\n",
        "baseline_model.save('./baseline_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRAL4g-wOHjo",
        "outputId": "7c077fb8-f343-454f-cab3-459de2b924f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro-F1 score: 0.952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 GRU (MACRO f1 0.958)\n",
        "Gated Recurrent Units (GRUs) are a type of recurrent neural network (RNN) that are often used in natural language processing tasks such as part-of-speech (POS) tagging. GRUs are similar to long short-term memory (LSTM) networks, but they have a simpler structure and fewer parameters, making them easier to train and faster to run. In POS tagging, GRUs can be used to process a sequence of words and predict the POS tags for each word in the sequence. GRUs are able to take into account contextual information from the previous words in the sequence, allowing them to make more accurate predictions about the POS tags for the current word. \n",
        "\n",
        "Both BiLSTMs (Bidirectional LSTMs) and Gated Recurrent Units (GRUs) have been shown to perform well on a variety of NLP tasks, including POS tagging, but here we obtained slightly better results than with the baseline; the reason may be that LSTMs are are particularly well-suited for tasks that require the model to remember and make use of long-term dependencies in the data, while the longest sentence in the Penn Treebank dataset has only 171 words and the average of words per sentence is around 20.  "
      ],
      "metadata": {
        "id": "MZ88BEh9qBkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "gru_model = tf.keras.Sequential(name='GRU')\n",
        "\n",
        "# Add the Embedding layer\n",
        "gru_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, \\\n",
        "                    weights = [embedding_matrix], input_length = max_len, trainable=True))\n",
        "\n",
        "# Add the GRU layer\n",
        "gru_model.add(GRU(units=128, return_sequences=True))\n",
        "\n",
        "# Add the Dense/Fully-Connected layer\n",
        "gru_model.add(TimeDistributed(Dense(len(tags_train)+1, activation='softmax')))\n",
        "\n",
        "# Compile the model\n",
        "gru_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summary\n",
        "gru_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c5c38f4-84c5-4343-8a94-5f6f7ef1cea0",
        "id": "IazFXPFgyMf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 171, 300)          2700600   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 171, 128)          165120    \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 171, 33)          4257      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,869,977\n",
            "Trainable params: 2,869,977\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_gru = gru_model.fit(X_train, y_train, epochs=10, verbose = True, validation_data=(X_val,y_val), batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef06182a-21dc-42dd-cb32-f75b2b2fd296",
        "id": "Y5JzsycPyMf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 17s 882ms/step - loss: 2.6378 - accuracy: 0.8737 - val_loss: 0.5287 - val_accuracy: 0.8834\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 13s 837ms/step - loss: 0.4013 - accuracy: 0.9041 - val_loss: 0.3521 - val_accuracy: 0.9104\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 13s 830ms/step - loss: 0.3130 - accuracy: 0.9205 - val_loss: 0.3204 - val_accuracy: 0.9148\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 15s 960ms/step - loss: 0.2680 - accuracy: 0.9334 - val_loss: 0.2860 - val_accuracy: 0.9275\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 14s 836ms/step - loss: 0.2301 - accuracy: 0.9464 - val_loss: 0.2676 - val_accuracy: 0.9333\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 13s 831ms/step - loss: 0.1957 - accuracy: 0.9542 - val_loss: 0.2515 - val_accuracy: 0.9383\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 13s 829ms/step - loss: 0.1655 - accuracy: 0.9620 - val_loss: 0.2403 - val_accuracy: 0.9429\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 13s 832ms/step - loss: 0.1400 - accuracy: 0.9686 - val_loss: 0.2331 - val_accuracy: 0.9465\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 13s 847ms/step - loss: 0.1188 - accuracy: 0.9743 - val_loss: 0.2288 - val_accuracy: 0.9498\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 13s 828ms/step - loss: 0.1010 - accuracy: 0.9786 - val_loss: 0.2269 - val_accuracy: 0.9516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = gru_model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de50b6aa-f90e-41cf-e989-d4b4dae0f292",
        "id": "hPIRHnThyMf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 2s 87ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the predictions and the true labels to 1D arrays\n",
        "predictions = y_pred.flatten()\n",
        "y_true = y_test.flatten()\n",
        "\n",
        "th = 0.1\n",
        "predictions[predictions >= th] = 1 \n",
        "predictions[predictions  < th] = 0\n",
        "\n",
        "# Compute the F1 score\n",
        "f1_gru = f1_score(y_true, predictions, average = 'macro')\n",
        "\n",
        "print(\"Macro-F1 score:\", round(f1_gru,3))\n",
        "\n",
        "gru_model.save('./gru_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36c0ac20-51c0-45b2-aef1-03c12c3aaabe",
        "id": "o47IL2wJyMf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro-F1 score: 0.958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Additional LSTM layer (MACRO f1 0.967) \n",
        "Using two BiLSTMs layers can allow the model to learn more complex patterns in the data and make more accurate predictions. \n",
        "However, they can increase the computational complexity of our model, which may require more computational resources to train.\n",
        "\n",
        "With the same number of epochs the results were similar to the baseline and the training process was slower; it is possible that the model with two BiLSTMs is more prone to overfitting, meaning that it is able to fit the training data very well but is less able to generalize to new data. Another possibility is that the model with two BiLSTMs simply takes longer to train. That is why we raised the training epochs to 15, obtaining better results."
      ],
      "metadata": {
        "id": "V0DshbMkqj2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "add_lstm_model = tf.keras.Sequential(name='Additional_LSTM')\n",
        "\n",
        "# Add the Embedding layer\n",
        "add_lstm_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, \\\n",
        "                    weights = [embedding_matrix], input_length = max_len, trainable=True))\n",
        "\n",
        "# Add the Bidirectional LSTM layer\n",
        "add_lstm_model.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
        "\n",
        "# Add another LSTM layer\n",
        "add_lstm_model.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
        "\n",
        "# Add the Dense/Fully-Connected layer\n",
        "add_lstm_model.add(TimeDistributed(Dense(units=len(tags_train)+1, activation='softmax')))\n",
        "\n",
        "# Compile the model\n",
        "add_lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summary\n",
        "add_lstm_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ec0aac5-aa5f-4c95-b839-0f9d8acf033f",
        "id": "bHg9dRXf018R"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Additional_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 171, 300)          2700600   \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 171, 256)         439296    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 171, 256)         394240    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDis  (None, 171, 33)          8481      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,542,617\n",
            "Trainable params: 3,542,617\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_add_lstm = add_lstm_model.fit(X_train, y_train, epochs=15, verbose = True, validation_data=(X_val,y_val), batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3852750-b094-4612-9401-12009fd6a79c",
        "id": "cvMOu5xe018T"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "16/16 [==============================] - 69s 4s/step - loss: 1.4722 - accuracy: 0.8472 - val_loss: 0.3739 - val_accuracy: 0.8900\n",
            "Epoch 2/15\n",
            "16/16 [==============================] - 58s 4s/step - loss: 0.3550 - accuracy: 0.8962 - val_loss: 0.3614 - val_accuracy: 0.8959\n",
            "Epoch 3/15\n",
            "16/16 [==============================] - 64s 4s/step - loss: 0.3400 - accuracy: 0.9006 - val_loss: 0.3539 - val_accuracy: 0.9001\n",
            "Epoch 4/15\n",
            "16/16 [==============================] - 58s 4s/step - loss: 0.3259 - accuracy: 0.9083 - val_loss: 0.3397 - val_accuracy: 0.9083\n",
            "Epoch 5/15\n",
            "16/16 [==============================] - 57s 4s/step - loss: 0.3005 - accuracy: 0.9193 - val_loss: 0.3131 - val_accuracy: 0.9155\n",
            "Epoch 6/15\n",
            "16/16 [==============================] - 59s 4s/step - loss: 0.2598 - accuracy: 0.9306 - val_loss: 0.2841 - val_accuracy: 0.9257\n",
            "Epoch 7/15\n",
            "16/16 [==============================] - 57s 4s/step - loss: 0.2119 - accuracy: 0.9443 - val_loss: 0.2642 - val_accuracy: 0.9337\n",
            "Epoch 8/15\n",
            "16/16 [==============================] - 66s 4s/step - loss: 0.1688 - accuracy: 0.9567 - val_loss: 0.2508 - val_accuracy: 0.9413\n",
            "Epoch 9/15\n",
            "16/16 [==============================] - 57s 4s/step - loss: 0.1323 - accuracy: 0.9668 - val_loss: 0.2482 - val_accuracy: 0.9465\n",
            "Epoch 10/15\n",
            "16/16 [==============================] - 59s 4s/step - loss: 0.1034 - accuracy: 0.9748 - val_loss: 0.2444 - val_accuracy: 0.9514\n",
            "Epoch 11/15\n",
            "16/16 [==============================] - 60s 4s/step - loss: 0.0816 - accuracy: 0.9816 - val_loss: 0.2481 - val_accuracy: 0.9544\n",
            "Epoch 12/15\n",
            "16/16 [==============================] - 60s 4s/step - loss: 0.0659 - accuracy: 0.9852 - val_loss: 0.2523 - val_accuracy: 0.9558\n",
            "Epoch 13/15\n",
            "16/16 [==============================] - 65s 4s/step - loss: 0.0539 - accuracy: 0.9877 - val_loss: 0.2579 - val_accuracy: 0.9569\n",
            "Epoch 14/15\n",
            "16/16 [==============================] - 63s 4s/step - loss: 0.0448 - accuracy: 0.9898 - val_loss: 0.2645 - val_accuracy: 0.9579\n",
            "Epoch 15/15\n",
            "16/16 [==============================] - 57s 4s/step - loss: 0.0378 - accuracy: 0.9917 - val_loss: 0.2713 - val_accuracy: 0.9584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = add_lstm_model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70e5f729-d4f4-43ed-fe70-e41769c54262",
        "id": "uShCzDvl018U"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 10s 397ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the predictions and the true labels to 1D arrays\n",
        "predictions = y_pred.flatten()\n",
        "y_true = y_test.flatten()\n",
        "\n",
        "th = 0.1\n",
        "predictions[predictions >= th] = 1 \n",
        "predictions[predictions  < th] = 0\n",
        "\n",
        "# Compute the F1 score\n",
        "f1_add_lstm = f1_score(y_true, predictions, average = 'macro')\n",
        "\n",
        "print(\"Macro-F1 score:\", round(f1_add_lstm,3))\n",
        "\n",
        "add_lstm_model.save('./add_lstm_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd0bf9a5-1ed6-4f70-c284-e3b5a79a3cb5",
        "id": "ogdkHUtd018V"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro-F1 score: 0.966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4 Additional dense layer (MACRO f1 0.969)\n",
        "\n",
        "Using two dense layers, one with a non-linear activation function and one with a softmax activation function, is a common pattern in neural network architectures for classification tasks.\n",
        "\n",
        "The purpose of the non-linear dense layer is to introduce non-linearity into the model, which can allow the model to learn more complex patterns in the data. Common choices for the activation function in this layer include ReLU (Rectified Linear Unit), sigmoid, and tanh.\n",
        "\n",
        "The purpose of the softmax dense layer is to produce a probability distribution over the possible classes. The softmax activation function transforms the output of the preceding layer into a probability distribution, where the sum of the probabilities is equal to 1. This is useful for classification tasks, where you want to predict the probability that an input belongs to each of the possible classes. Using two dense layers in this way can allow the model to learn more complex patterns in the data and make more accurate predictions.\n",
        "\n",
        "We have increased the number of training epochs to 15 for the same reasons as before."
      ],
      "metadata": {
        "id": "kpmMUtH4qnsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "add_fc_model = tf.keras.Sequential(name='Additional_FC')\n",
        "\n",
        "# Add the Embedding layer\n",
        "add_fc_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, \\\n",
        "                    weights = [embedding_matrix], input_length = max_len, trainable=True))\n",
        "\n",
        "# Add the Bidirectional LSTM layer\n",
        "add_fc_model.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
        "\n",
        "# Add another Dense layer\n",
        "add_fc_model.add(TimeDistributed(Dense(units=max_len, activation='relu')))\n",
        "\n",
        "# Add the Dense/Fully-Connected layer\n",
        "add_fc_model.add(TimeDistributed(Dense(units=len(tags_train)+1, activation='softmax')))\n",
        "\n",
        "# Compile the model\n",
        "add_fc_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summary\n",
        "add_fc_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40afed39-5862-400e-918d-e7aff4a56dcb",
        "id": "E7o-z-q502ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Additional_FC\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 171, 300)          2700600   \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 171, 256)         439296    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_3 (TimeDis  (None, 171, 171)         43947     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_4 (TimeDis  (None, 171, 33)          5676      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,189,519\n",
            "Trainable params: 3,189,519\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A smaller value for patience means that the model training will be stopped more quickly if the metric is not improving, which can be useful for avoiding overfitting or for reducing the training time."
      ],
      "metadata": {
        "id": "AkgYvki3Pjtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_add_fc = add_fc_model.fit(X_train, y_train, epochs=15, verbose = True, validation_data=(X_val,y_val), batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d4cd6e8-5c40-44a2-ac1e-92ef46c52617",
        "id": "97QAgS-D02ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "16/16 [==============================] - 38s 2s/step - loss: 1.8738 - accuracy: 0.8563 - val_loss: 0.4088 - val_accuracy: 0.9048\n",
            "Epoch 2/15\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.3407 - accuracy: 0.9138 - val_loss: 0.3354 - val_accuracy: 0.9117\n",
            "Epoch 3/15\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.2755 - accuracy: 0.9255 - val_loss: 0.2959 - val_accuracy: 0.9209\n",
            "Epoch 4/15\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.2225 - accuracy: 0.9397 - val_loss: 0.2714 - val_accuracy: 0.9323\n",
            "Epoch 5/15\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.1737 - accuracy: 0.9557 - val_loss: 0.2595 - val_accuracy: 0.9407\n",
            "Epoch 6/15\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.1315 - accuracy: 0.9670 - val_loss: 0.2558 - val_accuracy: 0.9476\n",
            "Epoch 7/15\n",
            "16/16 [==============================] - 35s 2s/step - loss: 0.0983 - accuracy: 0.9754 - val_loss: 0.2615 - val_accuracy: 0.9515\n",
            "Epoch 8/15\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0737 - accuracy: 0.9812 - val_loss: 0.2676 - val_accuracy: 0.9546\n",
            "Epoch 9/15\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0565 - accuracy: 0.9855 - val_loss: 0.2751 - val_accuracy: 0.9560\n",
            "Epoch 10/15\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0448 - accuracy: 0.9882 - val_loss: 0.2864 - val_accuracy: 0.9575\n",
            "Epoch 11/15\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0363 - accuracy: 0.9905 - val_loss: 0.2968 - val_accuracy: 0.9586\n",
            "Epoch 12/15\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0302 - accuracy: 0.9921 - val_loss: 0.3052 - val_accuracy: 0.9591\n",
            "Epoch 13/15\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0256 - accuracy: 0.9933 - val_loss: 0.3151 - val_accuracy: 0.9593\n",
            "Epoch 14/15\n",
            "16/16 [==============================] - 36s 2s/step - loss: 0.0222 - accuracy: 0.9942 - val_loss: 0.3224 - val_accuracy: 0.9598\n",
            "Epoch 15/15\n",
            "16/16 [==============================] - 32s 2s/step - loss: 0.0196 - accuracy: 0.9949 - val_loss: 0.3291 - val_accuracy: 0.9599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = add_fc_model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27032ea4-5988-40f9-b8ab-27f9c1989f64",
        "id": "GgLsDktF02ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 5s 215ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the predictions and the true labels to 1D arrays\n",
        "predictions = y_pred.flatten()\n",
        "y_true = y_test.flatten()\n",
        "\n",
        "th = 0.1\n",
        "predictions[predictions >= th] = 1 \n",
        "predictions[predictions  < th] = 0\n",
        "\n",
        "# Compute the F1 score\n",
        "f1_add_fc = f1_score(y_true, predictions, average = 'macro')\n",
        "\n",
        "print(\"Macro-F1 score:\", round(f1_add_fc,3))\n",
        "\n",
        "add_fc_model.save('./add_fc_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17c379bc-d6fd-4269-ebe4-e59bdcd82b17",
        "id": "TExtgi5i02ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro-F1 score: 0.969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Comparison\n"
      ],
      "metadata": {
        "id": "56AJZRatR6mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Create a list of epochs (i.e., the x-axis data)\n",
        "epochs = list(range(1, len(results_baseline.history['val_accuracy'])+1))\n",
        "\n",
        "# # Create a Plotly line plot using the epochs and validation accuracy data\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=epochs, y=results_baseline.history['val_accuracy'], name='Baseline - BiLSTM Model', mode='lines+markers'))\n",
        "fig.add_trace(go.Scatter(x=epochs, y=results_gru.history['val_accuracy'], name='GRU Model', mode='lines+markers'))\n",
        "fig.show()\n",
        "\n",
        "# Create a list of epochs (i.e., the x-axis data)\n",
        "epochs = list(range(1, len(results_add_lstm.history['val_accuracy'])+1))\n",
        "\n",
        "fig2 = go.Figure()\n",
        "fig2.add_trace(go.Scatter(x=epochs, y=results_add_lstm.history['val_accuracy'], name='2 BiLSTMs Model', mode='lines+markers'))\n",
        "fig2.add_trace(go.Scatter(x=epochs, y=results_add_fc.history['val_accuracy'], name='2 FCs Model', mode='lines+markers'))\n",
        "fig2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BstVR3coR-3I",
        "outputId": "47ebefa7-e82b-473d-b15c-f27149a35646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"298e0a2c-d25e-4c06-9f52-25d072158455\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"298e0a2c-d25e-4c06-9f52-25d072158455\")) {                    Plotly.newPlot(                        \"298e0a2c-d25e-4c06-9f52-25d072158455\",                        [{\"mode\":\"lines+markers\",\"name\":\"Baseline - BiLSTM Model\",\"x\":[1,2,3,4,5,6,7,8,9,10],\"y\":[0.8867369890213013,0.8991081714630127,0.9118755459785461,0.915918231010437,0.920487642288208,0.9252461194992065,0.9309995770454407,0.9369915723800659,0.9409982562065125,0.9449238777160645],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"GRU Model\",\"x\":[1,2,3,4,5,6,7,8,9,10],\"y\":[0.8834190964698792,0.9104259014129639,0.9148332476615906,0.9275240898132324,0.9333360195159912,0.9383421540260315,0.9428845643997192,0.9465490579605103,0.9497814178466797,0.9515731930732727],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('298e0a2c-d25e-4c06-9f52-25d072158455');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"fc611676-bbc4-44c1-8bc5-45042fc96d01\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fc611676-bbc4-44c1-8bc5-45042fc96d01\")) {                    Plotly.newPlot(                        \"fc611676-bbc4-44c1-8bc5-45042fc96d01\",                        [{\"mode\":\"lines+markers\",\"name\":\"2 BiLSTMs Model\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\"y\":[0.8900233507156372,0.8958938121795654,0.9000625610351562,0.908282995223999,0.9155175685882568,0.925687313079834,0.9336511492729187,0.9413493871688843,0.9464635252952576,0.9513570666313171,0.9544498920440674,0.9557779431343079,0.9568899273872375,0.9578668475151062,0.9584430456161499],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"2 FCs Model\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\"y\":[0.9048210978507996,0.9116954803466797,0.9208883047103882,0.932305097579956,0.9406875967979431,0.9476115107536316,0.9515101313591003,0.9545579552650452,0.9559580087661743,0.9575201869010925,0.9586321711540222,0.9591003656387329,0.959343433380127,0.9597801566123962,0.9599466919898987],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('fc611676-bbc4-44c1-8bc5-45042fc96d01');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_width = max(len(str(f1_baseline)), len(str(f1_gru)), len(str(f1_add_lstm)), len(str(f1_add_fc)))\n",
        "\n",
        "header_row = f'| F1 Score Baseline {\" \" * (max_width - len(\"F1 Score Baseline\"))} | F1 Score GRU {\" \" * (max_width - len(\"F1 Score GRU\"))} |\\\n",
        " F1 Score Add. BiLSTM {\" \" * (max_width - len(\"F1 Score Add. BiLSTM\"))} | F1 Score Add. Dense {\" \" * (max_width - len(\"F1 Score Add. Dense\"))} |'\n",
        "separator_row = '-' * len(header_row)\n",
        "data_row = f'| {f1_baseline:<{max_width}} | {f1_gru:<{max_width}} | {f1_add_lstm:<{max_width}} | {f1_add_fc:<{max_width}} |'\n",
        "\n",
        "print(header_row)\n",
        "print(separator_row)\n",
        "print(data_row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOqQ09-ejG4j",
        "outputId": "df5e76a3-f133-45f3-d0d9-2928e3635c6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| F1 Score Baseline   | F1 Score GRU        | F1 Score Add. BiLSTM  | F1 Score Add. Dense  |\n",
            "--------------------------------------------------------------------------------------------\n",
            "| 0.9524195137886767 | 0.9581359536923748 | 0.966182171087751  | 0.9687673190990866 |\n"
          ]
        }
      ]
    }
  ]
}