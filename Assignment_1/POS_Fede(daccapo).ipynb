{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNl3QmnxnC+1ioHg1fNQ7B3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antoniototimorelli/nlp_unibo_2022-23/blob/main/Assignment_1/POS_Fede(daccapo).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import treebank\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import progressbar\n",
        "import tensorflow\n",
        "from collections import defaultdict\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import Sequential, Input, Model\n",
        "from tensorflow.keras.layers import Embedding, Dense, TimeDistributed, LSTM, GRU, Bidirectional, SimpleRNN, RNN\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle"
      ],
      "metadata": {
        "id": "wr9z1Rt2QbM8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notebook Fatto per capire il procedimento, non è esatto perchè la divisione non è fatta come chiesto, ma con train_test_split"
      ],
      "metadata": {
        "id": "0Ou0uUiVlY1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.PreProcess\n"
      ],
      "metadata": {
        "id": "UHbCUY8tRDOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('treebank')\n",
        "nltk.download('universal_tagset')\n",
        "treebank_corpus = treebank.tagged_sents()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFAZMkL-Q5A7",
        "outputId": "8cd8ee2b-7bd8-47ac-e5b0-3217fff8a29a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "treebank_corpus[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvaTUeDzRQQa",
        "outputId": "19886072-f509-4cd6-f8aa-005bdbf69034"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Pierre', 'NNP'),\n",
              " ('Vinken', 'NNP'),\n",
              " (',', ','),\n",
              " ('61', 'CD'),\n",
              " ('years', 'NNS'),\n",
              " ('old', 'JJ'),\n",
              " (',', ','),\n",
              " ('will', 'MD'),\n",
              " ('join', 'VB'),\n",
              " ('the', 'DT'),\n",
              " ('board', 'NN'),\n",
              " ('as', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('nonexecutive', 'JJ'),\n",
              " ('director', 'NN'),\n",
              " ('Nov.', 'NNP'),\n",
              " ('29', 'CD'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.1 Divide in words(X) and tags(Y)"
      ],
      "metadata": {
        "id": "mRuclSm_Rpr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for sentence in treebank_corpus:\n",
        "  X_sentence = []\n",
        "  y_sentence = []\n",
        "  for entity in sentence:\n",
        "    X_sentence.append(entity[0])\n",
        "    y_sentence.append(entity[1])\n",
        "\n",
        "  X.append(X_sentence)\n",
        "  y.append(y_sentence)"
      ],
      "metadata": {
        "id": "7JxD1pFPRfyT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = len(set([word.lower() for sentence in X for word in sentence]))\n",
        "num_tags = len(set([word.lower() for sentence in y for word in sentence]))"
      ],
      "metadata": {
        "id": "Yj2Hhs0ASA7s"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total number of tagged sentences: {}\".format(len(X)))\n",
        "print(\"Vocabulary size: {}\".format(num_words))\n",
        "print(\"Total number of tags: {}\".format(num_tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBov1EyfSUp1",
        "outputId": "f2d03cfb-4738-4e23-f39a-3b2b168690c6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of tagged sentences: 3914\n",
            "Vocabulary size: 11387\n",
            "Total number of tags: 46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's look at first data point\n",
        "# this is one data point that will be fed to the RNN\n",
        "print('sample X: ', X[0], '\\n')\n",
        "print('sample Y: ', y[0], '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xka6G7ROSXs8",
        "outputId": "b97fbfc4-bdd7-4a22-f7dc-7b1ac62648fe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample X:  ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.'] \n",
            "\n",
            "sample Y:  ['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'CD', '.'] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Vectorize X and y\n",
        "word_tokenizer = Tokenizer()\n",
        "word_tokenizer.fit_on_texts(X)\n",
        "X_encoded = word_tokenizer.texts_to_sequences(X)"
      ],
      "metadata": {
        "id": "BP8yz9CxSbCX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag_tokenizer = Tokenizer()\n",
        "tag_tokenizer.fit_on_texts(y)\n",
        "y_encoded = tag_tokenizer.texts_to_sequences(y)"
      ],
      "metadata": {
        "id": "QIq0-cFVZE8e"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# look at first encoded data point\n",
        "\n",
        "print(\"** Raw data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
        "print('X: ', X[0], '\\n')\n",
        "print('Y: ', y[0], '\\n')\n",
        "print()\n",
        "print(\"** Encoded data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
        "print('X: ', X_encoded[0], '\\n')\n",
        "print('Y: ', y_encoded[0], '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8SfxzrJZbmV",
        "outputId": "933ece48-52ec-4bb7-8394-27234e1833a3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "** Raw data point ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "X:  ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.'] \n",
            "\n",
            "Y:  ['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'CD', '.'] \n",
            "\n",
            "\n",
            "** Encoded data point ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "X:  [5601, 3746, 1, 2024, 86, 331, 1, 46, 2405, 2, 131, 27, 6, 2025, 332, 459, 2026, 3] \n",
            "\n",
            "Y:  [3, 3, 8, 10, 6, 7, 8, 21, 13, 4, 1, 2, 4, 7, 1, 3, 10, 9] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check lengths\n",
        "\n",
        "different_length = [1 if len(input) != len(output) else 0 for input, output in zip(X_encoded,y_encoded)]\n",
        "print(\"{} sentences have disparate input-output lengths.\".format(sum(different_length)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cqqa3M83Zf_P",
        "outputId": "132fb65d-48e5-4bce-e6b8-5a86f5ea49d8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 sentences have disparate input-output lengths.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.2 Pad sequences"
      ],
      "metadata": {
        "id": "LKj4ZnqjZ5dT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lengths = [len(seq) for seq in X_sentence]\n",
        "print(\"Length of longest sentence: {}\".format(max(lengths)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uk0CyQMmZ3py",
        "outputId": "aa098d6f-cbf3-409d-db87-a6e71ebcef0c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of longest sentence: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(lengths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "Y6_i7suvaETG",
        "outputId": "1e4deda8-47f7-4029-ea64-2e9177e94df7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f179e71a2b0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.lib.pretty import MAX_SEQ_LENGTH\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "#Pad each sequence to max_seq_length using keras\n",
        "#sentences longer than max_seq truncated\n",
        "#sentences shorter padded with zeroes\n",
        "\n",
        "# Truncation and padding can either be 'pre' or 'post'. \n",
        "# For padding we are using 'pre' padding type, that is, add zeroes on the left side.\n",
        "# For truncation, we are using 'post', that is, truncate a sentence from right side.\n",
        "\n",
        "MAX_SEQ_LENGTH = 100\n",
        "\n",
        "X_padded = pad_sequences(X_encoded, maxlen = MAX_SEQ_LENGTH, padding = 'pre', truncating='post')\n",
        "y_padded = pad_sequences(y_encoded, maxlen = MAX_SEQ_LENGTH, padding = 'pre', truncating='post')"
      ],
      "metadata": {
        "id": "U0zQayp7aIoe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the first sequence\n",
        "print(X_padded[0], \"\\n\")\n",
        "print(y_padded[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTFuBmFZa2Q9",
        "outputId": "21b94188-4f33-4b1f-819e-f9b2a4a308e6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0 5601 3746\n",
            "    1 2024   86  331    1   46 2405    2  131   27    6 2025  332  459\n",
            " 2026    3] \n",
            "\n",
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  3  3  8 10  6  7  8 21 13  4  1  2  4  7\n",
            "  1  3 10  9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = X_padded, y_padded"
      ],
      "metadata": {
        "id": "3h--IUavevkj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2 Word Embeddings\n"
      ],
      "metadata": {
        "id": "pMbL8JonbdVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Use the 300 dimensional GLove Word Embeddings\n",
        "glove_dir = './'\n",
        "embedding_dim = 300\n",
        "vocab_size = len(word_tokenizer.word_index) + 1\n",
        "embedding_dict = {} #initialize dictionary\n",
        "f = open(os.path.join(glove_dir, f'glove.6B.{embedding_dim}d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embedding_dict[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embedding_dict))\n",
        "print('Vocab of size %s' % len(embedding_dict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUtEzF4EbJ2_",
        "outputId": "95675424-29dc-40f5-c4af-c75359c5c1f3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n",
            "Vocab of size 400000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_weights = np.zeros((vocab_size,embedding_dim))\n",
        "word2ind = word_tokenizer.word_index\n",
        "for word, index in word2ind.items():\n",
        "  try:\n",
        "    embedding_weights[index, :] = embedding_dict[word]\n",
        "  except KeyError:\n",
        "    pass"
      ],
      "metadata": {
        "id": "griJq6Nvbyqx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Embeddings shape: {}\".format(embedding_weights.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uQBdBWFcnUj",
        "outputId": "d2a91b77-38c5-48e7-9648-ab8d5233c95e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings shape: (11388, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "embedding_weights[word_tokenizer.word_index['bottom']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfnhp0Sgcssv",
        "outputId": "eea49dbe-3ced-492e-af72-4f8543cfeee1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.61680001e-01,  5.45570016e-01, -4.21449989e-01, -1.32129997e-01,\n",
              "        1.43869996e-01,  3.33620012e-01, -1.68740004e-01, -1.52049996e-02,\n",
              "        5.05720019e-01, -1.14370000e+00, -1.26359999e-01, -5.18639982e-02,\n",
              "       -6.50840029e-02,  3.54719982e-02, -3.45279992e-01,  2.09189996e-01,\n",
              "       -3.05170000e-01,  3.27719986e-01,  3.66230011e-01, -3.96120012e-01,\n",
              "       -2.18559995e-01,  2.79549986e-01,  1.25749996e-02, -7.39459991e-02,\n",
              "       -1.07630000e-01, -2.38110006e-01,  3.42689991e-01,  4.51849997e-01,\n",
              "        2.59860000e-03,  1.32290006e-01,  1.43790007e-01,  1.45569995e-01,\n",
              "        4.76429984e-02, -3.54240000e-01, -1.14040005e+00,  4.29199994e-01,\n",
              "        3.10660005e-01, -1.34020001e-01,  7.56710023e-02,  4.42640007e-01,\n",
              "        1.20920002e-01,  1.78749993e-01,  4.56500016e-02,  4.57439989e-01,\n",
              "       -1.56560004e-01,  1.85450003e-01,  2.26889998e-01, -1.55049995e-01,\n",
              "       -3.61490011e-01,  6.20420016e-02, -1.18060000e-01,  8.91269967e-02,\n",
              "        1.61850005e-01, -5.08050025e-01, -8.31329972e-02,  8.45359988e-04,\n",
              "        7.96469972e-02, -6.56159997e-01, -3.30810010e-01,  5.38940012e-01,\n",
              "        5.32880008e-01, -5.50949991e-01,  5.87149978e-01,  2.67309994e-01,\n",
              "       -1.70540009e-02, -5.17750025e-01,  1.68479994e-01, -2.92220004e-02,\n",
              "       -1.06600001e-01, -1.69200003e-01,  2.65480012e-01,  1.40040005e-02,\n",
              "       -2.49760002e-01,  1.01779997e-01, -2.46720001e-01,  2.48899996e-01,\n",
              "        1.67160004e-01,  4.15300012e-01, -2.26620004e-01, -4.75939989e-01,\n",
              "       -2.99849987e-01, -1.59949996e-02, -1.99100003e-01, -1.45229995e-01,\n",
              "       -8.31070021e-02,  3.01249996e-02,  5.65240011e-02, -3.67989987e-02,\n",
              "       -4.93739992e-01, -1.04610004e-01,  5.60890019e-01,  4.12849993e-01,\n",
              "       -2.14340001e-01, -4.22930002e-01, -1.48880005e-01,  2.93729991e-01,\n",
              "       -3.49029988e-01,  3.23179990e-01,  1.76789999e-01, -5.22520006e-01,\n",
              "       -1.11170001e-01,  1.00060001e-01,  8.34140033e-02, -5.89079976e-01,\n",
              "       -2.29409993e-01,  1.89119995e-01,  5.09370029e-01, -4.50320005e-01,\n",
              "        3.90309989e-01,  4.00549993e-02,  1.53160006e-01, -6.80130005e-01,\n",
              "        3.10319990e-01, -6.80559993e-01, -2.35489994e-01,  1.43250003e-01,\n",
              "       -9.75700021e-02, -2.87230015e-01,  5.67409992e-02, -2.63069987e-01,\n",
              "       -3.61279994e-01, -8.91070008e-01,  9.39819992e-01,  2.93650001e-01,\n",
              "       -9.83619988e-02, -3.85479987e-01, -1.02339998e-01, -2.62450010e-01,\n",
              "        1.61540002e-01, -2.34740004e-02,  7.73520023e-02,  1.24440002e+00,\n",
              "        4.80590016e-02,  7.71679997e-01, -6.17169999e-02, -1.08690001e-01,\n",
              "       -4.13910002e-01,  6.88099980e-01, -3.40030015e-01,  2.93309987e-01,\n",
              "        1.48330003e-01,  1.15700001e-02, -1.61009997e-01, -7.67840028e-01,\n",
              "       -3.87490004e-01, -1.40509993e-01, -2.93520000e-02,  2.57669985e-01,\n",
              "        2.49720007e-01,  1.61459997e-01,  1.36540001e-02,  1.99650005e-01,\n",
              "       -2.16330007e-01, -7.33500004e-01,  5.43879986e-01,  2.86119998e-01,\n",
              "        1.13760002e-01, -2.10789993e-01, -3.33440006e-01,  6.35519981e-01,\n",
              "       -2.40119994e-01, -1.79859996e-01, -2.08079994e-01, -3.05429995e-01,\n",
              "        3.68620008e-01, -2.33390003e-01,  1.96319997e-01,  6.07549995e-02,\n",
              "       -6.62169978e-02, -6.61659986e-03, -3.70359987e-01, -1.82270005e-01,\n",
              "        1.03040002e-01, -6.68959975e-01, -2.84729991e-02,  3.27639997e-01,\n",
              "       -4.65209991e-01,  4.01300013e-01, -5.09140015e-01,  1.56369999e-01,\n",
              "        3.61330003e-01,  4.25900012e-01,  5.51289976e-01, -2.52270013e-01,\n",
              "        2.30739996e-01, -5.18639982e-01,  5.27740002e-01,  1.87999997e-02,\n",
              "        2.55479991e-01,  5.25409997e-01,  4.08609986e-01,  8.29200029e-01,\n",
              "        4.34920013e-01,  1.84379995e-01,  3.04259986e-01,  2.81899989e-01,\n",
              "       -1.65140003e-01, -2.61460006e-01, -3.20259988e-01,  1.41589999e-01,\n",
              "        1.25039995e+00,  5.19590005e-02,  3.91790003e-01, -1.87909994e-02,\n",
              "        8.63199979e-02, -1.76080003e-01,  2.67910004e-01, -6.94429994e-01,\n",
              "       -3.32419991e-01, -3.21289986e-01, -7.97379985e-02, -1.17559999e-01,\n",
              "       -2.50970006e-01,  2.53919989e-01,  4.78940010e-01,  1.85870007e-01,\n",
              "        1.38899997e-01, -7.33459964e-02,  1.05130002e-01, -5.77500015e-02,\n",
              "       -5.07510006e-02,  5.03650010e-01, -2.00240001e-01, -1.79309994e-01,\n",
              "        7.69670010e-02, -1.83280006e-01, -2.12960005e-01,  6.29929975e-02,\n",
              "        1.18759997e-01,  9.28530023e-02, -2.92869985e-01,  1.26760006e-01,\n",
              "        3.25139984e-02,  4.55400012e-02,  3.63720000e-01, -2.95749992e-01,\n",
              "       -5.25440015e-02, -1.28360000e-02,  3.66730005e-01,  2.03860000e-01,\n",
              "        1.13040000e-01, -1.75060004e-01,  4.67860013e-01,  3.92739996e-02,\n",
              "       -7.84030020e-01, -3.32819998e-01,  6.49089992e-01,  2.35440001e-01,\n",
              "        8.69899988e-03,  3.67910005e-02, -2.65749991e-01,  9.34230015e-02,\n",
              "        1.05040002e+00,  6.04109988e-02,  1.34599999e-01,  2.47350007e-01,\n",
              "        2.18740001e-01, -2.91509996e-03, -4.93250012e-01,  2.43890002e-01,\n",
              "       -4.29199994e-01, -1.57509997e-01, -2.71849990e-01,  2.10989997e-01,\n",
              "        1.84130005e-03, -3.84850018e-02, -2.28520006e-01, -1.12800002e-01,\n",
              "        1.85929999e-01,  3.50019991e-01,  1.26289994e-01, -1.22259997e-01,\n",
              "       -1.09200001e-01,  6.74279988e-01,  1.26509994e-01,  7.64119998e-02,\n",
              "       -8.45350027e-01, -3.59090000e-01,  3.55219990e-02, -1.47430003e-01,\n",
              "       -5.91440022e-01,  7.46330023e-01, -8.68070006e-01, -2.22749993e-01,\n",
              "       -3.72999996e-01,  1.41530000e-02,  3.06270003e-01, -5.82669973e-01,\n",
              "        5.71879983e-01,  6.82689995e-02, -2.97349989e-01,  8.05289969e-02,\n",
              "       -4.84310001e-01,  1.95079997e-01,  9.85379964e-02, -9.01070016e-04,\n",
              "        5.09190023e-01, -2.49160007e-01,  1.14840001e-01, -1.69560000e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(y)"
      ],
      "metadata": {
        "id": "3FZb8xi8czVc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxOXhTV6c42d",
        "outputId": "63f3b2a8-89f0-4b76-ef7c-98a0c4ad28db"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3914, 100, 47)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25)"
      ],
      "metadata": {
        "id": "-ebuQ2tkdpTl"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_val,y_train,y_val = train_test_split(X_train,y_train,test_size=0.25)"
      ],
      "metadata": {
        "id": "AqzGIECXfxX4"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print number of samples in each set\n",
        "print(\"TRAINING DATA\")\n",
        "print('Shape of input sequences: {}'.format(X_train.shape))\n",
        "print('Shape of output sequences: {}'.format(y_train.shape))\n",
        "print(\"-\"*50)\n",
        "print(\"VALIDATION DATA\")\n",
        "print('Shape of input sequences: {}'.format(X_val.shape))\n",
        "print('Shape of output sequences: {}'.format(y_val.shape))\n",
        "print(\"-\"*50)\n",
        "print(\"TESTING DATA\")\n",
        "print('Shape of input sequences: {}'.format(X_test.shape))\n",
        "print('Shape of output sequences: {}'.format(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYWQ8gpOf4u_",
        "outputId": "3b018d91-0ca8-4240-a975-8431c791f9be"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINING DATA\n",
            "Shape of input sequences: (2201, 100)\n",
            "Shape of output sequences: (2201, 100, 47)\n",
            "--------------------------------------------------\n",
            "VALIDATION DATA\n",
            "Shape of input sequences: (734, 100)\n",
            "Shape of output sequences: (734, 100, 47)\n",
            "--------------------------------------------------\n",
            "TESTING DATA\n",
            "Shape of input sequences: (979, 100)\n",
            "Shape of output sequences: (979, 100, 47)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "baseline_model = Sequential(name='Baseline')\n",
        "\n",
        "# Add the Embedding layer\n",
        "# baseline_model.add(Embedding(input_dim=vocab_length, output_dim=embedding_dim, \\\n",
        "#                     weights=[embedding_matrix], input_length=MAX_LENGTH, trainable=False))\n",
        "baseline_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, \\\n",
        "                    weights=[embedding_weights], input_length=MAX_SEQ_LENGTH, trainable=True))\n",
        "\n",
        "# Add the Bidirectional LSTM layer\n",
        "baseline_model.add(Bidirectional(LSTM(units=256, return_sequences=True)))\n",
        "\n",
        "# Add the Dense/Fully-Connected layer\n",
        "baseline_model.add(TimeDistributed(Dense(units=47, activation='softmax')))\n",
        "\n",
        "# Compile the model\n",
        "baseline_model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summary\n",
        "baseline_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uik28V6wf6QX",
        "outputId": "ea0bbfff-30ae-471e-df31-c2ef77777bac"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Baseline\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 100, 300)          3416400   \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 100, 512)         1140736   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 100, 47)          24111     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,581,247\n",
            "Trainable params: 4,581,247\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_baseline = baseline_model.fit(X_train, y_train, validation_data=(X_val, y_val),batch_size=128, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLf95LUBgLAS",
        "outputId": "54fafea6-ffb0-4a89-fa62-880ea4f76276"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "18/18 [==============================] - 6s 94ms/step - loss: 1.7143 - accuracy: 0.7509 - val_loss: 0.6791 - val_accuracy: 0.8365\n",
            "Epoch 2/10\n",
            "18/18 [==============================] - 1s 44ms/step - loss: 0.5707 - accuracy: 0.8615 - val_loss: 0.4436 - val_accuracy: 0.8892\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - 1s 44ms/step - loss: 0.3678 - accuracy: 0.9102 - val_loss: 0.2881 - val_accuracy: 0.9301\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - 1s 44ms/step - loss: 0.2413 - accuracy: 0.9422 - val_loss: 0.1994 - val_accuracy: 0.9522\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - 1s 44ms/step - loss: 0.1659 - accuracy: 0.9613 - val_loss: 0.1475 - val_accuracy: 0.9644\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.1198 - accuracy: 0.9719 - val_loss: 0.1160 - val_accuracy: 0.9722\n",
            "Epoch 7/10\n",
            "18/18 [==============================] - 1s 44ms/step - loss: 0.0901 - accuracy: 0.9789 - val_loss: 0.0956 - val_accuracy: 0.9765\n",
            "Epoch 8/10\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.0700 - accuracy: 0.9838 - val_loss: 0.0827 - val_accuracy: 0.9789\n",
            "Epoch 9/10\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0561 - accuracy: 0.9871 - val_loss: 0.0733 - val_accuracy: 0.9808\n",
            "Epoch 10/10\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.0459 - accuracy: 0.9893 - val_loss: 0.0672 - val_accuracy: 0.9820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = baseline_model.evaluate(X_test, y_test, return_dict = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDQECzYng7mR",
        "outputId": "ddb9cf5d-e25d-462c-9c17-2085b58a836f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0670 - accuracy: 0.9820\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = baseline_model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BexAaciDiWc0",
        "outputId": "8c56420f-3c86-48f8-ad57-c8b7b93c1837"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 1s 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "# Flatten the predictions and the true labels to 1D arrays\n",
        "predictions = predictions.flatten()\n",
        "y_true = y_test.flatten()\n",
        "\n",
        "th = 0.1\n",
        "predictions[predictions >= th] = 1 \n",
        "predictions[predictions  < th] = 0\n",
        "\n",
        "# Compute the F1 score\n",
        "f1_baseline = f1_score(y_true, predictions, average = 'macro')\n",
        "\n",
        "print(\"Macro-F1 score:\", round(f1_baseline,3))\n",
        "\n",
        "baseline_model.save('./baseline_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPJz028UiX7D",
        "outputId": "b875f58f-4aae-49a2-ee4c-38ede93e3969"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro-F1 score: 0.984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GRU\n",
        "\n"
      ],
      "metadata": {
        "id": "dAESB5Muj13B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "gru_model = tensorflow.keras.Sequential(name='GRU')\n",
        "\n",
        "# Add the Embedding layer\n",
        "gru_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, \\\n",
        "                    weights = [embedding_weights], input_length = MAX_SEQ_LENGTH, trainable=True))\n",
        "\n",
        "# Add the GRU layer\n",
        "gru_model.add(GRU(units=128, return_sequences=True))\n",
        "\n",
        "# Add the Dense/Fully-Connected layer\n",
        "gru_model.add(TimeDistributed(Dense(47, activation='softmax')))\n",
        "\n",
        "# Compile the model\n",
        "gru_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summary\n",
        "gru_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBDrY_fJie5M",
        "outputId": "7f4a23b7-00e9-422f-9254-ef80ef8d3721"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 100, 300)          3416400   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 100, 128)          165120    \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDis  (None, 100, 47)          6063      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,587,583\n",
            "Trainable params: 3,587,583\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_gru = gru_model.fit(X_train, y_train, epochs=10, verbose = True, validation_data=(X_val,y_val), batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkZTQuBSkEc7",
        "outputId": "93891dab-5280-471a-f058-0d8b554ed3d8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "18/18 [==============================] - 3s 44ms/step - loss: 3.0055 - accuracy: 0.7902 - val_loss: 1.0743 - val_accuracy: 0.7600\n",
            "Epoch 2/10\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.8249 - accuracy: 0.8184 - val_loss: 0.6529 - val_accuracy: 0.8655\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.5744 - accuracy: 0.8767 - val_loss: 0.4860 - val_accuracy: 0.8953\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.4292 - accuracy: 0.9126 - val_loss: 0.3697 - val_accuracy: 0.9249\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.3255 - accuracy: 0.9347 - val_loss: 0.2882 - val_accuracy: 0.9404\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.2511 - accuracy: 0.9490 - val_loss: 0.2304 - val_accuracy: 0.9513\n",
            "Epoch 7/10\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.1969 - accuracy: 0.9600 - val_loss: 0.1888 - val_accuracy: 0.9598\n",
            "Epoch 8/10\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.1566 - accuracy: 0.9689 - val_loss: 0.1586 - val_accuracy: 0.9662\n",
            "Epoch 9/10\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.1268 - accuracy: 0.9751 - val_loss: 0.1368 - val_accuracy: 0.9695\n",
            "Epoch 10/10\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.1048 - accuracy: 0.9789 - val_loss: 0.1207 - val_accuracy: 0.9720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = gru_model.predict(X_test)\n",
        "# Flatten the predictions and the true labels to 1D arrays\n",
        "predictions = y_pred.flatten()\n",
        "y_true = y_test.flatten()\n",
        "\n",
        "th = 0.1\n",
        "predictions[predictions >= th] = 1 \n",
        "predictions[predictions  < th] = 0\n",
        "\n",
        "# Compute the F1 score\n",
        "f1_gru = f1_score(y_true, predictions, average = 'macro')\n",
        "\n",
        "print(\"Macro-F1 score:\", round(f1_gru,3))\n",
        "\n",
        "gru_model.save('./gru_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iA_ixZKFkJGB",
        "outputId": "508092d1-1ac9-4017-f745-ec508fdf2fba"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 0s 3ms/step\n",
            "Macro-F1 score: 0.975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Additional LSTM Layer"
      ],
      "metadata": {
        "id": "FhSgCrzzkTAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "add_lstm_model = tensorflow.keras.Sequential(name='Additional_LSTM')\n",
        "\n",
        "# Add the Embedding layer\n",
        "add_lstm_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, \\\n",
        "                    weights = [embedding_weights], input_length = MAX_SEQ_LENGTH, trainable=True))\n",
        "\n",
        "# Add the Bidirectional LSTM layer\n",
        "add_lstm_model.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
        "\n",
        "# Add another LSTM layer\n",
        "add_lstm_model.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
        "\n",
        "# Add the Dense/Fully-Connected layer\n",
        "add_lstm_model.add(TimeDistributed(Dense(units=47, activation='softmax')))\n",
        "\n",
        "# Compile the model\n",
        "add_lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summary\n",
        "add_lstm_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSaKyv0qkMoF",
        "outputId": "14335da6-a9db-45e3-d18c-33be06d429a4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Additional_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 100, 300)          3416400   \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 100, 256)         439296    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 100, 256)         394240    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_3 (TimeDis  (None, 100, 47)          12079     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,262,015\n",
            "Trainable params: 4,262,015\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_add_lstm = add_lstm_model.fit(X_train, y_train, epochs=15, verbose = True, validation_data=(X_val,y_val), batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bje3sTIykdZx",
        "outputId": "1d34f890-f95c-43c9-9e8d-709d36c4887e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "18/18 [==============================] - 9s 132ms/step - loss: 1.8430 - accuracy: 0.7216 - val_loss: 0.8052 - val_accuracy: 0.7733\n",
            "Epoch 2/15\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.7760 - accuracy: 0.7827 - val_loss: 0.7375 - val_accuracy: 0.7916\n",
            "Epoch 3/15\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.7085 - accuracy: 0.8101 - val_loss: 0.6484 - val_accuracy: 0.8341\n",
            "Epoch 4/15\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.5860 - accuracy: 0.8541 - val_loss: 0.4947 - val_accuracy: 0.8816\n",
            "Epoch 5/15\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.4260 - accuracy: 0.8963 - val_loss: 0.3495 - val_accuracy: 0.9152\n",
            "Epoch 6/15\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.2975 - accuracy: 0.9287 - val_loss: 0.2499 - val_accuracy: 0.9411\n",
            "Epoch 7/15\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.2084 - accuracy: 0.9521 - val_loss: 0.1832 - val_accuracy: 0.9607\n",
            "Epoch 8/15\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.1482 - accuracy: 0.9694 - val_loss: 0.1410 - val_accuracy: 0.9693\n",
            "Epoch 9/15\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.1092 - accuracy: 0.9772 - val_loss: 0.1160 - val_accuracy: 0.9730\n",
            "Epoch 10/15\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0841 - accuracy: 0.9818 - val_loss: 0.0989 - val_accuracy: 0.9760\n",
            "Epoch 11/15\n",
            "18/18 [==============================] - 1s 48ms/step - loss: 0.0669 - accuracy: 0.9852 - val_loss: 0.0887 - val_accuracy: 0.9779\n",
            "Epoch 12/15\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0550 - accuracy: 0.9875 - val_loss: 0.0811 - val_accuracy: 0.9796\n",
            "Epoch 13/15\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0461 - accuracy: 0.9899 - val_loss: 0.0757 - val_accuracy: 0.9807\n",
            "Epoch 14/15\n",
            "18/18 [==============================] - 1s 47ms/step - loss: 0.0392 - accuracy: 0.9915 - val_loss: 0.0724 - val_accuracy: 0.9817\n",
            "Epoch 15/15\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0340 - accuracy: 0.9928 - val_loss: 0.0697 - val_accuracy: 0.9823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = add_lstm_model.predict(X_test)\n",
        "# Flatten the predictions and the true labels to 1D arrays\n",
        "predictions = y_pred.flatten()\n",
        "y_true = y_test.flatten()\n",
        "\n",
        "th = 0.1\n",
        "predictions[predictions >= th] = 1 \n",
        "predictions[predictions  < th] = 0\n",
        "\n",
        "# Compute the F1 score\n",
        "f1_add_lstm = f1_score(y_true, predictions, average = 'macro')\n",
        "\n",
        "print(\"Macro-F1 score:\", round(f1_add_lstm,3))\n",
        "\n",
        "add_lstm_model.save('./add_lstm_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUPhfmVBkgTZ",
        "outputId": "4530dba8-8202-4c48-e47d-1cc9dd83e397"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 2s 24ms/step\n",
            "Macro-F1 score: 0.985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Additional Dense Layer"
      ],
      "metadata": {
        "id": "WZDFRILUklPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "add_fc_model = tensorflow.keras.Sequential(name='Additional_FC')\n",
        "\n",
        "# Add the Embedding layer\n",
        "add_fc_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, \\\n",
        "                    weights = [embedding_weights], input_length = MAX_SEQ_LENGTH, trainable=True))\n",
        "\n",
        "# Add the Bidirectional LSTM layer\n",
        "add_fc_model.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
        "\n",
        "# Add another Dense layer\n",
        "add_fc_model.add(TimeDistributed(Dense(units=MAX_SEQ_LENGTH, activation='relu')))\n",
        "\n",
        "# Add the Dense/Fully-Connected layer\n",
        "add_fc_model.add(TimeDistributed(Dense(units=47, activation='softmax')))\n",
        "\n",
        "# Compile the model\n",
        "add_fc_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summary\n",
        "add_fc_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iTv5limknIY",
        "outputId": "13a975e1-6ed8-442c-92aa-3aa6bb1ef6ec"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Additional_FC\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 100, 300)          3416400   \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirectio  (None, 100, 256)         439296    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_4 (TimeDis  (None, 100, 100)         25700     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_5 (TimeDis  (None, 100, 47)          4747      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,886,143\n",
            "Trainable params: 3,886,143\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_add_fc = add_fc_model.fit(X_train, y_train, epochs=15, verbose = True, validation_data=(X_val,y_val), batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rh0XwDUnk1FB",
        "outputId": "cb4be662-63d5-4e2f-efa2-146d95e5ab94"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "18/18 [==============================] - 4s 80ms/step - loss: 2.2887 - accuracy: 0.7184 - val_loss: 0.8363 - val_accuracy: 0.7845\n",
            "Epoch 2/15\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.7396 - accuracy: 0.8152 - val_loss: 0.6365 - val_accuracy: 0.8549\n",
            "Epoch 3/15\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.5688 - accuracy: 0.8641 - val_loss: 0.4744 - val_accuracy: 0.8838\n",
            "Epoch 4/15\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.4067 - accuracy: 0.8987 - val_loss: 0.3307 - val_accuracy: 0.9188\n",
            "Epoch 5/15\n",
            "18/18 [==============================] - 1s 29ms/step - loss: 0.2769 - accuracy: 0.9338 - val_loss: 0.2283 - val_accuracy: 0.9452\n",
            "Epoch 6/15\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.1874 - accuracy: 0.9564 - val_loss: 0.1647 - val_accuracy: 0.9611\n",
            "Epoch 7/15\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.1306 - accuracy: 0.9698 - val_loss: 0.1262 - val_accuracy: 0.9692\n",
            "Epoch 8/15\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0950 - accuracy: 0.9775 - val_loss: 0.1028 - val_accuracy: 0.9738\n",
            "Epoch 9/15\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.0724 - accuracy: 0.9821 - val_loss: 0.0887 - val_accuracy: 0.9768\n",
            "Epoch 10/15\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.0572 - accuracy: 0.9857 - val_loss: 0.0795 - val_accuracy: 0.9788\n",
            "Epoch 11/15\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.0467 - accuracy: 0.9882 - val_loss: 0.0742 - val_accuracy: 0.9805\n",
            "Epoch 12/15\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0390 - accuracy: 0.9903 - val_loss: 0.0700 - val_accuracy: 0.9810\n",
            "Epoch 13/15\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.0329 - accuracy: 0.9917 - val_loss: 0.0668 - val_accuracy: 0.9820\n",
            "Epoch 14/15\n",
            "18/18 [==============================] - 1s 28ms/step - loss: 0.0284 - accuracy: 0.9929 - val_loss: 0.0649 - val_accuracy: 0.9824\n",
            "Epoch 15/15\n",
            "18/18 [==============================] - 0s 28ms/step - loss: 0.0249 - accuracy: 0.9937 - val_loss: 0.0638 - val_accuracy: 0.9829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = add_fc_model.predict(X_test)\n",
        "# Flatten the predictions and the true labels to 1D arrays\n",
        "predictions = y_pred.flatten()\n",
        "y_true = y_test.flatten()\n",
        "\n",
        "th = 0.1\n",
        "predictions[predictions >= th] = 1 \n",
        "predictions[predictions  < th] = 0\n",
        "\n",
        "# Compute the F1 score\n",
        "f1_add_fc = f1_score(y_true, predictions, average = 'macro')\n",
        "\n",
        "print(\"Macro-F1 score:\", round(f1_add_fc,3))\n",
        "\n",
        "add_fc_model.save('./add_fc_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTvmDNpGk3c5",
        "outputId": "4ba7e88f-7225-47f4-ba00-bff8d2a21aa9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 1s 6ms/step\n",
            "Macro-F1 score: 0.986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# # Create a list of epochs (i.e., the x-axis data)\n",
        "epochs = list(range(1, len(results_baseline.history['val_accuracy'])+1))\n",
        "\n",
        "# # Create a Plotly line plot using the epochs and validation accuracy data\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=epochs, y=results_baseline.history['val_accuracy'], name='Baseline - BiLSTM Model', mode='lines+markers'))\n",
        "fig.add_trace(go.Scatter(x=epochs, y=results_gru.history['val_accuracy'], name='GRU Model', mode='lines+markers'))\n",
        "fig.show()\n",
        "\n",
        "# Create a list of epochs (i.e., the x-axis data)\n",
        "epochs = list(range(1, len(results_add_lstm.history['val_accuracy'])+1))\n",
        "\n",
        "fig2 = go.Figure()\n",
        "fig2.add_trace(go.Scatter(x=epochs, y=results_add_lstm.history['val_accuracy'], name='2 BiLSTMs Model', mode='lines+markers'))\n",
        "fig2.add_trace(go.Scatter(x=epochs, y=results_add_fc.history['val_accuracy'], name='2 FCs Model', mode='lines+markers'))\n",
        "fig2.show()\n",
        "\n",
        "max_width = max(len(str(f1_baseline)), len(str(f1_gru)), len(str(f1_add_lstm)), len(str(f1_add_fc)))\n",
        "\n",
        "header_row = f'| F1 Score Baseline {\" \" * (max_width - len(\"F1 Score Baseline\"))} | F1 Score GRU {\" \" * (max_width - len(\"F1 Score GRU\"))} |\\\n",
        " F1 Score Add. BiLSTM {\" \" * (max_width - len(\"F1 Score Add. BiLSTM\"))} | F1 Score Add. Dense {\" \" * (max_width - len(\"F1 Score Add. Dense\"))} |'\n",
        "separator_row = '-' * len(header_row)\n",
        "data_row = f'| {f1_baseline:<{max_width}} | {f1_gru:<{max_width}} | {f1_add_lstm:<{max_width}} | {f1_add_fc:<{max_width}} |'\n",
        "\n",
        "print(header_row)\n",
        "print(separator_row)\n",
        "print(data_row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9h51xR-Dk75q",
        "outputId": "ba94e7cc-8fb6-4fed-9b68-ab882d170bdc"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"50f1f4f4-39d9-4fbf-8cad-84c53b1cd3ad\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"50f1f4f4-39d9-4fbf-8cad-84c53b1cd3ad\")) {                    Plotly.newPlot(                        \"50f1f4f4-39d9-4fbf-8cad-84c53b1cd3ad\",                        [{\"mode\":\"lines+markers\",\"name\":\"Baseline - BiLSTM Model\",\"x\":[1,2,3,4,5,6,7,8,9,10],\"y\":[0.8365258574485779,0.8891825675964355,0.9300544857978821,0.9522479772567749,0.964359700679779,0.972234308719635,0.976485013961792,0.9789236783981323,0.9808310866355896,0.9820299744606018],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"GRU Model\",\"x\":[1,2,3,4,5,6,7,8,9,10],\"y\":[0.7599591016769409,0.8654904365539551,0.8952997326850891,0.9249182343482971,0.9403542280197144,0.9513078927993774,0.9597684144973755,0.9661852717399597,0.9694958925247192,0.9719618558883667],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('50f1f4f4-39d9-4fbf-8cad-84c53b1cd3ad');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"286d3a56-955a-4246-895e-ecaa7ca52b02\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"286d3a56-955a-4246-895e-ecaa7ca52b02\")) {                    Plotly.newPlot(                        \"286d3a56-955a-4246-895e-ecaa7ca52b02\",                        [{\"mode\":\"lines+markers\",\"name\":\"2 BiLSTMs Model\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\"y\":[0.7733379006385803,0.7916212677955627,0.8341144323348999,0.8816484808921814,0.915163516998291,0.9411444067955017,0.9607493281364441,0.9693460464477539,0.9729836583137512,0.9760218262672424,0.9778746366500854,0.9795640110969543,0.9806675910949707,0.9817438721656799,0.9822888374328613],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"2 FCs Model\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\"y\":[0.7844958901405334,0.8549318909645081,0.8838011026382446,0.9188147187232971,0.9451907277107239,0.9611443877220154,0.9691962003707886,0.9737738370895386,0.9768120050430298,0.9787874817848206,0.9804768562316895,0.9810490608215332,0.9820163249969482,0.982384204864502,0.9829427599906921],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('286d3a56-955a-4246-895e-ecaa7ca52b02');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| F1 Score Baseline   | F1 Score GRU        | F1 Score Add. BiLSTM  | F1 Score Add. Dense  |\n",
            "--------------------------------------------------------------------------------------------\n",
            "| 0.9836321274537105 | 0.9751587602930509 | 0.9852040049235016 | 0.9858732543780686 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ol_DnkuhlCwb"
      },
      "execution_count": 42,
      "outputs": []
    }
  ]
}