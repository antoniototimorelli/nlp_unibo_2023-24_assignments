{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMijYPXTpHbkKSoD/CoqDUH"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import treebank\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import progressbar\n",
        "import tensorflow\n",
        "from collections import defaultdict\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import Sequential, Input, Model\n",
        "from tensorflow.keras.layers import Embedding, Dense, TimeDistributed, LSTM, GRU, Bidirectional, SimpleRNN, RNN\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle"
      ],
      "metadata": {
        "id": "wr9z1Rt2QbM8"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notebook Fatto per capire il procedimento, non è esatto perchè la divisione non è fatta come chiesto, ma con train_test_split"
      ],
      "metadata": {
        "id": "0Ou0uUiVlY1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.PreProcess\n"
      ],
      "metadata": {
        "id": "UHbCUY8tRDOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('treebank')\n",
        "nltk.download('universal_tagset')\n",
        "treebank_corpus = treebank.tagged_sents(tagset='universal')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFAZMkL-Q5A7",
        "outputId": "083a0107-ade0-469c-aff7-7506bd226fc3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "treebank_corpus[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvaTUeDzRQQa",
        "outputId": "415d24c4-1df5-4b17-ba4d-d78383dcde5e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Pierre', 'NOUN'),\n",
              " ('Vinken', 'NOUN'),\n",
              " (',', '.'),\n",
              " ('61', 'NUM'),\n",
              " ('years', 'NOUN'),\n",
              " ('old', 'ADJ'),\n",
              " (',', '.'),\n",
              " ('will', 'VERB'),\n",
              " ('join', 'VERB'),\n",
              " ('the', 'DET'),\n",
              " ('board', 'NOUN'),\n",
              " ('as', 'ADP'),\n",
              " ('a', 'DET'),\n",
              " ('nonexecutive', 'ADJ'),\n",
              " ('director', 'NOUN'),\n",
              " ('Nov.', 'NOUN'),\n",
              " ('29', 'NUM'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.1 Divide in words(X) and tags(Y)"
      ],
      "metadata": {
        "id": "mRuclSm_Rpr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for sentence in treebank_corpus:\n",
        "  X_sentence = []\n",
        "  y_sentence = []\n",
        "  for entity in sentence:\n",
        "    X_sentence.append(entity[0])\n",
        "    y_sentence.append(entity[1])\n",
        "\n",
        "  X.append(X_sentence)\n",
        "  y.append(y_sentence)"
      ],
      "metadata": {
        "id": "7JxD1pFPRfyT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = len(set([word.lower() for sentence in X for word in sentence]))\n",
        "num_tags = len(set([word.lower() for sentence in y for word in sentence]))"
      ],
      "metadata": {
        "id": "Yj2Hhs0ASA7s"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total number of tagged sentences: {}\".format(len(X)))\n",
        "print(\"Vocabulary size: {}\".format(num_words))\n",
        "print(\"Total number of tags: {}\".format(num_tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBov1EyfSUp1",
        "outputId": "d83b38f6-45e5-4fec-8eaf-0f15052f0796"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of tagged sentences: 3914\n",
            "Vocabulary size: 11387\n",
            "Total number of tags: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's look at first data point\n",
        "# this is one data point that will be fed to the RNN\n",
        "print('sample X: ', X[0], '\\n')\n",
        "print('sample Y: ', y[0], '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xka6G7ROSXs8",
        "outputId": "630f01ab-7ae2-4fd0-ea60-4f69269c9ba0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample X:  ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.'] \n",
            "\n",
            "sample Y:  ['NOUN', 'NOUN', '.', 'NUM', 'NOUN', 'ADJ', '.', 'VERB', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN', 'NUM', '.'] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Vectorize X and y\n",
        "word_tokenizer = Tokenizer()\n",
        "word_tokenizer.fit_on_texts(X)\n",
        "X_encoded = word_tokenizer.texts_to_sequences(X)"
      ],
      "metadata": {
        "id": "BP8yz9CxSbCX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag_tokenizer = Tokenizer()\n",
        "tag_tokenizer.fit_on_texts(y)\n",
        "y_encoded = tag_tokenizer.texts_to_sequences(y)"
      ],
      "metadata": {
        "id": "QIq0-cFVZE8e"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# look at first encoded data point\n",
        "\n",
        "print(\"** Raw data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
        "print('X: ', X[0], '\\n')\n",
        "print('Y: ', y[0], '\\n')\n",
        "print()\n",
        "print(\"** Encoded data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
        "print('X: ', X_encoded[0], '\\n')\n",
        "print('Y: ', y_encoded[0], '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8SfxzrJZbmV",
        "outputId": "0fa66122-cdf0-441f-8868-9605f6d1b052"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "** Raw data point ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "X:  ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.'] \n",
            "\n",
            "Y:  ['NOUN', 'NOUN', '.', 'NUM', 'NOUN', 'ADJ', '.', 'VERB', 'VERB', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'NOUN', 'NUM', '.'] \n",
            "\n",
            "\n",
            "** Encoded data point ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "X:  [5601, 3746, 1, 2024, 86, 331, 1, 46, 2405, 2, 131, 27, 6, 2025, 332, 459, 2026, 3] \n",
            "\n",
            "Y:  [1, 1, 3, 8, 1, 7, 3, 2, 2, 5, 1, 4, 5, 7, 1, 1, 8, 3] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check lengths\n",
        "\n",
        "different_length = [1 if len(input) != len(output) else 0 for input, output in zip(X_encoded,y_encoded)]\n",
        "print(\"{} sentences have disparate input-output lengths.\".format(sum(different_length)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cqqa3M83Zf_P",
        "outputId": "778b1903-8a79-4251-de78-fd75ff3b35ca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 sentences have disparate input-output lengths.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.2 Pad sequences"
      ],
      "metadata": {
        "id": "LKj4ZnqjZ5dT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lengths = [len(seq) for seq in X_sentence]\n",
        "print(\"Length of longest sentence: {}\".format(max(lengths)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uk0CyQMmZ3py",
        "outputId": "21bb88d5-c76b-4754-af92-f0280a7c0747"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of longest sentence: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(lengths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "Y6_i7suvaETG",
        "outputId": "a0124f44-3db3-4009-9866-8400591c4039"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f43f9b67160>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.lib.pretty import MAX_SEQ_LENGTH\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "#Pad each sequence to max_seq_length using keras\n",
        "#sentences longer than max_seq truncated\n",
        "#sentences shorter padded with zeroes\n",
        "\n",
        "# Truncation and padding can either be 'pre' or 'post'. \n",
        "# For padding we are using 'pre' padding type, that is, add zeroes on the left side.\n",
        "# For truncation, we are using 'post', that is, truncate a sentence from right side.\n",
        "\n",
        "MAX_SEQ_LENGTH = 100\n",
        "\n",
        "X_padded = pad_sequences(X_encoded, maxlen = MAX_SEQ_LENGTH, padding = 'pre', truncating='post')\n",
        "y_padded = pad_sequences(y_encoded, maxlen = MAX_SEQ_LENGTH, padding = 'pre', truncating='post')"
      ],
      "metadata": {
        "id": "U0zQayp7aIoe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the first sequence\n",
        "print(X_padded[0], \"\\n\")\n",
        "print(y_padded[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTFuBmFZa2Q9",
        "outputId": "cfbc07fc-9f19-4836-ee91-6e766025f41b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0 5601 3746\n",
            "    1 2024   86  331    1   46 2405    2  131   27    6 2025  332  459\n",
            " 2026    3] \n",
            "\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 1 1 3 8 1 7 3 2 2 5 1 4 5 7 1 1 8 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = X_padded, y_padded"
      ],
      "metadata": {
        "id": "3h--IUavevkj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2 Word Embeddings\n"
      ],
      "metadata": {
        "id": "pMbL8JonbdVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Use the 300 dimensional GLove Word Embeddings\n",
        "glove_dir = './'\n",
        "embedding_dim = 300\n",
        "vocab_size = len(word_tokenizer.word_index) + 1\n",
        "embedding_dict = {} #initialize dictionary\n",
        "f = open(os.path.join(glove_dir, f'glove.6B.{embedding_dim}d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embedding_dict[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embedding_dict))\n",
        "print('Vocab of size %s' % len(embedding_dict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUtEzF4EbJ2_",
        "outputId": "cf5e27f8-c390-4168-b45d-2d099455807a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n",
            "Vocab of size 400000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_weights = np.zeros((vocab_size,embedding_dim))\n",
        "word2ind = word_tokenizer.word_index\n",
        "for word, index in word2ind.items():\n",
        "  try:\n",
        "    embedding_weights[index, :] = embedding_dict[word]\n",
        "  except KeyError:\n",
        "    pass"
      ],
      "metadata": {
        "id": "griJq6Nvbyqx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Embeddings shape: {}\".format(embedding_weights.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uQBdBWFcnUj",
        "outputId": "a9702dcc-d22a-4d3a-e963-2b290d7b5e22"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings shape: (11388, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "embedding_weights[word_tokenizer.word_index['bottom']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfnhp0Sgcssv",
        "outputId": "c340385e-5d63-42e6-ee6b-592378ccc241"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.61680001e-01,  5.45570016e-01, -4.21449989e-01, -1.32129997e-01,\n",
              "        1.43869996e-01,  3.33620012e-01, -1.68740004e-01, -1.52049996e-02,\n",
              "        5.05720019e-01, -1.14370000e+00, -1.26359999e-01, -5.18639982e-02,\n",
              "       -6.50840029e-02,  3.54719982e-02, -3.45279992e-01,  2.09189996e-01,\n",
              "       -3.05170000e-01,  3.27719986e-01,  3.66230011e-01, -3.96120012e-01,\n",
              "       -2.18559995e-01,  2.79549986e-01,  1.25749996e-02, -7.39459991e-02,\n",
              "       -1.07630000e-01, -2.38110006e-01,  3.42689991e-01,  4.51849997e-01,\n",
              "        2.59860000e-03,  1.32290006e-01,  1.43790007e-01,  1.45569995e-01,\n",
              "        4.76429984e-02, -3.54240000e-01, -1.14040005e+00,  4.29199994e-01,\n",
              "        3.10660005e-01, -1.34020001e-01,  7.56710023e-02,  4.42640007e-01,\n",
              "        1.20920002e-01,  1.78749993e-01,  4.56500016e-02,  4.57439989e-01,\n",
              "       -1.56560004e-01,  1.85450003e-01,  2.26889998e-01, -1.55049995e-01,\n",
              "       -3.61490011e-01,  6.20420016e-02, -1.18060000e-01,  8.91269967e-02,\n",
              "        1.61850005e-01, -5.08050025e-01, -8.31329972e-02,  8.45359988e-04,\n",
              "        7.96469972e-02, -6.56159997e-01, -3.30810010e-01,  5.38940012e-01,\n",
              "        5.32880008e-01, -5.50949991e-01,  5.87149978e-01,  2.67309994e-01,\n",
              "       -1.70540009e-02, -5.17750025e-01,  1.68479994e-01, -2.92220004e-02,\n",
              "       -1.06600001e-01, -1.69200003e-01,  2.65480012e-01,  1.40040005e-02,\n",
              "       -2.49760002e-01,  1.01779997e-01, -2.46720001e-01,  2.48899996e-01,\n",
              "        1.67160004e-01,  4.15300012e-01, -2.26620004e-01, -4.75939989e-01,\n",
              "       -2.99849987e-01, -1.59949996e-02, -1.99100003e-01, -1.45229995e-01,\n",
              "       -8.31070021e-02,  3.01249996e-02,  5.65240011e-02, -3.67989987e-02,\n",
              "       -4.93739992e-01, -1.04610004e-01,  5.60890019e-01,  4.12849993e-01,\n",
              "       -2.14340001e-01, -4.22930002e-01, -1.48880005e-01,  2.93729991e-01,\n",
              "       -3.49029988e-01,  3.23179990e-01,  1.76789999e-01, -5.22520006e-01,\n",
              "       -1.11170001e-01,  1.00060001e-01,  8.34140033e-02, -5.89079976e-01,\n",
              "       -2.29409993e-01,  1.89119995e-01,  5.09370029e-01, -4.50320005e-01,\n",
              "        3.90309989e-01,  4.00549993e-02,  1.53160006e-01, -6.80130005e-01,\n",
              "        3.10319990e-01, -6.80559993e-01, -2.35489994e-01,  1.43250003e-01,\n",
              "       -9.75700021e-02, -2.87230015e-01,  5.67409992e-02, -2.63069987e-01,\n",
              "       -3.61279994e-01, -8.91070008e-01,  9.39819992e-01,  2.93650001e-01,\n",
              "       -9.83619988e-02, -3.85479987e-01, -1.02339998e-01, -2.62450010e-01,\n",
              "        1.61540002e-01, -2.34740004e-02,  7.73520023e-02,  1.24440002e+00,\n",
              "        4.80590016e-02,  7.71679997e-01, -6.17169999e-02, -1.08690001e-01,\n",
              "       -4.13910002e-01,  6.88099980e-01, -3.40030015e-01,  2.93309987e-01,\n",
              "        1.48330003e-01,  1.15700001e-02, -1.61009997e-01, -7.67840028e-01,\n",
              "       -3.87490004e-01, -1.40509993e-01, -2.93520000e-02,  2.57669985e-01,\n",
              "        2.49720007e-01,  1.61459997e-01,  1.36540001e-02,  1.99650005e-01,\n",
              "       -2.16330007e-01, -7.33500004e-01,  5.43879986e-01,  2.86119998e-01,\n",
              "        1.13760002e-01, -2.10789993e-01, -3.33440006e-01,  6.35519981e-01,\n",
              "       -2.40119994e-01, -1.79859996e-01, -2.08079994e-01, -3.05429995e-01,\n",
              "        3.68620008e-01, -2.33390003e-01,  1.96319997e-01,  6.07549995e-02,\n",
              "       -6.62169978e-02, -6.61659986e-03, -3.70359987e-01, -1.82270005e-01,\n",
              "        1.03040002e-01, -6.68959975e-01, -2.84729991e-02,  3.27639997e-01,\n",
              "       -4.65209991e-01,  4.01300013e-01, -5.09140015e-01,  1.56369999e-01,\n",
              "        3.61330003e-01,  4.25900012e-01,  5.51289976e-01, -2.52270013e-01,\n",
              "        2.30739996e-01, -5.18639982e-01,  5.27740002e-01,  1.87999997e-02,\n",
              "        2.55479991e-01,  5.25409997e-01,  4.08609986e-01,  8.29200029e-01,\n",
              "        4.34920013e-01,  1.84379995e-01,  3.04259986e-01,  2.81899989e-01,\n",
              "       -1.65140003e-01, -2.61460006e-01, -3.20259988e-01,  1.41589999e-01,\n",
              "        1.25039995e+00,  5.19590005e-02,  3.91790003e-01, -1.87909994e-02,\n",
              "        8.63199979e-02, -1.76080003e-01,  2.67910004e-01, -6.94429994e-01,\n",
              "       -3.32419991e-01, -3.21289986e-01, -7.97379985e-02, -1.17559999e-01,\n",
              "       -2.50970006e-01,  2.53919989e-01,  4.78940010e-01,  1.85870007e-01,\n",
              "        1.38899997e-01, -7.33459964e-02,  1.05130002e-01, -5.77500015e-02,\n",
              "       -5.07510006e-02,  5.03650010e-01, -2.00240001e-01, -1.79309994e-01,\n",
              "        7.69670010e-02, -1.83280006e-01, -2.12960005e-01,  6.29929975e-02,\n",
              "        1.18759997e-01,  9.28530023e-02, -2.92869985e-01,  1.26760006e-01,\n",
              "        3.25139984e-02,  4.55400012e-02,  3.63720000e-01, -2.95749992e-01,\n",
              "       -5.25440015e-02, -1.28360000e-02,  3.66730005e-01,  2.03860000e-01,\n",
              "        1.13040000e-01, -1.75060004e-01,  4.67860013e-01,  3.92739996e-02,\n",
              "       -7.84030020e-01, -3.32819998e-01,  6.49089992e-01,  2.35440001e-01,\n",
              "        8.69899988e-03,  3.67910005e-02, -2.65749991e-01,  9.34230015e-02,\n",
              "        1.05040002e+00,  6.04109988e-02,  1.34599999e-01,  2.47350007e-01,\n",
              "        2.18740001e-01, -2.91509996e-03, -4.93250012e-01,  2.43890002e-01,\n",
              "       -4.29199994e-01, -1.57509997e-01, -2.71849990e-01,  2.10989997e-01,\n",
              "        1.84130005e-03, -3.84850018e-02, -2.28520006e-01, -1.12800002e-01,\n",
              "        1.85929999e-01,  3.50019991e-01,  1.26289994e-01, -1.22259997e-01,\n",
              "       -1.09200001e-01,  6.74279988e-01,  1.26509994e-01,  7.64119998e-02,\n",
              "       -8.45350027e-01, -3.59090000e-01,  3.55219990e-02, -1.47430003e-01,\n",
              "       -5.91440022e-01,  7.46330023e-01, -8.68070006e-01, -2.22749993e-01,\n",
              "       -3.72999996e-01,  1.41530000e-02,  3.06270003e-01, -5.82669973e-01,\n",
              "        5.71879983e-01,  6.82689995e-02, -2.97349989e-01,  8.05289969e-02,\n",
              "       -4.84310001e-01,  1.95079997e-01,  9.85379964e-02, -9.01070016e-04,\n",
              "        5.09190023e-01, -2.49160007e-01,  1.14840001e-01, -1.69560000e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(y)"
      ],
      "metadata": {
        "id": "3FZb8xi8czVc"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxOXhTV6c42d",
        "outputId": "d2f261b1-0bc3-453b-8dc8-3a2562670f7c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3914, 100, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25)"
      ],
      "metadata": {
        "id": "-ebuQ2tkdpTl"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_val,y_train,y_val = train_test_split(X_train,y_train,test_size=0.25)"
      ],
      "metadata": {
        "id": "AqzGIECXfxX4"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print number of samples in each set\n",
        "print(\"TRAINING DATA\")\n",
        "print('Shape of input sequences: {}'.format(X_train.shape))\n",
        "print('Shape of output sequences: {}'.format(y_train.shape))\n",
        "print(\"-\"*50)\n",
        "print(\"VALIDATION DATA\")\n",
        "print('Shape of input sequences: {}'.format(X_val.shape))\n",
        "print('Shape of output sequences: {}'.format(y_val.shape))\n",
        "print(\"-\"*50)\n",
        "print(\"TESTING DATA\")\n",
        "print('Shape of input sequences: {}'.format(X_test.shape))\n",
        "print('Shape of output sequences: {}'.format(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYWQ8gpOf4u_",
        "outputId": "e9c8c227-0a71-445f-a996-68077d8cb28c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINING DATA\n",
            "Shape of input sequences: (2201, 100)\n",
            "Shape of output sequences: (2201, 100, 13)\n",
            "--------------------------------------------------\n",
            "VALIDATION DATA\n",
            "Shape of input sequences: (734, 100)\n",
            "Shape of output sequences: (734, 100, 13)\n",
            "--------------------------------------------------\n",
            "TESTING DATA\n",
            "Shape of input sequences: (979, 100)\n",
            "Shape of output sequences: (979, 100, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "baseline_model = Sequential(name='Baseline')\n",
        "\n",
        "# Add the Embedding layer\n",
        "# baseline_model.add(Embedding(input_dim=vocab_length, output_dim=embedding_dim, \\\n",
        "#                     weights=[embedding_matrix], input_length=MAX_LENGTH, trainable=False))\n",
        "baseline_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, \\\n",
        "                    weights=[embedding_weights], input_length=MAX_SEQ_LENGTH, trainable=True))\n",
        "\n",
        "# Add the Bidirectional LSTM layer\n",
        "baseline_model.add(Bidirectional(LSTM(units=256, return_sequences=True)))\n",
        "\n",
        "# Add the Dense/Fully-Connected layer\n",
        "baseline_model.add(TimeDistributed(Dense(units=13, activation='softmax')))\n",
        "\n",
        "# Compile the model\n",
        "baseline_model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summary\n",
        "baseline_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uik28V6wf6QX",
        "outputId": "72ff9a1a-4e50-4643-a615-5696409f984a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Baseline\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 100, 300)          3416400   \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirectio  (None, 100, 512)         1140736   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_3 (TimeDis  (None, 100, 13)          6669      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,563,805\n",
            "Trainable params: 4,563,805\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_baseline = baseline_model.fit(X_train, y_train, validation_data=(X_val, y_val),batch_size=128, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLf95LUBgLAS",
        "outputId": "ba7e3ab6-2cc2-4bad-b425-95fa153ad390"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "18/18 [==============================] - 8s 93ms/step - loss: 1.0646 - accuracy: 0.7923 - val_loss: 0.4165 - val_accuracy: 0.8813\n",
            "Epoch 2/10\n",
            "18/18 [==============================] - 1s 43ms/step - loss: 0.3201 - accuracy: 0.9101 - val_loss: 0.2313 - val_accuracy: 0.9327\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - 1s 43ms/step - loss: 0.1816 - accuracy: 0.9482 - val_loss: 0.1411 - val_accuracy: 0.9597\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - 1s 43ms/step - loss: 0.1141 - accuracy: 0.9675 - val_loss: 0.0958 - val_accuracy: 0.9728\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - 1s 43ms/step - loss: 0.0765 - accuracy: 0.9787 - val_loss: 0.0712 - val_accuracy: 0.9802\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - 1s 43ms/step - loss: 0.0538 - accuracy: 0.9857 - val_loss: 0.0569 - val_accuracy: 0.9835\n",
            "Epoch 7/10\n",
            "18/18 [==============================] - 1s 43ms/step - loss: 0.0395 - accuracy: 0.9898 - val_loss: 0.0489 - val_accuracy: 0.9854\n",
            "Epoch 8/10\n",
            "18/18 [==============================] - 1s 43ms/step - loss: 0.0303 - accuracy: 0.9922 - val_loss: 0.0447 - val_accuracy: 0.9863\n",
            "Epoch 9/10\n",
            "18/18 [==============================] - 1s 44ms/step - loss: 0.0242 - accuracy: 0.9937 - val_loss: 0.0415 - val_accuracy: 0.9873\n",
            "Epoch 10/10\n",
            "18/18 [==============================] - 1s 43ms/step - loss: 0.0197 - accuracy: 0.9950 - val_loss: 0.0393 - val_accuracy: 0.9879\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = baseline_model.evaluate(X_test, y_test, return_dict = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDQECzYng7mR",
        "outputId": "0b5091e1-ad2c-4b23-e709-f0793b74dc8f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 1s 15ms/step - loss: 0.0425 - accuracy: 0.9872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = baseline_model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BexAaciDiWc0",
        "outputId": "c8c25232-91a0-4cb1-9693-b5776790101f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 1s 10ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "# Flatten the predictions and the true labels to 1D arrays\n",
        "predictions = predictions.flatten()\n",
        "y_true = y_test.flatten()\n",
        "\n",
        "th = 0.1\n",
        "predictions[predictions >= th] = 1 \n",
        "predictions[predictions  < th] = 0\n",
        "\n",
        "# Compute the F1 score\n",
        "f1_baseline = f1_score(y_true, predictions, average = 'macro')\n",
        "\n",
        "print(\"Macro-F1 score:\", round(f1_baseline,3))\n",
        "\n",
        "baseline_model.save('./baseline_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPJz028UiX7D",
        "outputId": "c56eba60-77a9-4dfb-c032-30feb13533ca"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Macro-F1 score: 0.988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GRU\n",
        "\n"
      ],
      "metadata": {
        "id": "dAESB5Muj13B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "gru_model = tensorflow.keras.Sequential(name='GRU')\n",
        "\n",
        "# Add the Embedding layer\n",
        "gru_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, \\\n",
        "                    weights = [embedding_weights], input_length = MAX_SEQ_LENGTH, trainable=True))\n",
        "\n",
        "# Add the GRU layer\n",
        "gru_model.add(GRU(units=128, return_sequences=True))\n",
        "\n",
        "# Add the Dense/Fully-Connected layer\n",
        "gru_model.add(TimeDistributed(Dense(13, activation='softmax')))\n",
        "\n",
        "# Compile the model\n",
        "gru_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summary\n",
        "gru_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBDrY_fJie5M",
        "outputId": "f9be5aaf-b2f5-41af-a832-2a7eb3fedf6c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 100, 300)          3416400   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 100, 128)          165120    \n",
            "                                                                 \n",
            " time_distributed_4 (TimeDis  (None, 100, 13)          1677      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,583,197\n",
            "Trainable params: 3,583,197\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_gru = gru_model.fit(X_train, y_train, epochs=10, verbose = True, validation_data=(X_val,y_val), batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkZTQuBSkEc7",
        "outputId": "9577dfb4-691c-4548-ea36-4d4752e107e7"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "18/18 [==============================] - 3s 44ms/step - loss: 1.7232 - accuracy: 0.8297 - val_loss: 0.6558 - val_accuracy: 0.8551\n",
            "Epoch 2/10\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4608 - accuracy: 0.8884 - val_loss: 0.3397 - val_accuracy: 0.9108\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.2801 - accuracy: 0.9274 - val_loss: 0.2299 - val_accuracy: 0.9410\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.1915 - accuracy: 0.9516 - val_loss: 0.1658 - val_accuracy: 0.9579\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.1373 - accuracy: 0.9655 - val_loss: 0.1263 - val_accuracy: 0.9680\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.1017 - accuracy: 0.9755 - val_loss: 0.1004 - val_accuracy: 0.9743\n",
            "Epoch 7/10\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0770 - accuracy: 0.9820 - val_loss: 0.0832 - val_accuracy: 0.9782\n",
            "Epoch 8/10\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0598 - accuracy: 0.9861 - val_loss: 0.0719 - val_accuracy: 0.9801\n",
            "Epoch 9/10\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0477 - accuracy: 0.9890 - val_loss: 0.0643 - val_accuracy: 0.9822\n",
            "Epoch 10/10\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0391 - accuracy: 0.9909 - val_loss: 0.0591 - val_accuracy: 0.9827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = gru_model.predict(X_test)\n",
        "# Flatten the predictions and the true labels to 1D arrays\n",
        "predictions = y_pred.flatten()\n",
        "y_true = y_test.flatten()\n",
        "\n",
        "th = 0.1\n",
        "predictions[predictions >= th] = 1 \n",
        "predictions[predictions  < th] = 0\n",
        "\n",
        "# Compute the F1 score\n",
        "f1_gru = f1_score(y_true, predictions, average = 'macro')\n",
        "\n",
        "print(\"Macro-F1 score:\", round(f1_gru,3))\n",
        "\n",
        "gru_model.save('./gru_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iA_ixZKFkJGB",
        "outputId": "608f34ad-ddf3-4961-887a-3eda0503b2a0"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 1s 5ms/step\n",
            "Macro-F1 score: 0.984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Additional LSTM Layer"
      ],
      "metadata": {
        "id": "FhSgCrzzkTAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "add_lstm_model = tensorflow.keras.Sequential(name='Additional_LSTM')\n",
        "\n",
        "# Add the Embedding layer\n",
        "add_lstm_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, \\\n",
        "                    weights = [embedding_weights], input_length = MAX_SEQ_LENGTH, trainable=True))\n",
        "\n",
        "# Add the Bidirectional LSTM layer\n",
        "add_lstm_model.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
        "\n",
        "# Add another LSTM layer\n",
        "add_lstm_model.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
        "\n",
        "# Add the Dense/Fully-Connected layer\n",
        "add_lstm_model.add(TimeDistributed(Dense(units=13, activation='softmax')))\n",
        "\n",
        "# Compile the model\n",
        "add_lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summary\n",
        "add_lstm_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSaKyv0qkMoF",
        "outputId": "09111e2e-7646-41b1-985c-9c9b28254462"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Additional_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 100, 300)          3416400   \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirectio  (None, 100, 256)         439296    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirectio  (None, 100, 256)         394240    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_5 (TimeDis  (None, 100, 13)          3341      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,253,277\n",
            "Trainable params: 4,253,277\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_add_lstm = add_lstm_model.fit(X_train, y_train, epochs=15, verbose = True, validation_data=(X_val,y_val), batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bje3sTIykdZx",
        "outputId": "1902d9d6-63e1-4b48-ae9b-028e0af7df75"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "18/18 [==============================] - 8s 129ms/step - loss: 1.1443 - accuracy: 0.7723 - val_loss: 0.5624 - val_accuracy: 0.8176\n",
            "Epoch 2/15\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.5316 - accuracy: 0.8264 - val_loss: 0.4917 - val_accuracy: 0.8333\n",
            "Epoch 3/15\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.4283 - accuracy: 0.8675 - val_loss: 0.3464 - val_accuracy: 0.9018\n",
            "Epoch 4/15\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.2732 - accuracy: 0.9226 - val_loss: 0.2050 - val_accuracy: 0.9373\n",
            "Epoch 5/15\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.1605 - accuracy: 0.9534 - val_loss: 0.1270 - val_accuracy: 0.9654\n",
            "Epoch 6/15\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.1000 - accuracy: 0.9731 - val_loss: 0.0869 - val_accuracy: 0.9767\n",
            "Epoch 7/15\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.0655 - accuracy: 0.9835 - val_loss: 0.0656 - val_accuracy: 0.9819\n",
            "Epoch 8/15\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.0448 - accuracy: 0.9891 - val_loss: 0.0546 - val_accuracy: 0.9848\n",
            "Epoch 9/15\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.0326 - accuracy: 0.9923 - val_loss: 0.0491 - val_accuracy: 0.9860\n",
            "Epoch 10/15\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.0252 - accuracy: 0.9940 - val_loss: 0.0454 - val_accuracy: 0.9872\n",
            "Epoch 11/15\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.0202 - accuracy: 0.9952 - val_loss: 0.0441 - val_accuracy: 0.9873\n",
            "Epoch 12/15\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.0168 - accuracy: 0.9961 - val_loss: 0.0426 - val_accuracy: 0.9878\n",
            "Epoch 13/15\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0145 - accuracy: 0.9966 - val_loss: 0.0426 - val_accuracy: 0.9879\n",
            "Epoch 14/15\n",
            "18/18 [==============================] - 1s 45ms/step - loss: 0.0127 - accuracy: 0.9971 - val_loss: 0.0427 - val_accuracy: 0.9881\n",
            "Epoch 15/15\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 0.0112 - accuracy: 0.9974 - val_loss: 0.0425 - val_accuracy: 0.9881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = add_lstm_model.predict(X_test)\n",
        "# Flatten the predictions and the true labels to 1D arrays\n",
        "predictions = y_pred.flatten()\n",
        "y_true = y_test.flatten()\n",
        "\n",
        "th = 0.1\n",
        "predictions[predictions >= th] = 1 \n",
        "predictions[predictions  < th] = 0\n",
        "\n",
        "# Compute the F1 score\n",
        "f1_add_lstm = f1_score(y_true, predictions, average = 'macro')\n",
        "\n",
        "print(\"Macro-F1 score:\", round(f1_add_lstm,3))\n",
        "\n",
        "add_lstm_model.save('./add_lstm_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUPhfmVBkgTZ",
        "outputId": "afe03844-c1ca-4cd3-ce2f-b0ff4eae4de4"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 2s 13ms/step\n",
            "Macro-F1 score: 0.99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_17_layer_call_fn, lstm_cell_17_layer_call_and_return_conditional_losses, lstm_cell_19_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Additional Dense Layer"
      ],
      "metadata": {
        "id": "WZDFRILUklPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "add_fc_model = tensorflow.keras.Sequential(name='Additional_FC')\n",
        "\n",
        "# Add the Embedding layer\n",
        "add_fc_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, \\\n",
        "                    weights = [embedding_weights], input_length = MAX_SEQ_LENGTH, trainable=True))\n",
        "\n",
        "# Add the Bidirectional LSTM layer\n",
        "add_fc_model.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
        "\n",
        "# Add another Dense layer\n",
        "add_fc_model.add(TimeDistributed(Dense(units=MAX_SEQ_LENGTH, activation='relu')))\n",
        "\n",
        "# Add the Dense/Fully-Connected layer\n",
        "add_fc_model.add(TimeDistributed(Dense(units=13, activation='softmax')))\n",
        "\n",
        "# Compile the model\n",
        "add_fc_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summary\n",
        "add_fc_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iTv5limknIY",
        "outputId": "9efbdb70-0fd2-4c3a-f2f1-0b2d8fe924fd"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Additional_FC\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     (None, 100, 300)          3416400   \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirectio  (None, 100, 256)         439296    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_6 (TimeDis  (None, 100, 100)         25700     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_7 (TimeDis  (None, 100, 13)          1313      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,882,709\n",
            "Trainable params: 3,882,709\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_add_fc = add_fc_model.fit(X_train, y_train, epochs=15, verbose = True, validation_data=(X_val,y_val), batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rh0XwDUnk1FB",
        "outputId": "b74e518c-64db-471c-a732-b98d18dd034d"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "18/18 [==============================] - 5s 79ms/step - loss: 1.4908 - accuracy: 0.7712 - val_loss: 0.5284 - val_accuracy: 0.8307\n",
            "Epoch 2/15\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.4424 - accuracy: 0.8651 - val_loss: 0.3542 - val_accuracy: 0.9000\n",
            "Epoch 3/15\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.2827 - accuracy: 0.9189 - val_loss: 0.2132 - val_accuracy: 0.9373\n",
            "Epoch 4/15\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1709 - accuracy: 0.9502 - val_loss: 0.1336 - val_accuracy: 0.9601\n",
            "Epoch 5/15\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.1076 - accuracy: 0.9686 - val_loss: 0.0911 - val_accuracy: 0.9729\n",
            "Epoch 6/15\n",
            "18/18 [==============================] - 1s 30ms/step - loss: 0.0705 - accuracy: 0.9804 - val_loss: 0.0683 - val_accuracy: 0.9796\n",
            "Epoch 7/15\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.0485 - accuracy: 0.9864 - val_loss: 0.0550 - val_accuracy: 0.9830\n",
            "Epoch 8/15\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.0351 - accuracy: 0.9902 - val_loss: 0.0490 - val_accuracy: 0.9844\n",
            "Epoch 9/15\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.0269 - accuracy: 0.9926 - val_loss: 0.0452 - val_accuracy: 0.9857\n",
            "Epoch 10/15\n",
            "18/18 [==============================] - 0s 26ms/step - loss: 0.0216 - accuracy: 0.9942 - val_loss: 0.0434 - val_accuracy: 0.9864\n",
            "Epoch 11/15\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.0179 - accuracy: 0.9952 - val_loss: 0.0424 - val_accuracy: 0.9872\n",
            "Epoch 12/15\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.0155 - accuracy: 0.9959 - val_loss: 0.0433 - val_accuracy: 0.9868\n",
            "Epoch 13/15\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.0421 - val_accuracy: 0.9876\n",
            "Epoch 14/15\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.0421 - val_accuracy: 0.9877\n",
            "Epoch 15/15\n",
            "18/18 [==============================] - 0s 27ms/step - loss: 0.0106 - accuracy: 0.9971 - val_loss: 0.0424 - val_accuracy: 0.9878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = add_fc_model.predict(X_test)\n",
        "# Flatten the predictions and the true labels to 1D arrays\n",
        "predictions = y_pred.flatten()\n",
        "y_true = y_test.flatten()\n",
        "\n",
        "th = 0.1\n",
        "predictions[predictions >= th] = 1 \n",
        "predictions[predictions  < th] = 0\n",
        "\n",
        "# Compute the F1 score\n",
        "f1_add_fc = f1_score(y_true, predictions, average = 'macro')\n",
        "\n",
        "print(\"Macro-F1 score:\", round(f1_add_fc,3))\n",
        "\n",
        "add_fc_model.save('./add_fc_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTvmDNpGk3c5",
        "outputId": "cf88cdd9-f451-49d7-8bf2-5910bf2625f7"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 1s 8ms/step\n",
            "Macro-F1 score: 0.99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_22_layer_call_fn, lstm_cell_22_layer_call_and_return_conditional_losses, lstm_cell_23_layer_call_fn, lstm_cell_23_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# # Create a list of epochs (i.e., the x-axis data)\n",
        "epochs = list(range(1, len(results_baseline.history['val_accuracy'])+1))\n",
        "\n",
        "# # Create a Plotly line plot using the epochs and validation accuracy data\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=epochs, y=results_baseline.history['val_accuracy'], name='Baseline - BiLSTM Model', mode='lines+markers'))\n",
        "fig.add_trace(go.Scatter(x=epochs, y=results_gru.history['val_accuracy'], name='GRU Model', mode='lines+markers'))\n",
        "fig.show()\n",
        "\n",
        "# Create a list of epochs (i.e., the x-axis data)\n",
        "epochs = list(range(1, len(results_add_lstm.history['val_accuracy'])+1))\n",
        "\n",
        "fig2 = go.Figure()\n",
        "fig2.add_trace(go.Scatter(x=epochs, y=results_add_lstm.history['val_accuracy'], name='2 BiLSTMs Model', mode='lines+markers'))\n",
        "fig2.add_trace(go.Scatter(x=epochs, y=results_add_fc.history['val_accuracy'], name='2 FCs Model', mode='lines+markers'))\n",
        "fig2.show()\n",
        "\n",
        "max_width = max(len(str(f1_baseline)), len(str(f1_gru)), len(str(f1_add_lstm)), len(str(f1_add_fc)))\n",
        "\n",
        "header_row = f'| F1 Score Baseline {\" \" * (max_width - len(\"F1 Score Baseline\"))} | F1 Score GRU {\" \" * (max_width - len(\"F1 Score GRU\"))} |\\\n",
        " F1 Score Add. BiLSTM {\" \" * (max_width - len(\"F1 Score Add. BiLSTM\"))} | F1 Score Add. Dense {\" \" * (max_width - len(\"F1 Score Add. Dense\"))} |'\n",
        "separator_row = '-' * len(header_row)\n",
        "data_row = f'| {f1_baseline:<{max_width}} | {f1_gru:<{max_width}} | {f1_add_lstm:<{max_width}} | {f1_add_fc:<{max_width}} |'\n",
        "\n",
        "print(header_row)\n",
        "print(separator_row)\n",
        "print(data_row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9h51xR-Dk75q",
        "outputId": "78ddff54-0846-4ec8-f719-27384351cc3c"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"2383f717-3fef-49c4-881b-998c9224c2a4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2383f717-3fef-49c4-881b-998c9224c2a4\")) {                    Plotly.newPlot(                        \"2383f717-3fef-49c4-881b-998c9224c2a4\",                        [{\"mode\":\"lines+markers\",\"name\":\"Baseline - BiLSTM Model\",\"x\":[1,2,3,4,5,6,7,8,9,10],\"y\":[0.8813351392745972,0.9327384233474731,0.959713876247406,0.9727792739868164,0.9802315831184387,0.9835013747215271,0.985435962677002,0.9862942695617676,0.9873297214508057,0.9879019260406494],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"GRU Model\",\"x\":[1,2,3,4,5,6,7,8,9,10],\"y\":[0.8551226258277893,0.9108174443244934,0.9409536719322205,0.9579018950462341,0.9679564237594604,0.9742643237113953,0.9782425165176392,0.980095386505127,0.9821662306785583,0.9827247858047485],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2383f717-3fef-49c4-881b-998c9224c2a4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"955ff0db-a252-45f5-853c-45b48bc95e99\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"955ff0db-a252-45f5-853c-45b48bc95e99\")) {                    Plotly.newPlot(                        \"955ff0db-a252-45f5-853c-45b48bc95e99\",                        [{\"mode\":\"lines+markers\",\"name\":\"2 BiLSTMs Model\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\"y\":[0.8175613284111023,0.8332561254501343,0.9017847180366516,0.9373160600662231,0.96536785364151,0.9766620993614197,0.9819209575653076,0.9848228693008423,0.9860081672668457,0.9871662259101868,0.9873297214508057,0.9877793192863464,0.9879427552223206,0.9881062507629395,0.9881471395492554],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"2 FCs Model\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\"y\":[0.8307084441184998,0.9000136256217957,0.9372615814208984,0.9600545167922974,0.9728610515594482,0.9795504212379456,0.9829564094543457,0.9844141602516174,0.9856811761856079,0.9864168763160706,0.987234354019165,0.986839234828949,0.987602174282074,0.9877384305000305,0.9878201484680176],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('955ff0db-a252-45f5-853c-45b48bc95e99');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| F1 Score Baseline   | F1 Score GRU        | F1 Score Add. BiLSTM  | F1 Score Add. Dense  |\n",
            "--------------------------------------------------------------------------------------------\n",
            "| 0.9878441173344092 | 0.9835631809219132 | 0.9900770847658635 | 0.989751297228914  |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ol_DnkuhlCwb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}