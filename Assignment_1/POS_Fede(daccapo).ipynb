{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQKgtm78SLTQAAdDB1Eswd"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import treebank\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import progressbar\n",
        "import tensorflow\n",
        "from collections import defaultdict\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import Sequential, Input, Model\n",
        "from tensorflow.keras.layers import Embedding, Dense, TimeDistributed, LSTM, GRU, Bidirectional, SimpleRNN, RNN\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "import progressbar\n",
        "from IPython.display import display_html\n",
        "from itertools import chain,cycle\n",
        "# Downloading Glove Word Embeddings\n",
        "pbar = None\n",
        "def show_progress(block_num, block_size, total_size):\n",
        "    global pbar\n",
        "    if pbar is None:\n",
        "        pbar = progressbar.ProgressBar(maxval=total_size)\n",
        "        pbar.start()\n",
        "\n",
        "    downloaded = block_num * block_size\n",
        "    if downloaded < total_size:\n",
        "        pbar.update(downloaded)\n",
        "    else:\n",
        "        pbar.finish()\n",
        "        pbar = None\n",
        "\n",
        "# Display dataframes\n",
        "def display(*args,titles=cycle([''])):\n",
        "    html_str=''\n",
        "    for df,title in zip(args, chain(titles,cycle(['</br>'])) ):\n",
        "        html_str+='<th style=\"text-align:left\"><td style=\"vertical-align:top\">'\n",
        "        html_str+=f'<h4 style=\"text-align: left;\">{title}</h2>'\n",
        "        html_str+=df.to_html().replace('table','table style=\"display:inline\"')\n",
        "        html_str+='</td></th>'\n",
        "    display_html(html_str,raw=True)"
      ],
      "metadata": {
        "id": "wr9z1Rt2QbM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Da controllare.\n",
        "\n"
      ],
      "metadata": {
        "id": "0Ou0uUiVlY1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.PreProcess\n"
      ],
      "metadata": {
        "id": "UHbCUY8tRDOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('treebank')\n",
        "\n",
        "# Get the files' list\n",
        "fileids = treebank.fileids()\n",
        "\n",
        "treebank_corpus_complete = treebank.tagged_sents()\n",
        "train_corpus = treebank.tagged_sents(fileids[:100])\n",
        "val_corpus = treebank.tagged_sents(fileids[100:150])\n",
        "test_corpus = treebank.tagged_sents(fileids[150:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFAZMkL-Q5A7",
        "outputId": "51143845-8d98-4efe-d1e8-ea0d71a17b08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "treebank_corpus_complete[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvaTUeDzRQQa",
        "outputId": "640508d2-91f0-4aea-99bc-fd6d7745411b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Pierre', 'NNP'),\n",
              " ('Vinken', 'NNP'),\n",
              " (',', ','),\n",
              " ('61', 'CD'),\n",
              " ('years', 'NNS'),\n",
              " ('old', 'JJ'),\n",
              " (',', ','),\n",
              " ('will', 'MD'),\n",
              " ('join', 'VB'),\n",
              " ('the', 'DT'),\n",
              " ('board', 'NN'),\n",
              " ('as', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('nonexecutive', 'JJ'),\n",
              " ('director', 'NN'),\n",
              " ('Nov.', 'NNP'),\n",
              " ('29', 'CD'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.1 Divide in words(X) and tags(Y)\n",
        "We do it for all the corpuses"
      ],
      "metadata": {
        "id": "mRuclSm_Rpr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for sentence in treebank_corpus_complete:\n",
        "  X_sentence = []\n",
        "  y_sentence = []\n",
        "  for entity in sentence:\n",
        "    X_sentence.append(entity[0])\n",
        "    y_sentence.append(entity[1])\n",
        "\n",
        "  X.append(X_sentence)\n",
        "  y.append(y_sentence)"
      ],
      "metadata": {
        "id": "7JxD1pFPRfyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for sentence in train_corpus:\n",
        "  X_sentence = []\n",
        "  y_sentence = []\n",
        "  for entity in sentence:\n",
        "    X_sentence.append(entity[0])\n",
        "    y_sentence.append(entity[1])\n",
        "\n",
        "  X_train.append(X_sentence)\n",
        "  y_train.append(y_sentence)"
      ],
      "metadata": {
        "id": "VJwojo7yCW93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val = []\n",
        "y_val = []\n",
        "\n",
        "for sentence in val_corpus:\n",
        "  X_sentence = []\n",
        "  y_sentence = []\n",
        "  for entity in sentence:\n",
        "    X_sentence.append(entity[0])\n",
        "    y_sentence.append(entity[1])\n",
        "\n",
        "  X_val.append(X_sentence)\n",
        "  y_val.append(y_sentence)"
      ],
      "metadata": {
        "id": "pv85-g07CXj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for sentence in test_corpus:\n",
        "  X_sentence = []\n",
        "  y_sentence = []\n",
        "  for entity in sentence:\n",
        "    X_sentence.append(entity[0])\n",
        "    y_sentence.append(entity[1])\n",
        "\n",
        "  X_test.append(X_sentence)\n",
        "  y_test.append(y_sentence)"
      ],
      "metadata": {
        "id": "wnkFCt6wCX39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Dataframes for sentences\n",
        "\n",
        "#Train\n",
        "X_train_df = [[word, i] for i, sentence in enumerate(X_train) for word in sentence]\n",
        "X_train_df = pd.DataFrame(X_train_df, columns = ['word','sentence'])\n",
        "display(X_train_df.head())\n",
        "\n",
        "#Val\n",
        "X_val_df = [[word, i] for i, sentence in enumerate(X_val) for word in sentence]\n",
        "X_val_df = pd.DataFrame(X_val_df, columns = ['word','sentence'])\n",
        "display(X_val_df.head())\n",
        "\n",
        "#Test\n",
        "X_test_df = [[word, i] for i, sentence in enumerate(X_test) for word in sentence]\n",
        "X_test_df = pd.DataFrame(X_test_df, columns = ['word','sentence'])\n",
        "display(X_test_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "tMnm-zTmokHe",
        "outputId": "cbac89f3-cc0b-49f4-ce3d-ab2bba803171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<th style=\"text-align:left\"><td style=\"vertical-align:top\"><h4 style=\"text-align: left;\"></h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pierre</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Vinken</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>,</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>years</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table style=\"display:inline\"></td></th>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<th style=\"text-align:left\"><td style=\"vertical-align:top\"><h4 style=\"text-align: left;\"></h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>House-Senate</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>conference</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>approved</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>major</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table style=\"display:inline\"></td></th>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<th style=\"text-align:left\"><td style=\"vertical-align:top\"><h4 style=\"text-align: left;\"></h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Intelogic</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Trace</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Inc.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>,</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>San</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table style=\"display:inline\"></td></th>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Dataframes for tags\n",
        "\n",
        "#Train\n",
        "y_train_df = [[word, i] for i, sentence in enumerate(y_train) for word in sentence]\n",
        "y_train_df = pd.DataFrame(y_train_df, columns = ['tag','sentence'])\n",
        "display(X_train_df.head())\n",
        "\n",
        "#Val\n",
        "y_val_df = [[word, i] for i, sentence in enumerate(y_val) for word in sentence]\n",
        "y_val_df = pd.DataFrame(y_val_df, columns = ['tag','sentence'])\n",
        "display(y_val_df.head())\n",
        "\n",
        "#Test\n",
        "y_test_df = [[word, i] for i, sentence in enumerate(y_test) for word in sentence]\n",
        "y_test_df = pd.DataFrame(y_test_df, columns = ['tag','sentence'])\n",
        "display(y_test_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "P9BQap5IsDV9",
        "outputId": "cd8a9517-8962-4dac-d533-8f88ff55c4df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<th style=\"text-align:left\"><td style=\"vertical-align:top\"><h4 style=\"text-align: left;\"></h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pierre</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Vinken</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>,</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>61</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>years</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table style=\"display:inline\"></td></th>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<th style=\"text-align:left\"><td style=\"vertical-align:top\"><h4 style=\"text-align: left;\"></h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tag</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DT</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NNP</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NN</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>VBD</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>JJ</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table style=\"display:inline\"></td></th>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<th style=\"text-align:left\"><td style=\"vertical-align:top\"><h4 style=\"text-align: left;\"></h2><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tag</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NNP</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NNP</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NNP</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>,</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NNP</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table style=\"display:inline\"></td></th>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = len(set([word.lower() for sentence in X for word in sentence]))\n",
        "num_tags = len(set([word.lower() for sentence in y for word in sentence]))\n",
        "num_tags_train = len(set([word.lower() for word in y_train_df.tag]))\n",
        "num_tags_test = len(set([word.lower() for word in y_test_df.tag]))\n",
        "num_tags_val = len(set([word.lower() for word in y_val_df.tag]))\n"
      ],
      "metadata": {
        "id": "Yj2Hhs0ASA7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total number of tagged sentences: {}\".format(len(X)))\n",
        "print(\"Vocabulary size: {}\".format(num_words))\n",
        "print(\"Total number of tags Complete: {}\".format(num_tags))\n",
        "print(\"Total number of tags Train: {}\".format(num_tags_train))\n",
        "print(\"Total number of tags Test: {}\".format(num_tags_test))\n",
        "print(\"Total number of tags Val: {}\".format(num_tags_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBov1EyfSUp1",
        "outputId": "9ed3d0ed-d58d-4c01-d615-39718b1b0c89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of tagged sentences: 3914\n",
            "Vocabulary size: 11387\n",
            "Total number of tags Complete: 46\n",
            "Total number of tags Train: 46\n",
            "Total number of tags Test: 41\n",
            "Total number of tags Val: 45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's look at first data point\n",
        "# this is one data point that will be fed to the RNN\n",
        "print('sample X: ', X[0], '\\n')\n",
        "print('sample Y: ', y[0], '\\n')\n",
        "print('sample X train: ', X_train[0], '\\n')\n",
        "print('sample Y train: ', y_train[0], '\\n')\n",
        "print('sample X val: ', X_val[0], '\\n')\n",
        "print('sample Y val: ', y_val[0], '\\n')\n",
        "print('sample X test: ', X_test[0], '\\n')\n",
        "print('sample Y test: ', y_test[0], '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xka6G7ROSXs8",
        "outputId": "475e18ac-b2fd-4817-b553-e39e14bb8ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample X:  ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.'] \n",
            "\n",
            "sample Y:  ['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'CD', '.'] \n",
            "\n",
            "sample X train:  ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.'] \n",
            "\n",
            "sample Y train:  ['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'CD', '.'] \n",
            "\n",
            "sample X val:  ['A', 'House-Senate', 'conference', 'approved', 'major', 'portions', 'of', 'a', 'package', 'for', 'more', 'than', '$', '500', 'million', '*U*', 'in', 'economic', 'aid', 'for', 'Poland', 'that', '*T*-1', 'relies', 'heavily', 'on', '$', '240', 'million', '*U*', 'in', 'credit', 'and', 'loan', 'guarantees', 'in', 'fiscal', '1990', 'in', 'hopes', 'of', '*', 'stimulating', 'future', 'trade', 'and', 'investment', '.'] \n",
            "\n",
            "sample Y val:  ['DT', 'NNP', 'NN', 'VBD', 'JJ', 'NNS', 'IN', 'DT', 'NN', 'IN', 'JJR', 'IN', '$', 'CD', 'CD', '-NONE-', 'IN', 'JJ', 'NN', 'IN', 'NNP', 'WDT', '-NONE-', 'VBZ', 'RB', 'IN', '$', 'CD', 'CD', '-NONE-', 'IN', 'NN', 'CC', 'NN', 'NNS', 'IN', 'JJ', 'CD', 'IN', 'NNS', 'IN', '-NONE-', 'VBG', 'JJ', 'NN', 'CC', 'NN', '.'] \n",
            "\n",
            "sample X test:  ['Intelogic', 'Trace', 'Inc.', ',', 'San', 'Antonio', ',', 'Texas', ',', 'said', '0', 'it', 'bought', '2.7', 'million', 'shares', '*RNR*-1', ',', 'or', 'about', '18', '%', '*RNR*-1', ',', 'of', 'its', 'common', 'stock', 'from', 'an', 'unaffiliated', 'shareholder', 'for', '$', '3.625', '*U*', 'a', 'share', ',', 'or', '$', '9.9', 'million', '*U*', '.'] \n",
            "\n",
            "sample Y test:  ['NNP', 'NNP', 'NNP', ',', 'NNP', 'NNP', ',', 'NNP', ',', 'VBD', '-NONE-', 'PRP', 'VBD', 'CD', 'CD', 'NNS', '-NONE-', ',', 'CC', 'IN', 'CD', 'NN', '-NONE-', ',', 'IN', 'PRP$', 'JJ', 'NN', 'IN', 'DT', 'JJ', 'NN', 'IN', '$', 'CD', '-NONE-', 'DT', 'NN', ',', 'CC', '$', 'CD', 'CD', '-NONE-', '.'] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Vectorize X and y\n",
        "word_tokenizer = Tokenizer()\n",
        "word_tokenizer.fit_on_texts(X)\n",
        "X_encoded = word_tokenizer.texts_to_sequences(X)\n",
        "X_train_encoded = word_tokenizer.texts_to_sequences(X_train)\n",
        "X_val_encoded = word_tokenizer.texts_to_sequences(X_val)\n",
        "X_test_encoded = word_tokenizer.texts_to_sequences(X_test)"
      ],
      "metadata": {
        "id": "BP8yz9CxSbCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract tags not present in test and val\\n\",\n",
        "y_lab = [tag for sentence in y_train for tag in sentence]\n",
        "y_t_lab  = list(set(y_lab))\n",
        "y_lab = [tag for sentence in y_val for tag in sentence]\n",
        "y_v_lab  =list(set(y_lab))\n",
        "y_lab = [tag for sentence in y_test for tag in sentence]\n",
        "y_te_lab  =list(set(y_lab))\n",
        "ignore = [tags for tags in y_t_lab if tags not in y_v_lab or tags not in y_te_lab]"
      ],
      "metadata": {
        "id": "ASdKaEjYWQ2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag_tokenizer = Tokenizer()\n",
        "tag_tokenizer.fit_on_texts(y)\n",
        "y_encoded = tag_tokenizer.texts_to_sequences(y)\n",
        "y_train_encoded = tag_tokenizer.texts_to_sequences(y_train)\n",
        "y_val_encoded = tag_tokenizer.texts_to_sequences(y_val)\n",
        "y_test_encoded = tag_tokenizer.texts_to_sequences(y_test)\n",
        "ignore_encoded = tag_tokenizer.texts_to_sequences(ignore)\n",
        "ignore_encoded = [tag for sentence in ignore_encoded for tag in sentence]"
      ],
      "metadata": {
        "id": "QIq0-cFVZE8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# look at first encoded data point\n",
        "\n",
        "print(\"** Complete **\", \"\\n\", \"-\"*100, \"\\n\")\n",
        "print(\"** Raw data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
        "print('X: ', X[0], '\\n')\n",
        "print('Y: ', y[0], '\\n')\n",
        "print()\n",
        "print(\"** Encoded data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
        "print('X: ', X_encoded[0], '\\n')\n",
        "print('Y: ', y_encoded[0], '\\n')\n",
        "\n",
        "print(\"** Train **\", \"\\n\", \"-\"*100, \"\\n\")\n",
        "print(\"** Raw data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
        "print('X: ', X_train[0], '\\n')\n",
        "print('Y: ', y_train[0], '\\n')\n",
        "print()\n",
        "print(\"** Encoded data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
        "print('X: ', X_train_encoded[0], '\\n')\n",
        "print('Y: ', y_train_encoded[0], '\\n')\n",
        "\n",
        "print(\"** Validation **\", \"\\n\", \"-\"*100, \"\\n\")\n",
        "print(\"** Raw data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
        "print('X: ', X_val[0], '\\n')\n",
        "print('Y: ', y_val[0], '\\n')\n",
        "print()\n",
        "print(\"** Encoded data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
        "print('X: ', X_val_encoded[0], '\\n')\n",
        "print('Y: ', y_val_encoded[0], '\\n')\n",
        "\n",
        "print(\"** Test **\", \"\\n\", \"-\"*100, \"\\n\")\n",
        "print(\"** Raw data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
        "print('X: ', X_test[0], '\\n')\n",
        "print('Y: ', y_test[0], '\\n')\n",
        "print()\n",
        "print(\"** Encoded data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
        "print('X: ', X_test_encoded[0], '\\n')\n",
        "print('Y: ', y_test_encoded[0], '\\n')\n",
        "\n",
        "print(\"** Ignore **\", \"\\n\", \"-\"*100, \"\\n\")\n",
        "print(\"** Raw data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
        "print('X: ', ignore, '\\n')\n",
        "print()\n",
        "print(\"** Encoded data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
        "print('X: ', ignore_encoded, '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8SfxzrJZbmV",
        "outputId": "cd67ae42-2039-4d02-f7da-1062c9f6b4c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "** Complete ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "** Raw data point ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "X:  ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.'] \n",
            "\n",
            "Y:  ['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'CD', '.'] \n",
            "\n",
            "\n",
            "** Encoded data point ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "X:  [5601, 3746, 1, 2024, 86, 331, 1, 46, 2405, 2, 131, 27, 6, 2025, 332, 459, 2026, 3] \n",
            "\n",
            "Y:  [3, 3, 8, 10, 6, 7, 8, 21, 13, 4, 1, 2, 4, 7, 1, 3, 10, 9] \n",
            "\n",
            "** Train ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "** Raw data point ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "X:  ['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.'] \n",
            "\n",
            "Y:  ['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'CD', '.'] \n",
            "\n",
            "\n",
            "** Encoded data point ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "X:  [5601, 3746, 1, 2024, 86, 331, 1, 46, 2405, 2, 131, 27, 6, 2025, 332, 459, 2026, 3] \n",
            "\n",
            "Y:  [3, 3, 8, 10, 6, 7, 8, 21, 13, 4, 1, 2, 4, 7, 1, 3, 10, 9] \n",
            "\n",
            "** Validation ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "** Raw data point ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "X:  ['A', 'House-Senate', 'conference', 'approved', 'major', 'portions', 'of', 'a', 'package', 'for', 'more', 'than', '$', '500', 'million', '*U*', 'in', 'economic', 'aid', 'for', 'Poland', 'that', '*T*-1', 'relies', 'heavily', 'on', '$', '240', 'million', '*U*', 'in', 'credit', 'and', 'loan', 'guarantees', 'in', 'fiscal', '1990', 'in', 'hopes', 'of', '*', 'stimulating', 'future', 'trade', 'and', 'investment', '.'] \n",
            "\n",
            "Y:  ['DT', 'NNP', 'NN', 'VBD', 'JJ', 'NNS', 'IN', 'DT', 'NN', 'IN', 'JJR', 'IN', '$', 'CD', 'CD', '-NONE-', 'IN', 'JJ', 'NN', 'IN', 'NNP', 'WDT', '-NONE-', 'VBZ', 'RB', 'IN', '$', 'CD', 'CD', '-NONE-', 'IN', 'NN', 'CC', 'NN', 'NNS', 'IN', 'JJ', 'CD', 'IN', 'NNS', 'IN', '-NONE-', 'VBG', 'JJ', 'NN', 'CC', 'NN', '.'] \n",
            "\n",
            "\n",
            "** Encoded data point ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "X:  [6, 5083, 847, 440, 223, 5084, 4, 6, 714, 13, 57, 61, 17, 281, 30, 16, 7, 218, 838, 13, 1194, 14, 15, 5085, 1564, 23, 17, 5086, 30, 16, 7, 464, 8, 506, 2356, 7, 258, 242, 7, 1073, 4, 11, 5087, 416, 155, 8, 158, 3] \n",
            "\n",
            "Y:  [4, 3, 1, 11, 7, 6, 2, 4, 1, 2, 29, 2, 24, 10, 10, 5, 2, 7, 1, 2, 3, 28, 5, 17, 12, 2, 24, 10, 10, 5, 2, 1, 14, 1, 6, 2, 7, 10, 2, 6, 2, 5, 19, 7, 1, 14, 1, 9] \n",
            "\n",
            "** Test ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "** Raw data point ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "X:  ['Intelogic', 'Trace', 'Inc.', ',', 'San', 'Antonio', ',', 'Texas', ',', 'said', '0', 'it', 'bought', '2.7', 'million', 'shares', '*RNR*-1', ',', 'or', 'about', '18', '%', '*RNR*-1', ',', 'of', 'its', 'common', 'stock', 'from', 'an', 'unaffiliated', 'shareholder', 'for', '$', '3.625', '*U*', 'a', 'share', ',', 'or', '$', '9.9', 'million', '*U*', '.'] \n",
            "\n",
            "Y:  ['NNP', 'NNP', 'NNP', ',', 'NNP', 'NNP', ',', 'NNP', ',', 'VBD', '-NONE-', 'PRP', 'VBD', 'CD', 'CD', 'NNS', '-NONE-', ',', 'CC', 'IN', 'CD', 'NN', '-NONE-', ',', 'IN', 'PRP$', 'JJ', 'NN', 'IN', 'DT', 'JJ', 'NN', 'IN', '$', 'CD', '-NONE-', 'DT', 'NN', ',', 'CC', '$', 'CD', 'CD', '-NONE-', '.'] \n",
            "\n",
            "\n",
            "** Encoded data point ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "X:  [2394, 10527, 102, 1, 634, 3267, 1, 694, 1, 21, 10, 22, 1171, 3631, 30, 89, 318, 1, 45, 55, 642, 24, 318, 1, 4, 37, 168, 62, 29, 39, 10528, 1009, 13, 17, 10529, 16, 6, 83, 1, 45, 17, 3403, 30, 16, 3] \n",
            "\n",
            "Y:  [3, 3, 3, 8, 3, 3, 8, 3, 8, 11, 5, 18, 11, 10, 10, 6, 5, 8, 14, 2, 10, 1, 5, 8, 2, 23, 7, 1, 2, 4, 7, 1, 2, 24, 10, 5, 4, 1, 8, 14, 24, 10, 10, 5, 9] \n",
            "\n",
            "** Ignore ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "** Raw data point ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "X:  ['#', 'SYM', 'FW', 'LS', 'UH'] \n",
            "\n",
            "\n",
            "** Encoded data point ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "X:  [46, 44, 43, 45] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check lengths\n",
        "\n",
        "different_length = [1 if len(input) != len(output) else 0 for input, output in zip(X_encoded,y_encoded)]\n",
        "print(\"{} sentences have disparate input-output lengths.\".format(sum(different_length)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "Cqqa3M83Zf_P",
        "outputId": "c280f222-2a26-4bdb-e84e-5c7034765cf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-45-385c2428b7d5>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    print(\"{} sentences have disparate input-output lengths.\".format(sum(different_length))\u001b[0m\n\u001b[0m                                                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.2 Pad sequences"
      ],
      "metadata": {
        "id": "LKj4ZnqjZ5dT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lengths = [len(seq) for seq in X]\n",
        "print(\"Length of longest sentence: {}\".format(max(lengths)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uk0CyQMmZ3py",
        "outputId": "5cd358af-0187-4bf3-b442-8f7bc374b76d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of longest sentence: 271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(lengths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "Y6_i7suvaETG",
        "outputId": "7fd9dc29-21cf-4f2a-f187-048c5f88f8d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5c95ad48e0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.lib.pretty import MAX_SEQ_LENGTH\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "#Pad each sequence to max_seq_length using keras\n",
        "#sentences longer than max_seq truncated\n",
        "#sentences shorter padded with zeroes\n",
        "\n",
        "# Truncation and padding can either be 'pre' or 'post'. \n",
        "# For padding we are using 'pre' padding type, that is, add zeroes on the left side.\n",
        "# For truncation, we are using 'post', that is, truncate a sentence from right side.\n",
        "\n",
        "MAX_SEQ_LENGTH = max(lengths)\n",
        "\n",
        "X_padded = pad_sequences(X_encoded, maxlen = MAX_SEQ_LENGTH, padding = 'pre', truncating='post')\n",
        "y_padded = pad_sequences(y_encoded, maxlen = MAX_SEQ_LENGTH, padding = 'pre', truncating='post')\n",
        "\n",
        "X_train_padded = pad_sequences(X_train_encoded, maxlen = MAX_SEQ_LENGTH, padding = 'pre', truncating='post')\n",
        "y_train_padded = pad_sequences(y_train_encoded, maxlen = MAX_SEQ_LENGTH, padding = 'pre', truncating='post')\n",
        "\n",
        "X_val_padded = pad_sequences(X_val_encoded, maxlen = MAX_SEQ_LENGTH, padding = 'pre', truncating='post')\n",
        "y_val_padded = pad_sequences(y_val_encoded, maxlen = MAX_SEQ_LENGTH, padding = 'pre', truncating='post')\n",
        "\n",
        "X_test_padded = pad_sequences(X_test_encoded, maxlen = MAX_SEQ_LENGTH, padding = 'pre', truncating='post')\n",
        "y_test_padded = pad_sequences(y_test_encoded, maxlen = MAX_SEQ_LENGTH, padding = 'pre', truncating='post')"
      ],
      "metadata": {
        "id": "U0zQayp7aIoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the first sequence\n",
        "print(X_padded[0], \"\\n\")\n",
        "print(y_padded[0], \"\\n\")\n",
        "\n",
        "# print the first sequence train\n",
        "print(X_train_padded[0], \"\\n\")\n",
        "print(y_train_padded[0], \"\\n\")\n",
        "\n",
        "# print the first sequence val\n",
        "print(X_val_padded[0], \"\\n\")\n",
        "print(y_val_padded[0], \"\\n\")\n",
        "\n",
        "# print the first sequence test\n",
        "print(X_test_padded[0], \"\\n\")\n",
        "print(y_test_padded[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTFuBmFZa2Q9",
        "outputId": "0e922c18-aab1-403a-c004-bd865c19f065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0 5601 3746    1 2024   86  331    1   46 2405    2  131   27    6\n",
            " 2025  332  459 2026    3] \n",
            "\n",
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  3  3  8 10  6  7  8 21 13  4  1\n",
            "  2  4  7  1  3 10  9] \n",
            "\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0 5601 3746    1 2024   86  331    1   46 2405    2  131   27    6\n",
            " 2025  332  459 2026    3] \n",
            "\n",
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  3  3  8 10  6  7  8 21 13  4  1\n",
            "  2  4  7  1  3 10  9] \n",
            "\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    6\n",
            " 5083  847  440  223 5084    4    6  714   13   57   61   17  281   30\n",
            "   16    7  218  838   13 1194   14   15 5085 1564   23   17 5086   30\n",
            "   16    7  464    8  506 2356    7  258  242    7 1073    4   11 5087\n",
            "  416  155    8  158    3] \n",
            "\n",
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  4  3  1 11  7  6  2  4  1  2 29  2 24 10 10  5  2\n",
            "  7  1  2  3 28  5 17 12  2 24 10 10  5  2  1 14  1  6  2  7 10  2  6  2\n",
            "  5 19  7  1 14  1  9] \n",
            "\n",
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0  2394 10527\n",
            "   102     1   634  3267     1   694     1    21    10    22  1171  3631\n",
            "    30    89   318     1    45    55   642    24   318     1     4    37\n",
            "   168    62    29    39 10528  1009    13    17 10529    16     6    83\n",
            "     1    45    17  3403    30    16     3] \n",
            "\n",
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  3  3  3  8  3  3  8  3  8 11  5 18 11 10\n",
            " 10  6  5  8 14  2 10  1  5  8  2 23  7  1  2  4  7  1  2 24 10  5  4  1\n",
            "  8 14 24 10 10  5  9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = X_padded, y_padded\n",
        "X_train, y_train = X_train_padded, y_train_padded\n",
        "X_val, y_val = X_val_padded, y_val_padded\n",
        "X_test, y_test = X_test_padded, y_test_padded"
      ],
      "metadata": {
        "id": "3h--IUavevkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2 Word Embeddings\n",
        "\n",
        "Invece di creare il vocabolario con glove ed aggiungerci le oov del dataset, tratto glove come oov aggiungendolo al vocabolario delle parole del dataset\n"
      ],
      "metadata": {
        "id": "pMbL8JonbdVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Download the GloVe embeddings file\n",
        "url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
        "urllib.request.urlretrieve(url, 'glove.6B.zip', show_progress)\n",
        "\n",
        "# Extract the zip file\n",
        "zip_ref = zipfile.ZipFile('glove.6B.zip', 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "ow-mut5oFAPu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dea04439-1a53-4dd8-a7ea-2548cd05d656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100% (862182613 of 862182613) |##########| Elapsed Time: 0:02:39 Time:  0:02:39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use the 300 dimensional GLove Word Embeddings\n",
        "glove_dir = './'\n",
        "embedding_dim = 300\n",
        "vocab_size = len(word_tokenizer.word_index) + 1\n",
        "embedding_dict = {} #initialize dictionary\n",
        "f = open(os.path.join(glove_dir, f'glove.6B.{embedding_dim}d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embedding_dict[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embedding_dict))\n",
        "print('Vocab of size %s' % len(embedding_dict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUtEzF4EbJ2_",
        "outputId": "c1e69cf0-07de-40fe-92e2-87c86d12ee19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n",
            "Vocab of size 400000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_weights = np.zeros((vocab_size,embedding_dim))\n",
        "word2ind = word_tokenizer.word_index\n",
        "for word, index in word2ind.items():\n",
        "  try:\n",
        "    embedding_weights[index, :] = embedding_dict[word]\n",
        "  except KeyError:\n",
        "    pass"
      ],
      "metadata": {
        "id": "griJq6Nvbyqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Embeddings shape: {}\".format(embedding_weights.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uQBdBWFcnUj",
        "outputId": "f2efd586-024b-4007-87b9-8f29a95a79fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings shape: (11388, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "embedding_weights[word_tokenizer.word_index['bottom']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfnhp0Sgcssv",
        "outputId": "74179470-ccb1-47b1-8e38-7a6e3cc526ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.61680001e-01,  5.45570016e-01, -4.21449989e-01, -1.32129997e-01,\n",
              "        1.43869996e-01,  3.33620012e-01, -1.68740004e-01, -1.52049996e-02,\n",
              "        5.05720019e-01, -1.14370000e+00, -1.26359999e-01, -5.18639982e-02,\n",
              "       -6.50840029e-02,  3.54719982e-02, -3.45279992e-01,  2.09189996e-01,\n",
              "       -3.05170000e-01,  3.27719986e-01,  3.66230011e-01, -3.96120012e-01,\n",
              "       -2.18559995e-01,  2.79549986e-01,  1.25749996e-02, -7.39459991e-02,\n",
              "       -1.07630000e-01, -2.38110006e-01,  3.42689991e-01,  4.51849997e-01,\n",
              "        2.59860000e-03,  1.32290006e-01,  1.43790007e-01,  1.45569995e-01,\n",
              "        4.76429984e-02, -3.54240000e-01, -1.14040005e+00,  4.29199994e-01,\n",
              "        3.10660005e-01, -1.34020001e-01,  7.56710023e-02,  4.42640007e-01,\n",
              "        1.20920002e-01,  1.78749993e-01,  4.56500016e-02,  4.57439989e-01,\n",
              "       -1.56560004e-01,  1.85450003e-01,  2.26889998e-01, -1.55049995e-01,\n",
              "       -3.61490011e-01,  6.20420016e-02, -1.18060000e-01,  8.91269967e-02,\n",
              "        1.61850005e-01, -5.08050025e-01, -8.31329972e-02,  8.45359988e-04,\n",
              "        7.96469972e-02, -6.56159997e-01, -3.30810010e-01,  5.38940012e-01,\n",
              "        5.32880008e-01, -5.50949991e-01,  5.87149978e-01,  2.67309994e-01,\n",
              "       -1.70540009e-02, -5.17750025e-01,  1.68479994e-01, -2.92220004e-02,\n",
              "       -1.06600001e-01, -1.69200003e-01,  2.65480012e-01,  1.40040005e-02,\n",
              "       -2.49760002e-01,  1.01779997e-01, -2.46720001e-01,  2.48899996e-01,\n",
              "        1.67160004e-01,  4.15300012e-01, -2.26620004e-01, -4.75939989e-01,\n",
              "       -2.99849987e-01, -1.59949996e-02, -1.99100003e-01, -1.45229995e-01,\n",
              "       -8.31070021e-02,  3.01249996e-02,  5.65240011e-02, -3.67989987e-02,\n",
              "       -4.93739992e-01, -1.04610004e-01,  5.60890019e-01,  4.12849993e-01,\n",
              "       -2.14340001e-01, -4.22930002e-01, -1.48880005e-01,  2.93729991e-01,\n",
              "       -3.49029988e-01,  3.23179990e-01,  1.76789999e-01, -5.22520006e-01,\n",
              "       -1.11170001e-01,  1.00060001e-01,  8.34140033e-02, -5.89079976e-01,\n",
              "       -2.29409993e-01,  1.89119995e-01,  5.09370029e-01, -4.50320005e-01,\n",
              "        3.90309989e-01,  4.00549993e-02,  1.53160006e-01, -6.80130005e-01,\n",
              "        3.10319990e-01, -6.80559993e-01, -2.35489994e-01,  1.43250003e-01,\n",
              "       -9.75700021e-02, -2.87230015e-01,  5.67409992e-02, -2.63069987e-01,\n",
              "       -3.61279994e-01, -8.91070008e-01,  9.39819992e-01,  2.93650001e-01,\n",
              "       -9.83619988e-02, -3.85479987e-01, -1.02339998e-01, -2.62450010e-01,\n",
              "        1.61540002e-01, -2.34740004e-02,  7.73520023e-02,  1.24440002e+00,\n",
              "        4.80590016e-02,  7.71679997e-01, -6.17169999e-02, -1.08690001e-01,\n",
              "       -4.13910002e-01,  6.88099980e-01, -3.40030015e-01,  2.93309987e-01,\n",
              "        1.48330003e-01,  1.15700001e-02, -1.61009997e-01, -7.67840028e-01,\n",
              "       -3.87490004e-01, -1.40509993e-01, -2.93520000e-02,  2.57669985e-01,\n",
              "        2.49720007e-01,  1.61459997e-01,  1.36540001e-02,  1.99650005e-01,\n",
              "       -2.16330007e-01, -7.33500004e-01,  5.43879986e-01,  2.86119998e-01,\n",
              "        1.13760002e-01, -2.10789993e-01, -3.33440006e-01,  6.35519981e-01,\n",
              "       -2.40119994e-01, -1.79859996e-01, -2.08079994e-01, -3.05429995e-01,\n",
              "        3.68620008e-01, -2.33390003e-01,  1.96319997e-01,  6.07549995e-02,\n",
              "       -6.62169978e-02, -6.61659986e-03, -3.70359987e-01, -1.82270005e-01,\n",
              "        1.03040002e-01, -6.68959975e-01, -2.84729991e-02,  3.27639997e-01,\n",
              "       -4.65209991e-01,  4.01300013e-01, -5.09140015e-01,  1.56369999e-01,\n",
              "        3.61330003e-01,  4.25900012e-01,  5.51289976e-01, -2.52270013e-01,\n",
              "        2.30739996e-01, -5.18639982e-01,  5.27740002e-01,  1.87999997e-02,\n",
              "        2.55479991e-01,  5.25409997e-01,  4.08609986e-01,  8.29200029e-01,\n",
              "        4.34920013e-01,  1.84379995e-01,  3.04259986e-01,  2.81899989e-01,\n",
              "       -1.65140003e-01, -2.61460006e-01, -3.20259988e-01,  1.41589999e-01,\n",
              "        1.25039995e+00,  5.19590005e-02,  3.91790003e-01, -1.87909994e-02,\n",
              "        8.63199979e-02, -1.76080003e-01,  2.67910004e-01, -6.94429994e-01,\n",
              "       -3.32419991e-01, -3.21289986e-01, -7.97379985e-02, -1.17559999e-01,\n",
              "       -2.50970006e-01,  2.53919989e-01,  4.78940010e-01,  1.85870007e-01,\n",
              "        1.38899997e-01, -7.33459964e-02,  1.05130002e-01, -5.77500015e-02,\n",
              "       -5.07510006e-02,  5.03650010e-01, -2.00240001e-01, -1.79309994e-01,\n",
              "        7.69670010e-02, -1.83280006e-01, -2.12960005e-01,  6.29929975e-02,\n",
              "        1.18759997e-01,  9.28530023e-02, -2.92869985e-01,  1.26760006e-01,\n",
              "        3.25139984e-02,  4.55400012e-02,  3.63720000e-01, -2.95749992e-01,\n",
              "       -5.25440015e-02, -1.28360000e-02,  3.66730005e-01,  2.03860000e-01,\n",
              "        1.13040000e-01, -1.75060004e-01,  4.67860013e-01,  3.92739996e-02,\n",
              "       -7.84030020e-01, -3.32819998e-01,  6.49089992e-01,  2.35440001e-01,\n",
              "        8.69899988e-03,  3.67910005e-02, -2.65749991e-01,  9.34230015e-02,\n",
              "        1.05040002e+00,  6.04109988e-02,  1.34599999e-01,  2.47350007e-01,\n",
              "        2.18740001e-01, -2.91509996e-03, -4.93250012e-01,  2.43890002e-01,\n",
              "       -4.29199994e-01, -1.57509997e-01, -2.71849990e-01,  2.10989997e-01,\n",
              "        1.84130005e-03, -3.84850018e-02, -2.28520006e-01, -1.12800002e-01,\n",
              "        1.85929999e-01,  3.50019991e-01,  1.26289994e-01, -1.22259997e-01,\n",
              "       -1.09200001e-01,  6.74279988e-01,  1.26509994e-01,  7.64119998e-02,\n",
              "       -8.45350027e-01, -3.59090000e-01,  3.55219990e-02, -1.47430003e-01,\n",
              "       -5.91440022e-01,  7.46330023e-01, -8.68070006e-01, -2.22749993e-01,\n",
              "       -3.72999996e-01,  1.41530000e-02,  3.06270003e-01, -5.82669973e-01,\n",
              "        5.71879983e-01,  6.82689995e-02, -2.97349989e-01,  8.05289969e-02,\n",
              "       -4.84310001e-01,  1.95079997e-01,  9.85379964e-02, -9.01070016e-04,\n",
              "        5.09190023e-01, -2.49160007e-01,  1.14840001e-01, -1.69560000e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(y)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test,47)\n",
        "y_val = to_categorical(y_val,47)"
      ],
      "metadata": {
        "id": "3FZb8xi8czVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.shape)\n",
        "print(y_train.shape)\n",
        "print(y_val.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxOXhTV6c42d",
        "outputId": "5a2b0224-7279-4ccf-ddbd-27bd8310a6e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3914, 271, 47)\n",
            "(1963, 271, 47)\n",
            "(1299, 271, 47)\n",
            "(652, 271, 47)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25)"
      ],
      "metadata": {
        "id": "-ebuQ2tkdpTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train,X_val,y_train,y_val = train_test_split(X_train,y_train,test_size=0.25)"
      ],
      "metadata": {
        "id": "AqzGIECXfxX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print number of samples in each set\n",
        "print(\"TRAINING DATA\")\n",
        "print('Shape of input sequences: {}'.format(X_train.shape))\n",
        "print('Shape of output sequences: {}'.format(y_train.shape))\n",
        "print(\"-\"*50)\n",
        "print(\"VALIDATION DATA\")\n",
        "print('Shape of input sequences: {}'.format(X_val.shape))\n",
        "print('Shape of output sequences: {}'.format(y_val.shape))\n",
        "print(\"-\"*50)\n",
        "print(\"TESTING DATA\")\n",
        "print('Shape of input sequences: {}'.format(X_test.shape))\n",
        "print('Shape of output sequences: {}'.format(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYWQ8gpOf4u_",
        "outputId": "98746f86-1294-4a20-a83d-f7d740cd6f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINING DATA\n",
            "Shape of input sequences: (1963, 271)\n",
            "Shape of output sequences: (1963, 271, 47)\n",
            "--------------------------------------------------\n",
            "VALIDATION DATA\n",
            "Shape of input sequences: (1299, 271)\n",
            "Shape of output sequences: (1299, 271, 47)\n",
            "--------------------------------------------------\n",
            "TESTING DATA\n",
            "Shape of input sequences: (652, 271)\n",
            "Shape of output sequences: (652, 271, 47)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ignore_class_accuracy(classes=[0]):\n",
        "    def ignore_accuracy(y_true, y_pred):\n",
        "        y_true_class = K.argmax(y_true, axis=-1)\n",
        "        y_pred_class = K.argmax(y_pred, axis=-1)\n",
        "        \n",
        "        matches = K.cast(K.equal(y_true_class, y_pred_class), 'int32')\n",
        "        for to_ignore in classes:\n",
        "          ignore_mask = K.cast(K.not_equal(y_pred_class, to_ignore), 'int32')\n",
        "          matches = matches * ignore_mask\n",
        "        accuracy = K.sum(matches) / K.maximum(K.sum(ignore_mask), 1)\n",
        "        return accuracy\n",
        "    return ignore_accuracy"
      ],
      "metadata": {
        "id": "dnbUcZsAZNj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "baseline_model = Sequential(name='Baseline')\n",
        "\n",
        "# Add the Embedding layer\n",
        "# baseline_model.add(Embedding(input_dim=vocab_length, output_dim=embedding_dim, \\\n",
        "#                     weights=[embedding_matrix], input_length=MAX_LENGTH, trainable=False))\n",
        "baseline_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, \\\n",
        "                    weights=[embedding_weights], input_length=MAX_SEQ_LENGTH, trainable=True, mask_zero=True))\n",
        "\n",
        "# Add the Bidirectional LSTM layer\n",
        "baseline_model.add(Bidirectional(LSTM(units=256, return_sequences=True)))\n",
        "\n",
        "# Add the Dense/Fully-Connected layer\n",
        "baseline_model.add(TimeDistributed(Dense(units=47, activation='softmax')))\n",
        "\n",
        "# Compile the model\n",
        "baseline_model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy',ignore_class_accuracy([*ignore_encoded])])\n",
        "\n",
        "\n",
        "# Summary\n",
        "baseline_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uik28V6wf6QX",
        "outputId": "0105f3a6-2df8-4dc3-ddec-89c035393be8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Baseline\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 271, 300)          3416400   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 271, 512)         1140736   \n",
            " l)                                                              \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 271, 47)          24111     \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,581,247\n",
            "Trainable params: 4,581,247\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_baseline = baseline_model.fit(X_train, y_train, validation_data=(X_val, y_val),batch_size=128, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLf95LUBgLAS",
        "outputId": "8c77ae8e-eeee-481f-a52b-9f46ad5a3861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 33s 2s/step - loss: 0.2737 - accuracy: 0.2888 - ignore_accuracy: 0.0850 - val_loss: 0.2085 - val_accuracy: 0.4735 - val_ignore_accuracy: 0.0450\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 21s 1s/step - loss: 0.1651 - accuracy: 0.5774 - ignore_accuracy: 0.0552 - val_loss: 0.1207 - val_accuracy: 0.6843 - val_ignore_accuracy: 0.0650\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 21s 1s/step - loss: 0.0933 - accuracy: 0.7597 - ignore_accuracy: 0.0726 - val_loss: 0.0755 - val_accuracy: 0.7973 - val_ignore_accuracy: 0.0757\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 21s 1s/step - loss: 0.0589 - accuracy: 0.8455 - ignore_accuracy: 0.0808 - val_loss: 0.0537 - val_accuracy: 0.8538 - val_ignore_accuracy: 0.0811\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 21s 1s/step - loss: 0.0406 - accuracy: 0.8937 - ignore_accuracy: 0.0855 - val_loss: 0.0420 - val_accuracy: 0.8843 - val_ignore_accuracy: 0.0840\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 21s 1s/step - loss: 0.0297 - accuracy: 0.9235 - ignore_accuracy: 0.0884 - val_loss: 0.0347 - val_accuracy: 0.9033 - val_ignore_accuracy: 0.0858\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.0227 - accuracy: 0.9411 - ignore_accuracy: 0.0899 - val_loss: 0.0304 - val_accuracy: 0.9131 - val_ignore_accuracy: 0.0867\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 21s 1s/step - loss: 0.0181 - accuracy: 0.9533 - ignore_accuracy: 0.0911 - val_loss: 0.0276 - val_accuracy: 0.9176 - val_ignore_accuracy: 0.0872\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 21s 1s/step - loss: 0.0146 - accuracy: 0.9641 - ignore_accuracy: 0.0922 - val_loss: 0.0259 - val_accuracy: 0.9228 - val_ignore_accuracy: 0.0877\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 21s 1s/step - loss: 0.0120 - accuracy: 0.9705 - ignore_accuracy: 0.0927 - val_loss: 0.0243 - val_accuracy: 0.9266 - val_ignore_accuracy: 0.0880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = baseline_model.evaluate(X_test, y_test, return_dict = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDQECzYng7mR",
        "outputId": "41027987-cb72-4384-e254-575da5551a72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 3s 135ms/step - loss: 0.0221 - accuracy: 0.9327 - ignore_accuracy: 0.0888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = baseline_model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BexAaciDiWc0",
        "outputId": "6b0a70c3-c53f-4597-ca98-ce515ffd5137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 5s 130ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the class probabilities into class labels\n",
        "predicted_labels = np.argmax(predictions, axis=-1)\n",
        "\n",
        "true_pos = defaultdict(int)\n",
        "false_pos = defaultdict(int)\n",
        "false_neg = defaultdict(int)\n",
        "precision = defaultdict(float)\n",
        "recall = defaultdict(float)\n",
        "f1score = defaultdict(float)\n",
        "\n",
        "\n",
        "for tag in y_te_lab:\n",
        "  if tag not in ignore:\n",
        "    for idx_sentence in range(len(y_test_encoded)):\n",
        "      for idx_word in range(len(y_test_encoded[idx_sentence])):\n",
        "        if y_test_encoded[idx_sentence][idx_word] == tag_tokenizer.texts_to_sequences(tag):\n",
        "          if predicted_labels[idx_sentence][idx_word] == y_test[idx_sentence][idx_word]:\n",
        "               true_pos[y_test_encoded[idx_sentence][idx_word]] += 1\n",
        "          else:\n",
        "          # If the predicted tag does not match ground truth we increase false negative count for that tag\n",
        "          # and false positive count for the wrongly predicted tag\n",
        "            false_neg[y_test_encoded[idx_sentence][idx_word]] += 1\n",
        "            false_pos[predicted_labels[idx_sentence][idx_word][idx_word]] += 1\n",
        "    # We then compute precision, recall and F1 scores\n",
        "    if true_pos[tag] != 0:\n",
        "      precision[tag] = true_pos[tag] / (true_pos[tag] + false_pos[tag])\n",
        "      recall[tag] = true_pos[tag] / (true_pos[tag] + false_neg[tag])\n",
        "      f1score[tag] = 2 * ((precision[tag] * recall[tag]) / (precision[tag] + recall[tag])) \n",
        "    else:\n",
        "      print(tag)\n",
        "      print(true_pos[tag])\n",
        "      print(false_pos[tag])\n",
        "      print(false_neg[tag])\n",
        "      print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxHfVKsplJ6z",
        "outputId": "4fefff89-03d1-48a6-9649-904db390cdf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDT\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "NN\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "VBP\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "DT\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            ":\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "RBS\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "''\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "CC\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "JJS\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "WRB\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "PRP$\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "``\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "TO\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "JJ\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "WP\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "WP$\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "VBD\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "RBR\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "MD\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "NNS\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "NNP\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "VBZ\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "RB\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "RP\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "POS\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "VBG\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "VB\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "VBN\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            ",\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "-RRB-\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "PRP\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "-LRB-\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "NNPS\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "CD\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "JJR\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "-NONE-\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            ".\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "EX\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "WDT\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "IN\n",
            "0\n",
            "0\n",
            "0\n",
            "\n",
            "$\n",
            "0\n",
            "0\n",
            "0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for tag in y_te_lab:\n",
        "  if tag not in ignore:\n",
        "    print(f'Tag: {tag}')\n",
        "    print(f'\\tPrecision: {precision[tag]}')\n",
        "    print(f'\\tRecall: {recall[tag]}')\n",
        "    print(f'\\tF1-score: {f1score[tag]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoExaLMtlS11",
        "outputId": "97897c0a-7c57-46c5-e136-7b8fe7e649d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tag: PDT\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: NN\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: VBP\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: DT\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: :\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: RBS\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: ''\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: CC\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: JJS\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: WRB\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: PRP$\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: ``\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: TO\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: JJ\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: WP\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: WP$\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: VBD\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: RBR\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: MD\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: NNS\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: NNP\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: VBZ\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: RB\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: RP\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: POS\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: VBG\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: VB\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: VBN\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: ,\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: -RRB-\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: PRP\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: -LRB-\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: NNPS\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: CD\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: JJR\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: -NONE-\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: .\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: EX\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: WDT\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: IN\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n",
            "Tag: $\n",
            "\tPrecision: 0.0\n",
            "\tRecall: 0.0\n",
            "\tF1-score: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "provola = [el[1] for el in f1score.items()]\n",
        "\n",
        "sum = 0\n",
        "\n",
        "for p in provola:\n",
        "  sum += p\n",
        "\n",
        "print(f'MACRO F1-score: {sum / len(f1score.items())}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4RxsfMDlVT2",
        "outputId": "9c8d24c0-b9b1-4d10-9c27-f44e124e37ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MACRO F1-score: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "# Flatten the predictions and the true labels to 1D arrays\n",
        "predictions = predictions.flatten()\n",
        "y_true = y_test.flatten()\n",
        "\n",
        "print(predictions)\n",
        "th = 0.1\n",
        "predictions[predictions >= th] = 1 \n",
        "predictions[predictions  < th] = 0\n",
        "\n",
        "# Compute the F1 score\n",
        "f1_baseline = f1_score(y_true, predictions, average = 'macro')\n",
        "\n",
        "print(\"Macro-F1 score:\", round(f1_baseline,3))\n",
        "\n",
        "baseline_model.save('./baseline_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPJz028UiX7D",
        "outputId": "51f8833e-0d91-4200-9dc0-eeffbe85d232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.0994846e-02 2.1621110e-02 2.1324312e-02 ... 9.4370756e-07 3.6169158e-07\n",
            " 3.3871888e-07]\n",
            "Macro-F1 score: 0.577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GRU\n",
        "\n"
      ],
      "metadata": {
        "id": "dAESB5Muj13B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "gru_model = tensorflow.keras.Sequential(name='GRU')\n",
        "\n",
        "# Add the Embedding layer\n",
        "gru_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, \\\n",
        "                    weights = [embedding_weights], input_length = MAX_SEQ_LENGTH, trainable=True))\n",
        "\n",
        "# Add the GRU layer\n",
        "gru_model.add(GRU(units=128, return_sequences=True))\n",
        "\n",
        "# Add the Dense/Fully-Connected layer\n",
        "gru_model.add(TimeDistributed(Dense(47, activation='softmax')))\n",
        "\n",
        "# Compile the model\n",
        "gru_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy',ignore_class_accuracy([*ignore_encoded])])\n",
        "\n",
        "# Summary\n",
        "gru_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBDrY_fJie5M",
        "outputId": "e5f98cf2-0dfe-493f-ca35-f871840c7019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 271, 300)          3416400   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 271, 128)          165120    \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDis  (None, 271, 47)          6063      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,587,583\n",
            "Trainable params: 3,587,583\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_gru = gru_model.fit(X_train, y_train, epochs=10, verbose = True, validation_data=(X_val,y_val), batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkZTQuBSkEc7",
        "outputId": "a8ab7494-197f-4af1-9d62-14183140b802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 6s 78ms/step - loss: 2.9663 - accuracy: 0.9171 - ignore_accuracy: 0.9173 - val_loss: 0.4003 - val_accuracy: 0.9133 - val_ignore_accuracy: 0.9146\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.3991 - accuracy: 0.9149 - ignore_accuracy: 0.9150 - val_loss: 0.3170 - val_accuracy: 0.9233 - val_ignore_accuracy: 0.9244\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.2861 - accuracy: 0.9294 - ignore_accuracy: 0.9300 - val_loss: 0.2560 - val_accuracy: 0.9409 - val_ignore_accuracy: 0.9419\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.2394 - accuracy: 0.9476 - ignore_accuracy: 0.9478 - val_loss: 0.2238 - val_accuracy: 0.9534 - val_ignore_accuracy: 0.9545\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.2063 - accuracy: 0.9565 - ignore_accuracy: 0.9567 - val_loss: 0.1927 - val_accuracy: 0.9601 - val_ignore_accuracy: 0.9610\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.1758 - accuracy: 0.9647 - ignore_accuracy: 0.9647 - val_loss: 0.1655 - val_accuracy: 0.9671 - val_ignore_accuracy: 0.9678\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.1491 - accuracy: 0.9706 - ignore_accuracy: 0.9705 - val_loss: 0.1428 - val_accuracy: 0.9713 - val_ignore_accuracy: 0.9720\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.1267 - accuracy: 0.9755 - ignore_accuracy: 0.9755 - val_loss: 0.1239 - val_accuracy: 0.9750 - val_ignore_accuracy: 0.9755\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.1082 - accuracy: 0.9791 - ignore_accuracy: 0.9790 - val_loss: 0.1085 - val_accuracy: 0.9775 - val_ignore_accuracy: 0.9780\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0927 - accuracy: 0.9820 - ignore_accuracy: 0.9820 - val_loss: 0.0961 - val_accuracy: 0.9799 - val_ignore_accuracy: 0.9804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = gru_model.predict(X_test)\n",
        "# Flatten the predictions and the true labels to 1D arrays\n",
        "predictions = y_pred.flatten()\n",
        "y_true = y_test.flatten()\n",
        "\n",
        "th = 0.1\n",
        "predictions[predictions >= th] = 1 \n",
        "predictions[predictions  < th] = 0\n",
        "\n",
        "# Compute the F1 score\n",
        "f1_gru = f1_score(y_true, predictions, average = 'macro')\n",
        "\n",
        "print(\"Macro-F1 score:\", round(f1_gru,3))\n",
        "\n",
        "gru_model.save('./gru_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iA_ixZKFkJGB",
        "outputId": "05ee597e-e95d-471a-efd5-f3dd166d29d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 0s 6ms/step\n",
            "Macro-F1 score: 0.981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Additional LSTM Layer"
      ],
      "metadata": {
        "id": "FhSgCrzzkTAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "add_lstm_model = tensorflow.keras.Sequential(name='Additional_LSTM')\n",
        "\n",
        "# Add the Embedding layer\n",
        "add_lstm_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, \\\n",
        "                    weights = [embedding_weights], input_length = MAX_SEQ_LENGTH, trainable=True))\n",
        "\n",
        "# Add the Bidirectional LSTM layer\n",
        "add_lstm_model.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
        "\n",
        "# Add another LSTM layer\n",
        "add_lstm_model.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
        "\n",
        "# Add the Dense/Fully-Connected layer\n",
        "add_lstm_model.add(TimeDistributed(Dense(units=47, activation='softmax')))\n",
        "\n",
        "# Compile the model\n",
        "add_lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy',ignore_class_accuracy([*ignore_encoded])])\n",
        "\n",
        "# Summary\n",
        "add_lstm_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSaKyv0qkMoF",
        "outputId": "3ec54978-0b48-4af2-dd46-6fa3b2f30e76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Additional_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 271, 300)          3416400   \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 271, 256)         439296    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 271, 256)         394240    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_3 (TimeDis  (None, 271, 47)          12079     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,262,015\n",
            "Trainable params: 4,262,015\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_add_lstm = add_lstm_model.fit(X_train, y_train, epochs=15, verbose = True, validation_data=(X_val,y_val), batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bje3sTIykdZx",
        "outputId": "63fd11ac-e91a-4e02-a0da-e1e8e809a0bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "16/16 [==============================] - 9s 220ms/step - loss: 1.6599 - accuracy: 0.8856 - ignore_accuracy: 0.8868 - val_loss: 0.3189 - val_accuracy: 0.9145 - val_ignore_accuracy: 0.9159\n",
            "Epoch 2/15\n",
            "16/16 [==============================] - 2s 127ms/step - loss: 0.3013 - accuracy: 0.9157 - ignore_accuracy: 0.9156 - val_loss: 0.2915 - val_accuracy: 0.9175 - val_ignore_accuracy: 0.9187\n",
            "Epoch 3/15\n",
            "16/16 [==============================] - 2s 127ms/step - loss: 0.2875 - accuracy: 0.9199 - ignore_accuracy: 0.9195 - val_loss: 0.2829 - val_accuracy: 0.9214 - val_ignore_accuracy: 0.9227\n",
            "Epoch 4/15\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.2793 - accuracy: 0.9223 - ignore_accuracy: 0.9223 - val_loss: 0.2753 - val_accuracy: 0.9266 - val_ignore_accuracy: 0.9278\n",
            "Epoch 5/15\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.2704 - accuracy: 0.9273 - ignore_accuracy: 0.9275 - val_loss: 0.2648 - val_accuracy: 0.9308 - val_ignore_accuracy: 0.9319\n",
            "Epoch 6/15\n",
            "16/16 [==============================] - 2s 128ms/step - loss: 0.2562 - accuracy: 0.9334 - ignore_accuracy: 0.9333 - val_loss: 0.2464 - val_accuracy: 0.9374 - val_ignore_accuracy: 0.9386\n",
            "Epoch 7/15\n",
            "16/16 [==============================] - 2s 128ms/step - loss: 0.2317 - accuracy: 0.9433 - ignore_accuracy: 0.9431 - val_loss: 0.2169 - val_accuracy: 0.9474 - val_ignore_accuracy: 0.9486\n",
            "Epoch 8/15\n",
            "16/16 [==============================] - 2s 128ms/step - loss: 0.1984 - accuracy: 0.9511 - ignore_accuracy: 0.9513 - val_loss: 0.1819 - val_accuracy: 0.9541 - val_ignore_accuracy: 0.9553\n",
            "Epoch 9/15\n",
            "16/16 [==============================] - 2s 129ms/step - loss: 0.1628 - accuracy: 0.9585 - ignore_accuracy: 0.9588 - val_loss: 0.1493 - val_accuracy: 0.9611 - val_ignore_accuracy: 0.9620\n",
            "Epoch 10/15\n",
            "16/16 [==============================] - 2s 127ms/step - loss: 0.1319 - accuracy: 0.9673 - ignore_accuracy: 0.9675 - val_loss: 0.1234 - val_accuracy: 0.9687 - val_ignore_accuracy: 0.9695\n",
            "Epoch 11/15\n",
            "16/16 [==============================] - 2s 128ms/step - loss: 0.1067 - accuracy: 0.9744 - ignore_accuracy: 0.9746 - val_loss: 0.1020 - val_accuracy: 0.9749 - val_ignore_accuracy: 0.9756\n",
            "Epoch 12/15\n",
            "16/16 [==============================] - 2s 128ms/step - loss: 0.0859 - accuracy: 0.9807 - ignore_accuracy: 0.9808 - val_loss: 0.0847 - val_accuracy: 0.9800 - val_ignore_accuracy: 0.9807\n",
            "Epoch 13/15\n",
            "16/16 [==============================] - 2s 128ms/step - loss: 0.0689 - accuracy: 0.9861 - ignore_accuracy: 0.9861 - val_loss: 0.0709 - val_accuracy: 0.9844 - val_ignore_accuracy: 0.9850\n",
            "Epoch 14/15\n",
            "16/16 [==============================] - 2s 128ms/step - loss: 0.0556 - accuracy: 0.9894 - ignore_accuracy: 0.9894 - val_loss: 0.0608 - val_accuracy: 0.9863 - val_ignore_accuracy: 0.9867\n",
            "Epoch 15/15\n",
            "16/16 [==============================] - 2s 129ms/step - loss: 0.0453 - accuracy: 0.9913 - ignore_accuracy: 0.9913 - val_loss: 0.0532 - val_accuracy: 0.9878 - val_ignore_accuracy: 0.9882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = add_lstm_model.predict(X_test)\n",
        "# Flatten the predictions and the true labels to 1D arrays\n",
        "predictions = y_pred.flatten()\n",
        "y_true = y_test.flatten()\n",
        "\n",
        "th = 0.1\n",
        "predictions[predictions >= th] = 1 \n",
        "predictions[predictions  < th] = 0\n",
        "\n",
        "# Compute the F1 score\n",
        "f1_add_lstm = f1_score(y_true, predictions, average = 'macro')\n",
        "\n",
        "print(\"Macro-F1 score:\", round(f1_add_lstm,3))\n",
        "\n",
        "add_lstm_model.save('./add_lstm_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUPhfmVBkgTZ",
        "outputId": "ab8db2b3-d2d6-4750-db6b-be70abf5d72d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 2s 25ms/step\n",
            "Macro-F1 score: 0.988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Additional Dense Layer"
      ],
      "metadata": {
        "id": "WZDFRILUklPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "add_fc_model = tensorflow.keras.Sequential(name='Additional_FC')\n",
        "\n",
        "# Add the Embedding layer\n",
        "add_fc_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, \\\n",
        "                    weights = [embedding_weights], input_length = MAX_SEQ_LENGTH, trainable=True))\n",
        "\n",
        "# Add the Bidirectional LSTM layer\n",
        "add_fc_model.add(Bidirectional(LSTM(units=128, return_sequences=True)))\n",
        "\n",
        "# Add another Dense layer\n",
        "add_fc_model.add(TimeDistributed(Dense(units=MAX_SEQ_LENGTH, activation='relu')))\n",
        "\n",
        "# Add the Dense/Fully-Connected layer\n",
        "add_fc_model.add(TimeDistributed(Dense(units=47, activation='softmax')))\n",
        "\n",
        "# Compile the model\n",
        "add_fc_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy',ignore_class_accuracy([*ignore_encoded])])\n",
        "\n",
        "# Summary\n",
        "add_fc_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iTv5limknIY",
        "outputId": "f57bb318-ae1a-425e-9e2f-b765760caf7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Additional_FC\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 271, 300)          3416400   \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirectio  (None, 271, 256)         439296    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_4 (TimeDis  (None, 271, 271)         69647     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_5 (TimeDis  (None, 271, 47)          12784     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,938,127\n",
            "Trainable params: 3,938,127\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_add_fc = add_fc_model.fit(X_train, y_train, epochs=15, verbose = True, validation_data=(X_val,y_val), batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rh0XwDUnk1FB",
        "outputId": "463a75ef-7b6f-4874-b6c5-526b9929a4aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "16/16 [==============================] - 5s 139ms/step - loss: 2.1903 - accuracy: 0.8939 - ignore_accuracy: 0.8948 - val_loss: 0.3033 - val_accuracy: 0.9179 - val_ignore_accuracy: 0.9191\n",
            "Epoch 2/15\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.2889 - accuracy: 0.9286 - ignore_accuracy: 0.9286 - val_loss: 0.2679 - val_accuracy: 0.9308 - val_ignore_accuracy: 0.9319\n",
            "Epoch 3/15\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.2515 - accuracy: 0.9373 - ignore_accuracy: 0.9376 - val_loss: 0.2302 - val_accuracy: 0.9442 - val_ignore_accuracy: 0.9452\n",
            "Epoch 4/15\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.2076 - accuracy: 0.9485 - ignore_accuracy: 0.9488 - val_loss: 0.1835 - val_accuracy: 0.9525 - val_ignore_accuracy: 0.9535\n",
            "Epoch 5/15\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.1616 - accuracy: 0.9572 - ignore_accuracy: 0.9573 - val_loss: 0.1425 - val_accuracy: 0.9621 - val_ignore_accuracy: 0.9628\n",
            "Epoch 6/15\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.1232 - accuracy: 0.9682 - ignore_accuracy: 0.9684 - val_loss: 0.1103 - val_accuracy: 0.9711 - val_ignore_accuracy: 0.9716\n",
            "Epoch 7/15\n",
            "16/16 [==============================] - 1s 78ms/step - loss: 0.0932 - accuracy: 0.9762 - ignore_accuracy: 0.9764 - val_loss: 0.0861 - val_accuracy: 0.9775 - val_ignore_accuracy: 0.9781\n",
            "Epoch 8/15\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0710 - accuracy: 0.9823 - ignore_accuracy: 0.9824 - val_loss: 0.0691 - val_accuracy: 0.9819 - val_ignore_accuracy: 0.9823\n",
            "Epoch 9/15\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0548 - accuracy: 0.9865 - ignore_accuracy: 0.9865 - val_loss: 0.0575 - val_accuracy: 0.9849 - val_ignore_accuracy: 0.9854\n",
            "Epoch 10/15\n",
            "16/16 [==============================] - 1s 81ms/step - loss: 0.0432 - accuracy: 0.9895 - ignore_accuracy: 0.9896 - val_loss: 0.0492 - val_accuracy: 0.9870 - val_ignore_accuracy: 0.9875\n",
            "Epoch 11/15\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0346 - accuracy: 0.9915 - ignore_accuracy: 0.9915 - val_loss: 0.0439 - val_accuracy: 0.9882 - val_ignore_accuracy: 0.9886\n",
            "Epoch 12/15\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0284 - accuracy: 0.9929 - ignore_accuracy: 0.9930 - val_loss: 0.0400 - val_accuracy: 0.9892 - val_ignore_accuracy: 0.9896\n",
            "Epoch 13/15\n",
            "16/16 [==============================] - 1s 79ms/step - loss: 0.0238 - accuracy: 0.9941 - ignore_accuracy: 0.9940 - val_loss: 0.0371 - val_accuracy: 0.9900 - val_ignore_accuracy: 0.9904\n",
            "Epoch 14/15\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0203 - accuracy: 0.9950 - ignore_accuracy: 0.9950 - val_loss: 0.0353 - val_accuracy: 0.9905 - val_ignore_accuracy: 0.9909\n",
            "Epoch 15/15\n",
            "16/16 [==============================] - 1s 80ms/step - loss: 0.0175 - accuracy: 0.9957 - ignore_accuracy: 0.9957 - val_loss: 0.0341 - val_accuracy: 0.9909 - val_ignore_accuracy: 0.9913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = add_fc_model.predict(X_test)\n",
        "# Flatten the predictions and the true labels to 1D arrays\n",
        "predictions = y_pred.flatten()\n",
        "y_true = y_test.flatten()\n",
        "\n",
        "th = 0.1\n",
        "predictions[predictions >= th] = 1 \n",
        "predictions[predictions  < th] = 0\n",
        "\n",
        "# Compute the F1 score\n",
        "f1_add_fc = f1_score(y_true, predictions, average = 'macro')\n",
        "\n",
        "print(\"Macro-F1 score:\", round(f1_add_fc,3))\n",
        "\n",
        "add_fc_model.save('./add_fc_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTvmDNpGk3c5",
        "outputId": "ce7b20d5-c0a5-4934-d6ae-00aac956aa3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 1s 13ms/step\n",
            "Macro-F1 score: 0.992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# # Create a list of epochs (i.e., the x-axis data)\n",
        "epochs = list(range(1, len(results_baseline.history['val_accuracy'])+1))\n",
        "\n",
        "# # Create a Plotly line plot using the epochs and validation accuracy data\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=epochs, y=results_baseline.history['val_accuracy'], name='Baseline - BiLSTM Model', mode='lines+markers'))\n",
        "fig.add_trace(go.Scatter(x=epochs, y=results_gru.history['val_accuracy'], name='GRU Model', mode='lines+markers'))\n",
        "fig.show()\n",
        "\n",
        "# Create a list of epochs (i.e., the x-axis data)\n",
        "epochs = list(range(1, len(results_add_lstm.history['val_accuracy'])+1))\n",
        "\n",
        "fig2 = go.Figure()\n",
        "fig2.add_trace(go.Scatter(x=epochs, y=results_add_lstm.history['val_accuracy'], name='2 BiLSTMs Model', mode='lines+markers'))\n",
        "fig2.add_trace(go.Scatter(x=epochs, y=results_add_fc.history['val_accuracy'], name='2 FCs Model', mode='lines+markers'))\n",
        "fig2.show()\n",
        "\n",
        "max_width = max(len(str(f1_baseline)), len(str(f1_gru)), len(str(f1_add_lstm)), len(str(f1_add_fc)))\n",
        "\n",
        "header_row = f'| F1 Score Baseline {\" \" * (max_width - len(\"F1 Score Baseline\"))} | F1 Score GRU {\" \" * (max_width - len(\"F1 Score GRU\"))} |\\\n",
        " F1 Score Add. BiLSTM {\" \" * (max_width - len(\"F1 Score Add. BiLSTM\"))} | F1 Score Add. Dense {\" \" * (max_width - len(\"F1 Score Add. Dense\"))} |'\n",
        "separator_row = '-' * len(header_row)\n",
        "data_row = f'| {f1_baseline:<{max_width}} | {f1_gru:<{max_width}} | {f1_add_lstm:<{max_width}} | {f1_add_fc:<{max_width}} |'\n",
        "\n",
        "print(header_row)\n",
        "print(separator_row)\n",
        "print(data_row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9h51xR-Dk75q",
        "outputId": "32fb60b5-780a-404f-95f5-ac2e0c27b982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"90be16eb-513a-4805-8177-a43f21314883\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"90be16eb-513a-4805-8177-a43f21314883\")) {                    Plotly.newPlot(                        \"90be16eb-513a-4805-8177-a43f21314883\",                        [{\"mode\":\"lines+markers\",\"name\":\"Baseline - BiLSTM Model\",\"x\":[1,2,3,4,5,6,7,8,9,10],\"y\":[0.46034276485443115,0.6748947501182556,0.795580267906189,0.8513830304145813,0.8836740851402283,0.9012928605079651,0.9114852547645569,0.9188514947891235,0.9234516024589539,0.9267889261245728],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"GRU Model\",\"x\":[1,2,3,4,5,6,7,8,9,10],\"y\":[0.9132741689682007,0.9232563376426697,0.9409111142158508,0.9534441828727722,0.9601453542709351,0.9671220183372498,0.9713432788848877,0.9749793410301208,0.9775075316429138,0.9798624515533447],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('90be16eb-513a-4805-8177-a43f21314883');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"32bd535a-e1ed-4fe5-9c39-feb132d5f314\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"32bd535a-e1ed-4fe5-9c39-feb132d5f314\")) {                    Plotly.newPlot(                        \"32bd535a-e1ed-4fe5-9c39-feb132d5f314\",                        [{\"mode\":\"lines+markers\",\"name\":\"2 BiLSTMs Model\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\"y\":[0.9144814610481262,0.9175039529800415,0.9214496612548828,0.9265912771224976,0.930778443813324,0.9374057054519653,0.9473764896392822,0.9541088938713074,0.9610515236854553,0.9687042832374573,0.9748969674110413,0.9799562096595764,0.9844416379928589,0.9862710237503052,0.9877737164497375],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"2 FCs Model\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\"y\":[0.9178845882415771,0.9307869672775269,0.9441863894462585,0.9524527788162231,0.9620656371116638,0.9710648655891418,0.9775331020355225,0.9818764925003052,0.9849387407302856,0.9870209693908691,0.9882112145423889,0.9891883730888367,0.9900206923484802,0.9905490875244141,0.9909496307373047],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('32bd535a-e1ed-4fe5-9c39-feb132d5f314');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| F1 Score Baseline   | F1 Score GRU        | F1 Score Add. BiLSTM  | F1 Score Add. Dense  |\n",
            "--------------------------------------------------------------------------------------------\n",
            "| 0.5773874728575583 | 0.9809876536929896 | 0.9879542437390483 | 0.9923407445251189 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ol_DnkuhlCwb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}